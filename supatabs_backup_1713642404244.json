{"duplicates":{"1269206":["0385c906-fef7-4eaf-88d2-b67bd7dc211a"],"2891514":["3fbf3026-2b7f-4642-a26d-08a2edf9ff1a"],"4924945":["ef370858-5e6c-4f19-aa04-6a94f8f99f64"],"5796372":["6b5f1826-aa9a-47ee-8001-c95850b008a6"],"7483352":["3fecefa3-add7-495d-a840-6ba4a6bffc9b"],"8474565":["db976253-6afd-40aa-acca-6d9db44c4e1b"],"8934602":["ebd71c1b-5c02-4120-b356-0c9634b7d4a2"],"11006067":["28b7ade5-a20a-4277-b33c-eeee58007b75"],"11967459":["5a33af87-8a82-4c27-b30f-c1f7f41b9861"],"12080536":["de5f0d45-4ef5-4173-90cb-ed5aa9bdadb2"],"18813529":["8183e7d5-1a5b-47d4-b786-917cf7c1ac62"],"19093058":["1a142934-7899-43ce-8f7f-c436f9195477"],"21323214":["064934a5-4895-468a-a356-4bfae5d731ad"],"22745006":["67c544b0-3b41-4858-a74a-e895942a7a56"],"23611130":["2fc64f98-18d2-4ca8-8554-eb1b82ab17ec"],"27703443":["153d6b74-cad0-4d06-8e01-4f116df28e45"],"28456994":["0ac7c2ba-b0ea-4471-8189-695d02bcc2d2"],"37257546":["a9cf9fbd-9b76-4852-9733-010ebb1ca332"],"39743790":["a7ba7be9-1dd1-496c-8b28-33297276759e"],"41694986":["dd82ee09-2b2f-45b7-9934-3793e8026850"],"47784846":["6b314714-7cf7-4c1f-8ec3-3febaaa0e32a"],"49426206":["d8b94bc7-c102-455f-8e46-ef4c9faf940b"],"52861902":["ac0af513-4341-41d8-986f-779060d4d052"],"53192355":["dbf209a0-60b2-4f0a-bc87-5cc66788e127"],"54122432":["ff1007fa-7ad9-49bf-aaa5-c584c08bfcaf"],"55804790":["0211a236-bd04-4ea6-a2ed-041d2bff0033"],"56526916":["13393972-aa6f-4432-986a-4f23907c9b31"],"57818893":["50a9e263-7b46-4ca2-9521-7243cc37e892"],"62300965":["d1eec573-c753-4c4a-88fd-ab0d438b8ab4"],"62755699":["5a3c66d7-2c92-4531-a8bf-3363181c46ce"],"63782213":["1e95bb6e-47a7-48f7-b9b9-370700e6d26e"],"63790474":["2e3fb0d7-0bc5-4f62-bdd5-c782265027ce"],"63852956":["a39bcd95-d06b-442e-9b7e-d2083c7580af"],"67418766":["c00629c5-5209-4ca4-9f56-a7f2519bb6b0"],"70552973":["6babff64-cbdc-445e-b0fc-f7724d0b146d"],"72700574":["12732f08-a17c-427e-ae58-6d55ff2068df"],"72862051":["3d1c8b84-cdce-4d3b-af2d-db2f0c9af295"],"73103392":["1b095f1a-8bd3-4641-92de-076d39c15d62"],"75284259":["46268940-fbeb-45b1-a185-eacf17c268f0"],"76821880":["4f28036d-0355-403f-8744-34ad75ce2410"],"76861193":["5d7bca29-53ac-4644-bd3b-64aeb76c5c53"],"77084981":["871f398d-78f4-45c7-b006-848aff0cb988"],"82496373":["216a973f-127f-47b8-9de3-6db37cd16f2a"],"82893579":["fba88ecd-f0ad-4e44-89af-751bba64b2c5"],"82896566":["424b71b5-253c-4f92-8ba6-602aa0202374"],"83719307":["242dc478-8924-4f33-8b4c-eaf06216bf95"],"85089080":["6c6c59a4-62b0-42b3-9fe0-7a15acd4135c"],"87592410":["7e3014d2-344d-4b77-853a-a27c77cd394c"],"87621810":["68981960-f1d7-4a91-8a45-b131b7a257c2"],"88484885":["0bb67b91-2579-462e-a5ba-3537985b90c6"],"93146111":["02f7c53f-8462-4836-8db0-09d390f7c4b2"],"93682064":["764206bd-ace3-49ec-8eeb-089a8214f270"],"96536694":["35b82e01-4904-4956-b868-0478b14c9eef"],"96795967":["eb84a4a4-55c2-456c-962e-2e3b0803994d"],"98393868":["3a469613-bd89-48a6-b819-15ef1d5ecf8a"],"99184336":["513cf06e-d9ee-437f-bda6-f217e8cb2103"],"99626837":["08d40414-513c-443d-9ecb-33776fea98d1"],"100058334":["3b010ae6-b4d4-4079-bfb8-b951dadbb500"],"100910002":["171258d2-38db-4432-87de-7427093dd3ab"],"103996996":["af5bb978-1467-43c8-9e87-d73ee80e0c6d"],"107572894":["5ed7c339-82c3-472f-afaf-7e91877082c4"],"108508348":["80b2301f-d596-4188-b5b7-ec31c38d2975"],"111888120":["36d0a788-fde6-4c80-93f6-ce92c2fea5ff"],"112473784":["93a5b2cf-f76e-4ed2-b782-e6affa228766"],"114923077":["93584556-bb9d-4ee5-8847-76925fa8e24c"],"120349416":["97c4fa83-04b5-4e2e-a11b-1a1903f37b55"],"120504766":["1b2a9c1a-2434-4b1e-858f-43792d02ff7c"],"122371047":["6fee6f47-d5a1-464a-a899-3e0db4668a6e"],"123243916":["255decb8-0260-4e1a-926b-095d1ff9fb1f"],"127901191":["6642b31a-1640-43e1-bf23-135aab2413d7"],"128145339":["e839b1b2-9b7f-4f75-806f-e0ce96a861a6"],"130605363":["1eb5a845-5ab0-4b8e-8891-983b54885a76"],"132449811":["2fc9d625-5f7e-4723-8137-fdfc267d6e27"],"132942110":["aecb330a-8da2-4034-ad1b-90aa3c6283a3"],"133875575":["6d32735e-2dea-4df5-8c20-5c156de31143"],"134041516":["9ddd8796-2946-4b7a-b891-a59ab333e215"],"135087676":["0bf63945-9788-452f-8cea-fc01a3d9f13c"],"135144060":["f743f225-a18e-4b1c-b957-7cfa09b6bd20"],"135395193":["831ab2f3-59da-4947-a371-2b80cb4f4063"],"138537283":["b83b818b-5166-4505-b2de-0617e3b95782"],"139921905":["d7218778-0827-47c6-9dfc-b2bf728bfc0c"],"140170458":["e0dfabf6-7ea9-4049-b200-728fac40cb9f"],"143752713":["09b0ca6e-c813-42ba-b55c-547709bf8ba8"],"144506352":["0787a81d-aa13-4501-9e3e-2b82071c1d6e"],"144712006":["331da261-dceb-450f-bcfb-aed8df5dc216"],"146996476":["0a4cff00-527a-49d3-84ac-e9106bd5d346"],"147278042":["df497248-e0af-4537-bde2-31e4cf023e4d"],"147707385":["ec58ad06-5be7-47e7-9023-d0a053f03b3e"],"151461913":["bb9b3804-9c5d-409e-9a3e-7c7e0a1c6da3"],"152483568":["30cfae2f-9064-4f4d-ad1a-d23cbd546d0c"],"157053173":["b23c2f48-b21b-4010-8e71-ac710379ca65"],"157130716":["1e1b74d8-5624-4ce1-9b74-1632483b32d8"],"158362017":["9ab99abf-57f3-4836-9dc8-6e60a268fcd4"],"164010873":["fb07fcff-4322-4b4c-90f4-c653e7990efc"],"166894526":["ac0831cb-a479-4f90-9e89-9d3c31b5390d"],"167623112":["38fa38ce-e7d0-4c37-9090-157cc708502d"],"168389151":["31e7cc56-91b5-4368-982c-8e2738284bd6"],"168525574":["b4fe1d9f-bf68-483a-94f6-fca98ee21fec"],"170496099":["acd9ceb8-7d71-49ad-b5fe-14f8b0487431"],"172288317":["4ee76121-d760-4e63-abed-2ca99283f087"],"174543452":["91b0ab53-863b-413d-b411-7d114a0bcf8a"],"177757069":["5ac30751-1514-458a-a027-906dd91485aa"],"181205551":["bfda56f2-e59a-4e65-99ce-c2925b9c6eb1"],"181587509":["0adaa8ef-1607-4e2a-9d79-a802a6acab0e"],"183827198":["c492e52f-0d83-4aff-b21a-cec1c79f4a6b"],"184406291":["32c71d76-5896-4147-8f91-84e644d33c79"],"184474768":["93b5902a-0364-433c-a23b-0d78f32dec41"],"184537102":["2223eab2-9ae2-42c2-a997-ae90ccf34d5e"],"186781070":["b122139b-642f-4894-9d81-7256155b8e47"],"187878778":["5677aaa0-718f-47b5-90a0-b6334f44db47"],"188646138":["44f6e37f-dcf7-48e2-ad38-93c6542e7246"],"192233419":["606d7549-101b-482c-b99f-d9f2e02a242c"],"194378004":["4f5d0205-23c4-4b7f-9f57-6a871e5a93eb"],"194513186":["afddbba9-2b7e-4346-89cb-783034e06de7"],"194629551":["d6d8c219-f43f-4058-b6ce-f12764bd1c56"],"195902014":["cc56f167-b0c6-4d2b-af2c-c1ddfa4a99dc"],"199829756":["4d2d916c-fbbb-409e-9872-e0390b0e4054"],"200544991":["3f2f9adf-3c5a-4a71-ab3d-20373d62d2fb"],"205687853":["e029bb69-678e-402e-ba42-067357af5bd6"],"206437050":["2516172f-9f91-4064-b4b8-0fc9e669d67a"],"206471362":["a1de1f99-25f0-43ce-a396-59917fe299c1"],"207641509":["d09f6b0c-2e15-41ed-bdcc-77cb3d03331d"],"210141357":["74c8199a-6edc-4e6d-ac29-dca94760a8bb"],"210225288":["99f73011-c0c8-4349-846b-1e1e124aeb41"],"211416505":["3128e798-915b-402c-84fd-277153483814"],"213861162":["a9492998-1efa-4e6f-9263-42a716327f77"],"216648084":["f78e123a-2945-4d31-a1c9-5e5b2300543d"],"217690617":["b09b5c00-92a1-4d47-a4eb-b4ed54087208"],"219612264":["aed99d9d-6a74-4ef1-8549-de20073bfa6c"],"220266290":["433dd18c-201b-48a3-bdd8-1cc3aade711f"],"220341956":["afcc3465-920d-4909-bc88-ab3a8e5a99f5"],"220788912":["b45f79c4-da18-4a23-bef6-425ad95e4570"],"223653181":["4c3b1d0e-b05f-4a40-98d1-46f7efcb7842"],"223936920":["7cbe09af-74b5-4766-9e88-1dcd2c3d395b"],"225299344":["37e4f217-bde4-40a9-9797-c2fec138b901"],"227337328":["3ab50e68-619d-455d-b9e6-eacd86d59df4"],"227694561":["523605c0-47e3-4134-a85b-325de9908e81"],"227756399":["08af76a6-4fc9-4b0f-82cd-384ce4fa51c4"],"227967775":["3cdd7d4b-77f9-43c7-b3ad-418f445275bc"],"228595747":["171619a2-215b-4857-b653-9410075dd063"],"228808067":["7b77534d-de24-40d1-90d9-f2c27c24e30f"],"233064466":["eb3d2c81-9187-4572-bc81-feac47eee2c4"],"234809507":["0b64d5ec-dccd-4aad-897b-4fdcd7b9f4d4"],"234901065":["96f962d3-1416-4dcc-8768-60f255ba8e1f"],"235623791":["c1fcdc0d-20a2-4c09-acc8-d4ccda43e0be"],"235976735":["aab7d139-dee6-40cb-b9c8-c346ed8ec3bf"],"240377236":["bc67db1c-53da-4f26-8223-1a812ed11946"],"241952680":["8f5fd4a5-b64e-4cf2-9914-23a31f282bfc"],"242264450":["1b800271-f261-497a-9202-4121ff59cab2"],"242660182":["ab8d2e6f-22d0-4ef6-82a2-cf4cc5d0f64b"],"243056503":["9811f2f0-7d30-4cd2-bcca-e326420f4bf0"],"249264801":["8517ab5d-d0e2-41a1-a7db-1c806eace623"],"250042597":["819c5074-e39d-40d9-ac53-51265e7b4a4d"],"255620339":["ee44bd45-d2da-4c3d-9cc2-e98cf23ba28f"],"261156253":["d28ace27-f79b-466e-94cc-6f94960dd2af"],"263462330":["d8243774-8763-4b02-9767-9ed766d8844a"],"263844596":["bf3a298b-1b9b-4bd8-aef2-ceaebce5f0a0"],"269255024":["8887850c-e5ef-43dc-a913-c313192f7aa4"],"271046282":["baef84e8-85bb-4c94-9b9d-32147f87d4a9"],"271851272":["c0898cd5-4346-4a6c-a825-03b32318697a"],"274144557":["cf0fd6b9-1573-4234-afee-0d0ae9b13e00"],"275737571":["f64ff1cf-b4f8-428a-8a20-4325a7ddae83"],"283279701":["de609dad-9f3c-40b6-9b70-2f24369a2c28"],"285012475":["cc3cace3-6472-4ffa-9b6d-26362bd22ac5"],"285651999":["63e2e076-0fdc-4b79-b59c-36dc7b51a9b4"],"286131681":["f56534d4-58a1-4df2-b505-2634d9262853"],"287744096":["78d878a7-f96a-4301-b089-f9335cf5e939"],"289229359":["77877adc-eb02-457a-aa59-9abf259c813d"],"289931015":["7a1e4f27-163a-429b-9b90-550c9ad37276"],"296688086":["40f76221-8a75-46f3-9911-8afd7b5f7b2d"],"299484675":["d912e728-0190-403f-8b1f-c79bdef63036"],"300067958":["fb1107e6-ef0a-4398-90f3-1448263549ac"],"302516837":["796ce604-99e6-428e-b884-9b3e36ba28a1"],"304380395":["7b3fe2a8-fc68-4c55-8613-a0ae3993b435"],"304827070":["2e47f208-853b-4c85-9614-28a9fd43bc08"],"307518589":["986bab0d-db64-40f8-bf23-dbccfc8beefd"],"313391009":["e6e8f815-a9d8-465b-b5a8-9dd1130e02eb"],"314715040":["b221817c-671c-4a4d-a9b5-198ceeccb765"],"316016851":["28a05b01-3145-4ab1-8d09-c3e957c3ed89"],"316126160":["1388392c-06a6-456c-b82b-d62405a2c894"],"321909376":["af64b13a-dd95-4965-ad7d-e1761f1a667e"],"322070424":["1fe4dec3-4873-4578-a7a7-632a6f07dfbc"],"328525243":["9f3da9f5-34af-4c0d-ac54-185749a52f5c"],"333930344":["a2a94d73-1917-48cb-9f8e-854bbc39b68e"],"334307844":["57567886-a7d5-4a80-a623-1b019571a019"],"335778792":["12180479-1f1c-47e7-8eef-14a0c11ad796"],"336770599":["3b9fba3e-de3b-46eb-b1b9-021e5aec56f5"],"337187663":["c93dfc43-c2cc-4a92-a418-1be4ed5d86b8"],"337211323":["e3f88fd2-ad62-40ab-89cf-30919b94cd44"],"337386967":["6e9e5065-a29c-4ae7-88dd-be547578b3e7"],"341708480":["891ebd40-2956-4e18-8256-8649d8704fe2"],"344114097":["e191b73e-6773-433f-bcde-4765c7680731"],"344918643":["c9b543fc-a155-446c-b84d-8f8efb5b72bb"],"350167764":["f0acec57-d7a0-4478-81ca-257fad1a9790"],"350638837":["436805d8-e5d4-4f41-ab79-30404a3b6e68"],"350803415":["ecf88057-1dd4-4de9-9af4-d043e0a19f53"],"351020586":["b0ce7407-5b86-4b7d-80e4-beda305b5862"],"352550152":["175a513b-5b22-4817-8982-521a7ba24146"],"352963873":["f8ac1493-3e17-457c-8751-17b34332c8e1"],"353995841":["442b66d5-a659-4f18-a45c-e85a44de181e"],"354043103":["38795709-4d62-44f6-a63c-e5a48717aed7"],"356531614":["891f98cf-f610-4aca-b866-f6089b5878d8"],"356732956":["02bcca57-70cf-413a-8f6b-477050471a79"],"357975046":["709ded56-8dd0-4f9a-ae2c-bb74aae5589f"],"358004052":["feba601a-dbac-4a31-a701-9ede211b01fa"],"359101441":["cfd5dc36-a45f-472a-8874-52859b77b50a"],"359480007":["6aa03dd3-f50f-43b8-a9b1-69836e96e50e"],"360386468":["8b6a86ec-94a3-4557-b71c-37588e37ea14"],"361355112":["06dacab3-3302-40c2-be0b-3abf08b9ba8f"],"363376650":["7bdafd06-268f-4690-ada4-36ee5efd63ee"],"366189245":["969c3202-87b4-40a4-b671-ef2ee8b4142b"],"366967375":["bce9a1d2-2105-4118-939b-e99af67dd53f"],"372160207":["c1590af1-517e-48a6-874b-78327b19b3fa"],"372619764":["42fdc09b-6683-43f5-b0e9-e547a667f433"],"376922952":["3e7602b5-f16b-4431-bbb8-aba10803b460"],"377858971":["493c98cd-11b3-47ae-8eef-4f8c4d50173a"],"383112564":["1159066d-f3e9-49f9-98f4-eb32be1f1943"],"386166186":["c77f214c-44f0-482c-90bf-b0a01aa50918"],"389129759":["5eb25819-230f-4dad-ab19-a2e49a72a336"],"390075088":["96df627a-17fd-4a72-a975-6204b7ced665"],"392271409":["5d6e485c-936c-4ba4-b06b-fb08566f07d6"],"392680166":["e329ef51-4e25-48dd-a99f-1573846359d5"],"394595564":["2b4f3727-d6c3-4309-9c25-eafbdaaf917f"],"397020341":["eec5f64e-8c6c-4f33-8a22-6885b65de97a"],"398642439":["c9a122d0-9db0-4af0-a163-95a1ea02b53c"],"400304094":["8d10893b-e29d-4823-823d-664c1c7d4e23"],"403745911":["9b5715a5-6d83-42a5-86a6-78057436e008"],"406629031":["dfab040d-d1dc-4ef7-a65b-f4c9cdaaf03e"],"409192444":["8dc4a2eb-f74a-423c-9c3c-da4e2fae7260"],"409977114":["87d72195-dbe0-4759-a6c5-48e31e6564ac"],"412000900":["77ec9296-d4a5-423f-8575-119c76bb64cb"],"412016408":["b192fd39-b4f0-43ef-9ae2-a7f2e5a3d23b"],"412217186":["38ec1379-bf58-4e7d-8989-4add5335048c"],"415586641":["d61d0b35-1e9e-4918-a70b-370c40ed581d"],"417582620":["6ccb5da5-8f5b-4478-b1cf-808f9f3f99bc"],"420559922":["adf3e95e-b2ff-4047-a28d-ec1dae19acd0"],"420594240":["b1abb7a6-e546-4c6d-b68c-a17093685d2f"],"422046295":["d3b5e31e-89c7-45a6-a982-a455f9673ffc"],"425549123":["209dc13f-e40a-4ecb-9816-dbcc3422507c"],"425695688":["2aa88bcf-e235-4606-bd1c-6671d84bdaaf"],"426505312":["a8365043-17d1-4bd0-9e54-71668c6f2bf4"],"426577793":["ffd85426-8bda-4c81-a6fa-d98dbf463966"],"427362846":["2a726ebd-4890-4984-9a79-dc72b27588e2"],"429221091":["a6fd65a8-3697-4ce9-b106-e626eccf2e7d"],"429667417":["6239fc54-e4a8-4134-948c-aedf2b95a48f"],"429805940":["317c5a57-33e8-4f6c-a995-9e13ec463fe3"],"431231208":["d596840d-4026-4ab3-a270-2c49264a6203"],"433840597":["0f24ef4b-908a-413d-b163-164a2e0eec5f"],"436127475":["9b827c0a-e05b-4534-8650-7e0dfab556e7"],"436708820":["31653d67-a94d-4a08-b83d-e75a6a3c2a27"],"437783876":["96d36051-cc5b-4a3a-8a57-6ef7cd59fa81"],"437953311":["e6c4969d-521a-4589-85cb-1b493ad3a9f2"],"439016754":["b577994f-4083-43c0-913b-d8031559c86f"],"439878600":["146eed5b-eedf-4888-aee2-7051c76f6467"],"440211012":["fce97f28-1cff-4bb2-8c4b-7d8af0f6870c"],"444105762":["2bddea93-8e0a-4978-9281-ee36842934ef"],"444396881":["255f536e-18d1-4fbd-a292-00f4dd3b8c11"],"445865413":["66980613-1a71-44ce-a8df-a4183759d253"],"447540026":["9acb8811-2a9c-478e-9c06-6300d97e093d"],"450076733":["6014b209-5628-4828-99ee-eeca9fc145ea"],"451930374":["53829bf7-8342-4d3b-a960-52c355b6c408"],"452718979":["dc91eeb0-a430-4451-9612-7eae692ac5e2"],"456898084":["daf8a966-1031-411f-80ff-778ee3e1a4a0"],"457237703":["3c8a03e6-5705-4d56-97a1-a5f645cac505"],"457572457":["07ee3c8d-d70b-46ea-8074-d7116ae9e740"],"459966860":["20c6df43-34cd-41c0-8756-e0b0ed5f9003"],"460939437":["b2883352-45a4-47d1-9a60-e2224edbc030"],"461540011":["7f7ff597-8b4d-432d-adbf-b0e787e98da0"],"465384838":["c4a37d15-8883-492f-a22f-5b1cd0f3e411"],"465791303":["3af03237-e2db-45a4-8eb2-5986b9c02e99"],"465844565":["39470500-4677-4b06-9949-b2ac689546a1"],"469891518":["177d045b-f66b-4bdc-8c47-1619ffae4879"],"472793484":["e3d3d183-9ce8-4961-b30c-4cf191871a93"],"473689322":["248916aa-c90c-4644-bf39-ec1baa5958ce"],"474459332":["4a8d6ea4-3f08-466d-9b2e-ddf0c6c81870"],"475644563":["595af1ff-59a0-4f17-b621-ac5f42949490"],"477618331":["d59be67a-69e6-4405-b64e-288b1bf0876a"],"480929569":["97065b15-d4f3-4379-8e1a-3edba60b7891"],"483372034":["fbb2b2d3-5933-4eb7-9519-3ff651fb8faf"],"484287209":["860d9144-7a8d-4fe2-9dd6-c50f0afaea6c"],"484370512":["d214c87c-f0d7-4563-9fb3-c20da9b38c17"],"485449021":["f54ae8c9-0703-4953-86b2-fdd6ab2a87d0"],"491792033":["f438d6e5-6e7d-4191-a360-e007188e7447"],"491877966":["05c69fe5-6bfc-42a7-a1ba-55dace50c199"],"495025627":["05998975-b11c-4e0a-8d0c-0588d589a8e0"],"496498351":["81569853-9574-4c26-8319-aac0519e2a38"],"497352195":["dd796acb-f061-46fe-8e74-361281d1c2ca"],"498073134":["5c5d6a3d-daa9-46fa-a7ce-51173fae2a0e"],"509115257":["47f65177-b775-4439-b7e2-5c5521af8da8"],"511564083":["aa63ebb6-e3e3-4825-921f-c7aedbeff444"],"512459723":["19fb0397-d5cf-4c85-bba5-8031f3f37aa1"],"514977264":["e198a0bc-2e77-4ac7-98f9-416a64c85102"],"516853908":["d0ec772b-0ba9-4a75-b5b2-b2948aa5f4ca"],"519584118":["96b41ec1-3a28-4058-bef3-6eadc24789e9"],"527172038":["977ffbcf-31df-49f2-a783-197fb35057ac"],"527931483":["7fb20421-c533-4c17-af84-d4dc97461671"],"528611695":["1d0e8991-ed93-496e-95e7-24ecfb83a8fd"],"532020145":["42ba8e0b-74e9-4abc-a646-6d03d1c21943"],"532020291":["162530b0-c288-42f1-9ed6-5896e008bdbe"],"534097265":["59e8c3f8-f965-4525-b900-506d22b4a712"],"535641501":["8919a406-e2e2-42e9-9d03-5c6d86c46201"],"539352355":["5a6afcfa-49d6-4dee-997a-74d3ca9ac80e"],"540343950":["0882ecdc-e36d-4860-818a-920e56913500"],"540708422":["96244c4e-1221-4f63-99b3-95bb5c65c91c"],"541494370":["7a7dcb31-fbde-405b-be2f-2144c202f4b1"],"542341094":["85c5aa66-5dc0-4946-a9f3-30b06e98203a"],"549543490":["3565bdac-8acb-4330-98d8-248a29e9a46d"],"550859081":["0164304b-dd5d-4ea3-85e4-dc2aebed700a"],"552381216":["5387a4cf-50e1-4be0-b77c-914852c31484"],"553826425":["bfc472bc-c86f-4d02-b423-4d4535348c6e"],"555285816":["7e94a762-be4d-4ac3-bad9-9d7a788d3e0a"],"556282831":["760e4695-4164-4c92-bc36-d3e5979b0f67"],"560018357":["7b1485cc-dc71-4d99-9114-c363490806dc"],"565164423":["fa73cdb1-8836-4740-98b9-3f85b83df258"],"570014327":["b6b8912a-10b0-414e-bee7-fadcc2f984aa"],"570980450":["5e4bbef8-d7cf-4cf6-aa97-0f5d43895582"],"571493640":["557ee541-69e9-4c61-a12b-217db047615a"],"572436101":["1e7dc795-2743-4147-b4cf-ec1307590ce7"],"572548062":["23853f21-af08-4c69-9cb5-7a8bee62d14f"],"576098075":["19abf5dc-d5ce-4d2a-b908-1a1d004299fb"],"580155861":["fc071d7e-60ad-40ae-af2a-f912ce77708c"],"580989073":["5fe20ddf-ea8d-4add-9cb8-67d6518a6103"],"588921186":["d7c684c8-8670-4d13-927d-11b4623c2262"],"589140293":["cf6a207a-6c90-4063-ba84-714ed6250428"],"589163778":["34c70966-a118-43bb-8598-a7f002ed143d"],"589348725":["9723297e-c367-4b71-91ca-165c331fd401"],"593163202":["9c032091-66ee-4266-9cbf-c744dc32143f"],"594417112":["f7b48769-dc08-4201-b579-87cb49c78b72"],"597378043":["b62a90c2-a4ca-400d-a748-d332284a5edc"],"599941883":["5bd81609-8e9f-4991-9463-50297bdfe5ea"],"601720795":["5edb0760-63b1-492d-bb27-10cfbed5d6d2"],"603032340":["2d77110d-cb21-4d77-8e78-ab5867ea7ae4"],"603295186":["037759ff-8efe-49a3-977e-aa21f7186998"],"605504746":["6c66fb8d-5263-45bc-8442-b196654af675"],"609707673":["9cd527b5-3905-412e-8d52-a0be0df75af0"],"614417450":["dffe99ba-1058-4788-8267-62c0f6ad9111"],"619393569":["a04790fd-9330-4438-9d96-9e56e8a1049b"],"619732820":["882da82a-07da-4863-9e30-f9ce14fa2394"],"619743848":["4d65a79d-2a7b-4004-b09a-6c53ea78229b"],"621301332":["5cc1a4f4-daed-4d7f-9304-d56c79e34550"],"624191677":["4149a3fb-6470-4cf2-adc6-d9905cd072c5"],"624658536":["e789d36f-c0cc-47b3-9336-6c3fed56e518"],"625723680":["b7fc58fe-6a25-4f7d-a046-74e60b8076cd"],"629640202":["866cff29-6cd4-42dc-acc9-26950ee9b20c"],"630569311":["6537466b-5df1-4c4d-bd29-7c076a50b74b"],"633252349":["ddb01ec7-236b-4639-9939-57fb1da46424"],"633980975":["25703dc7-d84a-44fa-93d5-7b37c5c960e1"],"640126600":["0fc5ef45-8a07-44dd-8943-195a464b958e"],"641440552":["81d0544c-79ec-494d-8338-cf059ce7eda8"],"642592519":["34c55d33-4671-476f-a8f7-be3c5e7b5860"],"643662293":["4827574e-2226-4455-a739-7d81df740ed5"],"643726864":["be5b8c72-3e8d-4048-944b-fcdae2fc7f45"],"643811276":["f1367f2c-cd80-41d3-b310-a43c1a73baf8"],"644947840":["dce23512-5d0d-49b0-91a3-a41eb7f00ef0"],"646465465":["e6b44118-05f1-4ff7-bdcd-02784dda0961"],"646742027":["8e5df407-af53-446b-9a68-4b04e9e68932"],"650153016":["f501d3e2-7f4b-4fca-8a56-3d8280b5e5f9"],"651963139":["77a62518-a093-45ae-8cde-d5249ec253ae"],"653228948":["a949d948-ac0c-44c8-887a-f1cdff91e47a"],"657236656":["a88dea16-e21a-4634-a8d1-2641911ed34c"],"657380278":["6cae0277-cf5e-4cb9-8a0f-7a51d8856214"],"657619739":["e8eb15cd-720f-45db-b354-41ef32d00fcb"],"658794533":["e5b0e5e6-1b9f-4c26-8a36-f0150282d162"],"658903721":["e4940624-db6c-4709-82ea-d9d4605d2606"],"659754713":["8cc7cda5-8306-4373-8173-9d1a4b7c5811"],"660610915":["db1ead76-992a-42ca-b644-fb5a061b3abc"],"663361683":["26f9a3fd-bfb2-48c8-9a82-6e36beff2c5f"],"666844452":["2b8d6ea0-47a2-4103-acff-0078e4a21ecb"],"674516165":["a8d7f2c8-9849-4009-b325-a3b0c5c317dc"],"676090880":["9c54bf2d-3a39-47e5-93ab-e90e353daf40"],"676466690":["cc0f3beb-4ac5-4aa8-b21d-9fbd6ff7ceef"],"676605010":["9ba20deb-ab74-4c89-b28f-75b5538a3110"],"677800854":["663abb32-dd9d-4389-a5c7-e5ab2be9454f"],"679849139":["cce010b3-671e-48db-aadb-05ec5f023797"],"684765284":["150431fa-6511-4c2d-9e83-51664e9c0155"],"685397382":["9094c7a5-79bb-4cd2-a9a1-f6544cb12851"],"688325647":["306329b8-f3d6-4d47-acf1-7172bd95af80"],"688904172":["9dd5af28-ad76-4b32-b32e-38b2eb3216f4"],"688906177":["dc360f80-b3d4-4ab4-bf70-663a36d90c2c"],"695032825":["e7b9267d-573d-48c4-b12d-2f319e3451bc"],"706977001":["1ca25453-d92a-4166-9e49-659ccf5a35e1"],"708301481":["6a8d9b9b-63dc-47a8-9022-d7bf19196e8d"],"709361584":["25190dd3-50cb-4410-87b4-91da1656b9cf"],"710731352":["68cc8b2f-5f07-4823-89e2-3372b193b423"],"712922125":["c8295f25-011a-43ef-be61-3bb148236f16"],"714897600":["fab5d6df-edcf-4136-8e26-7bad66b3095a"],"715672501":["5389f66c-8a79-4d82-943a-7687a5aa223a"],"715732367":["76296eae-00ed-413b-bef0-089e60305a27"],"715822458":["ef126cd1-e414-42f6-be4a-907a0dc7cb14"],"717104482":["8685d659-8f96-4a61-a3e9-1d6cacf33012"],"721374352":["a5c7754b-0546-483d-b3b5-2e57bb686203"],"722585763":["9d1f8594-95df-4ce7-871e-ae2b4f8122b7"],"725680623":["226bc329-8fed-4fb9-9e5b-e94280de3800"],"726670522":["6ca676a0-86d0-40a5-9351-ae7507218c18"],"727061136":["92ba2442-a6ed-429a-b55f-f9bd6af379ed"],"729554924":["66c807ae-efc8-446d-bc53-1e89e22a7b22"],"735465665":["bcc81d76-0dd2-4625-8e20-637f4f940af0"],"736662432":["7a3945e0-dfb8-490e-a6a7-441de611e653"],"743847098":["1e5148b7-9249-4bbe-882d-a2f074e38d37"],"743937764":["2b54ba7e-18a5-43a7-bd15-8133c870815f"],"745120151":["b9f29d8f-4cce-42d7-93a5-acf5dc839f30"],"750041789":["72ead16f-f75c-4008-8383-3a7a5f1cdec3"],"750799092":["a6e3b00a-bdc7-40dc-a0f4-5e1d84bdda18"],"752073065":["ba5fcc3b-b4e0-40ea-a764-415f495c6153"],"754985608":["9925b09a-8e96-475b-9f33-2e1557005808"],"760005215":["639e52b0-c822-47bf-8a68-6f2e8319d74b"],"760237484":["965c2fb2-da09-43ad-bf0e-9968caeebbfb"],"761103301":["67959314-e6d0-4f9d-a8d5-6b4c1663cf0b"],"762468700":["17a60040-f88f-48bb-a70a-b59b7ef8e52d"],"763211304":["15f901a2-98ab-4a28-89c4-0327f866aadf"],"764442800":["2381ec4e-7533-4c70-bc03-4b997a9a4cb1"],"764821072":["3c849b72-b3fa-468a-b5c3-f460a419d293"],"765788410":["c1dd8690-cd89-4670-91f4-c403b3e93896"],"767631735":["754dda69-7d98-46dc-a959-6f8305a14e5f"],"767906426":["dc19fbe2-55cd-4921-bacc-7e6ad1e9cbcd"],"770511944":["a8cb5e65-63b3-4633-b134-7266d7366022"],"773660079":["219ea30e-8e68-4b8c-8d83-d94b9bb1ce5c"],"776034338":["ee618ce0-fb26-4efd-820f-6688e50007af"],"777111615":["44b00988-a7b6-4b49-9e28-f905219533ec"],"778185692":["3d996b78-ef42-40e3-91ce-f43025093e0a"],"778996245":["e702419a-5458-499a-af32-f9570b5966bf"],"780411338":["87177ef2-8de8-4099-a567-bff83bd2e62f"],"781522283":["4c0414fe-7b7d-4b1f-b868-4286b4b56101"],"790228059":["e29bddde-eb99-44eb-94a1-510e7eccf760"],"799497744":["64b41008-2927-4ac9-b1c5-39ec826838c0"],"800048163":["95086fab-bef6-4fde-945b-4f301d7b7290"],"803310930":["ca521068-4860-4824-8b42-c1d0530d56c7"],"805376821":["9e400d34-fe16-42e5-a7b7-34a36320634e"],"806050308":["d9264fcd-88e9-4ea8-bc8a-692fe0ebe7e7"],"806584215":["f422b44f-9a3a-4ed3-afb0-8a75406f6079"],"807102578":["d015261d-53c6-4165-b396-0ca88a27b516"],"807695921":["aa46c1bd-922f-400e-97c2-dcb40836133a"],"807722385":["6d570b7b-1209-479d-8d0c-6d9611057c5c"],"808867681":["f7b149dd-36cb-4bb4-abe6-1db51131af4c"],"811646469":["ea454c57-1428-4008-bac6-88247af196e1"],"815883537":["f89555e2-61fb-4051-be0e-944d2c355066"],"818932679":["4713649e-b41e-4af5-92f4-56456401c3b0"],"819913065":["b0f93922-1f7f-4a7c-9b78-6848454a72a6"],"821324472":["16f3dd59-d9b6-4efc-be80-edb1c165638a"],"822618871":["df652957-287b-4fe4-bcaa-c6a92e9ea57f"],"827918566":["3b84dc90-5824-4a83-adbe-d70f8c5e282e"],"829603759":["8d96602b-78b7-4fba-ac28-c306e4650966"],"830183507":["52ed82be-bf7f-425b-8003-2c03f7f08406"],"831312186":["643355aa-0bf1-4afe-8c4e-bcc7a32e1577"],"835202301":["55a8a24d-c529-4771-91de-bfb13a4f1232"],"836213611":["2701c9c1-03cc-41a0-92d3-eb2cb29b5ffc"],"839648009":["558167d9-37c1-4ef4-8e37-d638c6f4163f"],"839801174":["e3e4a284-bb37-4c9a-bd2b-fa756313eeef"],"842098460":["19e990c4-37fd-4856-85d9-1915364dfda6"],"842128431":["3059da4e-4615-4fb6-8b96-c83aa4be966a"],"842783883":["a9c83c85-8b71-4474-8fee-f71357bcd323"],"844909175":["68316ed6-4f5b-4b8a-bc31-b77714673032"],"845600553":["7d9818c6-abcc-4c30-b5fa-9b5e85f9201c"],"845627319":["24d89ad9-8c62-4a3f-bf96-7a16a70c3135"],"846376162":["ec4a37aa-9d11-4b11-8003-e84b3b738357"],"847602815":["e8bf78d1-66ff-43c1-90d7-ccc36d808cb4"],"848717582":["9d3aab25-51cf-4775-b6e4-e810e77a99cf"],"853061365":["0761e1ed-a452-48b4-9de8-14afad97e00b"],"855581447":["2f58d0bf-a57a-4312-a21f-9f3e029c3715"],"858249982":["cdf3ac08-a19b-404e-b75f-47ef387205ff"],"859490371":["b23c2784-ad82-4b29-ace9-54a57ce65759"],"862641963":["f658f451-657b-4bfc-8ce8-d1040e0d360d"],"868152533":["4ad9ee0d-4340-4c3f-9d9e-8b101895555d"],"871000014":["d015700a-4f55-499b-b7ae-5e482dd84233"],"871124526":["ff7cf611-c232-4667-8957-9e44cc0982ef"],"872704797":["522d0090-2c63-41cf-a879-91d52aba9692"],"874670835":["25d0c14e-baeb-4499-9e31-eefdae811c3c"],"875508595":["66281e14-f0f2-4632-9c64-a6761d852726"],"876160341":["a767782d-7765-43a7-be5b-99248b2b60ee"],"876739350":["cd2d0dc8-3240-4d81-a99c-777229f5b8aa"],"878410922":["03270f44-4899-497d-8b5a-07afc7d62d96"],"880011716":["7fc9c64b-b17f-4643-a62e-83d93cc474e7"],"880472561":["33e8f1b8-c642-4769-8244-b0305c70e077"],"884539298":["761be789-80b0-4feb-9dae-1ae34bf3b868"],"888356641":["9735b38a-db46-491d-a7ec-13805da4ca23"],"889642243":["190bc495-a962-40db-b816-13b2fe57d15f"],"896834999":["44e01b53-8cc4-4e79-842e-a901a6deea3a"],"897725437":["bc87b64a-4a0a-4fe7-b510-15bfd61437a9"],"904999034":["80c8a0dc-963b-4276-93b5-342361793b2a"],"919588136":["6eb0872f-c77b-4b46-9372-e90f12eaface"],"920054738":["d710cb67-3c6c-4b49-81ae-94e494759d69"],"921601186":["51822f43-a1de-4f67-8c38-1201cc0ad995"],"923049196":["308e0c75-73fb-44ee-8028-e2f4a5b76a01"],"928160543":["ea8a02ae-3884-46b6-a255-c6bb2b9f040f"],"931426593":["d3665a8d-91e4-4f86-91ee-ffb0757d39d7"],"933219248":["58d6f3dd-f8c4-4dad-a9b3-ddbae049e48d"],"934143860":["4abaa3f1-ca5d-4e10-8901-03448a8bf876"],"936192650":["1d1c6226-f22d-41c7-a866-7bca8fc52546"],"936279962":["5318c336-fd06-4e6c-b14d-9155b37085bf"],"940919109":["e3761bed-ea04-410f-ac81-1c4238b7111b"],"941217670":["37008d9a-d0c2-4306-a2e8-a20d91e15124"],"942208939":["d0b2baeb-8fbc-492d-b3b1-3a13f6496232"],"945201746":["9b7b9434-eb3f-452c-a59d-f15cedcf26ed"],"947147219":["a373482e-23c1-447b-a881-09a612beaa45"],"950524729":["0da2e664-df05-4ada-b15d-081b101d4903"],"951111979":["96bf680c-ca4d-45bc-acff-ef90cb473228"],"953217105":["d8f95278-c801-4c07-835f-026b32df5c92"],"954011304":["d321b268-a44b-43b2-ad15-5db7e2373bd9"],"955501139":["5ca6a1db-b63d-4b40-af23-7549dfc748fb"],"955972947":["9a03ee71-52d9-4f00-ab43-5160db3cb854"],"956346666":["7643c88c-7772-41b1-808e-8979a4e20816"],"957040659":["9a2f7de1-f491-44d4-8f2e-f6b77d8f599f"],"960211338":["a7d935c1-a556-4d6e-90d3-ec3484295423"],"961155624":["a0d46181-caa8-477e-8eaa-3c9983a667d0"],"966755570":["bfb0f44c-dbda-40b1-ab1c-a715c43885dc"],"968274711":["0acec050-ce1c-419d-89de-e007602f96f4"],"968430120":["ed7c1fa3-c516-48b6-8b8f-2df50b8d26cd"],"969752047":["5293bc84-9da1-4e13-b621-94383403f6c7"],"973385699":["c43ff2e7-b38f-455a-ae6e-5c78375b7fd3"],"973471561":["a6d708b7-4d20-4e85-902f-22efb5f35de2"],"976396681":["483a66ab-211b-4ed8-ba38-d1629b6f654b"],"976576391":["2f34a5b7-b50a-4893-a5b8-533ff0091b40"],"977527784":["4301f355-c915-462b-b0ce-b83478805cc4"],"978099025":["a822113a-6bf5-4740-ab1b-0acc338ece77"],"980738416":["7f66a341-66a8-4453-ba5c-9c623d77830e"],"981282303":["07b1a01a-b056-4b80-8b26-132131b433fa"],"982911206":["0a03da23-5541-43f5-8fc8-24f66642438d"],"985085086":["2ddf56b0-5379-42fc-9cd7-012cd29832a6"],"985096435":["dbdb8a1c-52cb-417c-8ce7-6a56a9471842"],"985555476":["4e36ea12-7294-416f-8634-bbdf28f0be9d"],"988092097":["f40f6fd1-a6dc-4541-bfda-2e754c17a97b"],"989004487":["f57ecca7-8d35-4c76-b9fd-3998d7cba37c"],"989317751":["011f5e08-c73a-405e-a35b-edcfc6ce9642"],"990218400":["8aa817d4-a608-46e9-a6c9-367f46a4a3e3"],"991416208":["9aa3373c-8794-4646-8d18-a7dfe9c02003"],"991987509":["e6a53655-aada-453d-a17c-0224b83b6f5b"],"992417805":["6110e5b8-b42e-467b-b19d-66092f1207c0"],"994394728":["73977942-0a40-49e3-a068-8f538087fe3f"],"994504345":["1a22b6d0-cc2a-4807-ae46-78028bdf06be"],"996024474":["ca843290-d994-4c67-afac-85c57d7effd0"],"1000026236":["fab02f30-74aa-43d8-ab88-70bf2f9d51d5"],"1000839436":["18bb600f-d858-43e0-aea5-2bec3cb4c0ab"],"1003761078":["afa3386b-9b85-46cb-b92b-71925e045c9f"],"1008101716":["2bb53527-5f41-4c0c-95e1-6573270f3793"],"1010421498":["832d845d-f35b-41cc-8b3c-a063fcd40dfd"],"1010983399":["a46b39fd-3feb-40a3-8ed3-317367ff92e0"],"1012837424":["7bad0de7-cc50-4b60-ac85-7821efbe135c"],"1015141190":["e53176a1-287e-4fa6-b072-16a50de544e9"],"1016166019":["2f4e9c1e-0ca1-4880-ac20-0c9f3d190a75"],"1016491954":["0e76b6a7-047f-406b-a4aa-b3fad98386ea"],"1016622047":["e110d474-2f28-4ec7-9166-76d3208f0b91"],"1021044865":["bc1514ec-6ab0-4a8b-b20f-236406e67056"],"1021621529":["3dcfdc16-661d-4196-8a4b-e5572fad8e97"],"1022197471":["83f04485-a292-48c0-b5ea-db76e1e102d5"],"1022938109":["3567ebc5-a706-40d2-861f-73b16adae55c"],"1023983897":["7aa0d4a0-4d8a-4cca-b935-ae4817b17f0b"],"1026305225":["02249019-08e1-43ce-bb0d-75561f3a54bc"],"1027897428":["4603f258-5c0b-4fd0-912c-00f3a249b627"],"1027920023":["71f061ae-8540-4f8d-8fd6-3c26d0f069c1"],"1028777354":["80cb20ef-b15a-4c7c-856b-195968a40403"],"1030191618":["02780c50-0332-41c3-af6f-690f696fce12"],"1033394670":["6f36f836-9366-4237-ae53-065ce30cd7d8"],"1035138092":["31764a9d-a7df-497c-8ecb-0364704407c8"],"1035589853":["dc0dd2f2-f872-44ff-9120-230128a33d41"],"1037491329":["22b6f428-2781-4d07-a9d5-69f1539a534f"],"1038481379":["0aa9911c-9abd-43ea-b36b-d55065acb893"],"1040029748":["796fff37-2385-4272-a7fb-147f1ed6a0fd"],"1040300222":["f8e269b0-9707-48b4-8c12-c239877bcd58"],"1040737152":["840288b4-8530-46b4-bf8b-2d2fd3658cc4"],"1044905518":["a80a8c64-36f5-48bc-bb86-26e93178f55b"],"1050362755":["42e8ea35-f8b8-4091-abb7-a8d9ccc33fa1"],"1050646338":["71eeee39-a0f8-482f-a2cb-69052fa7f785"],"1051720840":["cd1986f4-2600-4ff1-a69c-05c486a0dbd8"],"1051749557":["68a211fd-8c58-4240-8762-555f07df00ad"],"1053564469":["dd41b4d1-522a-4cd8-a647-8f7f71106d28"],"1055115541":["d4d18cb4-851c-4e85-bc23-653d7d944691"],"1056499307":["d3feb378-df27-43bc-8cfe-274335769c87"],"1057670076":["e8625aa4-9029-4839-b8d2-976e5f6cee60"],"1057859834":["fc59d3a2-0286-47d4-b0d4-1f81f674e3d7"],"1061857164":["ccc618a1-7c3d-406e-afb6-904f0d2464fe"],"1066313938":["b5b86fc2-a1e0-49f9-81e5-67636302edc1"],"1067050765":["77f9fe5e-c129-4e10-84a4-30eeebae1c21"],"1067449169":["8ef5aad2-683c-4182-b64d-4e0017cd8f57"],"1067615226":["611d261f-9554-447a-ab8a-70fe3b5b82f3"],"1070034349":["822aceb8-5c19-4454-8e9a-6152e5a6a296"],"1071077465":["c94909f3-f27a-4731-ba8c-85dc654b1ab7"],"1071242823":["1ee1b201-eaf1-446c-9553-a5d0f05470c6"],"1071765452":["7e605b00-1e8c-4165-b69a-df742df6020d"],"1074566383":["c1488719-75d7-44bb-a668-41200ef30079"],"1076017933":["0222be4d-de12-4971-84d1-9d574533b51b"],"1077448226":["a86ba149-556b-4420-b9d5-96e75e46431b"],"1078405399":["026816dd-b582-464b-b7e3-7c4c74a09daa"],"1079646728":["ad8d668a-43a0-46f6-bdf1-777b4875e9b1"],"1079725409":["d76d6c30-6120-4ff2-aeb7-dabf50e7a16c"],"1080431694":["d124bef7-9829-454d-a262-b7c9a27527ad"],"1081006076":["48f87b1e-7441-4a26-b275-c19c4f75bd1c"],"1081444255":["3d571f65-2b12-4608-b3ff-14de54f9ce17"],"1084243048":["e2c4a9cb-8221-4af2-ad18-5a6b5cab6c71"],"1084949974":["8d98cf06-aa97-4d74-849b-5375fdd328cd"],"1086947719":["fe64ced5-e590-4c93-a9e1-6c36619ea871"],"1087047865":["c724c17c-093f-4cbe-8ffa-f557115b148d"],"1087136831":["de5ae3c5-7717-4154-96bf-6323447e731b"],"1089574331":["79a31136-4c7c-4dbd-aeea-22d386470aa3"],"1091995491":["4d8528ff-0e28-4e22-a675-9573b5b33837"],"1092347817":["9f2fc7b8-a1ec-4bc2-92cd-79febd448b27"],"1093405145":["62bde13a-f10d-411d-ad38-a95272b280b3"],"1093566252":["a9593d2d-bc25-4df9-8437-ac0c295af358"],"1094389418":["1c3b6aa6-6926-4416-9dbb-3c046995b95d"],"1095016852":["9b1043ec-420e-44fa-8206-3d05724851b2"],"1095501704":["657b55b4-7397-4f53-b53f-a772a244afce"],"1096968359":["f2f05047-934d-4e50-bf54-2aa17ca00dda"],"1097494881":["d71b2c4a-e6fd-4d42-8442-bd414377e80a"],"1097716830":["a71f25a3-19e9-4637-8cc7-f3d38a3dd308"],"1097788671":["a9c10b94-9d29-4739-9bc6-a14c7ad19d52"],"1099507269":["9fc6b6de-009f-4b5e-aba5-b6da27d9b0d4"],"1100366614":["bc20f866-c7de-4e82-b465-b478e19ed9cc"],"1102206205":["805a6464-2256-4708-86bc-6c9f650d0795"],"1105676381":["a3ce4743-f584-49c0-a5f1-bcf36c53560f"],"1106141347":["05913654-95bd-4ae0-8d77-683a36c9181b"],"1111050242":["d76d9785-f991-48a5-91e4-facaaab3430c"],"1111892420":["9286fbcf-b68b-4962-bd7a-8a03f4429c7f"],"1113650646":["4ca32fee-d25f-4d9e-ad44-5a171de0ffc5"],"1114196726":["2c9c19fc-e161-40d7-b660-d2b697c437f8"],"1116518669":["c74c8a32-0927-4d1a-8d03-ec2d6bc507a8"],"1116869283":["c8084f28-f9fe-4f84-8150-760c4e4ee891"],"1120933501":["b979df37-1275-442f-b410-131d6012227e"],"1125556853":["a680346f-b20b-4d23-8ec4-de9ae1ec953a"],"1128924813":["21f9942a-cb0e-46b3-90d4-c94f29063aa5"],"1134188281":["db891d46-b961-461e-8088-083fed633001"],"1136116730":["df48cd39-815a-450d-a0d9-7be7a94452e5"],"1137467364":["436e5d32-927e-4b39-9012-0e8a1da9c4d2"],"1139605017":["3fbb1247-c64e-4bb3-9ee8-d8290017bd50"],"1142752071":["e38e382f-22a1-404c-8a18-f163176c3fc5"],"1144485327":["fbbfdd7c-9d97-4937-bdcc-6b82f84dba6c"],"1148611333":["976485f7-5ee9-43bb-a5b2-4fc4e8920e61"],"1149472566":["5b3ba212-13f8-4680-bdc1-de75a1c35303"],"1150959091":["c5d60d98-e3f3-4733-8626-9bc760baa6c3"],"1152054565":["bed410ea-20cf-4747-bb08-545254a5dff1"],"1156572775":["7a104634-cdee-4e14-b2db-a83c5aa08703"],"1159868617":["3ff9cd92-fe2a-4754-affe-569138e1567c"],"1168178943":["0de6c6b6-59bd-4369-80c1-b62adb99d3c9"],"1169340215":["61689ba5-a02e-4a00-8882-f8672f237af5"],"1170574821":["a55cce89-a344-46cc-aa5e-a6050e3277a4"],"1172140734":["174c4177-83cc-4b0d-8459-5f7954894095"],"1172487478":["c012bc37-3ebe-42bc-8fda-fd0751883584"],"1173094081":["2837eb6a-9184-4f90-93a4-6dbaadedcb6b"],"1175208920":["4da779d6-9cb5-4ead-9c38-1205b70ca69f"],"1177014712":["f72b7065-9e71-4737-8a82-437449d669ba"],"1178890263":["72601d89-abc8-4732-b03c-c63cc67d4b95"],"1179212253":["49592e41-5c84-4784-85fa-34f7ce25a46a"],"1182154736":["487f38ce-1932-4123-86e9-4686a7dafcd6"],"1184302046":["4e0d1def-77d3-4c3e-8e09-ca3afe1d6787"],"1190432225":["abad647d-c43c-4c5b-aa83-ce9d49e8ef1c"],"1190753338":["151da54b-93d3-48a1-a6c0-139483b36949"],"1190961972":["2dd3c032-97f4-47a5-9094-9cfed73fde42"],"1191182645":["10048ccb-4ad0-47e1-afb2-fdbfc4021595"],"1192024035":["cae831fd-bfc5-4c4e-ad1e-6d2ddd4901a2"],"1192060039":["d1049c6d-261e-49f0-a277-384321c1da7b"],"1192060389":["03ce0198-8a78-4bb4-8192-afc331aa6d46"],"1193092053":["5b956494-5b6b-4678-883a-8000960a0d0d"],"1194335187":["f2dcb80c-4dd0-41d8-8e38-a70b6fb9fbd5"],"1194770376":["0576bce8-f78c-4908-864e-ca54e94c5f78"],"1196762365":["612c2f24-780d-47bb-ade5-a3d6b2ce6a9b"],"1197238615":["b070e0c9-fa47-4c31-b02f-927b57c3fa64"],"1197986801":["1e9eb58d-6976-49b0-a083-d21d6159d65a"],"1198340208":["ee618d2d-db05-429a-a19c-370faa1ecdc5"],"1201821500":["115ff84a-747d-497b-890d-ab8cd058017a"],"1202891296":["ac6b7cdc-26b5-4e36-8742-4afd309ca4c9"],"1205695300":["bad3f624-4bca-4aff-ad8a-9f0f43d949ba"],"1209431248":["66dff8e0-edde-4bf3-943e-c7fb30c9a82d"],"1213969046":["5cc85d80-ef13-4fe4-9e88-c041e84f1990"],"1215253519":["fbcee4a8-6a0b-45c8-b412-f8a73f38aafc"],"1217938857":["d1d6a02a-d4c4-4202-a684-1d5c7a43fc6c"],"1219402349":["b264252f-0340-4a76-9ac5-8fdfe996e77b"],"1224442849":["c937334b-e4da-466f-a63d-10c763f94b66"],"1224834892":["1b337013-50e5-44cc-857b-55ef30bde64e"],"1226149296":["de4a2fbf-3974-4e2e-8f10-0529b1d3e364"],"1226934114":["00717da7-3939-4694-971a-f1f37c4fb56f"],"1227799236":["2c46e708-26a2-4f3f-9958-65d3be43e46c"],"1231191306":["9359990d-b0e5-4d99-ae63-62d5b8483467"],"1231903953":["fcd7ed61-0181-450a-8f63-be058e7ce8d8"],"1232092347":["8e1f98cf-25db-4684-a417-42c6499a11c0"],"1232397942":["5f0ca100-842c-491f-b844-0eb1cb7023a7"],"1237944286":["a69c4b3c-0514-47d5-9520-672a8dbfbad3"],"1239909620":["96e2c7e5-790e-44c5-b041-5aadefd54552"],"1241825578":["ab717e4e-85f5-495d-a21a-818ba7242dc9"],"1243230473":["7f166644-a2e0-449f-8160-eb176fb8babb"],"1243881876":["fe3cc76e-9a6e-441c-9fbe-3acb0b106cd2"],"1248371701":["4470ef50-a3f4-4da9-b7e0-4cfa5e4866ac"],"1249368366":["42a52177-b1b7-4cf4-8d40-6bf855f63f0d"],"1249772743":["82674030-107c-4a60-93f0-ae14ddb5640c"],"1250753656":["a2599b0a-0e01-45d7-b642-0de731380be8"],"1253808673":["24512467-2b96-4833-8ced-fe717f59cbe4"],"1254678531":["86a0434e-4d98-490a-a1c8-7ae4d86b50f4"],"1258597252":["83e4840c-8962-4d93-bd24-de454842447c"],"1260387249":["357a85b4-4838-4045-9436-906ec4461bb1"],"1260687341":["952ecadf-d98a-4331-9c20-eceec25785d7"],"1262064695":["1e4aabc6-38bf-4690-8d94-63f8a2c0c1c6"],"1272443426":["8f02a3a6-5333-4efc-b484-68775b6e2acf"],"1272914878":["d0a74205-8eb6-4098-8c45-0142c63cd734"],"1274965000":["d4c4716f-07fc-4865-9535-58e6f6964ce0"],"1275722189":["eaa885f3-e248-48c7-b4eb-7e368c535b43"],"1278749646":["ef9596a3-8e88-46b9-916f-fb8c073d72db"],"1279941635":["ad381fbf-da02-4b09-8619-76108c7f9639"],"1282017133":["bebe47e1-7ea8-475f-b9ea-454c9576d04a"],"1282127958":["c37892df-a525-494f-a595-fe99426cc450"],"1282581055":["a8017712-ac61-4cce-9996-499bedfa2fac"],"1288465512":["8552eeed-11e7-4de1-adf3-2a959df19a23"],"1292066092":["5931bbec-f86e-4d94-a710-fa5ad505df1d"],"1294293000":["20559d99-54a9-4482-9a5d-123b2bf1f3da"],"1295388165":["34b1da31-c8e0-475d-9750-c36ed1cb9c11"],"1296971202":["2c4e5cc5-c760-4f35-991f-3cdb4d97fa59"],"1299324213":["fc807498-7e25-4d80-a990-01f937b28283"],"1300274723":["89f146d5-8b60-4422-9e62-d2a2c632dc9d"],"1316496830":["3aadad7e-290f-4fea-a56a-7026b16fefcc"],"1317948735":["e816fb20-ed33-4117-a868-7b7264cf0ab3"],"1319344358":["b5136288-f32e-482d-93bc-a61fdb0fc987"],"1321436853":["7aa97348-b3c1-4612-8337-76f0bd73adab"],"1322482791":["5d7e0cbe-437e-439b-a121-cef07af2db6c"],"1328608375":["bd481916-2e81-4c88-9b06-ae8d69379a43"],"1328633324":["f8a95621-b926-40b3-b616-bb1a521ecb30"],"1335553438":["4cd62234-64a1-4c65-8047-e032d854e552"],"1335882807":["15ed8a65-8f38-4db5-8fc2-aa690473cbb6"],"1336123425":["6206efbb-d3c5-45f8-b671-f4186f5c7438"],"1336907184":["6bd6c6a2-b945-4ded-a878-cca33d528087"],"1337191064":["f453b916-987a-4536-acc8-0ebf44d2d75c"],"1337329852":["c80f5bad-d5fa-4f10-afd4-8670a3d7c864"],"1338619289":["051bd9e1-9005-480e-afc6-0d2753657642"],"1343450059":["8749b66f-b5fb-481b-8f99-009c8a3ea6b5"],"1345325784":["a369ac59-0aab-4454-a625-507314d3b065"],"1347393569":["81ecd826-e5f1-4dca-a985-f43729144cfc"],"1348144683":["99de62e9-b006-4d2a-8ce7-0a4ac73aa1d8"],"1352976111":["c4189adf-6865-4e4a-9bd0-fc6190a20e90"],"1356609756":["14ef4e62-897c-4f3f-834c-1e0064845ef4"],"1358646918":["77864362-9a36-4618-8b31-5b58d7004eba"],"1359718619":["72e52a3e-0557-45c3-8443-c00cea1c937e"],"1359975083":["f99ff99c-71d2-4abd-a947-d136c12dc213"],"1361089496":["eefb602d-6ac5-4219-899c-4fc4e842ab9c"],"1361436249":["8750a9de-7651-4445-8860-edc5a71b5318"],"1362852906":["f9f7ede2-8b1c-4f39-94a9-a6ef2f447271"],"1369192761":["a0a2c991-a14b-4b95-ba65-30bb0386f0f7"],"1369603897":["9ebf2b5b-5d10-411e-ad05-442866b084b1"],"1373929064":["2211d733-7345-4ada-bcf1-15ad6c5cd117"],"1376050201":["da40a818-29e1-413d-b66d-616aed38669f"],"1384361620":["0aff241c-0282-4001-8026-44d0b116b57b"],"1386062946":["e6208b0d-880c-427b-b921-719a9e37ac77"],"1388319075":["fc662e90-ba09-4f40-9936-f677a7a448a8"],"1390508640":["89235314-a600-4aa5-bdd9-5395463113c1"],"1391783945":["6aedf61e-be24-47fe-bba7-b539ae5d3448"],"1395318305":["0328a2ed-5a62-480b-8cfc-ee3835a3b8db"],"1397440684":["667cdc10-b206-430c-92e0-1617484ead70"],"1398719802":["553bac8d-14a9-44cd-8a3a-f36a11cd2074"],"1399349625":["acf9c0b7-23bc-466a-bee6-18ef04d5dc97"],"1401303593":["502ac76a-6327-4305-a576-4d8b85b28deb"],"1401479837":["87de8db5-6cf0-49e5-ace3-664c05a21f66"],"1402317323":["7e02dc29-07f4-4132-805f-fa570c91a4c6"],"1402907909":["8f35bf76-b91d-46dc-9a73-a2a1a7083b8a"],"1404705674":["bcc3ccb6-9690-4f1f-a08e-c4784cddcc66"],"1405413746":["13850090-1bd6-4d44-80af-60cbc0b11f58"],"1408493002":["4f4eef69-e650-4357-8dd1-4984e55fa195"],"1412843515":["38831be0-5b38-4fd2-b5ce-fbf8bc752de2"],"1414453216":["065a65be-c37f-43a2-ac70-b661e9fbd59b"],"1415596750":["4d90f2cb-4ad6-49a4-b70f-98745696bfd9"],"1416590192":["b0a1700e-0d64-4573-9423-2c11123b6921"],"1419187119":["39081608-01b5-447d-b68c-f3075acaa9a0"],"1421670295":["65183e68-b4ad-42e5-8f76-a5e5a5fe8845"],"1423523078":["2fc2f830-f1b0-4a98-b9de-54fb7ceb6d0a"],"1431392686":["cfdf8f04-78aa-4bac-86eb-0413e56d5d27"],"1432278580":["8b80c09f-6202-4df1-a5fe-74a099c4304c"],"1432337001":["3f3b6461-a71a-4a84-92b3-6ae95363f5d8"],"1436242790":["1c150cc8-b016-4494-87f3-2a7f078ea8a7"],"1436555628":["c96aec69-466b-4f59-9ada-83278c76f3a3"],"1440401783":["44bb7041-845a-4997-9efd-0216ab5f84be"],"1444358259":["20278174-6c3e-487a-8d6b-f17132f41dd0"],"1449073457":["a44873d8-5c9b-4230-ab4d-1d2bdaf755ca"],"1449306304":["92e9ed35-ed19-4dcc-a0ee-34f92ead8cfa"],"1449467935":["e55b6e60-b544-49fe-a2a0-d4162cdfc242"],"1450933914":["4e164bb0-0018-483a-a9ae-bda984740e63"],"1452535734":["f1f6a750-f0bb-4ab5-9400-bc08c239ff6b"],"1455271668":["4771461e-8a0c-405c-8b2e-43170e9de9b2"],"1457257277":["f2f7cee8-f186-4890-b850-70d7431b7371"],"1461140445":["9da107a9-3061-499b-a304-1716424ad050"],"1462917081":["6e2d094f-20de-4a69-9f6f-fa85935ce7ea"],"1463765584":["54b62ab3-2d8d-4a02-8aad-973178f20ebf"],"1465397286":["3bfe0923-381c-46c2-963f-61b379b1a8d3"],"1466824369":["df5494a5-9d61-48bc-a10f-056144e5e88a"],"1466941263":["a945a253-1611-42e8-bb79-29a6aac9e32b"],"1467502838":["f959954e-09c0-4456-990c-7cea21a75fbf"],"1468434133":["3ddebffc-1a0d-4923-8454-5b3212ed2206"],"1469503993":["b371f6f0-b01c-4ee7-9fe1-708d1756856d"],"1472012191":["27ed23c5-c231-4c27-b486-b5f873f2a6c0"],"1475674128":["67319a2d-4d66-4bc7-b1c1-001cc20a2986"],"1476273991":["ed156bb9-8409-4010-867a-8f19b5380fb9"],"1476379686":["41aa4ef2-d525-4e5d-a4e6-4358b781537d"],"1478327585":["b2be948e-ebf3-4f03-a201-68a2952849ce"],"1478454322":["4f9c6822-21be-47ad-bb7d-e0f97f812c7f"],"1478497634":["aa39fe89-065e-45bc-9556-f18f0209ec7b"],"1479850230":["f9b51c9c-3976-4b82-85cb-157d918f19d5"],"1482655377":["a0a77edf-ba2f-4f76-b268-ac4f5264fd24"],"1483847439":["04780f4b-fa29-49aa-aedd-3d5a51c8be75"],"1483978172":["d92ccab7-3b6b-4062-9819-39b8abd2c5e7"],"1484163041":["4664c383-95ff-4155-a1d1-e73f77f6a9d9"],"1489227100":["687d8736-888d-4cbc-bf60-8dbfcb2a7583"],"1489270755":["a1c5807f-3c8e-4938-a6ec-d9a58ba55926"],"1490155264":["2fd06980-6382-4a8b-875a-3c1d4017b5da"],"1494404288":["c6a7e124-56d8-4cd7-8f5b-dcf4a99646aa"],"1494426619":["fa2cbf6d-000f-4e6d-be29-87e07cf66997"],"1495567366":["2a8b98e4-a99f-4f10-b22c-df92128b121c"],"1497185032":["eeda4a4a-a0be-4259-8372-edf00f2646e6"],"1497509167":["4353484d-8332-4bff-8576-bc2bb33de2e9"],"1499111405":["fadff827-3449-46f2-b83c-75b85ad955fb"],"1500255075":["6c8bda29-80b8-424e-b81f-2be064bab38a"],"1500837913":["3405943d-6264-4eea-b193-ee3f1b13eca0"],"1501123282":["543e8d42-7f5f-4505-97b4-78223d2d79d5"],"1507051695":["9e6cb536-1c96-4621-9057-bfaf366be1ee"],"1507953424":["7364a866-dd2d-41cc-a2f7-ef4f68bb5194"],"1508134479":["2b795794-1b0a-44d8-931f-289da14334e8"],"1511620759":["ff88914e-12c1-4b4f-8af4-bc408e2463e9"],"1514625917":["e4b316d1-2f62-40c9-9412-4ad04d306ce3"],"1517133134":["e90a9489-09b7-43e3-9b35-5793ce93731a"],"1517202480":["3d00076e-464a-47e1-be27-55b2a7fa7101"],"1519368269":["6c9bdaed-a5d4-4650-a8e6-3a0834445d3c"],"1519411554":["32646ceb-3202-4236-bd19-959ec5a03ba2"],"1524598866":["7d9660fe-f1bb-4789-8ee0-1a35ad566941"],"1525173266":["7284c80c-c99e-45e0-bc80-91d47ecaa84b"],"1526090976":["b0661611-c049-4b62-97ac-18b33c2a819c"],"1526759846":["d0efa1c1-c30e-4ea4-ab91-4b33d4e145a2"],"1529516548":["d3da43ea-1b20-4a4e-891d-28d66185f930"],"1530424574":["fe53e37c-2581-478d-a81d-27c4766e0826"],"1535086873":["49b595d5-282f-414b-ae80-21460eed3c9e"],"1539244914":["3b9ff0f9-75cb-411e-9f10-e044f60b9d3c"],"1541899612":["afe70dea-bae1-431e-8b0b-c76c35e08602"],"1543631718":["01c1b5cd-a43f-460d-a2ec-8d42284b477e"],"1547321604":["7f0a60ac-cf4a-493d-9dc3-cb73f50e3d20"],"1561515062":["2d5321e3-2bb7-4595-8b7a-fa0f5cc16e24"],"1567841403":["b051a1bc-fa03-425a-be7e-87e7b602e37a"],"1567984751":["9ba42614-ccb4-4d88-9d5b-09846092862e"],"1571689261":["de3d26c0-89a9-4286-9251-16a1c2375e45"],"1571920788":["76bd8b84-d971-49c7-a748-4078c754132a"],"1572163270":["d03780d9-31a1-401a-b18a-c37d4ed183e7"],"1575243522":["0e3c963e-3a74-4772-8cfe-b5cc6f15a3b6"],"1576928366":["997cb84c-1e0f-4da1-95e2-e43271afa4be"],"1577374655":["a1101238-35cd-438a-bd3c-d5f86ed63dbb"],"1578332293":["52f1a41c-1d26-4dd7-8e3d-a2444936e9d0"],"1582853845":["b69e4f79-62b5-4196-b4e4-d769adbda90f"],"1583333636":["e9a3c231-bef4-42a2-b8cb-93992837c989"],"1583934982":["26b26444-8cbd-4246-b5fc-5cf404aee289"],"1586472390":["09b281cd-5ba1-43b8-a212-030599918751"],"1588282828":["c264cbda-9afa-4cb6-a1c4-a7f4a681a4b8"],"1588448928":["52b6d19c-8a83-4fbb-adb8-782c50541f53"],"1589965971":["775c63fd-3bd2-4066-86c3-79a68f42572c"],"1591798302":["d909b7af-365b-4309-918d-737ed76649e9"],"1591979156":["3214bf7f-d4bd-48db-88a4-481534c6a1a4"],"1597593370":["63b57e9f-e80b-4757-a149-bce68f0daaac"],"1598000006":["037be2b9-57d1-458b-bb7e-fe6432725d7d"],"1598197923":["4c097cd9-3f8d-43f3-8e09-6d46334e5f92"],"1598338566":["29f80d34-eec3-48ac-9e9d-335c6d4c072f"],"1598520747":["ea9b0f3c-aeb2-4601-a2df-1be0381b17de"],"1598610094":["1500ce16-bce9-4200-9c71-51a8289b88a6"],"1599524640":["a2c0ffff-a97f-4507-9a51-c121e1584051"],"1600956753":["7fc05b39-992a-477c-bcc9-5df437b4bfa6"],"1601166438":["88afd632-31bc-4fb6-a9d4-f514be1b532c"],"1605489194":["6f7e6898-cf14-4402-8bbf-0be6ed6b7ede"],"1607614349":["6b8ace50-8169-4fe2-aa69-d9ebe2f91355"],"1608664114":["0c71db51-a4e3-469a-8f49-fe4dc8ebc742"],"1611159676":["347afbc9-6346-4bc8-86ee-88dd36430dfd"],"1614044337":["80ac90f8-67da-42f8-b7d3-d34c0c2b6ab1"],"1614695704":["ea3defb6-2c5a-4be0-acf6-fac58b189630"],"1614930486":["a873cc97-d50f-48f7-b47e-6052ad537745"],"1615760336":["b527233f-f496-4cc4-a7f4-0eab2f758527"],"1619149073":["0c1ae56b-262f-486c-9010-4d8742a77e47"],"1619438396":["f73f5a44-81e2-47ed-a5b3-7a5bbbf1a681"],"1621839090":["899fd39f-f1c5-4ea6-be99-108b6a86cb83"],"1621909433":["714da372-dc29-417d-a35f-ae62841b55d8"],"1625515451":["19fe3878-5c3a-4791-8a5f-cf5e9ca56c17"],"1626844274":["bcc62768-578d-4470-9827-4dd360bf6189"],"1629196292":["97268f9f-e3c9-4be6-b330-620dfacdafe3"],"1630797165":["13988548-5e81-4b3a-bd6f-d1220538838f"],"1631528821":["cb48416c-a9e4-4be1-be13-7f64e316da86"],"1633522347":["1f7a62b9-e11c-441f-b447-3104bbd9878e"],"1641840965":["60ff676b-a449-420c-a8f7-1845316cd25d"],"1642054891":["4307c4a8-68c5-4e24-97f2-70e9af48a369"],"1643488060":["173c264e-9209-429c-a1a1-653146da87bc"],"1643863403":["9a50a0f6-c451-4122-b5b9-fe5fba7ca0f0"],"1646338985":["f953d662-6c3b-4172-a985-00c1918bd5fd"],"1649082029":["f930d7b6-5558-48b2-a29d-efe98884d2a0"],"1649983506":["c10c90aa-73d0-4658-a860-d2fab31a5e82"],"1650215583":["c8fd2ace-1846-4b10-9964-6ab70102faee"],"1651988077":["ea890dbf-6c99-42ce-b24f-9e7fea4834e2"],"1653119530":["dec6afb4-1993-4303-8605-70ac9bcfc79a"],"1653412117":["e75cfab3-8ee2-444d-b436-03c2e3fb8dba"],"1653750505":["21d35f9a-17e1-4520-a943-927854304387"],"1654440355":["22c066f8-26df-494c-8ae7-27fe627e0ed5"],"1657626408":["0968250e-5354-4934-aee7-0aaedde27edd"],"1660159427":["d48b58ea-7d60-4da9-b586-b4622ee1ffc5"],"1662340341":["3c41d06b-3093-4f9c-9066-e6ad718c22fb"],"1662956202":["6f0563ab-48ab-40c2-8a8c-5d75a20d66ce"],"1665012052":["6a597d87-23ea-4d9a-a290-9b4bd91044eb"],"1665065609":["ad794b68-13df-44b4-804a-c880a94f3b27"],"1665555854":["7434fd61-c787-4c32-aee6-a13beca0b81f"],"1665713515":["7e29a184-4eb4-4df1-bb1d-2503e04bd2d1"],"1666554622":["f22e1f70-5551-499c-9dfa-b1428e10180a"],"1668223418":["131f824d-008a-4bff-b82b-64c91d98a41f"],"1669477032":["6ba3e731-692a-4325-a21d-d7e46f72c0dd"],"1672797756":["48b48fa4-7a2d-4a04-b91e-9acceb49eb39"],"1676150892":["c276f136-3710-48c3-8fe2-760321a85b55"],"1678881225":["f8a6aabf-4c99-44fb-82ee-4c5c4e7d549d"],"1679669058":["df55d1d1-16f7-4e35-b6f2-8f5bdfec9993"],"1683332089":["cb3e7e65-7c33-467a-bcee-64a3ba61e073"],"1689712057":["6561b13a-d58b-4adc-b165-534f11374e40"],"1689834824":["06237a0d-86b3-4fd4-8035-a22304622c53"],"1689890449":["2cdbdd17-5765-4748-9a76-07a5a498e7cc"],"1693148194":["6bc08b3e-c829-4be0-9a0a-f8f76f57a3a0"],"1693287420":["508f4302-148c-4c60-8fb8-9ab44fb853ab"],"1693889485":["4ce04b23-581c-4a8c-add6-16df96dc6417"],"1696807142":["3243be93-7919-4361-a1f2-67d753222034"],"1703434080":["0c3c869c-a205-4fc9-9f81-75632156681e"],"1704910712":["b25ca8ca-4797-4cdc-aa73-6e5854f96d9c"],"1706428491":["65bbdb98-a25b-4263-9d41-a2b2d3dba9d2"],"1712956738":["316a6c19-bf9d-4740-94a9-382f29edb226"],"1715118557":["fb9854b8-0a26-4173-ade4-02fe7fb7c3fd"],"1716759825":["abcce4e4-905c-4a7d-9840-573804cb0137"],"1720380888":["603992ed-f231-4c90-895d-e13c7680e71d"],"1723073047":["6f75b18f-ae24-4a9e-8042-46b9b0a1e20e"],"1728620672":["95844e2f-e7fc-4e5c-9ae0-e75491760d74"],"1729138493":["d9359220-7f1e-4b3d-a847-3c684d715196"],"1731020068":["c2383779-91f1-4b52-b684-c4dc51bcd043"],"1732240925":["be472e95-bd31-45e9-b5fd-ae72281e58bb"],"1734485683":["676c0e26-1a97-4207-a1e1-09e4b7ce1fac"],"1734541115":["7d188662-4729-472c-b369-67a1201b9fff"],"1735176179":["8f486662-1817-462d-9fb6-b3c4d336353b"],"1735938574":["7b1154ce-81ea-49f9-9b74-cebe38b0e61c"],"1737136473":["6f2d104a-4fc9-4351-be60-bb52a9b0b6e1"],"1737528413":["599603cf-09bd-4a84-9950-fc0b54205af0"],"1739297672":["28ef920d-1c66-4c4a-802a-94d9d0ee5ff1"],"1741404361":["f2959109-f530-45c8-82fe-2c0c0f432401"],"1742756840":["cdee6d6b-73de-4342-9c0d-d0e6c118cb60"],"1743782834":["72bf3ab3-fa2d-46aa-8be2-a2558db7216e"],"1749553897":["134eeb60-b073-4c8a-a94f-77aa84328818"],"1749589148":["6ad8aa25-e0e3-4a5c-8eee-f86798bede7a"],"1749644481":["2cec668f-2bf4-4b24-87e3-8bf4070fce5b"],"1750793990":["8224a4a3-e001-4d05-8153-eb6cb94952e5"],"1755007832":["b7ab3abd-a706-4d11-aa29-a3d0f4d6f3d3"],"1755558419":["c4eccd60-b44f-4e92-b644-238c0e3c590e"],"1756684421":["c698e970-ece8-478d-8292-7cbd04bad8d2"],"1756769087":["3961a9ec-37d3-4e66-9305-96fab9d8b5d2"],"1756831322":["27b6c0c9-5560-4aa3-b8a3-416c77b1d950"],"1757339156":["2b56e65a-5383-42d6-9a7a-bb6941923dc8"],"1760089700":["deeb8e6c-e905-4b70-b1d8-71166fe76f7a"],"1760445378":["a007b058-6947-46d3-b4b3-931deeefb312"],"1760887187":["61cd6300-5ee8-4362-83c4-bc247a70dce3"],"1766496233":["8d0e03c6-2d88-40d2-ac19-9f5f61ec24bd"],"1767641628":["ae080bcb-1fab-4508-b35a-0d7110e28528"],"1768810976":["2d7ae04b-8b1b-44cb-9f2d-190f36022f17"],"1770041773":["6a28bf08-429f-41c0-bcc3-7ebb520e0d95"],"1774455779":["0f10b87c-68bd-42b1-91ed-643e1fa70552"],"1775307344":["85c64763-56fb-4f98-a17c-04d830b69a50"],"1777299294":["24bb3365-d662-43a2-a643-dabb72474343"],"1777537625":["ec5fc6a9-7cc7-4c62-ada6-bb21ff9323ef"],"1780351112":["0350e780-e65c-4188-b651-15c98998e7e0"],"1784887691":["11729846-ebee-429a-9d18-e26e159a47aa"],"1786052405":["e889f749-f79c-4d86-8acc-226fc49d04d3"],"1792328743":["b71cee4f-c083-4e7d-824a-d1210e5c2b41"],"1792361889":["3b5b4ac3-e52b-45f6-8df0-7ebb224ccf0f"],"1794210479":["a94efbac-494a-4d53-9e61-5b98293b117c"],"1794860087":["88ead5e8-89a0-47d1-adfa-b32e3771ce9d"],"1799038738":["b14da689-d5d3-4bde-bb69-68a7acbfc977"],"1801425513":["8360a0f5-0eec-4c7d-872d-9446378190cf"],"1802392994":["19a4775d-6524-4e8a-adcb-45160b516346"],"1803526901":["9b38db6f-4513-4c1a-9311-ae69dae77cd9"],"1806881057":["ad3c19c9-20ce-4772-8579-7a10b3df7c4f"],"1807190379":["7dbcd202-e6ea-4ffe-a290-a413ffbd99e3"],"1809262810":["47e016fa-e694-436f-963e-18725142da79"],"1809654784":["18ead723-0e39-4b1a-a17e-132563612edc"],"1810680943":["31aa46e7-fe23-4dcd-819f-fc92f9aeba77"],"1811342939":["b1c4a230-b828-48eb-9f8a-c5460d46e1b4"],"1811772618":["55183cc9-dae6-4c91-a6a2-e76d480225c7"],"1812526842":["185ac316-2eac-4838-9d6e-5392b261b44c"],"1813330666":["96152890-8042-4d07-93fb-324991215b18"],"1815598703":["da6c575f-c0bb-4155-b4f4-7d19ddc373f5"],"1816527887":["d870b828-6dcc-4677-8fac-25201efc5874"],"1817788883":["ad93287e-8cb4-4edf-8eb8-cab45dba6ca2"],"1818041932":["83f807f0-68c3-4486-9a15-b668665b803a"],"1819395174":["b64865e0-be1d-46b1-b557-ee9d1177cb9d"],"1819860585":["7cbb8934-89f4-4e73-9ade-de9dcf533896"],"1820140969":["9ed60ddb-a14c-4b05-a1e7-a346b389b573"],"1820861845":["f1395f56-75f4-4639-a41c-63f6159f7302"],"1820909024":["84a9f355-f5a9-4dcc-9281-75d01f0b5f1a"],"1826605662":["3493e6a3-9a9e-4a4d-a513-450a914f3d0e"],"1832242434":["438ac4d4-6ad7-4678-8bae-ba01f0847692"],"1834992349":["ff08605e-4ccc-409d-9277-4b7d10e232be"],"1835633113":["82da2322-af79-4667-b564-258d09d12358"],"1839334437":["e423e617-e4ac-48cf-bd73-d9c0ef45bc44"],"1840134346":["8d090620-953b-48a9-9bb8-3fe6bd0f3af8"],"1841371617":["cd60ecea-3433-4a0d-8fdf-16523a9ee437"],"1842107419":["4709320f-4801-481d-b484-cc75ecc0c120"],"1842523621":["d3e39182-3916-4946-b668-f2396c902855"],"1844344875":["fe4a391e-43f1-4289-b7d9-c827cf7dde8a"],"1844400812":["9c77a595-462c-4935-be11-a0b1bac08002"],"1847282152":["9d07b2f9-90b0-4571-ba5e-00c10abd962e"],"1849609242":["dbf00824-d137-4312-af85-a286942b38b2"],"1853201430":["6224992f-cb9c-4a93-8149-8869a50ab9eb"],"1853277637":["65854bed-1a04-4e4d-9abf-7fa305c38012"],"1853568917":["beeb28cd-0658-4052-92b1-a198b00af325"],"1854407254":["9da88e7d-cb0d-4180-9f0b-6441bc38f7ed"],"1855736899":["e7485b1b-4137-4b93-9639-57db49b384a3"],"1862081224":["ecd925dc-433e-4c9b-9d28-c96b6d880b0e"],"1862230878":["c4d3c175-0a37-48db-9a2f-0fcb62b40ad8"],"1863805844":["8d8b53fa-4255-4e3c-8b58-07b9a1eb03fa"],"1864720656":["8d5a4666-6814-4d8c-a5a7-8e93b9b4321e"],"1865684379":["960ae934-aa23-4559-a921-3af15dbf26a8"],"1868081834":["98584169-0c0e-480d-9edb-a0ba3f88b738"],"1868875534":["459a5bc5-71d1-479d-a8a0-8e53abb67656"],"1869075437":["ef9bdb3c-25c5-48e4-b5bc-91d0f4614167"],"1869738234":["a4d64de4-deaf-49ac-ba12-e1d3ff956614"],"1871991178":["a31c1794-def2-4b3a-91aa-8c041a64cff1"],"1874903734":["40992ab3-c8e0-4540-a647-fb61caa83791"],"1875236294":["7a68d1a3-71da-44bd-b047-62b79d861ce9"],"1878364746":["b95973d5-20e1-4c13-b64a-e6042844ba30"],"1878447328":["3635469e-152a-4952-9262-307240731b7b"],"1879851114":["0191f095-074d-4785-bd38-d102713935e6"],"1880377912":["638b32b8-e2d4-4a69-a7d5-669b63c247c5"],"1881236576":["02b5694d-a9a5-4b43-ad01-e12278023284"],"1881635595":["0ee24cf9-b0af-41dd-b99d-f8677778c676"],"1881952299":["ac8fd655-8f3e-42ba-a891-0d958171b67b"],"1882014712":["0f418d09-ffbc-4163-be1a-2319f92e96be"],"1890289408":["f45af863-78f8-4e9d-9a1f-5c1862030ff6"],"1890879919":["0d23ed9f-069c-4dd5-9287-dd53e8c16f3f"],"1892991813":["c5c08a29-107a-464f-b2a4-906cc27855d9"],"1893252855":["31237155-9261-42eb-8ca1-f7d6946fb089"],"1893898197":["09ffee9a-24e4-4ac2-a960-a7642d3382b0"],"1894583856":["4f92a692-ed19-4b3c-8b80-bda3da891b32"],"1895820904":["da67f714-5445-4ef0-8539-a17679027f82"],"1904660049":["cb743032-7221-46f2-8e23-ad7af56ab9ed"],"1906988706":["7dd674eb-bca9-4103-b037-4a6c5a2ace67"],"1908934904":["18477f6b-3d21-4d10-9867-08f41f6ed814"],"1911895143":["f2f9b5fb-7784-473d-82cf-42178f020d59"],"1911927678":["b7d4efb5-4497-4ed5-a22c-5a141e2cae72"],"1915937915":["fb372b96-5622-45e1-bbee-8c8020dd6fc3"],"1916743442":["da00bf09-da92-4f3e-9320-57b3cb6e72ae"],"1918166761":["cf4ed58e-b64e-4fd4-bb24-a7696146e1bc"],"1918994942":["8ea4b73e-2e3c-4e34-bd80-09216ef6f2dc"],"1919558641":["7ff4d38e-797c-4c86-9a8d-184f9514879e"],"1921272035":["de4a6a21-4dcf-4db2-80aa-4124a554c357"],"1921454394":["72167a42-e08f-4c43-993e-3e845313a6d5"],"1921631332":["f51dfa50-e0fe-4ae8-9acf-86d61bc53f92"],"1923603161":["9e515664-33b1-4e58-905e-ef472649c3e0"],"1926058123":["d3c0dbd5-d8d4-4477-b434-a3fb39529842"],"1929512766":["96d80cb2-9596-453a-b504-67f9c31e204b"],"1930181255":["5cbc547b-acea-4959-8776-2eb61e8ac86c"],"1930563854":["72c9c8af-3b32-451e-90c2-271e13a3b073"],"1934560229":["48424c3e-9393-4f96-b8d7-f9f7f4ff9ecd"],"1936567183":["466e39a9-a055-49e6-8fa1-56e2e3d1071f"],"1937209074":["17630fd7-d8a0-491e-8c95-a6076e8cec40"],"1937335474":["5c48f1c8-01cd-47a2-add8-b6e0f8a74ec3"],"1937958434":["f309759e-402e-4a78-b02a-28cf725bf8ef"],"1938239823":["dd882fa2-0e7a-4c49-8c21-e2fc8caa7533"],"1938956015":["071ba8e8-3b70-46e4-8819-6e8849c2b155"],"1940859527":["c39e6e12-f9a1-45b4-a781-0e4813a1fe4c"],"1941426232":["e103f111-6527-418f-96db-261451461298"],"1941645871":["c13a499c-18e3-449d-9d41-0d481431d0b1"],"1942521323":["8ee7053d-01ff-4b2b-add5-332288e87893"],"1944810129":["9096da03-f413-495c-9144-400d3bb87030"],"1945307877":["cd2f9d62-1c91-47fb-8e64-ccb203f611cb"],"1948348894":["80cf50fa-cac2-4819-bcf9-3aa835c87d49"],"1952255056":["050f46e3-5cf2-475b-9999-0501adb7df91"],"1953694350":["a2122eb0-0cb1-4a23-929b-18b54718b103"],"1954446874":["1565578b-a1fc-4474-87fc-3dc1d17fc55f"],"1955864888":["4b02ad2a-8425-4b0e-986a-ac597c9ae6f8"],"1958911901":["efa242c8-3265-4a45-afc5-35542cc655f1"],"1960643081":["5418d067-31ff-4c2e-9043-3728b1ce2234"],"1961438058":["9878566a-1862-4f24-9085-e92d3758418e"],"1963749726":["75beaf72-2385-4d3e-a6bd-e851cdf50be1"],"1965724919":["cbd9c01f-520d-4ffa-86c0-ba1e20fcdf45"],"1976577947":["d6c9ff11-7e9f-4280-9b97-c37783e8bbde"],"1976911436":["8bae1fa2-0d5b-4724-8000-f1469576255b"],"1976929821":["168cf37c-3c7e-431d-88bf-d6b8ac8fc6cd"],"1978980647":["1d66f400-0d52-4d14-8be1-6aeda4d3650b"],"1979662680":["66f1d10b-43ec-466e-858d-91091a942aa1"],"1980255703":["cf10c556-bff7-492b-8c52-7da71f879e37"],"1980349599":["9568cb92-eec5-4fae-b196-4a049fe0f790"],"1981421500":["261ab86b-6669-47fb-81fe-9a9ab237a1a4"],"1983034306":["8518bbda-362c-4264-8ce5-2bf0ced6412a"],"1985637782":["bbb499e1-550c-4858-b789-de31b157350b"],"1990993782":["7bc32c1c-4d93-447d-9e75-77df012738c1"],"1994812270":["114f1e19-b17e-4cf5-9d20-f84ae3dc880d"],"1999741980":["9e5e4870-c755-42db-940f-e5e28b1d22c0"],"1999806024":["ced49039-a246-4786-892e-aa17eba031de"],"2001022950":["86d733e0-772f-4bc7-ab0d-637c6b045aee"],"2001866528":["26e3028b-161b-42f3-81c1-bbf03f7682db"],"2002308339":["da7a483f-c909-4719-b7bc-5f163bc6a640"],"2004698766":["5487492a-c912-49a5-9752-f966a2656b81"],"2006158215":["b8c5c5cb-89c1-4455-b34a-91b372f050e0"],"2006268128":["cf4d3d16-1452-4591-b180-d5e27d56ca5a"],"2006322349":["29300a3f-4e8a-4db5-acf4-be0bdb6ff36f"],"2009737125":["3099db36-40b8-4407-9ae8-9d3dea507b35"],"2012518001":["4dd3ec68-3edd-4562-8029-47ce3f51630c"],"2013424157":["455f0f2a-083c-45aa-a7f7-7444154f9d22"],"2013736477":["1a7195ad-3fd8-4b64-9bb6-212579f2b84e"],"2015011644":["9601518b-9e8a-4243-bfa5-0e53732674b0"],"2015415758":["24e1c7f4-92d5-4cc2-8532-d854de2cd8c9"],"2019787196":["b1511741-5751-4271-ba98-a21ea1bbd7a6"],"2020528599":["32bf022c-5c97-481e-b618-d1f066304acb"],"2020886933":["c8189035-7837-42fb-9959-08d6978ab3f7"],"2021692541":["129206dd-6c52-4972-8a1f-c4d4757b9751"],"2022060524":["888ff935-bd19-401d-a5f6-3fb04a4e6bd6"],"2022320907":["4613bb85-dd04-4047-ba6e-098ff0927ad6"],"2030141447":["a907d362-0b8b-47d4-95b7-0e0d324d4cf7"],"2030438206":["4310d073-f240-49db-bd70-6f3f04e96faa"],"2031548496":["dfb7dae2-8d17-4186-9306-f4585036a9be"],"2033115707":["5df8686d-6530-4693-8a39-d0ea258139fc"],"2034798801":["6880bd19-a67d-4c5d-8c59-faeae499f36a"],"2036886367":["b3cd67d7-710c-4e19-99b3-631e76e5fef1"],"2038394380":["cf1e9c5a-4b25-4b72-8ac9-237f160f1fc3"],"2039331102":["22ef94be-b42c-48a1-aed1-fb12e4fd0be5"],"2040841258":["4a10c229-c59d-444e-8f41-f7ad9c31bf04"],"2043104273":["b66db5e9-cfe9-4b56-ae63-b23c7983e6a0"],"2044459712":["e7ec0337-2569-4965-b894-199760565e3d"],"2044580993":["67e3599f-8718-4917-9890-88b16e5f9b08"],"2048554020":["eeddef85-9343-41e5-8bf8-29ecbb0a1be7"],"2054345189":["76349b5e-c433-4a13-b0b7-55626569f8dd"],"2059937492":["76f68b83-bb10-4831-9e87-eb09b4f31c26"],"2061812015":["e0471a57-9415-43f9-8b78-c1a25bc95a26"],"2065859654":["a4eb4e47-3952-46ca-be12-3b92e09a20d1"],"2067657633":["cfa9fe1a-df03-4b66-a698-db2308dddf73"],"2067688136":["95a52022-820f-4763-9480-374c77bba7e2"],"2075850409":["8f1a52f3-f6e7-423b-9969-fbe204e68c91"],"2076814543":["618650d2-6a00-4833-b560-d22003f60f64"],"2077699771":["cf4ee064-58b3-4ba4-bb72-f35b87b45ea9"],"2078737558":["ba182eeb-c198-4991-9f39-c6df80d70906"],"2080495955":["3eb98e95-7869-4493-bb45-a1c916186f58"],"2085597786":["1fd4ebdd-2e8e-4a39-9e00-8d6aadae1a1d"],"2086003364":["f745c269-0932-4aa4-a5e4-807f4b37fd64"],"2086507977":["3b49b89e-d262-4235-bf15-a08f663b37eb"],"2089473306":["4d0a4288-37e8-4e03-bf46-5aea9faafac0"],"2092320191":["af6ab83a-ce1c-4c54-bb8f-8d8827c605e2"],"2093796967":["b1ded8c4-3138-4b9f-ad3f-6362762dc23b"],"2095649503":["b3bec075-bf21-4955-8f9d-00e4d704e2c1"],"2096066013":["55388d6e-8f75-4240-aac4-348f068b4bc5"],"2097638423":["828cab97-402d-4df4-8b05-307cc7749109"],"2098891173":["7d444f3b-4978-4567-be08-27091e696f05"],"2102233860":["6c3de9e3-ac6f-41d7-8be8-d0f7d52c0977"],"2102870981":["2f3b5fbc-aada-414a-a2c6-34df57c0ff38"],"2112736529":["d2f2f306-6574-49c6-a693-cdbf0b75804a"],"2115148220":["95c02ad0-0e09-4558-9108-c03916f0b432"],"2120599664":["98d181f4-40c3-4762-8f91-c1f169ed1f9f"],"2121269688":["d92c8a30-12b5-44e3-8bbb-e5724e8d3987"],"2123626049":["1d9fc928-0d97-4df8-93af-d6a2aabb0041"],"2124549074":["a7d6b3d8-4e7b-487d-9a78-a88828600bd5"],"2127750481":["b6f847c6-5bcb-47c7-ad4f-b7432cf61844"],"2129781194":["45bc5e8b-d988-4199-bcd7-62c0b381a1ae"],"2129847588":["93a0c55d-7ffd-4bde-b7fd-80f7254b3e76"],"2130907011":["a4758a5a-9ccc-4c08-9776-77695a27ec37"],"2134917589":["0b345c7b-7782-42ac-bd7b-1461b3d91ae9"],"2136546235":["20b3d3db-677a-4d07-ab96-ae169fcb07e1"],"2136879577":["8c97e1b0-2e64-4996-960e-5a3654ed2bc4"],"2140159186":["08afd1fc-6fbb-415c-971e-4767eac4d8b5"],"2141001110":["ade50701-9dfd-4db8-8a24-31038bcdddfb"],"2141672512":["72acbc26-0334-488b-84c8-c23c62706194"],"2142184247":["52c5734c-f027-4d7c-8e7f-5727796ed45a"],"2144287586":["14002a12-6311-4e0f-9589-7fe8ca1bbdcc"],"2144381069":["963586df-5d60-42d6-acfa-a674eb85c3b5"],"2144811926":["20db8f2c-51fe-4d65-8319-41f50b91e03c"],"2144938522":["97da05c0-cc3d-4c9e-8ca5-00f61d2bba69"],"2145004806":["eea13735-4e7f-4b4a-9a94-172af96b145a"],"2148934932":["fd1545e0-9209-416f-bdf8-283821e4b2c2"],"2149494902":["847a1b99-dc80-4cc6-9640-519a8e40befb"],"2149610779":["88ef246c-755d-4872-8d25-b45b9278019d"],"2150314259":["c36da87e-41d6-4ecf-97ee-8bf977f4b1e2"],"2150872272":["91a274c1-3904-4250-8286-9e5e8c6ef500"],"2155756239":["72ea5fbc-a28b-4e39-ac45-c7d7b57bc748"],"2158874260":["3d8eed81-9cb4-4803-8e9e-2ec6d6bb4f79"],"2159402685":["701958a1-3dac-493f-991d-4ea701013f69"],"2165041282":["e4746daa-caa3-490a-885e-dbbfc619339e"],"2165480263":["8e018858-0430-4ef1-ba2d-153e600277ce"],"2165862814":["84b011a7-1f4e-411c-9631-22ab8c8a1f34"],"2168644513":["7d328e80-3d14-4acc-b31b-c6b632d8a0b6"],"2170043944":["f7923bbd-aa27-41e9-ad7e-4d5ca803e375"],"2174935954":["a6daf6af-d98a-4e7d-94d1-9cadb26239dd"],"2178895764":["325a77eb-5f0c-43f4-914b-29db3f921d71"],"2179938862":["c280a938-ba31-4386-904e-552bde60bdb1"],"2183845463":["446a816b-949c-40e7-ad98-ba2064b17039"],"2184524096":["d749388e-11f9-463a-9c91-ed35ed64ffea"],"2185021617":["86a6a24d-6d72-47b0-b7b6-6861da356db9"],"2188050224":["51c3c8a8-ee74-4c4c-a2a4-f8d9e6893e3b"],"2189641074":["45c7b39d-d2d5-4d30-b6ec-8aeeeabe9783"],"2189720085":["a26d9b01-771c-4089-a357-0d4546051bdc"],"2191638838":["093a0ba3-9fdb-4920-8096-1478a73d0638"],"2194547739":["70c915cf-3251-4fd4-b1c3-d467061b4440"],"2194796616":["dbab204b-7dad-44e9-a9b7-861801625ef4"],"2198643961":["63b1b010-05a6-4b6a-9d07-fc9aea3e4027"],"2201722110":["76f725d6-7092-4851-883d-c184c7e579fa"],"2201837748":["a0f97380-c39e-4b05-893a-959fb4202f98"],"2202406266":["54935cc5-6917-4e50-95ad-08b834cf86b8"],"2203569988":["131cdd64-e5ce-43eb-875a-c3b5264fc545"],"2204734350":["06d8e16d-9817-470e-b691-ccc5c8ecae1c"],"2205453027":["133e3545-cce5-40c3-8eb5-c2f047fee752"],"2205661200":["bd132ecb-0e11-45f6-81eb-54122bc08d25"],"2209609506":["7d820f7a-5252-46dc-b1c8-62696f57d706"],"2211460097":["ac34802d-c1b8-40f2-a672-0af255881913"],"2212924625":["9739e432-c1fd-44c3-a407-81e816f9e91e"],"2214914917":["08ee2e17-f0c8-4937-a32c-02004d7ab4d6"],"2216598841":["e69482c7-81d5-4930-939b-7e600a8e7b2c"],"2218221050":["06790174-9895-460e-9a0e-c279d493988c"],"2220178525":["9abf4e69-21d2-405e-bc85-1abc2e76afad"],"2221423418":["8ef91d4b-9089-49f3-8c66-dec917b5ca72"],"2224677789":["ff7ebdc3-da5f-4685-b6bd-a5108b6269ac"],"2225794099":["896c58a2-6cf6-4632-beee-1276a513c622"],"2226480186":["c2892429-e2ee-4f4a-8ae2-a16754aa8469"],"2228924565":["0ec32acd-329f-491e-94e5-c4ffda0c53e9"],"2229035819":["2a2018ae-02ec-4117-b288-182865fa028d"],"2230974872":["50221986-f10c-45a8-b56c-04011c05a5bb"],"2234110673":["d5c60aeb-350d-46cf-b99b-dae3e72e8de6"],"2236571285":["a5a32970-5fa9-4edd-b21c-ba3cd4f4f5e5"],"2241970736":["01069b98-ee05-49de-9b34-6af35a6b07ca"],"2242384802":["ce39c4fb-d291-4766-88e1-f0ee2aadb3e5"],"2248506230":["f6adbea3-8f5d-4209-927e-90f92a4bb9a9"],"2265608119":["1a781e15-5889-41eb-9e84-c05096d84970"],"2267645311":["622e1cf3-0bac-4bc2-a804-cbb663fb0aa8"],"2270094796":["1ee342b1-96b3-4a49-9c4d-4a9a13c49986"],"2271605547":["e8fc1f3c-bca4-40a6-98b5-bbbecafbd2be"],"2275209790":["d257054d-e2c4-4548-8e14-79c8100b76f6"],"2277645271":["7ea6ea1f-3010-4f43-962e-cab01ef70108"],"2283787469":["eaf48806-3909-4ff7-87e2-15fa7d4eface"],"2283994067":["9e5ee15f-194b-476e-b27c-637a02c3bbd8"],"2286032439":["092fd9b1-f44b-4f02-a3d7-6fe832b24323"],"2286304591":["93c6aa15-b8e1-49ec-8f2b-1ba5c3fe8165"],"2287310892":["c498c501-3668-43f0-9878-ff1ab89d4d8b"],"2288567854":["fb0307ee-079d-454c-9dfc-165669678a0e"],"2288934486":["cd8f5c15-b8d6-434e-9628-a870db958054"],"2290186218":["7f24d63b-1fb8-47f6-b502-b30bf629f428"],"2290481716":["b2be4e0c-d5af-422f-8313-3f28f1ba861f"],"2296494620":["31360250-3255-4b29-8311-02f79e8205af"],"2299542987":["0aca07c5-ab1c-4c97-9e0f-7b243d09477d"],"2301553712":["ac4d2713-74d6-42aa-b231-f6b5b1b06423"],"2306026193":["5646cdbe-e9df-4aff-83ad-b032d62cb707"],"2309388400":["85f9866a-36da-462b-823c-140f8a57c8f1"],"2310823949":["8d0934bc-e652-4207-b7c5-0e67d5d7fa0e"],"2311088719":["aa1dfa7b-c95c-40ea-86dc-8c53a9ebcec5"],"2311865409":["7dd4cce8-0543-4a48-9cec-7b8e26d5868b"],"2314050607":["68023304-fb02-4b74-98f3-bbecd9bb6932"],"2314673168":["7aee15e4-1e90-4ab7-8a85-f03db5c18dac"],"2314917294":["037fd3bb-dddf-4d5f-a96e-9c5882df07e8"],"2316793729":["bed1209d-302c-4dc0-984f-771fe9bec136"],"2318288025":["f2c81bf7-11c1-4605-b1fe-89119cc21021"],"2320570093":["b6a1d52e-8491-430d-a4ef-98d1fc5b1360"],"2321126406":["b7546a52-394a-4541-9a93-7efc56ff149a"],"2322235576":["d42236d7-ccbe-4236-8010-6ac5dd5193a2"],"2323571588":["69d85cc5-2eac-487c-891a-3ce78f6648f7"],"2334017397":["23649038-b77a-4fb2-8e38-853566bde230"],"2341941618":["a47dfcd4-8dee-4418-b65c-8de8dddf3a38"],"2344068277":["b934f372-100b-4c44-a998-8a69ddc687eb"],"2344176960":["3da0c35f-3563-45dc-aad6-e2283943bb10"],"2344584803":["49a756b6-abcb-40d0-8383-1c619ed64572"],"2345749106":["44bc36e7-636f-42a3-8157-f7e9752d08cb"],"2346245096":["24018e97-9fe2-49e9-b355-f7962ee99629"],"2346557520":["a6b80d23-d592-4995-bbef-40e50cc3c902"],"2349716275":["7ea2371a-e161-44c2-85c3-c411980849c9"],"2350645151":["6a2d4756-1c6b-42e8-bc6e-5fb75e8e220a"],"2351025858":["cefeb889-cbf9-4063-b142-67e98dd81e7d"],"2356097480":["2ad9434e-46b1-4d7e-8464-f992f7da4e07"],"2357759483":["415d8578-8b2e-494b-87a6-dd571bb76ffc"],"2358238682":["9ab82417-9c9e-4a77-be7b-ee7a4e3bb650"],"2358361830":["a8902c80-7ea2-4c3d-ae02-f206010ba9c2"],"2360979095":["61fbe29f-e11b-4a8b-95ad-f12e61347cc1"],"2361658118":["d1d7d149-ab78-46c8-a6b0-c86dcd67a848"],"2364641325":["1b8b27cd-d871-45ec-b96a-c5788db41b1d"],"2364666983":["acde1aad-53f3-40e1-ab94-527b038abc98"],"2367568875":["2c54f308-34db-44f5-a002-3de943f26327"],"2368401698":["f394b376-0874-4c10-85ba-1c855ca689f8"],"2370923450":["8a7ed0bd-fbd1-43b6-abca-445670fdd8bb"],"2371155087":["2fe4b230-6da6-496b-9d0b-3586acbf4739"],"2374847554":["188fc90e-77d7-45b3-92c5-c5f271587dc1"],"2379137372":["16c430d1-9864-4b00-b7df-9f7f8e6abf40"],"2388982519":["57e5a87a-46e1-4d24-b05a-3ac42d0dcdd6"],"2389397285":["f87b87e5-f518-4c00-9770-9f142a5d0e4c"],"2391020173":["cbf4aaa1-b4e8-4aa7-aa53-b25406cb4edc"],"2392904593":["39fabcf1-ea5f-4d5c-8869-e9b2a984743f"],"2401186314":["03e64c96-48cc-439e-b7d8-6a8bf3a4ade3"],"2402288967":["529cd507-7ea0-4f31-b548-1014aa067ef3"],"2402805997":["b9b5a849-d9c3-422a-9883-7ef7186c15b3"],"2406565550":["78d24066-f389-4a14-947a-97df4c485f68"],"2407621925":["777e132b-cf01-496f-9190-677587aee5b5"],"2408867087":["1a785165-7b77-45ef-98e3-572050d82a64"],"2409011704":["728ba7ad-74c3-45dc-a6e7-542c9d7c5c8f"],"2409768041":["295e34ff-7c4b-46cd-9195-262fb1a7e683"],"2410270316":["ac695dda-7d8e-4e8b-851f-3cca9a64e842"],"2410500236":["caf8b0a3-0c9d-4e29-87b6-c1ad27621c2f"],"2413854867":["4bd28d0d-3224-4fcf-ae16-4332f4d198bb"],"2415231743":["b0409585-6739-42cf-898f-b00c5afb1436"],"2423506804":["f52cd846-f4f7-450c-aa6b-1e452cc7b08d"],"2423845396":["594eda2a-6128-4ea4-a057-615940cc2a18"],"2424834354":["34cef832-9742-4fdd-ae6a-f2a8058799c5"],"2426093307":["20bd45b3-5502-4680-a152-97d7c335206f"],"2426256412":["ecc5e1e9-e4ba-4299-9e79-4ed998e3430c"],"2426790625":["6ad88eb1-8a76-4adf-8332-37c122fe46fd"],"2428295120":["e422689e-7ea2-4ba9-beb7-0dfd977b08d0"],"2429650517":["f47e4dc7-dc7c-4f13-a4d9-810bd91c9ea6"],"2430594930":["93612b1f-cb2d-494f-87fb-e653192016ad"],"2432098932":["87162daf-7a37-4125-a493-a8cb84f7566d"],"2437869304":["3f7e1059-7e9a-409b-a4b2-80c32a6c97ac"],"2441442973":["0ba188de-520e-4e91-953e-e76920a2ec43"],"2442731580":["6ca619c4-cc83-47db-9a98-98267f75b41b"],"2443350432":["b4c0de1a-f9cd-42ee-9492-6c75511f8884"],"2444401157":["6de53084-bbf4-4b4a-a416-74ed469c905b"],"2445484256":["466348f3-7016-454d-9486-15c8272430fb"],"2446432771":["c6e38d33-0e1b-4015-82e5-80c6d3d7b570"],"2450478232":["189dd0e6-564e-4817-be0d-2974c618cc5e"],"2452183381":["a28cb657-7add-45f6-8d67-070a7dcbd382"],"2454227817":["562d36b0-6c2e-4b52-9b04-d6abcfb96397"],"2454256832":["59fb7e24-043b-443d-b78b-4fe293b98cba"],"2455152519":["a9312f34-16a2-44d5-909b-52eaae8ac9fd"],"2458058543":["e44be1a9-8e74-4a1f-ac0f-4608d3f5d783"],"2464067283":["6a97ef75-f3aa-4b8e-bc16-4dab84a17aef"],"2464571037":["92d94431-5873-459b-89f9-5514e2267e60"],"2465794608":["b421f4a1-e3d7-4519-aac0-78710c8c8a67"],"2466336466":["c0508d45-5791-4447-86f5-6de739bc52a1"],"2466768652":["6f2e2377-4f40-41ad-8aa2-9e7411518aff"],"2466978355":["257ac310-5496-40dd-9aca-eaf83add03dc"],"2468314127":["606f0641-a265-4024-b396-ab7668924d85"],"2470710019":["c19e0700-c6c7-4313-bcb5-ac3b00ff138a"],"2473768529":["0be7d096-526a-4dc4-a693-51dd5d78a223"],"2473934618":["38719923-1623-4b02-84ff-dce329c4aad5"],"2474120444":["2ab428e7-1909-4e58-8f10-0769c9c1a49e"],"2474737214":["f8822de3-b4d3-4289-9b8b-44285dde8f66"],"2475645397":["766ef7e5-7401-478c-9fd5-048b473b26b2"],"2478263265":["95732be6-d221-4861-a28f-8b45ec289f5c"],"2480338866":["ebbdd5a1-74cc-45b8-b15d-2ab8c8593978"],"2485930132":["b2f1c846-d93e-4d2f-bdfa-f01713e0a41c"],"2488476394":["699423e2-8053-4584-bb87-73de0013b8a8"],"2488546683":["0c657f75-83da-4235-a714-d7aa95c2edce"],"2488829523":["def0a083-c585-48e4-b46b-f90af653ca43"],"2489555080":["542f28fb-f8bb-44a1-b6b8-f11bd8c60568"],"2489581833":["21790ec5-fefb-44ce-8fe5-2b3db590eaae"],"2492117470":["ac91febd-0327-4d2a-9c03-1061b8f46859"],"2492140439":["de7a9d08-747f-48f6-b708-1e260a98181d"],"2496448049":["b2d67acb-acc4-4e1a-9220-4aeaef35d216"],"2497882268":["b2ed54ea-1d2d-4b9b-8fd6-821b42b5aaee"],"2504245290":["63c90f5a-c4a1-47d1-989b-e9f634ece105"],"2506267489":["5d035f0f-fc95-4dfd-a442-25d19b257345"],"2507509942":["eb656022-428a-474c-9c16-a62f53e4fb3e"],"2515648704":["32d20f62-7f07-4a22-8876-834359db92a2"],"2517045343":["facfe755-ba3f-41ae-a73b-397f17bef499"],"2520050382":["d0410231-e0bc-491f-9631-ba2b1702e750"],"2521892554":["888e87d2-1fbe-4f88-bb06-0050d44fe908"],"2522195777":["f9c40d02-4f41-4998-8d75-e772466019ce"],"2522842783":["cbf512c5-3d95-4805-8497-0466193de6c7"],"2524180902":["37a5ece8-55ee-4441-baf6-6a9d4c917733"],"2524919543":["a3fbe785-d00d-41d7-b188-931fcf786095"],"2526690955":["33a849b9-6127-4d46-bae3-94b72106dc6c"],"2531387587":["e310c8a0-a4f7-4832-bcfc-225a8cb93a6d"],"2535563396":["9359d77c-7f10-401c-833f-219e5b9c2c1c"],"2539021684":["83e18788-9241-4d65-adb1-7a6c7a518d29"],"2539610363":["d3765705-d0af-4820-805a-e5c71c09d38a"],"2539806461":["0a1742f3-8c4e-4ace-a451-8a47f545981a"],"2542586697":["884803d5-4855-4d65-989f-8066e29fa483"],"2543315481":["7950d96b-07c3-431c-80b0-5009df210c38"],"2543565737":["6214b748-d592-48aa-af1a-7f4c83f9bc06"],"2544145654":["0e354e57-1dd3-4c5a-852f-333f3549ca37"],"2545026449":["070e5830-37f0-4e7f-ab72-b8abc1e0bbbf"],"2547289423":["6f3fdb37-6f7b-457a-b4d5-802b62bcc235"],"2547902428":["fffc1f95-0a4b-4759-bd2b-a433cd0e0e9a"],"2548272210":["02d02d8b-ac2f-4344-ba1e-9da290080fa4"],"2550055745":["5a338bb7-fbee-4279-8a89-8dcf5573f3f0"],"2550245008":["5ea8f130-84bb-4e52-9d4f-8a9ca1296d5c"],"2552486795":["9992a83d-64a7-4b76-a085-8293ef053448"],"2555789288":["682872ea-a9cd-414d-b636-84a11fb7207e"],"2559857448":["7ce8cf88-b5a7-40f9-ad4d-3176e0368d06"],"2561975535":["9e58594e-8771-4350-ad70-78ec4b32a96b"],"2562253799":["6e3e438c-94cb-4863-894e-436cafc1b225"],"2564509041":["8fe72408-0526-4129-9d55-1058968bcfb6"],"2565754220":["33dcb637-092f-4933-8391-d31cef5326e7"],"2566397891":["bcc4ff8d-aa02-4205-9c10-b995fb074563"],"2567428276":["8834c57b-2ceb-4d4c-b7c5-6ae86f15f67d"],"2569813616":["bdefc8ae-df09-493c-b057-684164f23e36"],"2570092486":["937314c0-c0d7-463c-941f-14d013abc363"],"2573075239":["d610a191-2aae-441a-95aa-a472192a3848"],"2574438978":["49ec0e2c-1e42-4420-ad81-832768643346"],"2575744743":["f2d0f442-e643-437c-b43c-d43a00bf7f8b"],"2578359807":["cf81db61-f8f6-4348-af5e-57bd951031ad"],"2579367552":["15f9b05d-a01b-422c-a533-06998a8a698d"],"2579836121":["b35beb1d-e1c4-4953-bd36-747c0c75094a"],"2581385438":["4f30ed13-60ca-4d2a-879b-f598f07250a6"],"2581534729":["a3e98adf-6241-483d-8cf3-e6f95ed20957"],"2582063303":["f2b564da-e090-441b-9aac-cbd9b232af11"],"2586074630":["00106e46-905b-423b-be35-8e76a5a0ae6c"],"2587122113":["3791ffeb-9b98-4e68-bb4c-59deaa805b2b"],"2588008601":["3735fcbe-c4c3-43d0-87a0-81e7695f041a"],"2590181992":["aa3aaee9-51f1-4f0c-b35e-0c911878f350"],"2591285155":["17e35b99-90bc-45d3-b87b-6b88d79225d2"],"2594596657":["1cfcbb62-8984-4bfe-aada-b53066642cb1"],"2599279123":["030c52bb-eef0-4469-b307-a40e1ef340e7"],"2600329602":["381c4a7e-a9ed-4f36-9697-05ad903f26a9"],"2602155391":["23beba8c-d209-4864-a1c2-5554bcee4cc7"],"2602225618":["7ba8323a-9d30-45ea-9c36-f50d2a087fb4"],"2603081554":["d4f33f92-668d-4d4e-ac1f-4443687a9419"],"2604164848":["5a2bcef5-a6e2-4e2c-8746-d9bda227698a"],"2607606737":["223d61ba-9f0c-447d-afb1-2a75a95d4b95"],"2612510898":["1d90e86c-834b-4b38-a1af-11cc77834fc0"],"2613852098":["dbf865d0-883e-4b8b-be7a-e4111a03462c"],"2616368416":["7a3b3ee3-1f99-46c5-bd28-26a273addabf"],"2620019411":["35ca30b1-eaea-4113-923c-4e23e3f16c39"],"2621503905":["75fc50cf-db4d-4442-9d3c-e9e57c94b9bc"],"2623014144":["b460599c-c0ce-4c33-9fe7-0a8bdbca8e5a"],"2624885040":["84d2509b-4005-4e12-a552-88f65676b1f1"],"2625890113":["18030260-7ef8-4f38-95d1-c3309b1d1b4c"],"2627108543":["509344fc-e707-4ef6-94cd-38ecf11748fc"],"2633555175":["dd04a2c7-2eb3-4a19-84de-ecef7f207aed"],"2635128920":["125de8f2-3be8-45b4-a0c7-3f0ee9eec0cf"],"2635692656":["4a06fe37-7bf6-41fd-aa13-472dce7bf553"],"2643834526":["401bfd76-2b35-4eb1-82b3-a902646e3c59"],"2645471298":["68134338-ab1e-4e05-b17d-62cc8119dc70"],"2647913628":["ea86ebfe-29d5-4a76-9d8d-4692ffd3c6ff"],"2651205745":["a340038f-9869-4198-939c-e802ddd64c14"],"2651843942":["5b35623d-e002-4597-92e0-ca78b4894c65"],"2653427703":["1c40a923-3c73-4aac-a6a7-a95a300932e6"],"2654274280":["20a85fb8-c56f-420e-9671-460304d40bd5"],"2655771837":["8623ca4a-d3cb-401d-a3ed-8a47ce4dcbc0"],"2655972516":["fbe0dcbe-656b-4a8f-ac22-50358dd1ef82"],"2657091893":["b3e29d68-0134-4c0b-998b-d2c800faf295"],"2661076286":["4262572b-6b9f-4a9a-a838-3f746013dc0a"],"2667089977":["f4bd15a9-5bf0-43a5-ab6d-04a5600a811b"],"2667649759":["5b43d514-2f89-4df2-8118-25aaf642d5e4"],"2667960500":["d9c67fec-1530-4023-b052-214cc8eb653f"],"2670257763":["58453007-1111-467b-b655-bacf9b2d2af3"],"2671950063":["d77ff7b0-da76-4925-915e-2d12273819b5"],"2674346645":["ef1490ed-ae56-46d6-8469-eca7a185cdce"],"2677389657":["229f91be-b7e1-4b08-b8f3-6249c18e56d3"],"2678232941":["5790eb59-4da7-46ec-b80c-7138b717f447"],"2678255302":["9cf87265-1d62-4d57-a5eb-1fc14059790d"],"2680724817":["162ef0ca-b83f-4af0-bf8e-0c3b4c4e4b26"],"2683670482":["589f33eb-6557-4ce0-9d2d-cda9573e5365"],"2687703508":["e2b9f07d-0594-4db8-a601-e478a4274b84"],"2695063751":["2ecf9614-a8b0-4e6e-928b-f7f92f0cbab4"],"2696872648":["d905ea22-e5dd-4c09-85a1-538726de4d98"],"2697133519":["a4e5a89e-eb40-406a-9d0f-32aa4c9debbe"],"2698436352":["2cc785b2-3a5a-402b-bdb5-d00ed018a3a8"],"2698506236":["f2da88f9-02f7-4bf4-9c02-3b98d9e34618"],"2705031741":["a9187d46-90e5-4f40-8175-7e27aecc3ae5"],"2710926289":["479d63b4-5b80-4f35-b13c-d3c62043ca39"],"2716088855":["7cd2f34b-9b04-481c-8f81-420b14b4ee9e"],"2716793272":["c39ea286-ed32-4450-996d-8d8a24b8b024"],"2717526419":["9a3e49da-cff4-43bb-b25f-71c6eaf25951"],"2722992986":["efe4f2a4-f218-4353-9a34-c31c39dd3be8"],"2727079114":["a28f9d30-ae62-49be-abda-1d60e02e1dd6"],"2728092255":["75e1d38c-63f1-415e-9bd2-1c0e3eb93bc6"],"2729164300":["52bf9f48-c8fa-4afe-9ca6-4d99f018edf3"],"2730900216":["fc38f5e6-a4e8-484a-8991-a47c9052c3ab"],"2731104757":["1b9a61cd-c7a9-4b96-9ce9-286a4bdc2f85"],"2731479579":["1eaba1b8-3543-4138-9544-85f50fd6be78"],"2732181160":["d0dfba57-1b09-41de-ac47-c22399442bdc"],"2732434483":["130bf118-4946-46b1-9b5c-a8cc188588a5"],"2732721886":["1afc7771-ab81-4919-82ca-b263392cac28"],"2732899936":["6583b783-8cb7-4a13-a405-137ba74b5c72"],"2733869006":["413bf559-7810-458f-83cc-de383a1bb87b"],"2736874201":["61e993ee-42b8-4912-86ab-4eadc7d32c87"],"2737493368":["74b933c3-d6b1-4f8a-ae1a-7e5fc8626ca2"],"2738515914":["5d0c459e-e347-4f1f-9693-fc13af9acc8f"],"2739018073":["8aff9be9-9628-4626-b9c9-80ceade3e90e"],"2742501780":["526d010f-00f9-4d79-818b-ec4b8f0308ec"],"2745370129":["a334900c-9299-4d2f-97e4-c338c8ee6fe7"],"2748236629":["e6bb4aad-6317-4ccb-8a30-1604d499ba41"],"2750407937":["803f4cc1-1313-40b5-8d85-78488648dd9d"],"2751703097":["f8ec3257-6092-48f2-87e7-46289cccacd1"],"2752622249":["b9754266-39da-4348-b0fc-dc340c95aa92"],"2754160646":["c2f1e397-da38-4d3e-b437-ee334355d2d9"],"2755513387":["6ff02d65-8d49-4648-9553-9c8940adbfdb"],"2757001399":["d3e55775-476f-4e0a-9ef7-51e932fdc4ae"],"2757446386":["9b667131-ddb3-4ae0-bdb9-45a9f3d2166a"],"2762981992":["039e2090-24ab-4f32-9391-86c608b9311f"],"2763187724":["975908a6-ef29-4c95-8664-d795f4448d78"],"2764432700":["f906d180-ddef-4dbb-8353-17ad5b0c96ab"],"2771063623":["13edbf9b-3efb-4789-b303-22f1841d375a"],"2771508529":["51fb3506-7003-4701-8aa3-b364400954f6"],"2776901494":["19707a1e-53cb-4f62-8316-08a4b83d80ea"],"2778166138":["9bd79ee5-5ade-4083-952e-69c05142f267"],"2779248007":["fa0f2473-7e8d-484b-8398-8f9a8116496d"],"2782283579":["dabd287b-c36e-4c3d-83ad-d94b4a53a52c"],"2793695767":["0937d2a1-b0d0-4002-94bf-d35ced6b77e8"],"2794662754":["ad7e455a-5fe5-437e-a9e9-6aed66d985ea"],"2799030329":["223f174b-5ce2-4caa-a8fd-72a593b25465"],"2799567205":["3224d458-1e5f-485b-8934-fc01e70820da"],"2802032695":["6521c917-d4f1-4c78-a531-7534d3aa833f"],"2802763561":["ddd89c8d-0117-4bca-995e-bbbf45fc5cb3"],"2804303177":["928dbfb1-b2a4-43c4-bd2b-67c6ab21078b"],"2807156642":["f8502f8f-761d-485a-aa4d-212c5bc723da"],"2807733303":["21caf4a9-67d9-4360-8e26-201859559a90"],"2808658527":["ddf9439c-a9c0-4128-b643-457a58f1feb4"],"2809193253":["0c2278b6-46e1-41b1-a76a-7004fecad37e"],"2810034438":["9ea766cb-5f1f-4157-aa0b-ec98fc04a0ac"],"2812839986":["a7cfa601-9c98-4385-969a-4d3c237f376e"],"2816870237":["238f9e03-a672-4aa6-89bd-6ecfc9bf719b"],"2816923378":["b236660f-29c0-46ec-a621-18a9e13e68ed"],"2821311244":["5177c51e-66d6-420e-b898-b5d32769c31e"],"2821971602":["e1860437-87ba-40e3-bcf5-d7b32b784d4c"],"2823480473":["bd61ce02-8045-47b8-92df-dfb14c0b43f0"],"2832437193":["536804d9-ca98-4a9b-a8dc-4a69a296cb6a"],"2833582037":["671b1026-8e1a-420a-acdc-8d64427771cf"],"2835709780":["cc54b6b9-402c-4f49-9122-737251dd1cfa"],"2836132865":["caa5950d-d192-411a-97e9-366adba2e0be"],"2836217393":["a5ccddd0-dd97-4bde-a1d4-788982062cdf"],"2837302487":["a7c7ec30-9976-4d65-936f-fb5c3b6586e1"],"2837685975":["0c3ea0b7-4086-403d-84cd-dd0b06675faa"],"2838420066":["16f6e5b1-df51-44d9-8570-a3067c564407"],"2840140572":["6cfbdc2f-380e-4a8d-bd7c-578012d6c72a"],"2841267845":["0d27e46e-728c-48f0-ac4f-e182148c12c9"],"2842223618":["22d51f1a-382f-4ffb-a693-bca81a8a99ca"],"2843573407":["9c6c7744-bc55-46f8-b1b2-fa196b7b7a3b"],"2844400837":["988eff0e-7139-4088-a48a-3c8303ecbc8e"],"2847004046":["21e67989-f36a-49ff-88e1-3a966ffd3241"],"2850519083":["27af9fb2-29fd-418b-8691-5a172dd39e13"],"2856643233":["bea34725-9670-41d6-b639-51b78d6a10ca"],"2858473772":["78829ae5-ef72-4b28-8a1e-cbfb49f28169"],"2858762226":["942c1b86-11bc-4fbd-9cec-f81db8092e6c"],"2861065422":["4cb2b7c2-9053-41ac-a807-d031c3d974a2"],"2861463892":["a1e8ab2d-f1b2-49d2-b9a5-fe17def29094"],"2869628783":["57fd2939-98db-4141-8b47-34dac0fe237b"],"2871553857":["558c35d3-8418-4491-b19c-3e28d6cae4e5"],"2873270042":["2ad48625-f4a2-4391-9bfc-900aa398a2ff"],"2874640002":["7127064a-a759-4213-9094-aaa87c1ddcbc"],"2875163400":["870551bc-707d-44b8-a1e8-64a3c319f6e1"],"2878734918":["c853f1f7-8536-4d1b-8d1b-2f26cf7c67b3"],"2887055090":["6c9cb724-d419-410e-ad1f-c2d92072c812"],"2890867447":["bc8e92da-d973-497f-a8db-b62e0e54cdf9"],"2894226882":["2173f0b4-b932-41a8-aa9f-eb6c03c72660"],"2899421808":["b41a2207-1bed-40fe-ab1e-4a955bde42c6"],"2902869045":["ab0e9932-7bcc-4f3e-8cd9-1c09d8a7c406"],"2906006170":["7767f239-889b-4c9e-885f-916f8d76eeeb"],"2906691630":["55fe93b5-1b6d-496c-ab89-5d4804274abd"],"2907802632":["3cbc104a-6633-49a8-8807-b282d86258f6"],"2908732286":["034547ae-2c31-4fd3-9c8f-b03b7481944a"],"2916616792":["78a6241c-a226-414c-a551-e24c5ccc1c9a"],"2917537480":["c066d29a-1260-4692-8aa9-a8b8ca822bf2"],"2918893266":["754a712a-ff3f-4753-be5b-ec258b062989"],"2919584482":["e4a29e1b-b88e-40df-8481-ef98b2e78ccc"],"2921477969":["87b809f4-bd30-472f-8709-11f58b71378d"],"2923529323":["e4dc54eb-17c2-4e97-96e1-5535f350d38c"],"2927051187":["7fc89588-a742-42c1-aa2f-d0cb5777efc3"],"2927743176":["5c8d7b47-837e-40a9-b8a0-380068ae9b97"],"2929488401":["21237e0a-bfce-431c-bfd3-791a2b134391"],"2931179806":["005bd8c8-e9e3-460e-9e57-e4d3fa7b8158"],"2931378193":["179d842c-af1f-4bbe-8333-a18f8417df0f"],"2933304113":["261bebbb-7c64-44b3-a8dd-4e824d5ae8e9"],"2934544421":["5aa68719-8547-4910-8ea1-c79fa0b3c5a2"],"2935097120":["03d4c442-3973-4ff0-b48f-6f6f7709f5a7"],"2939911646":["db650e89-12e1-4746-87d4-310edb3b1c98"],"2940472093":["381e8bfd-5030-424a-9a0c-56faf78f7ede"],"2943752312":["3068e208-97bd-4518-8e4b-3489455752e2"],"2944058604":["af21ef0f-35dc-43b5-a4cf-5953e4b4b423"],"2948839512":["3e0494ee-e263-4a4a-8d29-71cfe8c57615"],"2949543944":["8881b76a-8c2d-49e6-9eaf-1c1a7bd3d124"],"2950325871":["80e1fabd-3249-40f1-9c08-1862d270ed7b"],"2960399912":["9762a2fb-37cb-49b0-b2fa-efdd0916330d"],"2960897309":["f6c2fbfb-98aa-4109-b8ad-6861e4929ff4"],"2965090793":["6b02b6da-593a-4782-9cfd-be26f471beac"],"2966865344":["e46a8d30-6145-401e-8951-96db5523ff04"],"2967624274":["b91be660-94de-4cf6-8683-3c911cf38fe3"],"2970838988":["eebf3462-f365-48a5-add3-5af7269dcb81"],"2973117666":["d6f286da-c628-4ec3-8fc4-31817bee3be3"],"2973157565":["4597b73e-f1b4-45b5-b3de-7c3dfa62fd48"],"2976495785":["66be895f-7909-482b-a812-5d8a2aeec187"],"2981220121":["55a76010-2962-4682-ba29-0c55844dd96c"],"2982436219":["dce20756-1372-46f2-a100-1e0bbc4cfc3d"],"2982448945":["20e9cb38-cd8a-4ed9-9e3f-70f1fdc73507"],"2983924894":["8f19bb8c-7df4-4ded-afdf-7653ccb55eec"],"2984111685":["214eac5c-795a-49ad-aac2-240d45e30a36"],"2986276682":["c051997f-01eb-4b9b-95aa-528e1537bc93"],"2993317593":["7f6e2be7-f6e2-40d7-a921-09a6cf9591c4"],"2999245877":["54037c60-ca18-4cc8-8780-63020f612b86"],"3000558435":["8a9cf8be-5449-4698-acff-f68085e06844"],"3006566059":["49190e4b-feec-4587-989a-8558ab51e314"],"3006955494":["73be16cb-7439-4979-8247-c906cecfd346"],"3007335172":["e1e62490-79ce-4c03-ba42-08ad416bbe48"],"3007711002":["47bd6d39-9063-4bea-b9ef-7a0560963164"],"3007904610":["d7615a30-dd7d-48f2-a2eb-2c80760dd172"],"3008586067":["5a44d850-0ced-4f52-a7c6-93d50a0b6fa5"],"3009514575":["f6275902-9d08-4077-bd64-25fc019ff273"],"3010932530":["19bbb56d-ee9b-4211-9389-0e9a2b8361b5"],"3011118170":["31cff877-c659-4471-a077-04b1ee1e3422"],"3014187745":["b1b1a3d5-26d4-4ea6-ac58-5a4c3a6afdee"],"3023702110":["9e38025c-e02c-4c2f-92a0-fa00351a4aeb"],"3025361602":["1462ece9-22fa-4cd1-a1f5-cc71c53a1243"],"3027096240":["9129aa26-f320-4214-8ffc-707dace1ceb5"],"3028500414":["6400b961-2cee-4c05-bddc-e86274ead516"],"3031198692":["d074f017-2350-4b80-8aa8-c75346bf2fff"],"3031513443":["9a784d23-2df5-4198-a4b5-5d965744f262"],"3031955766":["31219425-24ef-4276-812e-a417c5e9a2f6"],"3034785271":["df8f0fe3-1353-4423-ac34-8fbdcf75cbf2"],"3035007080":["bc863141-e62c-4261-a657-f1cf2a73089a"],"3038336842":["84c85910-d832-4a7e-ac42-4c63ef85e032"],"3038660287":["daf6ddc7-d1d4-457c-8e50-597eb47c996a"],"3041347348":["a3638a17-fc21-462b-8dd0-48851b54c4c6"],"3043456552":["6e1fcad9-5a42-4539-9336-6116101eb707"],"3044991376":["801ea190-6351-4fad-9811-19b9e9423010"],"3045385154":["6a93ec3d-5360-443a-a01f-8cf71976e902"],"3049109720":["fdd22754-9a43-4e54-9578-0974be8bfd44"],"3053423330":["77dd7d08-92c8-41e6-ac23-3c04aa26d070"],"3053479686":["64b21e7e-10c6-4d57-b5cf-4bc01c297256"],"3054035313":["798adc65-aac0-421d-8894-80bbddc42f5c"],"3054328253":["166a42c3-13d2-4fee-bd2c-3dd97f7bfb01"],"3058110541":["2273891d-99f0-40a9-ad7a-ca8eb5744cac"],"3058981446":["c61cad5c-680b-4047-8ade-8047e5af4522"],"3059786398":["17904826-a4dc-4e91-9401-3a0030a69225"],"3061668906":["dc4c1288-c76f-4dd9-b032-a87c18e2620b"],"3064194918":["83106cb0-16b1-49ee-876c-4cf53f4ff832"],"3069335006":["e7bd6b09-03d6-4259-a8b7-02f059426021"],"3069931823":["f6406f75-fe1d-4720-8388-1b5feaf4c7e6"],"3070074995":["793488b2-04e8-4000-a640-f8aa934a53d2"],"3070234627":["7793b247-f0ac-4cd5-9fcb-670ef3280929"],"3072881722":["2d926b14-05c5-4cea-9058-e70e0308081c"],"3074775735":["36c39215-34ff-4940-89f8-a6db748081d0"],"3081405748":["3d867364-de7a-4cd7-8dfe-2e6096c0f142"],"3081564566":["015beac7-d3db-4e93-ae87-6a752bab5b42"],"3090292620":["547eaeb3-b704-4593-8c90-44e7ad31070e"],"3090522042":["29ce30da-ac4d-488c-b65a-47074edda53b"],"3093613292":["b794ad53-48ce-46a0-84e9-1d599fbc5fb3"],"3097315436":["69e68e65-c8fe-497c-8ecb-85cefb39aff7"],"3097877769":["527f12e3-dff8-45d6-8c5f-16a6b32e2588"],"3099895969":["93766505-7c7b-452a-ba10-0661379c4958"],"3104118055":["84ff3661-6678-41c3-83ad-a36705076c6c"],"3106089709":["ea870603-e510-46df-a4b3-95c4e8c4f12a"],"3108186280":["1d365d76-47af-47d1-93c8-3e5cdd0e3abf"],"3116927034":["ffd3fb69-8009-4af4-b959-a6bb4cf07d7e"],"3117012172":["00f266bb-ab48-4954-8505-9f0bd83ab238"],"3118589324":["587b9ddf-3c3b-49fb-b955-31bca2670a44"],"3120885217":["5ef7921c-d314-4b82-89ca-881630956c92"],"3121664878":["6e480d3e-cec1-4a37-ab19-3ed010d339d9"],"3121968611":["740c5cea-352b-4825-bea2-42c4035c068c"],"3122746118":["9d27a6d7-208b-4f7e-9b91-7f791ebbb301"],"3124045233":["6d76aee7-c49c-4289-a2fe-4375ef6a15f1"],"3127453783":["adbe6e53-9dab-4407-a2a7-5f61da3e83bf"],"3128933993":["5ab97902-45cd-4402-a9bb-e94fd69339fe"],"3129374137":["775724c0-b4ec-4660-b180-4f54eae437f1"],"3135824301":["7b966a82-20fd-4196-9aa0-d68b3baa86d6"],"3136524952":["b958e72a-1377-4430-90e3-fb2ca48adcc3"],"3144724762":["5cdc9ec6-095d-4b3b-9eee-efafcd3e6bbd"],"3152428246":["f2a30d31-5839-4368-9c8e-c08e95b8cd0b"],"3153615793":["4540a588-3bb2-4d29-8b97-71f007a383e7"],"3154183917":["3fb6087a-3f76-4a9a-9ec7-69b62d15b05b"],"3154311496":["69fec033-de23-4315-bc5d-a78db0da58b6"],"3157413405":["fd029c22-382f-48ef-9798-57614a703a0b"],"3158725714":["dfd4f960-7f18-4360-971f-beed2dc654ca"],"3159416823":["bd2cf572-6365-4db6-bc9e-ac0202d4ced9"],"3160719904":["74b2bf47-1782-4e59-88c8-088799e53dbd"],"3161292222":["1f16e825-14a7-42f9-8ec9-e5db9ea4d7da"],"3161686294":["cd97bef6-3691-4fd3-bdee-dcd8ca3f2151"],"3163159027":["43c76fd5-f259-4e7a-a121-f04db644454d"],"3163845229":["33dbfa98-3ee0-4bac-8b0c-7122a83253c9"],"3164023649":["7941b9cb-a2e4-40bf-a5a1-d0baffedf603"],"3164723348":["144066c3-7892-4416-ae64-20bd03c492ab"],"3166612054":["d19b0eea-94c5-4639-ae2d-feca58be3922"],"3167702473":["a5236af8-787f-4621-8a1d-f587ccbdd8d2"],"3169416846":["d15484f5-8458-4bd6-b101-23342cce49ad"],"3169500686":["53fbad97-6785-46ca-ad8e-0b0c8bab408d"],"3170073069":["d0486a6c-afe8-4e8f-986c-0192885989b0"],"3170767923":["5a1a7ef6-04f4-493c-b6a7-491f068af8ab"],"3175570770":["3bfe29cd-da3e-44f5-9c28-d12e2501458c"],"3175779812":["2cf0b420-bd9f-4d6a-8fad-d8ea6a870b35"],"3175989496":["7eda712f-54b3-4116-8808-b3f8aca1c8c2"],"3176958560":["bb681d72-ab2a-419a-9da7-c692a030a268"],"3177677158":["5dff1f71-a5ea-49dc-b6ec-bb355a425a87"],"3178002872":["93c4f549-dd15-4119-ba0a-1dbe8967f87c"],"3179039635":["aef419d3-ca36-463d-bb29-008188887d0a"],"3179833187":["cc83f25c-b069-47e9-9ce0-b4928649bd3f"],"3180257458":["a1199307-1a69-4e84-a9dc-8ccca5ba2b52"],"3180478382":["b1236b1d-b89a-4fc7-bb12-eaffc01ccef6"],"3181003238":["5825c935-8d14-44f4-81c6-066517c1e157"],"3183012169":["6b75f4ab-34bf-4f7d-a0e6-18079e8e685b"],"3186382836":["4975c18b-8f6c-42f8-bfb0-b22dc68e96a5"],"3187485395":["bfd1aefc-b1b4-476b-82a7-708c3acc4d15"],"3188330212":["e84b961f-7031-433d-9de4-03dbe5d2da5b"],"3189450112":["aaf29799-5e50-435b-925b-fd1eebd5d52f"],"3190910386":["4b27ed0c-bbe5-4321-a509-dcc90d0aacc5"],"3193905576":["8854e20c-092b-4cfc-a2af-8330f5feca29"],"3198953028":["aef6d6fa-37e5-4092-8997-ccfefc4fc395"],"3202393006":["4cb8f8a1-97a9-456b-a187-0792390b7e86"],"3205176385":["2acc3fa1-0fd6-4928-90c9-2bd9fba84c28"],"3206055938":["12c2f774-867d-4618-9072-00d61cfc38b6"],"3207890073":["a7922bfe-f3de-4ec4-9501-f7763cf54512"],"3214983878":["bcd489d7-50ae-4fe5-aa91-f78dc2526b5a"],"3219028572":["32977b51-a1a0-4c49-81c6-80d2d2edf9b7"],"3219105939":["dd93902e-d8df-4c92-a84d-6dc0f6a55572"],"3220151993":["46a39dd5-9986-4c52-b125-5c8c1d6234d3"],"3220396777":["a26c5b2b-12d3-4e72-b274-6b99ddc122b2"],"3222116831":["1e966eb9-4b98-4d09-afc4-918b41441460"],"3227431860":["1dd91b26-b215-4134-9b2d-53dd817806c5"],"3228821630":["e2557fc8-48ea-4bfa-8b05-bb28bc59fd35"],"3233773757":["e9761205-4ea7-4b0b-aa53-494b902cfb99"],"3240066272":["92e48bfc-b1b4-4e0d-96d5-82636c0935d9"],"3240378486":["ffb90a50-770e-45b8-ba02-14ca10b89678"],"3245763406":["61047030-38a4-49c5-9a78-5733b2f62f08"],"3249643651":["424a755e-7de4-4741-8e35-073cd6262445"],"3254682999":["b218604f-931f-4a7a-9860-d3f1abc4b191"],"3255984667":["5a901e87-7a53-46fb-823f-9881a0cca937"],"3256228889":["da05e3c0-a0e0-4bc4-b0d4-2db437f82ffe"],"3258810023":["83c9e30f-7b9d-4c63-a41b-96416bb4d410"],"3259129363":["dd2939ae-18f8-4472-8a0f-4136a63c1bfb"],"3262350034":["f3744e8f-8434-4a5e-af93-f9f2fbc784b1"],"3263857218":["68daca0f-ad50-4ee5-8ad3-154cf03351bf"],"3264692941":["104ca3d5-e21f-406d-9b29-7620292cc9e3"],"3266118530":["097e3f4f-989e-494b-96d3-174a704440d3"],"3267043748":["c875821c-c523-4853-ad65-b899d5026220"],"3269659312":["c924c979-0a65-4cf8-aa1a-277f7065db7f"],"3269901312":["0c252931-df21-4114-a54d-163c225aad63"],"3271020594":["3d8d6276-0848-4879-96b5-87b69fd6d932"],"3271905200":["2afc1d9f-c1ef-485c-b769-fe9d193c24f7"],"3272917445":["37f156eb-fb2f-4d61-9dc7-89be07c7ca5b"],"3274178440":["286223ff-2fe0-4fbf-98c6-034859dec861"],"3275214376":["a55169be-da9c-47e8-a7f7-7d20f68616f6"],"3277279508":["71ce53ff-0c45-46bd-9f3e-a8d652484464"],"3278163393":["2fe9e075-f0e0-4eb0-b330-2636ceff2dde"],"3278395063":["9279a752-1327-41dc-8ae3-9c5b1b089635"],"3279600383":["b39b82c5-22b5-4b68-a4e5-b682b26c7b57"],"3279979490":["d3ba3124-dd78-406d-ae87-d481dc467c53"],"3281674834":["baef21b8-82ad-4258-b6ae-2a8ec6d74a8d"],"3282149491":["a6e50119-952a-44f5-9e22-e1e2442969ad"],"3283724031":["c4536252-a3d0-4e8f-a4da-6421e9d16810"],"3291042515":["59191874-5601-413f-af10-79574e5de8e6"],"3291444954":["41d7a6a4-5fce-497d-80be-a96cf3ccdb6d"],"3292475575":["5d603eec-8a9b-4f49-b41a-1462224d48ed"],"3296263611":["4e725864-c9ad-426a-abd2-e622a4528f29"],"3296865063":["6b69670a-0281-45bd-87fa-70efc1dcde9b"],"3300588124":["3f0ab461-5310-469d-ba34-05205b987ed5"],"3302713791":["614c6e85-cf75-4d84-bb51-560566e5b4c1"],"3308847257":["f4297e3d-ed44-4b1f-9254-018fb6bae757"],"3313373254":["8481953a-9abe-464b-b997-625c9781adc9"],"3316014275":["ec9e1084-6b9b-49ef-923e-a8afb09f60d7"],"3317241707":["802c089b-4290-4594-a076-4319ca4d2472"],"3321642187":["5b6d529e-3ed2-433d-a16b-51b435b4da0e"],"3322612530":["7a1804b6-fc99-4d0b-a48c-c8b45873c024"],"3322811178":["2523c8e8-a397-453b-adfd-464a2ce15958"],"3323245281":["8cd0277d-77b8-405b-82b2-aaa1b161877a"],"3327688935":["1d5b49a3-ac3c-4d2f-bc86-237747d4bdc0"],"3328321541":["03b12e6e-0849-4e8c-b0e1-6280e2fb3a14"],"3329055846":["d677496a-0109-4336-b93e-937626a5a1cd"],"3331835232":["fb0af0e6-745b-43fd-9096-75e96afad332"],"3332179812":["ec894930-e54e-434c-a676-cf7766c1a3a8"],"3332389674":["565586ac-8fb0-4b7c-b61d-40865fbb4ca6"],"3333984578":["c4b0ddc0-c644-45b3-8985-2e7dbbf0f6ec"],"3335560186":["59d28fb8-5c2c-4fe9-9634-65437bfcf412"],"3336974741":["a2b7e2fb-6a91-4909-850b-db9ccd967724"],"3339573599":["28e5557d-60fd-4a4b-8996-169eec28f27f"],"3343282784":["bf78c7c6-7d1a-41f6-8c93-cd518deba06b"],"3343881522":["ceda37eb-6a2a-4d4f-9d7a-514eb63ec941"],"3347192356":["77cfbe7e-77d1-41ac-92e0-000ec7879ff5"],"3349730268":["1ef11ea0-063a-4de9-8f39-dacad3fb3953"],"3355368661":["09bbfc3f-7050-42a8-a847-f4f44bfb5fee"],"3359562525":["8bc42cc0-77cf-440f-bd9d-ce13918b9f7d"],"3360729935":["7bebc7b3-798d-405a-88fe-a93eef88deb8"],"3361365394":["12434817-9863-41ad-ba20-8d8c1ef09d43"],"3361585667":["c0c764d9-1cf4-4503-8760-036f9a8fe313"],"3362568743":["07d3e309-8c9b-4bcd-909b-0616cf39eb63"],"3363387048":["760dcd17-97e7-4f90-b030-058765967e75"],"3366462216":["acc5e3c3-9b4f-4280-8f62-39c78ec35d3b"],"3367468173":["4c8fc1bd-ad99-40b0-a91d-746bf67079d0"],"3368102152":["f511bb73-f7ac-41a1-8bf3-b25b01886716"],"3372174628":["5785b6b3-7e46-4e72-a821-1737606f52e0"],"3375310298":["ec5ccaae-839a-4c76-b64e-86487d840181"],"3375447049":["75884ddd-93f9-451a-9f9d-0faf6db96ede"],"3378228894":["ae48d106-0af9-4f03-9341-1d752249e02f"],"3380057720":["0e8fd0d0-4a84-4417-94ca-3a332f0b1b2b"],"3381080885":["210589c9-695c-4f75-9b02-56004489b93d"],"3382018376":["6e6c0e64-e987-4f9c-b8eb-0ee822fc446c"],"3383098495":["40532e2c-885e-40af-b8f0-c1606bbb495b"],"3389522952":["c7b9b7a5-c529-456b-89e8-b7e7ccfc425a"],"3391756380":["c2a94995-02b4-4443-803b-f2538c6d5a3a"],"3398318926":["7aaac7d5-0064-4056-bb0a-d752c6153e11"],"3401002799":["5494f858-facc-4593-bafe-26a152e188e6"],"3401310067":["13f7c20c-fbdf-4c2f-a95b-fb063e2d6057"],"3403176931":["58f3f478-55d2-435f-a29e-ff425b2f9db7"],"3407048069":["47da4332-397b-4341-8ac8-f2597264e5b2"],"3407812757":["6fa404f6-a498-4ab7-91e5-fa527a506dff"],"3408379894":["7126e701-0fe1-4898-825e-7670ec13561a"],"3411616325":["1bbc0920-322b-4641-a7e4-4d93c1caeb1a"],"3412963124":["45eebf00-c95b-49da-97aa-8e9a025bd0ca"],"3414374936":["d3fd2204-646b-43a1-ba83-15a9d006d69c"],"3418910001":["584abf5e-46fb-4313-a128-1929a026bf41"],"3419928637":["12921cfe-c23c-4a9d-a0d7-893968b0fe05"],"3421757832":["8cdaac4c-d8bc-4484-97fb-9ae20baf0715"],"3423890752":["5034787e-3e08-4122-a214-95265cf738a5"],"3425021128":["4d6e6ab6-eb3a-422b-9936-ee31a80fe54f"],"3426741724":["8c88ae29-357d-4fd9-b109-5365d7783ca1"],"3427936265":["369b9833-0e82-4e0a-8e5b-ec08795fe182"],"3430204685":["d8c9c132-8462-433a-b82e-4ddb05eb2b44"],"3430726884":["3afd7439-b34e-494c-a7f9-d657732e0b9d"],"3431546451":["6d0a4767-5b8e-4deb-bdbf-6c58bfeba10a"],"3432001505":["a565ffc1-c01b-40a8-a9e0-8bcb054d3004"],"3433271951":["6ed1f909-d15f-4387-85bf-8846c3b02445"],"3437504931":["9a51f86c-803a-4482-8539-77da4837ba6a"],"3439278483":["ce94acc9-3f81-49fa-ab81-b7140da5449f"],"3442425392":["8109e103-8ad4-4270-ada9-bdacc25262de"],"3442546396":["b826276a-cc1d-4b96-bd7a-00e0bc47d541"],"3442828805":["ac4fb169-1d96-49a4-a92d-85da9ebb6333"],"3445353175":["88c74955-685e-4433-8f4a-c1443720f186"],"3447497814":["7acd1ffb-5acc-4bbc-abd7-1b6e9456701f"],"3448568809":["5be0542d-df21-46ab-911a-d9899661c002"],"3449000920":["6b332384-f732-4c72-a6c9-80d08b2d5a6a"],"3449575813":["1c6dc7d9-f52f-4c2e-ba86-ea66cfcee8ca"],"3450530096":["9a24c330-f10e-4a86-93e9-d14581f8dea5"],"3450542692":["438f3955-c0a3-4204-93d9-757a1786cd1b"],"3451750149":["3b91a462-1c25-45e8-bd71-d2a82ced6806"],"3453908092":["1ace8a1d-3efe-4d32-a5a6-8730ae8e3505"],"3453978658":["936ddb76-f9d1-4d11-83fb-a159e7d60596"],"3463425956":["411f1306-7442-4622-bb6e-bc16c56a984d"],"3465716604":["d393e196-af49-4d37-be36-bf599572d4c8"],"3474022547":["5ec7e00a-9a45-4771-a7f7-cdb5c9ab61d8"],"3475786561":["14b4373e-57fa-480b-94be-12273b209192"],"3476548560":["73220080-5390-434b-9865-64b7a6bdf782"],"3485653730":["e0df4160-9494-4724-89d5-5715160055a5"],"3490967432":["abb3e490-cb85-4dc0-b2ca-9c2707c6aeba"],"3492286664":["35c2449e-dfb5-4a56-b205-cdc65c3b12d9"],"3498603585":["c66e0400-d22d-4c4f-be14-3e63976b6792"],"3500110743":["0212243b-449c-47e7-8266-65c97ebd16f7"],"3502542477":["4911b657-196c-4eae-9d03-759769dd09a3"],"3504638096":["d9d831cc-175d-49c9-9ada-bc60ab18733a"],"3508698061":["8c40b998-0b59-4af1-bb19-ad236b2c7549"],"3509880209":["8b070059-38e4-48f5-ab08-758913f67407"],"3510981871":["dbc8e132-b0cb-484a-a436-66a4753b21f6"],"3513942017":["16b153b3-be0f-4fc5-8104-4111850909d3"],"3515495516":["75042416-e5f5-4763-bfb1-8cbbe6e28b2e"],"3517506543":["0b2a58ad-c6ed-4101-9a7d-63c594e54b94"],"3517582506":["5273036d-3fe7-4b52-a33b-a6cedfb4e58b"],"3518235943":["c0c580ae-fad5-4500-9e19-91ba8ca34637"],"3522856195":["e8919439-aba7-4180-9822-e9b9f1229388"],"3523024659":["87ca0348-9540-4e3c-b96d-63682734ec6f"],"3528562143":["5f2a5a31-f1bb-4d8f-a40a-9ef68cba2d8c"],"3528647978":["17a01d3b-5269-4865-b65a-b2e5b4228fce"],"3530937764":["102130c1-289f-45aa-816b-fe65430a15ef"],"3531073903":["7ec1d990-240b-4c72-b20c-4e13988744a3"],"3533186748":["4f1fcabe-5133-499a-9396-2dd753e94e22"],"3535396055":["924392eb-54ce-451c-b12a-f3f949459c9d"],"3536363562":["9dab00a6-b4c3-4a2d-89bd-91d0fb1437ad"],"3536766782":["670cc0b4-90fa-4626-b4f9-1a19a61b5cae"],"3537810051":["dc110fd7-6063-4613-a873-012ca65f9ae1"],"3538866480":["215f70f9-be22-4f3d-b8f4-6c8adfaae9a1"],"3540178906":["4327639d-032b-4f8c-aefd-68911f537f4e"],"3542283317":["3221babb-f0c2-4f63-a21a-92339c1d0536"],"3544442212":["080e5477-6f53-435b-a80a-167509347a84"],"3544476164":["35a1225f-aa15-4c16-b176-ad7068b69a29"],"3544577942":["7d002c0e-99eb-43b8-b7e5-ce9a53af88f7"],"3545692251":["2ad5886a-e140-4213-a493-684c4fb4a8be"],"3546355498":["9bc8a599-5859-4b89-b793-10b020d6a526"],"3550108773":["d02bd9af-929f-4b21-a8a3-e5dd760fecc4"],"3551947665":["f3e0ddcc-0027-40bc-82aa-5557aa37569c"],"3552372984":["defc752d-7c68-4db5-92d2-77f41a3fb620"],"3552795335":["03f456dc-80b0-4738-8c4b-2de583e122fc"],"3553445177":["41e78ed4-dc89-4f28-8f42-ab548de50bfe"],"3553689107":["7f794915-34b9-41b6-a521-34f380c68c69"],"3559111250":["a547e615-2d43-4a00-bf06-51e4e9f0b664"],"3565564199":["cf65c35d-c3ad-41f9-af7a-f61a33cf2f48"],"3566872392":["51719e25-ba53-44f6-bd97-4be480a8d8a7"],"3570090455":["68a9a7be-2655-414e-b30d-2b7ff276425a"],"3571265460":["866b3b15-71ac-49ba-a621-f44ea03913cb"],"3572724303":["7132a6c2-b9ea-4033-9b13-69a002c9029f"],"3575476337":["c37a4f86-764d-4363-a3e0-466d4144edee"],"3576745475":["8e5ad8e1-3716-40a5-b6f3-dd9843ea6fc0"],"3580899246":["156a830c-46a1-44c0-a044-b6f500e61134"],"3585605991":["576071db-1923-4963-a148-7fe7d4847c54"],"3586937685":["4abd8a52-027e-416f-8686-a55662cbca53"],"3588062970":["2d54eae4-fed1-4704-b278-de7d10797460"],"3588533639":["b7dcc8e8-b11b-432e-baba-05a3d96739df"],"3589633474":["1885b752-3038-484b-81fa-8766ad15c704"],"3592811079":["7fc1c557-8f26-4522-957d-0f3e351716f7"],"3593493462":["12994b68-40fa-4dbc-a655-c5bbb4b5ca6d"],"3593805695":["253ada38-2849-4633-97e0-12e78af6eb3f"],"3594255809":["3e3eaa1b-e0e1-4b0c-9b2c-a83011f94366"],"3595038854":["108382a4-b649-4705-bd08-db90f7076f4b"],"3595903037":["da3b6754-8460-4e1a-9e9f-06b54cfa8a41"],"3603222762":["c7fd96c5-0918-4b6d-8c5c-25c542aa554d"],"3606948269":["a4fffbab-e80e-4afe-80d8-5228833d405b"],"3608368638":["41e8667d-f2b4-4155-9114-5b5155f21310"],"3610103744":["6b776c15-a1be-4d3d-b095-b94d633727d4"],"3614208452":["b57d411a-d693-4883-934d-711dc2b0b438"],"3615696018":["ec6be2ec-7cc8-40cb-b88a-85b348d4a7ed"],"3617833468":["2ac796da-d12a-4c95-a03b-d6c5d85c96ee"],"3622291441":["11970262-5841-41c7-9697-9ed770e35b83"],"3622977876":["16340caf-e8eb-4391-b562-44c101a25cda"],"3625623242":["c2e8d387-bddc-4f8d-ab38-ec813b61d049"],"3626767106":["fe95b612-5735-448f-92e1-3cf747616cac"],"3627818305":["aa03c19e-0360-4f65-a135-6ea92cc65e66"],"3628241798":["56bcc703-19e7-4f2d-9bdd-755ce14ff055"],"3629372491":["ad7e8db2-656f-4673-a88e-19cb7335722d"],"3631517853":["e96e3ab1-378b-4cd2-8775-938a5942fdbd"],"3631901574":["72b83e96-9218-402b-b3bb-fbf80bb2ac95"],"3635612065":["afdd4e93-3872-4bce-93b3-c5ed57b6b533"],"3635864759":["a0476c6e-fe58-4966-892d-c633b04191c3"],"3637233232":["ee7f362d-4909-41e5-b35c-23cc147462b1"],"3640425286":["4100e486-b0b6-4d8c-b870-b63052ab18dd"],"3642090135":["8f1cabc4-9191-4106-8d2c-11597119552d"],"3643270831":["e7334f89-2a42-4809-b793-d663ac7bf5dc"],"3644883124":["52e99827-1034-4596-9572-2ec8e5219559"],"3645095884":["66e456e0-2321-4049-8f96-ae731036ffc8"],"3648254667":["06ec9d69-33f3-4c3f-9b46-1478db50b368"],"3648566702":["4431d348-5ecb-4e40-9933-c473d1e128de"],"3649041333":["596cc7d2-62cd-428a-8e3d-0d632652eea7"],"3649925632":["03f4b8af-4b57-4bfb-acdf-53173ce2190a"],"3653758757":["0918f5e5-dd6b-4ecc-bc27-7f68dedbac6a"],"3654003227":["7aeb133b-87f8-4e35-8a74-49cc90bbb2f6"],"3654632149":["ba1fdea0-14fb-44db-9d4d-04fe1d0d2f1f"],"3654969164":["2836ced6-8a12-477e-8220-ae45581ff252"],"3656737423":["56bd054d-9d25-4d6d-bd33-55c1f394bd1b"],"3657496828":["89694dc3-61df-46b5-ac87-fe0a02640433"],"3659909925":["89b2520d-6cc9-4870-ae63-2e04f2986bb8"],"3660822363":["461c8fd6-ca48-4383-b9a1-abc10e4e45e2"],"3669361810":["087dd7f7-83d0-49f6-b839-8431b2d48eb0"],"3671734000":["60302835-3cac-4a2c-b0b3-365bc5d7d0f7"],"3673975972":["d1e96813-a92a-4fdc-a1b0-6333bf6e1804"],"3676832492":["7bdb3376-a2a4-4dee-8fca-b26019202b05"],"3680343252":["014586bd-1094-4138-8ca4-9f905b0ec715"],"3680713153":["2c2165d3-9869-4be0-98ee-e6b106604956"],"3681499198":["5755dcf5-a0b2-4e18-9b9b-9a6ebda4de95"],"3681527204":["53885156-e93b-4320-9fab-6e935c8032f1"],"3682972654":["d8db00e9-4388-4890-b39a-aca921a229ae"],"3684231860":["8f317653-3cc7-40d4-81d1-86c8e165cc65"],"3685183067":["97b4545f-bf7b-4f6c-9d2e-a292a5ca6ce1"],"3689457373":["06e08779-c2f3-4ff7-b1a5-525991086031"],"3691227986":["5321fa53-3072-4b97-b289-88df536eb875"],"3692362421":["d0af8671-a573-4640-bad2-dbfba6f5ab12"],"3695393589":["eba900e5-15af-4985-9495-fdd4d5d4c60c"],"3695446402":["3fce421b-afc0-4488-b8ce-7486db3a784d"],"3697594084":["510bd8a3-c1f2-4195-83a2-2cbd7cbf581f"],"3701903559":["acc607c5-98c9-4b99-8884-6aea1d309498"],"3702647307":["67781963-4adf-487b-a778-29c640da49f6"],"3703144731":["ed746543-82bd-4d2a-9908-22c5847db491"],"3703725788":["f0a40b40-42da-4744-9302-f10045614f7d"],"3705392883":["286e7346-7725-46ee-bd0b-77d56ebf64cc"],"3708870336":["e3dcd4de-8914-4633-9082-6be0d81ba8ea"],"3713860448":["081d2a1a-fa7e-489e-9a5e-7a06dd887af2"],"3714413115":["e2592844-f1ae-44e6-a4b6-a85a52ef57f7"],"3715455329":["7e22bdcc-337a-4324-93c9-20520f814202"],"3716139216":["cc706f41-df72-4513-9c15-e28969b282cd"],"3722990594":["dae71a31-b7ab-4806-a0b4-81162bf9fbb4"],"3724623399":["419a9846-1437-4a58-b63b-670e8ae629e9"],"3724932655":["f1550665-5550-4298-af96-4c6330c0fec2"],"3729238711":["706632eb-6e92-4fae-9c78-3082fd58ce82"],"3730388926":["72aaf879-26b7-4c82-a2e7-1b311b167d45"],"3734154957":["6b5ed9d7-2c57-440f-bea0-dc5313dd3193"],"3735129330":["ea94d4bd-41bc-4f95-a636-7ff63085677d"],"3736846307":["669d132f-7d36-43a2-aec5-2df58a00f3b9"],"3739686256":["5ab6fb63-3ad3-480f-9fd0-6a564c59fd3a"],"3740380516":["5e7def65-6c1d-429a-a9bb-1118c92dc5fc"],"3742730847":["576ee8e3-3df7-419c-a221-256c3249bc50"],"3746822126":["6b0044a5-ed0c-4874-90d6-cf3a928bc36c"],"3750663116":["05dfcbef-a15c-4bbc-b07c-25a503a934e7"],"3751017003":["c5768efd-6ea8-40eb-8148-6ac67dce9b99"],"3754559761":["b6925d26-5e6d-484d-ba4f-441b7036c21c"],"3759067146":["45e6796f-2e39-4395-b730-183db243d019"],"3763562825":["3a27defc-a746-408c-ad14-778dc1028b3c"],"3769537510":["25d9b142-fd61-49a3-a73e-799a8981a98d"],"3771303633":["0671521f-9253-4ffe-8b42-ba780b5a1afb"],"3774969776":["d85dd492-8f49-4769-a96f-40b77fb28914"],"3778071445":["a75a4f5d-f300-4614-841d-6eddcd502370"],"3778121923":["bfd013ed-3863-4f9f-a5d8-bf8132535be4"],"3779635082":["b150dd68-98ca-4fd6-899e-231eec092beb"],"3782543774":["edc057de-3e79-4649-b4d2-707942ff2b19"],"3784638194":["696315cf-c975-43c4-b6d5-2ad3dd7c3054"],"3785072203":["2fa05351-de65-4fa0-82eb-3587b7326418"],"3786625761":["c54e1de3-6df7-436f-bce1-f81f75504f99"],"3788011121":["18cade06-01f4-4365-8d7d-26bb6f25aefe"],"3788937199":["e33f08c7-716d-450a-a5ca-7d0425f9e021"],"3789460997":["6983b034-22f3-4200-bef1-ccbee2b6a524"],"3789762259":["2db0c1d2-a748-4b15-a889-ea2378389c59"],"3792931445":["790d924c-f402-4053-a1d3-bdc6d0cff4fc"],"3793287817":["748d0a1b-e506-4bb1-8127-46bbdc889a9e"],"3795567316":["4bc7c8f8-009a-4df8-b3b5-e420e98647b7"],"3795716327":["18902794-f0bb-47cc-af92-836ee423e0a0"],"3796508013":["92048e92-e35c-4f91-87ac-c07933995577"],"3799147737":["7891dbb0-c522-40fe-ae49-6c3a6acc38dd"],"3799351367":["ac28ff87-1923-4a12-a502-27d613ee705f"],"3801046956":["7ffee9bd-ab43-4251-9ad4-7e4bd2b7ed53"],"3801951402":["8571f7b6-70d5-479e-81ae-4460f62e6328"],"3806223139":["68264fa1-d328-4980-b68c-60ec3788386a"],"3806303323":["53786dad-ed56-4df8-bd24-51a0b3e3d268"],"3810226852":["d3071400-c92c-4a95-8a0b-d3c2e6f59fe7"],"3810260600":["8e9f8770-f8d7-4989-92bc-8170545d9d40"],"3812159488":["6352837a-297d-43a5-8276-1d941d79ef25"],"3820838416":["5e7ab637-fafc-4e39-8ca0-4b9dec366458"],"3821349954":["4993521f-ee01-43c1-a702-274c9ee4c92f"],"3825953258":["23472ca5-4e95-4dbc-93c3-2bca0770b4c8"],"3826209647":["dab71eae-45b2-47c7-9ced-b445add7a468"],"3826418340":["e2966d26-5235-458c-9901-3f7dfe5c041f"],"3826884474":["1a2df807-9282-4080-99c0-b7c094db4335"],"3829726548":["b8d5d188-0370-4376-8202-050ca3c94699"],"3832181415":["d985df45-38db-412d-bafa-b2d5b06e77dc"],"3832780452":["c889c11a-8af1-4aa5-a0c1-0bb7882ce92b"],"3836861678":["8342b36f-b509-4f43-b96f-6f5227d2d5fa"],"3838876818":["dd40628d-bea8-43a5-bc8c-b79f846f9cfe"],"3839034312":["a9125c6f-7855-451b-a107-bd52bbd2bc10"],"3840627821":["cf45617c-9db1-460b-bd0d-531187ed5f87"],"3842764214":["f91a2350-1a0e-400f-a917-0d6138297e53"],"3848035078":["3df07850-5537-490f-ac89-aad182d9233b"],"3849477569":["042ecd88-bb30-4a6e-bb41-1589880052f3"],"3850671481":["dfecc5cc-bc95-45e3-8024-53ca59df186b"],"3850753386":["052e5e66-5968-48c7-8c45-04601a56a0ba"],"3855295698":["d3ed8b23-fb1a-4860-9b8f-f324681a5438"],"3855518453":["ed504e3f-25c0-4259-9185-7e05b7eeba54"],"3856118425":["d6f9a423-a914-42c5-bf97-1f02dae5c0c0"],"3857025238":["0b8db75c-760d-411b-838a-3dcedb8380de"],"3860946322":["7e7ea512-b868-4b60-8777-d245a841c870"],"3862692167":["84116e49-39e9-4720-9483-00c4cce0ba65"],"3865998002":["85cb13bd-ee81-4bf5-8eb7-354c2208162c"],"3868160633":["39c80302-902f-4689-afbc-c82ac81dd7db"],"3868699834":["e96c92e8-5c30-431b-b545-3604f6235a01"],"3869884355":["81c87449-5085-4b3f-a4e0-b4702c3b8233"],"3870559675":["47de07f6-241a-42a5-afce-6ab25af58791"],"3870824081":["bdb49c60-27a1-477c-bd61-d9985bb0b98a"],"3871153642":["84aaa27d-b91d-49ac-9418-b6751111dac4"],"3873486230":["3f989401-44b4-4fb4-9e96-ac88a317619d"],"3874194658":["38a4f812-df80-44b6-9d08-7eaf56582d47"],"3875081831":["8f858812-b550-42ae-b88d-a439787797b6"],"3877082967":["8ad2340b-82f5-4053-b79e-b5713e5fb3f8"],"3878951210":["d4aa43eb-1518-42e1-a60e-a811e6a54815"],"3879265974":["3b5ef701-168d-4694-a205-eac6254194ad"],"3882256111":["2460ae9e-d937-4e9b-86e3-9301832bd380"],"3882609061":["54d486c7-a606-424b-a845-c84ab6325b4a"],"3882755725":["5c563fb9-3aba-4dd2-8c18-dea2ccc6bb14"],"3884043051":["d7572dfd-3f77-4ec2-b1e7-e79a2de6e2f3"],"3884743833":["223c65b6-d8fe-4b4f-aae9-6a0576113d48"],"3888626755":["68f3600a-239d-4ef3-b17c-2e9b470647d9"],"3892036383":["0d027331-433a-4bab-9cc0-3fbe73d735c1"],"3893613320":["0c9e16cb-3cd7-4c59-81ea-bc527bf834e5"],"3897701907":["a6474aa7-35b4-451e-88fd-e9e32911ff5b"],"3898987484":["ec466f43-d856-4e67-a409-74dc145fc17b"],"3899425805":["ecba58cd-6772-432b-bf48-4d26353ee786"],"3902441436":["b9ba237f-fcb9-42aa-b39e-c13192958f19"],"3905366733":["1bc3641f-2555-44de-b2af-573c6838b838"],"3905932111":["277376b2-0cff-4e33-b087-695419477c96"],"3907144262":["5e4c1a47-b242-41d7-a5cd-80512bf0d81f"],"3908998262":["b4486090-8bdf-4e51-93d6-28900f75f404"],"3909437601":["0757851c-1b70-41a6-8222-2585602de7b4"],"3912365962":["3b107d3b-7733-4823-ba55-172c61b3d17a"],"3913726153":["7d9c9ce1-ad6b-4523-8381-10652e318a91"],"3914274105":["fcf457f4-bf67-4a74-8e72-0a534642a86b"],"3915344343":["d57a1349-2cab-4dc7-a10c-903f89f3d22d"],"3916539226":["8d1d91e2-3d2b-4fbb-bbc8-c83fb51797dd"],"3919125675":["e81b8908-3b4b-4ca7-b3a6-a5c6d159dc41"],"3922618281":["d5c4b3dc-f095-4e4b-8794-0313a3b26b11"],"3924707215":["59b67f0b-d572-4639-9935-d8b1058b9b32"],"3928242576":["0cdfec59-48dc-4604-a783-858733cc01dd"],"3929867355":["f824e2d0-9a33-4a83-86a3-e28ed3b2ce79"],"3931551229":["57e0c6b6-c0d4-4123-85c0-64dfa94d55c5"],"3934178919":["a2221f16-2e20-4012-a456-5068b9261317"],"3934627270":["d15eb684-26ee-4a74-a47a-2739b7dafc22"],"3935543527":["867b55f1-497e-4b7a-800f-c2c740abcf43"],"3937801611":["fe1d24dc-d0e3-456e-b0a3-481708543a63"],"3938221492":["a4593e73-66ce-4dd7-9cf1-44a0eaac042a"],"3938669832":["a0f54ee8-2787-460d-9c5d-83521c03dab5"],"3942357775":["5168ef7a-080d-409c-8436-bb4e8fd9d534"],"3943837480":["0fbc3d9a-ec3b-44ad-8d25-62360436d3e5"],"3945930942":["f3f1af24-b065-4858-98ae-26584bc95f09"],"3948574403":["8f215cda-d79d-4650-a191-15caabe4e38c"],"3948665111":["fa0ab406-b3d9-484f-b803-04edcb4ce944"],"3949100456":["46b77938-fd40-432b-b8c8-303bad33994e"],"3953093961":["d24d9077-e8ef-4685-8eb4-7c2b3c5d01fc"],"3954091308":["8ac6816f-69c3-40b0-9bd5-86939ed4251d"],"3955545826":["e090a983-d19f-408f-9da5-e24db61f7ef7"],"3956499265":["3773d865-e217-4693-bdf8-e23f477cce1d"],"3956508861":["03ec49bf-4c1e-4e7d-a0f0-2deff117bdd9"],"3962805304":["d58cfd66-7d17-4a48-8495-8aa9910ed668"],"3966340651":["43d07f6c-1096-42e7-830c-1fae0e6ceaae"],"3967742629":["12ddf44c-8548-49e9-be9a-1e3f146a2a0f"],"3968703551":["935346e5-1095-45cc-bd46-a4df5168a5cc"],"3974010820":["abf5b369-3a1d-493e-a027-6bd57aea8572"],"3974015883":["90b09d09-71b2-4054-8bef-64caf223fd49"],"3975093384":["09d50b0e-0c95-46af-9330-2ef5b128ee05"],"3975159804":["415dc606-1639-4e3f-9f13-07f7ddead49a"],"3976004274":["117ae7d8-af9b-45aa-bb58-2581c77e61bd"],"3979875782":["ab451035-d6b4-4514-ab14-6eec2a8cbc0c"],"3981470230":["ef6d92b9-a4bc-46f7-8338-52418873131e"],"3983277549":["86006621-1254-440e-92bc-547d04723afb"],"3984338815":["e6667ddd-a3a1-4c9e-8b36-2986c65db3a3"],"3985362841":["9aaefc30-dec5-4085-af57-c07abec6d0af"],"3987054524":["df07f701-d902-4a88-a486-f56ba6842f81"],"3987499386":["27f153d6-fd49-4eee-8faf-9fb2954ee352"],"3987550705":["c02ed538-a7bb-496f-b855-f092e6dc2de6"],"3987888832":["44bf9227-20e9-47d7-806a-9339bb884cf3"],"3990479672":["1113ec32-7d4f-4495-b64a-4218f79f94f4"],"3992168403":["52932afd-1372-4431-8f3b-598e54b14607"],"3992808010":["30e8c90e-1b93-49c1-ab18-3a0162e1efda"],"3998480869":["c6b01bdd-6532-4cef-8256-2998b5ac229e"],"4001228208":["a7f86832-b0ad-43f2-8d21-4983f571b769"],"4003651580":["9d5c2dd3-eb85-4a8b-a587-055850a5b8be"],"4005315430":["4155f415-3d62-48e3-818e-b268bcf6ada7"],"4006271894":["673c4c2c-3ff8-461f-87b1-723e511300ee"],"4006446050":["caa0ad8e-662c-4a56-a7e3-e176d4144f54"],"4013564524":["61941647-0da2-4405-9395-9b5515845742"],"4017413531":["1b6d2437-87ee-4f94-838b-d5340e0ffda0"],"4019975107":["ada0e270-a9ce-4ef4-9013-2c460edf3329"],"4023564093":["bf479fad-fca9-4efa-9d54-f8017a95609c"],"4025803055":["30392452-3bd0-4523-82ae-1bb01a0e4746"],"4026049616":["44bba762-99b6-450d-b192-447c6afa47fc"],"4027058420":["86208296-f9b2-438c-856e-effa1a0326a9"],"4027887184":["8103ce22-2392-4e89-b96c-d8948c7ce7d4"],"4031715666":["201e4899-7e67-44fe-8bf5-c8585224e6c3"],"4033083562":["06ecd707-93b0-4822-979e-e336cf6d18fe"],"4034039357":["f7b747e6-1c18-45d5-8fa1-70f4cc8d7772"],"4035783228":["387cf492-b5e5-4c6d-9986-a0f2150809fd"],"4037093276":["ea07f017-2ad9-457a-ac2e-29ffa83c2e7a"],"4039360535":["3aec21c2-b4ed-4c49-b06e-db9e7a32ca9c"],"4039786692":["881aff31-3943-4752-b071-b4aa105e7959"],"4040975574":["2c0c88a0-7e3e-4fb4-ad4f-6668650145d1"],"4042724321":["24b87079-4b59-426a-87f3-15ec4f8e765e"],"4043363155":["35013ac2-e1c3-4b25-98da-821d8154c7e8"],"4045303773":["fcefa065-9df1-49eb-b292-fa33ac65495d"],"4045949250":["6dcd2051-3342-4d99-a4c0-c59bf95731e9"],"4047896486":["c31a4188-7070-46f4-8d61-d633712179b1"],"4048781848":["fd95cfae-3969-4cd0-b858-c61abc923a1d"],"4050359297":["0d7c4f30-0ee9-4435-9d0f-8d31f09029cc"],"4052209842":["e8c4df53-e1ec-4a03-a18f-82a9149f47b5"],"4052786358":["a785441f-79ab-4d5d-8af0-77f91fd5ab06"],"4052966580":["8fc9d576-7311-4a5d-b409-7817f872a799"],"4053658430":["d4af6d3b-be1b-4d03-b0a2-efee239806b9"],"4053790183":["1587cfad-6446-4ecc-8469-cb0d57cd80be"],"4054410169":["501d248b-c197-417a-8d63-5e29d5984dd0"],"4054821278":["e80c04a6-9015-4e7d-91c4-3e6d979f8d09"],"4056492746":["aeb2807b-992d-4b5f-b3aa-c7fac4bad70e"],"4056762495":["7092251d-84e0-47e7-b78d-8b40c996b2ca"],"4058114122":["9bc93df3-cd47-4f29-bcbe-19c4906abdc9"],"4058369912":["99d284f2-2637-4365-83d6-d11157ea6e92"],"4061010347":["67cd0cc3-1718-4fda-9a3d-11a01a96bf97"],"4063188829":["38d56644-1816-4130-a200-5da7f98f548a"],"4063795556":["fa5b425b-1658-4511-bb0d-7facf0d68c20"],"4067010624":["2e155a96-9b32-407b-98a8-3e8dcc3e3a60"],"4067385205":["041106c9-0cfa-480b-b428-483f44194528"],"4070007436":["1b6ffcab-1f62-483e-a13f-4f3c21e24853"],"4072935473":["747d43ab-9026-494d-9cf5-a699ad51cae0"],"4074319413":["79b6cbf1-be23-4f10-990a-01ab6579168f"],"4074537506":["f49fe8e9-aaf7-4c21-87a3-dce872c4b241"],"4074862764":["7b630346-9982-4b78-bf7e-5d19dd047586"],"4076240681":["b278bf30-96cd-4af1-b650-72ee2854afbe"],"4077076435":["3ff48e84-c6e0-4969-b009-82502a6d723b"],"4077265186":["5193d233-779f-486c-a59d-f28d2a0be897"],"4078451489":["6b627272-4f1f-4822-9297-8cc4a469c85a"],"4082967506":["7deb143e-a402-4a0a-8575-53be9fe05be7"],"4084241225":["3b085852-da56-4059-a8e6-bbcfd0f5dcdc"],"4086490939":["94d059a9-35ec-4c4e-afa1-182ca1330111"],"4087781226":["4bd86ccc-86b6-47f3-971a-ffdfa03c6bcb"],"4089254520":["23530fa5-7310-46a6-99d6-5a2dd27dbd74"],"4090285812":["fe91a0ee-1168-4d04-b79f-c8d02915359b"],"4092026371":["8f1960e6-655e-4da3-9ffd-820d1e27eab7"],"4092433859":["1905895f-4135-433d-b02d-b8cd653c54cc"],"4098672815":["e99397ed-a168-4b7c-a439-5284169d8121"],"4099133683":["cc66b961-fbe2-450c-b6b7-657ef9174ce5"],"4100686978":["b673535c-7423-4790-8205-7bc03141a572"],"4101505683":["6d15b2a7-2b97-4ded-a082-06ce42082f74"],"4101860646":["39bbf3d5-e080-408a-b23f-9d89f492b35f"],"4101902932":["474919d2-8916-4c63-8d88-875b17cd39a2"],"4101952635":["7a624ae6-b5fb-4016-9b61-4b2252b6da32"],"4110486158":["535744af-82c3-4ce6-95ab-a00bfa4d2111"],"4111574099":["9d45131c-1e7e-4707-9cbf-824c017a95d9"],"4112195240":["a5dfa9ef-35f8-4aae-9a8b-78a600dfb427"],"4116258450":["b8ac19f8-0079-4cb2-9053-dfb2463ac446"],"4116919529":["b306808f-41a8-41eb-809c-9340c8245321"],"4117360399":["b5a7ae0b-0a0f-4007-8c77-ba3c02ee33c4"],"4120848340":["5058c115-283f-4a29-b38c-f3940638b121"],"4121534908":["d2d8eb0e-a5c5-4fdb-951a-53075a9fef93"],"4122302971":["4ea7741c-a037-4fe2-8e21-8e2c950d871a"],"4123743357":["c5c8a119-4853-4d6e-bbb6-700125674829"],"4125374433":["baa7f950-196b-42d5-adad-52c6300d8c39"],"4126029223":["48ed0928-3bbf-494e-9d7e-6e188b6e56bc"],"4128577408":["ee32592c-36a4-413b-9402-279e9dfbd7ee"],"4129003383":["5d2433e8-5ec9-4b16-b4c2-321762631eb4"],"4131199200":["456b9048-0e2e-4a61-bb5d-5a30fd466e10"],"4133385474":["c50933d5-e152-4710-9243-58a8a509aa42"],"4138041244":["a296482f-ca31-45af-9a69-eedef2a0d4c8"],"4147785697":["7c89265e-aefc-4a91-9668-57f7cf4c7474"],"4149233340":["5fb0d103-019e-4abe-96f0-9dde163802f2"],"4151064722":["f8bf7272-e94a-472e-b5f0-58269d2f8b15"],"4155844497":["0054b298-6a95-45fc-8d1f-6971c3b67da0"],"4164132624":["e6479249-6d4f-498f-a374-1801e6c36848"],"4167277907":["a09637f2-cad2-4256-aee9-c17ee003966e"],"4167506238":["170c7de1-15c4-48be-9012-eb278a99c009"],"4167934597":["72cb856f-9139-4e21-aab8-22466ddcf8e2"],"4168319506":["87c3f06a-1562-42eb-9c05-6b56797dc859"],"4170186879":["de4e2fe2-0d71-4a96-9705-04d9cc975205"],"4171890637":["9eddc582-2000-41d0-9abc-c8a61d0bec17"],"4173022035":["3acf5bc1-e61b-427d-b723-161e3e519c54"],"4174291392":["7e331663-584e-48fd-b5b9-ca48e815d905"],"4174440570":["e4ae5d67-cb3c-4e54-8f4a-251f37e6451d"],"4174583135":["d9e22a14-a20e-48d9-9c9c-8e0028d99a33"],"4175343206":["926caf2e-f344-4d77-a2ad-065edec5b137"],"4176079292":["67a1c3d7-262f-43f2-a778-378a642c7497"],"4176621186":["34730365-2f3d-4a63-8bcb-27f7a61d2e40"],"4182195290":["31a02e84-2d37-44be-b034-000b9346f7b3"],"4182800922":["1467313f-64d6-4834-8223-dbd96d89a06d"],"4186122129":["f9c1a834-4ced-41f2-ab03-1730cef268ad"],"4187042887":["75d150c2-8848-4be5-86c0-37aec828003e"],"4188734945":["09bbcb89-6ca2-40a6-a9e9-d2fc2a58017c"],"4190558825":["f6f4efc7-b501-47ed-bc8c-a41899ad9084"],"4190942143":["192dd4da-d994-4036-909e-7a2e1a660075"],"4191327968":["a65d5a9c-b936-460b-a03c-cc2d0601cb4c"],"4193642069":["d40123ea-b0e9-4c4d-92b7-c93340149fee"],"4196751272":["c6ac2b81-7afa-4a62-bc3b-3185fda344bc"],"4196801951":["ae2e113c-5c15-476a-9ee8-31dac453b24d"],"4201478850":["ee18cfdf-4a4e-44e1-9186-871ddf4c7ae0"],"4201860341":["f1d63886-1904-4db9-86d4-853336bbb8a3"],"4203122756":["1f286fae-8751-4321-9831-ca415020d790"],"4207804715":["e2c9ac7b-1568-4f98-9cc5-74f28d599c0e"],"4208793584":["c0864925-b1da-4ed2-b921-530c8bb00932"],"4210350751":["341f5ce0-0ff6-4e45-b060-aaf8d1786fc0"],"4210863353":["ecc23277-aebf-428e-8cdb-4399deae9e6c"],"4211640752":["2dc09caf-51f2-4fa1-9e97-4863942b59e3"],"4212466585":["ba0383c1-052d-47cd-a26d-fd5f564b8b2e"],"4214443622":["53611b1b-0e1e-4595-a46f-63f2f44f7784"],"4218431083":["638b91fe-8fef-4382-87a2-0daf1ef9b64d"],"4219370750":["481a684e-0adc-4b13-8ee1-ea18b51ad4a1"],"4222462948":["efb5a566-9927-422d-9f8f-137ba75da03a"],"4223456277":["8ba7d579-20e6-436f-b9fb-f9f6e440a62a"],"4224450172":["18baa049-17af-4736-94e1-b10cc58b966c"],"4225912676":["f51357af-c8b1-4466-95d1-901163454f10"],"4226177284":["5382bf11-7e29-47ec-9246-4414afdf00c0"],"4227944963":["61f4d9b4-c9ba-445d-bf7b-ee250887949d"],"4228436433":["a9107bd4-82e4-499f-84c6-3371d673b865"],"4232555633":["654f0785-88e6-4e03-b519-bada535d8bf3"],"4232721855":["3268040e-a287-4672-90d7-626008885718"],"4233853479":["04fbf839-fd6b-4710-a042-a1f9fdad3fdc"],"4235990767":["76974c89-b044-4b43-9097-af2ca622e428"],"4237290571":["e506f569-0081-4c2d-83c4-a3ae949a3203"],"4237918717":["27ede712-5074-403d-980e-677da739da3a"],"4238209761":["7bbfc71d-9ebd-4279-bace-e0424736519c"],"4244404098":["a68b9d7c-6291-4de9-b985-ff5c53cc3645"],"4244659380":["5389629c-c3a3-4a9c-b4e7-8c0c91e03338"],"4245884035":["54bb66bd-98c9-4cc3-9690-4be530475823"],"4246127400":["143ad6d5-c484-4d8f-94f0-fd32e529529f"],"4248131145":["42c6800f-a53e-48e2-a3f2-5b80958c4a54"],"4248833521":["5502532f-a26b-4505-965f-7bb230913edc"],"4249128363":["2bc9fded-16e7-4f90-b3b7-3edfee088aa1"],"4251419567":["f2fee442-ae48-4512-8ebc-1b3a6877ed74"],"4258145765":["3c9e4032-1210-4a84-b744-6e1f0a1bab84"],"4258215472":["4389e5bf-3a1d-42fb-9bcd-f35206013ef0"],"4259020096":["d3009d55-8dfe-495b-a01a-bbd2fe1e658e"],"4259549140":["29141794-9a50-4647-8b45-7da84b2970fc"],"4262491275":["88a0d9ad-6880-4b89-9a9b-01121de7588d"],"4262898414":["f7692d26-b829-4efe-848b-ae7a67a12c11"],"4263430873":["29818b10-0de7-4d21-8709-5086b5ec67c6"],"4264517721":["2026bdaf-1aa2-4de9-bb69-924841ac8da6"],"4266085658":["6c6cf695-49f2-4b11-8f81-78cfc56a4c00"],"4267155936":["20e9f7ad-d425-4e32-8ee1-c7edd373acec"],"4268218322":["415e45b4-2d78-401a-9759-344c33425759"],"4269695132":["6d1740a0-ebdc-44aa-a2e8-ec4820e1e7d4"],"4271680446":["401e259d-943c-4997-9748-8ce0f173a68f"],"4273695001":["2646b953-24af-44b9-81a8-0694e8fc698c"],"4273829858":["1803ac10-d409-49d4-b33c-021b83e101c5"],"4274358078":["68bad277-bf49-4dd4-aca6-a85062f21f76"],"4279525422":["56d4b3bc-8e0a-491d-b832-cd330556103b"],"4282890761":["9352ae2d-944c-46d8-bf8b-d6b12b25886c"],"4283283902":["dd3c88d7-0b5e-46a8-9bac-43008d840145"],"4283793519":["e5ae2fcd-db20-45bc-80a8-951c2cf44d01"],"4286736320":["00d40f35-6677-49d0-84ad-abef076c5cf7"],"4288346555":["dcc91dc2-d8d4-4953-bc85-5b0c9c893399"],"4289180893":["827d300a-6185-494e-a4da-00ec6a26f779"]},"groupOrder":["e2be63cc-68e0-4204-a613-30ead569d36b","ad23b2fe-fa22-4cea-bec2-2b69b6d41bc4","7b940f80-4c86-462d-b24a-7ad474667494","df7695ac-1be4-44f5-9514-6be82d72386c","039e630a-85e0-43ae-b558-490de0ecfa88","c706f34a-a906-4e3b-833f-9f3a49aa182e","8679bb15-c649-469b-8eca-e2e8039b08d8","d39fdeec-b4b5-4f09-9c68-1fb75a48550d","fd1693a3-c0cc-4af6-b85e-f237a02ecc35","5955fc50-fcea-48cf-b744-5a3166a19eaa","8d2e5100-c82d-4f48-a078-5642acd1513d","1069c047-2ef8-434b-bf3e-0e33e6f3d821","865af253-6e50-4ad2-a59d-0ca7bbed1444","62a2c842-f5ce-4754-8eee-331b059d30c5","69a02a67-24f0-49a2-a940-6b76d2f942f2","7e4c6bed-76e5-4ca4-a401-380670552ce8","b2a9312c-7c0b-42f4-9b4b-bf76866918cb","848e2261-32fa-48dc-a71d-468245bf9a03","3d6daf19-54ca-47f5-81bf-8b293a2dd7a9","098260c1-997c-4e3b-a21d-7be23493d66b","a8076f3d-0690-488f-b704-49fddaafef9e","3025623d-18d2-46e5-8639-ce1b694b6ded","ead5747f-a49e-4d65-b9ac-1d682d076d59","6a946ba6-7ad8-4941-9519-ef3f3ac09f0e","63b6fec6-5b7c-4638-933a-689b395981d3","ae2ee58b-1ca4-48c6-8a3e-79df627e09cb","b08dce47-b2f0-46f2-84a3-310e9827aace","07d11d4b-c95b-4dd7-b7d1-4f4b2b8782ac","88b0782e-2093-4aab-bbdf-d8a54fb83f5e","56280e21-499b-4600-9ab4-b71fa171b969","8733f2b3-185e-4dce-bd42-3cdc79f274c0","4860388b-822f-45a8-81f6-cf3e0a44d240","91fe1317-12ef-463d-b0ee-62b8c3776430","5a5dd430-e55c-4c79-864d-6b4f15f71255","f8253f25-c6d4-4e43-85fe-d872f8e9300b","ef590093-a7df-4950-b77a-4b595c5feb32","ff5b4449-5139-4299-b472-7651592e187c","269b7213-d325-46c8-8aba-ebc42664bcbb","7c6e1ed1-9eb2-410a-baf8-aa58be819a97","f7df140f-6512-4a3d-84f6-0ca4f707be2b","4144c93b-55a9-4425-8121-f311dea25ee9","955e4a01-68e4-49ed-9763-7840ae97bc21","6969428f-f37a-41a0-bcf7-169d0175b997","6864f37a-c48e-4d95-be6e-030fc36934a6","0f643ebf-9c97-4f50-8311-e0b7ff127767","34ec7d64-6c18-4a5e-831c-a023c0afc93a","7e222ba2-2655-40c9-ac32-9f5d5862ea36","205eb848-bc5b-4335-acf6-ef32ff1727c1","936f79f6-bc41-4926-9856-0130f6e23a97","01cda4f8-3317-4772-9665-f548ebbc35c8","a0d37e74-3117-4143-a82c-1b900c4ed87f","8b25b61e-075a-4251-a620-9c89e4aae30f","8b57ff3a-c3ff-486d-aff7-a9233ba001d2","4e5de446-efaf-4019-934d-b52bb4b9498e","2b082bb2-5db1-4f3c-95f1-309c93995ee6","adb8224f-2784-4af1-956a-ee7834bf2640","b2d7df17-7c11-4912-a74f-e02d7cd50473","c44797d9-4bc5-4a38-8742-2b2d33233834","4f2bd6d5-eede-49b2-a681-ec9c57280a50","19638220-ac93-4a8e-b341-56701d15a5fb","80bea87c-7a7d-42f9-b759-492a7d554efb","58d3ed40-3995-4db2-a96c-bec671f4c9c8","a366f791-41fa-441b-99e8-7033e63ed84d","6d154842-79c1-475d-83c2-1d96f4a96db1","d1923abb-00a9-41a0-a8ac-84e7e4589e23","707b2565-c78f-4755-8a7a-320d3f0dc749","387c412a-abb4-4c80-99ea-fa724eb1e25a","f06d6e07-de0a-4038-a34b-fd9ff20211ec","e8e67bd0-68fc-47cb-b4bf-1a0f02a4c964","d7853436-7b98-49b5-b547-1fb9fde86fb7","f97253e0-7f91-4745-ada5-715cecf900a3","a0cc5e06-8f12-4173-b828-dc1f0a9b40c3","50030438-f184-4b1b-81fd-c3ba9eff44db","de41ee7d-e823-445e-9d10-11683b348943","1440bfc8-03b8-46aa-bcc1-5fed3a005f5a","72e8e6c5-cd5f-455a-9c64-f5576065c825","8cd3511c-30cf-47d5-95a4-50910abd9f77","15f67c43-58bb-4c47-89ca-5def73bd903b","4dfacf04-fba0-4f2b-be55-952c96b03051","2b9360e0-8191-4a0e-b8e9-8a47cc983edf","cc4e9078-fea3-48a7-a62b-41e8f92804ed","39200a88-ae53-46a6-abb3-d6fb42826fcd","001b2562-d491-4176-9f43-a78f96b5d552","4524af27-7c64-4e24-be85-6013688c63fe","05aebbf3-99ec-4e4a-95bd-7e4bfb04423e","c91b1667-933b-4f41-891d-60a75e17c7e0","e0f0d78c-83b5-46c6-a160-77840d8b8f7c","dce432d2-4928-4043-962d-0fd8338a685a","178bbc51-697f-452e-b869-29520c609e63","6a319c70-9a3e-41b0-b5ab-4eb03fb0ae9f","0badbb01-a6c9-4d90-a8a5-2cfaa766c54f","0b4dcc74-7790-4d5a-a623-3a050d9519b6","c3dd29d4-2a3f-40b5-ab51-27693fc0592e","b18c43fa-e4e2-4fd2-bb42-3caad0c707ee","ffc01f37-845d-4c18-a468-dccefde1a8a5","9b7f8523-8249-4435-a46b-ee7a7922a71b","0efff4ac-efbd-4313-aa97-0dafe5bffbd4","57910501-2565-4bd2-a50c-862bd1195b97","7c667756-24e4-44ab-b2e5-b248dc5e18bb","6e53e295-db6a-4635-bdbf-6cfa0bed93d4","0b3ed360-063b-4465-b373-676349a52e27","5d873b5e-dee5-4577-a48d-e0d22534b270","67706324-e3fd-45b7-b7eb-b77883afee54","fb9280b7-427a-49ab-8f46-d66715441d65","caa6c7ff-959a-489f-9f5b-29a0694b623f","eea722d1-118e-44be-9f99-fe8f8c017b8a","26006ce8-3f0b-4dc3-b2cd-6e4073221750","0966995e-54f5-474d-8a43-9dae43a27d41","7da9bfc7-b504-42d6-8b99-b3bedf5cdb57","af4b8c85-1ab0-401a-b4c0-e15ce54cb9b9","6ebae86c-4a21-4881-aa55-759cb98f25af","e86e1526-bf51-4a32-b329-d55c0bb15b28","ddb12a56-9ab6-4d5d-8bc5-2d8183dd7498","5623357b-8566-476e-993b-065df3a63ee8","5db528da-5c94-492d-a023-8746a8bdcc19","b3d6e22d-adda-4ee9-8add-98cba171fbe9","92f33881-8bc9-443f-ac37-6dd712565b37","a3782f1d-a56b-484c-88e4-c4095e5eddea","6a5a2c11-2ea9-4919-a242-a7b106862e7d","2759e379-7c7b-4bf2-acae-0904256169b4","9d52f989-ba9d-4a44-88e7-c258557c6070","48f32eff-95d7-455b-bbba-376f42321564","e73a6fa7-a9a5-4f07-8372-5041335889ab","f0cd197b-893f-49f8-88f8-f0588075e75c","e22d691b-f4f2-41a2-b615-1081c9493efa","54a30ca5-65cb-4f86-a061-0699896bd4ff","5e3f5c33-2922-4e44-83de-ca4a55d15a04","1ad358b7-a871-4c00-927b-ba89b6e8c7b4","a0811b79-b686-4ba2-9a2c-b0895e5c1e45","1fa6c2d9-538e-4fd0-af4c-0a606dd75676","bf3a3d82-2d75-481d-8ab5-1937f4b6165f","6c709e28-a4bb-457a-b4a7-9d24b7ca9a24","758c2e39-d5b4-43e2-9fd4-123865871381","5d886d94-7d1f-4334-bc5e-dfbb2bba9a52","f0ce68f3-19e1-4802-a7de-5b17fc1932e6","754ac074-415a-4aa4-a9a2-6e7989b153f2","1eb8168c-94a6-484d-aa8f-ec9ed711ab4b","4e2243fe-2fbc-42ed-a783-c69909d5bdae","6425d57f-ba6b-4fe0-a8de-2efc4bb1cbf5","84e4d761-01ff-405d-ad18-cb363574381b","501e8146-9352-4470-9bc4-aa53f27260b0","95b6f3cb-9f78-43be-bbde-16e3bb832674","1dd86cf1-b783-4d3c-85e2-51d7d95f4fd7","77c0bc24-6846-4f52-abd7-09068a8b0c81","dd6de396-38a3-4f3c-b699-875a44a85dec","128e7bd4-5ace-4cdc-bb57-b8a286c4f10d","ba5e729b-c312-4c64-a63d-ccc6594f72c6","3e38d2a7-a487-4866-a991-c894bf966598","be97a08a-0ec0-41f3-ae6d-26d186503fd7","fcb353cd-3e3f-434c-bd2e-d2fa9dc84282","b6c95d24-8204-46f6-a216-9938225c9fea","efc20cbf-c8fb-49b3-a76d-3617a45bcf12","2e85c3b8-5c0e-494d-be34-de49f45eae09","1a2b4387-e093-4e26-b4ac-67a3f78ad18d","abc12228-e4ec-4aa7-987a-e75852c80397","f4456fa7-b3f6-47c8-b012-15915c961ba7","f8cf3180-6bf4-42e7-8970-742637df9551","39cf79d1-df04-4623-a111-b679f39eebdc","904163de-19a9-46ae-a36f-dd38edc2ec73","a2a7ed34-7b12-46c8-98d4-4970bad96b82","7f8aa8c9-d3a8-44ac-a776-460957cfb0c2","051ee274-7c73-44e4-830f-4afc1706892c","81c7c462-9c6f-4cf9-9e94-02beefd41b54","3c5b02a5-839a-4ec5-9033-fcece0a7e9b9","f17176c4-38c3-472f-b862-c757991a953b","48aceb61-5be3-4c18-ad95-c49ddefad742","f1a0cf32-9450-41dc-acc8-ba81a0e45340","a7bda4d5-fb94-4745-a06c-3243e121116b","9cc76e5f-1176-40cf-a502-2ee8ed73f270","bbcdb4f3-6a69-4c01-9dfe-528f41c5202c","67a72f4f-6dc9-4be4-a79c-c19fe469c4ce","2ee716f6-dc9e-4c4f-a776-2ac6760508c8","3ca7719c-7e34-4b95-8abc-d4f456c6ad75","2a53f72e-d7fa-40d5-813f-1692804af9c0","a4abea67-b7d1-40d9-b09a-d773a80fd7fa","e5add331-5e70-4b5c-963b-a60ce5509cef","abf95851-fc28-4039-9fd7-3e978263e1e2","3a92d9ae-beeb-4265-933f-b6c0110dbc56","0118187a-c2aa-4aae-9292-ea47b174f1e1","8d71f4f5-2934-425f-ae9e-f15bf18f27a9","a5a22c62-1f8c-4c8c-819a-132877d430b2","6f2ab800-982c-49f5-a694-9f72a3b550ed","6b26c73d-b506-40de-bed5-866ccd5a9f95","7aa6639c-f088-49dc-bc72-66364da449f1","4c1d943d-2c55-4133-a066-2f86cba9190e","b5addc35-d3b7-4b54-b54a-9a09b0e9f8e3","68a4a16c-0d34-42d9-af09-4d53be6903b1","19ed5ac3-f217-4675-944a-d205aa5aab53","42d5432a-b40b-4704-905c-2389fbbf99bb","69c75202-65b1-4744-a83e-39d930a2d3a9","204233fb-5a43-40b9-aa54-06962bc1286b","fdc8bb7c-325c-4c1c-a05c-f9cfac064c96","1f412214-3abf-41e2-8d06-f6b0e4690ef9","3a402f12-a334-4a0c-845b-641428ae7b78","30eea461-fe51-4cfb-ac28-7b80f02f3a74","76882e3b-1d65-45df-a5c1-e20b85137d9e","10cba73a-bcd7-49e8-8409-969cad15f542","90ac9f06-23d2-4b42-9c0c-b19643ff748f","6bcfcf2d-6222-4544-a3e8-67809966a5fa","01bfe0c2-65ea-4f1a-b1a0-7f9c680ab15b","2e28be70-433a-43ef-a018-ad872e9f3105","7376bf8d-a042-4e28-8dff-ca6a98172b03","bf2d1c3f-d0e8-415f-b07a-6a8ffd67befe","d83079a6-56a0-42da-9404-332d6a6e2bd9","3631bf4b-9f9a-4749-b963-b390530d732f","cb2f2e60-4865-4dbc-8d83-8427cd36567e","fbe5673a-8e41-4f6e-8e1a-017b06c8bc62","9cbdffe2-fe87-4cd0-aa7d-4c879f8544df","b1a701d9-a55b-4252-a3e7-d7a52edf7738","711e9191-6569-4082-bd64-b948aef8c9cd","29a64d92-96a4-433b-b0d2-53a6e75b1ec7","4f1b0eb1-c699-47bc-b765-66451a09c4eb","239f0e0d-7f42-4ada-a19b-734fd64ea237","f92b5723-d6a9-48f6-9ee3-2bb108d81a42","ca846564-a506-495e-a811-5179b2747e24","5fefc930-9f35-4b79-bfd7-3d819f42dcb3","90462918-bffc-4f9a-a0c9-b3443569d437","2e73d7c6-b081-40c9-8a2a-51188abdb506","44e22da3-2bb3-4d50-8f27-099638cd453e","f3886d01-6c00-4172-b106-e83907cc86e9","beefc811-23f1-4c39-af7b-f9281e058073","dee33520-8f73-4fcc-b573-3b47a443fe28","6bba5b4a-a28b-4880-a018-0be8a399e88b","7c4917d1-8e1c-430d-8f28-3d35eb12345a","1e058eed-f99a-41d2-a640-8fee9ce91b78","473b3789-eaf8-409a-a452-b276367bdc5a","83ec9527-8044-4d03-89f7-19569edb2c98","37c677af-2b42-4631-a64e-3a92d4983c55","701c33e0-aa0e-4b64-aeca-929df47897ec","b28f9316-22d7-4523-afd1-9a2f7cb9541d","f6646625-4dee-4e6e-8a36-08f21bce3e57","cb7054d6-8f34-4e09-9abc-562acc15e03f","4626dc9d-de3b-44db-8d27-4b3ea89e3f1f","c7c5195c-5712-4ecb-ad3c-966affb1a805","d4897693-8eb1-4b6a-8a93-881a7e3f2034","79db6515-4525-4142-8aae-7d4c60410945","7fb38a9a-4201-4705-9bf1-83c9d520b42b","69339992-4c43-461b-8322-e355c0207795","9e2a04cf-b00f-42df-9e00-e67471b2f1a5","b2292cd2-80ea-440f-a4e1-fe4833cd4148","6c005a13-a990-46c5-b04b-52b48af19555","e4a74553-0f48-4b6b-91b2-be2ca94a31b2","462ea1f2-e93c-4999-8611-ed88d7175e91","a71a4174-b34e-402e-ac6e-a75b74aebdbe","e2424d3c-d694-4252-b3f8-87f0404e18ba","44416fdc-7907-425e-9734-4ad72a7a6c4a","0383e4b8-aabf-415c-90f0-75b637dfc627","ee29eb57-d3ff-4923-88cb-041765e73fab","b7ce42ec-e6b9-4458-b76e-c45fb5a32a30","c2be2f31-81c7-4962-ba37-4e6e6af9d82a","661fde0c-11bd-4f62-bdce-b76ae83e171c","ece2d8f5-c70e-4be6-a578-b27978317a06","3efd29b6-0ba9-46c4-b93e-282df77ba719","5d7e29b2-5e8f-491b-bf46-a4f699f524ac","526ace24-6179-46de-b6f2-78367096527e","cf0110b6-ada4-4bb5-9bd1-6d2bd4ad0e1c","925e8b0b-67da-454b-bcf1-ecb403702ac3","2fa25d92-86ea-463c-91a4-38140efd73da","8851f087-f76b-4ca1-bbf7-808f7f6149e5","d70c6a11-9f5b-4b19-b1d5-d29cd43c6aa5","ca8f2909-c217-4874-966f-42f4f07ed8ec","5d2066eb-62f0-40e1-a8c9-735ed1ce7a37","28d83ac7-858c-4bf5-98b5-659476698cf3","faa04e71-2080-4730-a172-55e9b22ed67f","384c2fb3-8777-4f76-ac98-8d0229e15d99","e268804d-97eb-4757-9b45-bfab36a7845c","21a3f349-d615-4ee9-998a-8727edb6641f","6d07ee8b-9f16-4d29-817d-ed2ec545a558","718df102-b1ad-4c17-8b70-2b46436db36b","3f14242b-32a8-46b8-b08f-b1c6c77134f6","9426ac7a-613f-4df3-8aba-092515465a66","6277735a-bee1-47e6-9cb9-6c9fe2692f99","77172a63-2e60-4a6a-aacd-994fdeb0eee9","9e4c0ede-8fde-4ebb-a169-48aa8dd148b6","507422c6-4648-4069-8f0b-47e2c740d74f","8536aafd-5d8b-41ef-aa8c-a8d59bf0dd72","d2b2d4e7-0838-4413-83f8-562fe8cecb95","c0f550ed-0fbf-4966-8847-17aadb38dd87","8fbbfa40-c67b-473c-815e-dfe404d3894a","ab14dd4b-83eb-4be8-b7bd-d4c5d20d7ae5","d6efbd88-8708-4bc4-95bf-a04a17f009bc","e5e8a87e-b118-4861-9204-f89dbfda19a6","8a8fdb7b-cb0c-478f-a303-1872c7ddca63","b85c3d80-6e45-4f06-ac66-78cbe1a0d4e1","04b3c5c2-c9c8-4105-ba1c-4591916826a5","457a7629-2958-4b9b-9993-2217ea5ec4d1","125336d1-bcb8-43c5-b48a-3195513047b6","f216438f-c0b4-41b9-88ec-aa4e591fdad1","af15f00b-fcb1-4b97-930a-2323ddf8a792","79f4d86a-c8a1-4f52-a42e-605b23ba44dd","42342e22-0ddb-4fbd-913a-a06cb4a65061","ca04f1e4-46be-4553-bc19-af5b41fdc3ba","84b588c5-2227-497b-a414-560c41108b15","4fa222fb-2140-448d-b84f-bcac60d20d23","71d27d7f-ec64-4077-8a39-778c7866862d","34b0955e-e720-426e-9bcc-96ea6959d06f","47d915b4-051a-430f-b3e7-96791dc4f3a9","533e4c91-7abe-4e5a-ab7d-a3bce4bbdb1f","b570c755-2f7c-4ad0-b448-e071bf39079c","4de9f8a6-4ab5-4ca2-914b-63cee8228f19","e3d00566-dde8-42fa-bb8f-73846fc13947","d8c86e26-ab5f-4a69-a551-620cee5877d0","2a240ee3-6ebf-428f-97c7-6655716f22c5","9b947ec2-67b4-44f2-b6c8-cf1a6a35196b","0cd81e6c-c52e-471e-87da-200e7c117477","b9728cdb-86ed-4ee0-96ea-c8cc6e427018","c1a3bbde-bdda-4865-b782-9ba65246295f","a3351ad9-0f4f-482f-b442-3fe94ad91ca7","719b4530-c79e-4c0d-b68e-88eb8a8d4967","35dc884d-ef7b-40ee-842e-2f399fa132d9","a789e7a3-b44a-4d0e-b5f3-c576e459a627","297347b2-b970-4ef6-ad48-7347180867a7","78757ab0-0caf-433f-acb2-40aa137fd6fc","3abdb192-fe38-42e0-86f4-7010046314e3","3f2284a1-d5aa-4225-bc34-0841f34b022b","ba1825a0-411c-4a52-b1d7-638d1dac1192","f9f7484f-f5aa-4998-b2d2-e81d38c86fb2","32501a60-94a1-46b9-94ef-b8ba215c20d6","ba18d723-057a-4c83-80cf-161e44f93322","89dd7655-17cf-4966-9972-dccb57fa1a23","74791eab-4309-4b8d-a7ca-0229b26f4143","3e9fc564-7675-4577-a101-b32bc9e524b5","92ecea77-69de-4e65-80d8-c436b9bbebae","7f12bbea-2752-4280-9335-4af97330ea88","39567a2b-4b18-479d-8739-f5eac38bc0a3","32ecd4eb-1676-43ba-a3ec-de73646adaaa","b7029fd8-498f-4ba7-94be-a8c615443b5d","65f14778-9373-4c65-ac8d-e1f5a06910c1","42aecd57-f47c-43a8-8238-38da39dd46fc","59fc7eae-ed31-48e4-90b9-bab9dbb59dd8","751b7c9c-f550-4cab-ae47-4e8140140fe7","f71e6f32-3b09-4d78-9737-af88eee471d4","b62831dd-bd7c-4883-848d-07837062e0e8","768761b0-d841-49c1-944c-736b5bcc9284","fe206578-7ee1-43b1-b838-a974e0f55cb6","01404e1c-fc46-4556-bfea-2c9ee59047f7","f5812bd4-8a56-41b5-9609-0545b341d41a","31380387-79c5-423f-b971-2e744a27be0f","59d92716-6718-422b-9570-bb019726ce08","49f8cadd-5dec-4f89-b5e9-9d49942b7b99","ef748de2-35b6-49cf-852a-53179a85d0a0","e1d06cd8-4883-49d7-ad58-7508af6cb695","a37d7ad8-9ceb-483b-93cf-3a03f1446dc6","2535bf12-e80f-408b-a302-45bdddca05e1","50895397-2c4a-474c-94c7-9a694403753a","20a1f313-a905-4a36-886b-e5234ae4d814","831fc343-7c53-4005-983a-0cfb249a23f3","e0d6bb3d-80d6-416d-abd6-e312402f641f","cf82b730-2ad9-41cf-b25d-e238dbec15d5"],"groups":{"001b2562-d491-4176-9f43-a78f96b5d552":{"collapsed":false,"color":"green","date":1707730811204,"id":"001b2562-d491-4176-9f43-a78f96b5d552","locked":false,"tabIds":["832d845d-f35b-41cc-8b3c-a063fcd40dfd","558167d9-37c1-4ef4-8e37-d638c6f4163f"],"title":""},"0118187a-c2aa-4aae-9292-ea47b174f1e1":{"collapsed":false,"color":"green","date":1698547429951,"id":"0118187a-c2aa-4aae-9292-ea47b174f1e1","locked":false,"tabIds":["22ef94be-b42c-48a1-aed1-fb12e4fd0be5","de4e2fe2-0d71-4a96-9705-04d9cc975205","e9761205-4ea7-4b0b-aa53-494b902cfb99","8c97e1b0-2e64-4996-960e-5a3654ed2bc4","61e993ee-42b8-4912-86ab-4eadc7d32c87","d2d8eb0e-a5c5-4fdb-951a-53075a9fef93"],"title":""},"01404e1c-fc46-4556-bfea-2c9ee59047f7":{"collapsed":false,"color":"green","date":1698547429951,"id":"01404e1c-fc46-4556-bfea-2c9ee59047f7","locked":false,"tabIds":["83106cb0-16b1-49ee-876c-4cf53f4ff832","6014b209-5628-4828-99ee-eeca9fc145ea","3f989401-44b4-4fb4-9e96-ac88a317619d","d6f9a423-a914-42c5-bf97-1f02dae5c0c0","6f75b18f-ae24-4a9e-8042-46b9b0a1e20e","9bc8a599-5859-4b89-b793-10b020d6a526","caa0ad8e-662c-4a56-a7e3-e176d4144f54","e6667ddd-a3a1-4c9e-8b36-2986c65db3a3","80cb20ef-b15a-4c7c-856b-195968a40403","ae2e113c-5c15-476a-9ee8-31dac453b24d","35013ac2-e1c3-4b25-98da-821d8154c7e8","33dbfa98-3ee0-4bac-8b0c-7122a83253c9","e889f749-f79c-4d86-8acc-226fc49d04d3","997cb84c-1e0f-4da1-95e2-e43271afa4be","21237e0a-bfce-431c-bfd3-791a2b134391","c50933d5-e152-4710-9243-58a8a509aa42","91a274c1-3904-4250-8286-9e5e8c6ef500","5c8d7b47-837e-40a9-b8a0-380068ae9b97","7643c88c-7772-41b1-808e-8979a4e20816","61047030-38a4-49c5-9a78-5733b2f62f08"],"title":""},"01bfe0c2-65ea-4f1a-b1a0-7f9c680ab15b":{"collapsed":false,"color":"green","date":1698547429951,"id":"01bfe0c2-65ea-4f1a-b1a0-7f9c680ab15b","locked":false,"tabIds":["68316ed6-4f5b-4b8a-bc31-b77714673032","c7b9b7a5-c529-456b-89e8-b7e7ccfc425a","4389e5bf-3a1d-42fb-9bcd-f35206013ef0","d48b58ea-7d60-4da9-b586-b4622ee1ffc5","93c6aa15-b8e1-49ec-8f2b-1ba5c3fe8165","b4c0de1a-f9cd-42ee-9492-6c75511f8884","153d6b74-cad0-4d06-8e01-4f116df28e45","fc071d7e-60ad-40ae-af2a-f912ce77708c"],"title":""},"01cda4f8-3317-4772-9665-f548ebbc35c8":{"collapsed":false,"color":"green","date":1710534424134,"id":"01cda4f8-3317-4772-9665-f548ebbc35c8","locked":false,"tabIds":["d77ff7b0-da76-4925-915e-2d12273819b5","d40123ea-b0e9-4c4d-92b7-c93340149fee"],"title":""},"0383e4b8-aabf-415c-90f0-75b637dfc627":{"collapsed":false,"color":"green","date":1698547429951,"id":"0383e4b8-aabf-415c-90f0-75b637dfc627","locked":false,"tabIds":["fa0ab406-b3d9-484f-b803-04edcb4ce944","d985df45-38db-412d-bafa-b2d5b06e77dc","cbd9c01f-520d-4ffa-86c0-ba1e20fcdf45","14002a12-6311-4e0f-9589-7fe8ca1bbdcc","242dc478-8924-4f33-8b4c-eaf06216bf95","d905ea22-e5dd-4c09-85a1-538726de4d98","42fdc09b-6683-43f5-b0e9-e547a667f433","ade50701-9dfd-4db8-8a24-31038bcdddfb","c80f5bad-d5fa-4f10-afd4-8670a3d7c864","bcd489d7-50ae-4fe5-aa91-f78dc2526b5a","b09b5c00-92a1-4d47-a4eb-b4ed54087208","65183e68-b4ad-42e5-8f76-a5e5a5fe8845","ff7cf611-c232-4667-8957-9e44cc0982ef","e329ef51-4e25-48dd-a99f-1573846359d5","747d43ab-9026-494d-9cf5-a699ad51cae0","7cbb8934-89f4-4e73-9ade-de9dcf533896","77a62518-a093-45ae-8cde-d5249ec253ae","cbf512c5-3d95-4805-8497-0466193de6c7","da40a818-29e1-413d-b66d-616aed38669f","4f1fcabe-5133-499a-9396-2dd753e94e22","f22e1f70-5551-499c-9dfa-b1428e10180a","8ac6816f-69c3-40b0-9bd5-86939ed4251d","6aedf61e-be24-47fe-bba7-b539ae5d3448","0c2278b6-46e1-41b1-a76a-7004fecad37e","8d0934bc-e652-4207-b7c5-0e67d5d7fa0e","7f7ff597-8b4d-432d-adbf-b0e787e98da0","b35beb1d-e1c4-4953-bd36-747c0c75094a","31360250-3255-4b29-8311-02f79e8205af","c1590af1-517e-48a6-874b-78327b19b3fa","6f2d104a-4fc9-4351-be60-bb52a9b0b6e1","28b7ade5-a20a-4277-b33c-eeee58007b75","d9e22a14-a20e-48d9-9c9c-8e0028d99a33","18477f6b-3d21-4d10-9867-08f41f6ed814"],"title":""},"039e630a-85e0-43ae-b558-490de0ecfa88":{"collapsed":false,"color":"green","date":1713324620448,"id":"039e630a-85e0-43ae-b558-490de0ecfa88","locked":false,"tabIds":["896c58a2-6cf6-4632-beee-1276a513c622","45bc5e8b-d988-4199-bcd7-62c0b381a1ae","fe1d24dc-d0e3-456e-b0a3-481708543a63"],"title":""},"04b3c5c2-c9c8-4105-ba1c-4591916826a5":{"collapsed":false,"color":"green","date":1698547429951,"id":"04b3c5c2-c9c8-4105-ba1c-4591916826a5","locked":false,"tabIds":["a873cc97-d50f-48f7-b47e-6052ad537745"],"title":""},"051ee274-7c73-44e4-830f-4afc1706892c":{"collapsed":false,"color":"green","date":1698969459461,"id":"051ee274-7c73-44e4-830f-4afc1706892c","locked":false,"tabIds":["55fe93b5-1b6d-496c-ab89-5d4804274abd","de3d26c0-89a9-4286-9251-16a1c2375e45","ec466f43-d856-4e67-a409-74dc145fc17b","aa03c19e-0360-4f65-a135-6ea92cc65e66","86d733e0-772f-4bc7-ab0d-637c6b045aee","d0ec772b-0ba9-4a75-b5b2-b2948aa5f4ca","77cfbe7e-77d1-41ac-92e0-000ec7879ff5","ab0e9932-7bcc-4f3e-8cd9-1c09d8a7c406","18ead723-0e39-4b1a-a17e-132563612edc","e84b961f-7031-433d-9de4-03dbe5d2da5b","8f1cabc4-9191-4106-8d2c-11597119552d","796fff37-2385-4272-a7fb-147f1ed6a0fd","f422b44f-9a3a-4ed3-afb0-8a75406f6079","ad8d668a-43a0-46f6-bdf1-777b4875e9b1"],"title":""},"05aebbf3-99ec-4e4a-95bd-7e4bfb04423e":{"collapsed":false,"color":"green","date":1707681084318,"id":"05aebbf3-99ec-4e4a-95bd-7e4bfb04423e","locked":false,"tabIds":["b8d5d188-0370-4376-8202-050ca3c94699","b9ba237f-fcb9-42aa-b39e-c13192958f19","de7a9d08-747f-48f6-b708-1e260a98181d","ad381fbf-da02-4b09-8619-76108c7f9639"],"title":""},"07d11d4b-c95b-4dd7-b7d1-4f4b2b8782ac":{"collapsed":false,"color":"green","date":1711662107695,"id":"07d11d4b-c95b-4dd7-b7d1-4f4b2b8782ac","locked":false,"tabIds":["d2f2f306-6574-49c6-a693-cdbf0b75804a","d19b0eea-94c5-4639-ae2d-feca58be3922","2a2018ae-02ec-4117-b288-182865fa028d","ee18cfdf-4a4e-44e1-9186-871ddf4c7ae0","2bddea93-8e0a-4978-9281-ee36842934ef","b64865e0-be1d-46b1-b557-ee9d1177cb9d","48b48fa4-7a2d-4a04-b91e-9acceb49eb39","89f146d5-8b60-4422-9e62-d2a2c632dc9d"],"title":"stealing"},"0966995e-54f5-474d-8a43-9dae43a27d41":{"collapsed":false,"color":"green","date":1704658298905,"id":"0966995e-54f5-474d-8a43-9dae43a27d41","locked":false,"tabIds":["76bd8b84-d971-49c7-a748-4078c754132a","5494f858-facc-4593-bafe-26a152e188e6","5ec7e00a-9a45-4771-a7f7-cdb5c9ab61d8","1c150cc8-b016-4494-87f3-2a7f078ea8a7","4e0d1def-77d3-4c3e-8e09-ca3afe1d6787","1e7dc795-2743-4147-b4cf-ec1307590ce7","255decb8-0260-4e1a-926b-095d1ff9fb1f","3a27defc-a746-408c-ad14-778dc1028b3c","afe70dea-bae1-431e-8b0b-c76c35e08602","17630fd7-d8a0-491e-8c95-a6076e8cec40","0576bce8-f78c-4908-864e-ca54e94c5f78","38fa38ce-e7d0-4c37-9090-157cc708502d","ec4a37aa-9d11-4b11-8003-e84b3b738357","a3fbe785-d00d-41d7-b188-931fcf786095","ee32592c-36a4-413b-9402-279e9dfbd7ee","7364a866-dd2d-41cc-a2f7-ef4f68bb5194","0f418d09-ffbc-4163-be1a-2319f92e96be","bfb0f44c-dbda-40b1-ab1c-a715c43885dc","011f5e08-c73a-405e-a35b-edcfc6ce9642","f1f6a750-f0bb-4ab5-9400-bc08c239ff6b","7ffee9bd-ab43-4251-9ad4-7e4bd2b7ed53","a822113a-6bf5-4740-ab1b-0acc338ece77","2ac796da-d12a-4c95-a03b-d6c5d85c96ee","06237a0d-86b3-4fd4-8035-a22304622c53","7b1485cc-dc71-4d99-9114-c363490806dc","d4d18cb4-851c-4e85-bc23-653d7d944691","df5494a5-9d61-48bc-a10f-056144e5e88a","5c48f1c8-01cd-47a2-add8-b6e0f8a74ec3","7ea2371a-e161-44c2-85c3-c411980849c9","8ee7053d-01ff-4b2b-add5-332288e87893","4b02ad2a-8425-4b0e-986a-ac597c9ae6f8","adf3e95e-b2ff-4047-a28d-ec1dae19acd0","e3e4a284-bb37-4c9a-bd2b-fa756313eeef"],"title":""},"098260c1-997c-4e3b-a21d-7be23493d66b":{"collapsed":false,"color":"green","date":1711995659403,"id":"098260c1-997c-4e3b-a21d-7be23493d66b","locked":false,"tabIds":["f6c2fbfb-98aa-4109-b8ad-6861e4929ff4"],"title":""},"0b3ed360-063b-4465-b373-676349a52e27":{"collapsed":false,"color":"green","date":1705546225424,"id":"0b3ed360-063b-4465-b373-676349a52e27","locked":false,"tabIds":["7bad0de7-cc50-4b60-ac85-7821efbe135c"],"title":""},"0b4dcc74-7790-4d5a-a623-3a050d9519b6":{"collapsed":false,"color":"green","date":1706337696490,"id":"0b4dcc74-7790-4d5a-a623-3a050d9519b6","locked":false,"tabIds":["75884ddd-93f9-451a-9f9d-0faf6db96ede","fe53e37c-2581-478d-a81d-27c4766e0826"],"title":""},"0badbb01-a6c9-4d90-a8a5-2cfaa766c54f":{"collapsed":false,"color":"green","date":1706473663533,"id":"0badbb01-a6c9-4d90-a8a5-2cfaa766c54f","locked":false,"tabIds":["83e18788-9241-4d65-adb1-7a6c7a518d29","4613bb85-dd04-4047-ba6e-098ff0927ad6","08d40414-513c-443d-9ecb-33776fea98d1"],"title":""},"0cd81e6c-c52e-471e-87da-200e7c117477":{"collapsed":false,"color":"green","date":1698547429951,"id":"0cd81e6c-c52e-471e-87da-200e7c117477","locked":false,"tabIds":["6e1fcad9-5a42-4539-9336-6116101eb707","e4b316d1-2f62-40c9-9412-4ad04d306ce3"],"title":""},"0efff4ac-efbd-4313-aa97-0dafe5bffbd4":{"collapsed":false,"color":"green","date":1705607601846,"id":"0efff4ac-efbd-4313-aa97-0dafe5bffbd4","locked":false,"tabIds":["2dc09caf-51f2-4fa1-9e97-4863942b59e3"],"title":""},"0f643ebf-9c97-4f50-8311-e0b7ff127767":{"collapsed":false,"color":"green","date":1711226246789,"id":"0f643ebf-9c97-4f50-8311-e0b7ff127767","locked":false,"tabIds":["5df8686d-6530-4693-8a39-d0ea258139fc","78a6241c-a226-414c-a551-e24c5ccc1c9a","28ef920d-1c66-4c4a-802a-94d9d0ee5ff1","78829ae5-ef72-4b28-8a1e-cbfb49f28169","7d820f7a-5252-46dc-b1c8-62696f57d706","05c69fe5-6bfc-42a7-a1ba-55dace50c199","d92c8a30-12b5-44e3-8bbb-e5724e8d3987","dd41b4d1-522a-4cd8-a647-8f7f71106d28","f1395f56-75f4-4639-a41c-63f6159f7302","17a60040-f88f-48bb-a70a-b59b7ef8e52d","a565ffc1-c01b-40a8-a9e0-8bcb054d3004","9ed60ddb-a14c-4b05-a1e7-a346b389b573","306329b8-f3d6-4d47-acf1-7172bd95af80","952ecadf-d98a-4331-9c20-eceec25785d7","a7c7ec30-9976-4d65-936f-fb5c3b6586e1","4c8fc1bd-ad99-40b0-a91d-746bf67079d0","21790ec5-fefb-44ce-8fe5-2b3db590eaae","a4e5a89e-eb40-406a-9d0f-32aa4c9debbe","a86ba149-556b-4420-b9d5-96e75e46431b","c698e970-ece8-478d-8292-7cbd04bad8d2","a8017712-ac61-4cce-9996-499bedfa2fac","60ff676b-a449-420c-a8f7-1845316cd25d","e75cfab3-8ee2-444d-b436-03c2e3fb8dba","9b667131-ddb3-4ae0-bdb9-45a9f3d2166a","8e9f8770-f8d7-4989-92bc-8170545d9d40","005bd8c8-e9e3-460e-9e57-e4d3fa7b8158","9c54bf2d-3a39-47e5-93ab-e90e353daf40","1a2df807-9282-4080-99c0-b7c094db4335","7d9818c6-abcc-4c30-b5fa-9b5e85f9201c","527f12e3-dff8-45d6-8c5f-16a6b32e2588","466348f3-7016-454d-9486-15c8272430fb","e310c8a0-a4f7-4832-bcfc-225a8cb93a6d","0be7d096-526a-4dc4-a693-51dd5d78a223","0ec32acd-329f-491e-94e5-c4ffda0c53e9","c2383779-91f1-4b52-b684-c4dc51bcd043","54bb66bd-98c9-4cc3-9690-4be530475823","c13a499c-18e3-449d-9d41-0d481431d0b1","a04790fd-9330-4438-9d96-9e56e8a1049b","fd95cfae-3969-4cd0-b858-c61abc923a1d","03270f44-4899-497d-8b5a-07afc7d62d96"],"title":""},"1069c047-2ef8-434b-bf3e-0e33e6f3d821":{"collapsed":false,"color":"green","date":1712553212267,"id":"1069c047-2ef8-434b-bf3e-0e33e6f3d821","locked":false,"tabIds":["8f1960e6-655e-4da3-9ffd-820d1e27eab7","3b84dc90-5824-4a83-adbe-d70f8c5e282e","051bd9e1-9005-480e-afc6-0d2753657642","a6474aa7-35b4-451e-88fd-e9e32911ff5b","5ac30751-1514-458a-a027-906dd91485aa","102130c1-289f-45aa-816b-fe65430a15ef","1c40a923-3c73-4aac-a6a7-a95a300932e6","369b9833-0e82-4e0a-8e5b-ec08795fe182","b7dcc8e8-b11b-432e-baba-05a3d96739df","24512467-2b96-4833-8ced-fe717f59cbe4","673c4c2c-3ff8-461f-87b1-723e511300ee","38719923-1623-4b02-84ff-dce329c4aad5","72cb856f-9139-4e21-aab8-22466ddcf8e2","2c0c88a0-7e3e-4fb4-ad4f-6668650145d1","6983b034-22f3-4200-bef1-ccbee2b6a524","44b00988-a7b6-4b49-9e28-f905219533ec","67cd0cc3-1718-4fda-9a3d-11a01a96bf97","fbe0dcbe-656b-4a8f-ac22-50358dd1ef82","04fbf839-fd6b-4710-a042-a1f9fdad3fdc","c0864925-b1da-4ed2-b921-530c8bb00932"],"title":""},"10cba73a-bcd7-49e8-8409-969cad15f542":{"collapsed":false,"color":"green","date":1698547429951,"id":"10cba73a-bcd7-49e8-8409-969cad15f542","locked":false,"tabIds":["523605c0-47e3-4134-a85b-325de9908e81"],"title":""},"125336d1-bcb8-43c5-b48a-3195513047b6":{"collapsed":false,"color":"green","date":1698547429951,"id":"125336d1-bcb8-43c5-b48a-3195513047b6","locked":false,"tabIds":["3493e6a3-9a9e-4a4d-a513-450a914f3d0e","0c3ea0b7-4086-403d-84cd-dd0b06675faa","0350e780-e65c-4188-b651-15c98998e7e0","891ebd40-2956-4e18-8256-8649d8704fe2","72bf3ab3-fa2d-46aa-8be2-a2558db7216e","61941647-0da2-4405-9395-9b5515845742","8481953a-9abe-464b-b997-625c9781adc9","96b41ec1-3a28-4058-bef3-6eadc24789e9"],"title":""},"128e7bd4-5ace-4cdc-bb57-b8a286c4f10d":{"collapsed":false,"color":"green","date":1700769233554,"id":"128e7bd4-5ace-4cdc-bb57-b8a286c4f10d","locked":false,"tabIds":["d1e96813-a92a-4fdc-a1b0-6333bf6e1804","e1e62490-79ce-4c03-ba42-08ad416bbe48"],"title":"kant"},"1440bfc8-03b8-46aa-bcc1-5fed3a005f5a":{"collapsed":false,"color":"green","date":1708972992052,"id":"1440bfc8-03b8-46aa-bcc1-5fed3a005f5a","locked":false,"tabIds":["669d132f-7d36-43a2-aec5-2df58a00f3b9","22b6f428-2781-4d07-a9d5-69f1539a534f"],"title":""},"15f67c43-58bb-4c47-89ca-5def73bd903b":{"collapsed":false,"color":"green","date":1708547478850,"id":"15f67c43-58bb-4c47-89ca-5def73bd903b","locked":false,"tabIds":["4470ef50-a3f4-4da9-b7e0-4cfa5e4866ac","0b8db75c-760d-411b-838a-3dcedb8380de","0164304b-dd5d-4ea3-85e4-dc2aebed700a","ab451035-d6b4-4514-ab14-6eec2a8cbc0c","a4eb4e47-3952-46ca-be12-3b92e09a20d1","d0dfba57-1b09-41de-ac47-c22399442bdc","5a1a7ef6-04f4-493c-b6a7-491f068af8ab","9723297e-c367-4b71-91ca-165c331fd401"],"title":""},"178bbc51-697f-452e-b869-29520c609e63":{"collapsed":false,"color":"green","date":1706587655639,"id":"178bbc51-697f-452e-b869-29520c609e63","locked":false,"tabIds":["fe91a0ee-1168-4d04-b79f-c8d02915359b","a47dfcd4-8dee-4418-b65c-8de8dddf3a38","db976253-6afd-40aa-acca-6d9db44c4e1b","b23c2f48-b21b-4010-8e71-ac710379ca65","6e480d3e-cec1-4a37-ab19-3ed010d339d9","ec894930-e54e-434c-a676-cf7766c1a3a8","9d27a6d7-208b-4f7e-9b91-7f791ebbb301","86208296-f9b2-438c-856e-effa1a0326a9","1b800271-f261-497a-9202-4121ff59cab2","7126e701-0fe1-4898-825e-7670ec13561a","671b1026-8e1a-420a-acdc-8d64427771cf","e2b9f07d-0594-4db8-a601-e478a4274b84","c012bc37-3ebe-42bc-8fda-fd0751883584","cae831fd-bfc5-4c4e-ad1e-6d2ddd4901a2","e0dfabf6-7ea9-4049-b200-728fac40cb9f","a9cf9fbd-9b76-4852-9733-010ebb1ca332","aed99d9d-6a74-4ef1-8549-de20073bfa6c","53786dad-ed56-4df8-bd24-51a0b3e3d268","aa63ebb6-e3e3-4825-921f-c7aedbeff444","1b095f1a-8bd3-4641-92de-076d39c15d62","a767782d-7765-43a7-be5b-99248b2b60ee","cd2d0dc8-3240-4d81-a99c-777229f5b8aa","3d8d6276-0848-4879-96b5-87b69fd6d932","ec58ad06-5be7-47e7-9023-d0a053f03b3e","c1fcdc0d-20a2-4c09-acc8-d4ccda43e0be","2f4e9c1e-0ca1-4880-ac20-0c9f3d190a75","83e4840c-8962-4d93-bd24-de454842447c","7941b9cb-a2e4-40bf-a5a1-d0baffedf603","c94909f3-f27a-4731-ba8c-85dc654b1ab7"],"title":""},"19638220-ac93-4a8e-b341-56701d15a5fb":{"collapsed":false,"color":"green","date":1710035888320,"id":"19638220-ac93-4a8e-b341-56701d15a5fb","locked":false,"tabIds":["c1488719-75d7-44bb-a668-41200ef30079","130bf118-4946-46b1-9b5c-a8cc188588a5","f2f7cee8-f186-4890-b850-70d7431b7371","ea3defb6-2c5a-4be0-acf6-fac58b189630","f1550665-5550-4298-af96-4c6330c0fec2","b9b5a849-d9c3-422a-9883-7ef7186c15b3","2fc9d625-5f7e-4723-8137-fdfc267d6e27"],"title":""},"19ed5ac3-f217-4675-944a-d205aa5aab53":{"collapsed":false,"color":"green","date":1698547429951,"id":"19ed5ac3-f217-4675-944a-d205aa5aab53","locked":false,"tabIds":["bed410ea-20cf-4747-bb08-545254a5dff1"],"title":""},"1a2b4387-e093-4e26-b4ac-67a3f78ad18d":{"collapsed":false,"color":"green","date":1699828819881,"id":"1a2b4387-e093-4e26-b4ac-67a3f78ad18d","locked":false,"tabIds":["5c5d6a3d-daa9-46fa-a7ce-51173fae2a0e","bebe47e1-7ea8-475f-b9ea-454c9576d04a"],"title":""},"1ad358b7-a871-4c00-927b-ba89b6e8c7b4":{"collapsed":false,"color":"green","date":1702453507211,"id":"1ad358b7-a871-4c00-927b-ba89b6e8c7b4","locked":false,"tabIds":["9c032091-66ee-4266-9cbf-c744dc32143f","b7fc58fe-6a25-4f7d-a046-74e60b8076cd","589f33eb-6557-4ce0-9d2d-cda9573e5365","84ff3661-6678-41c3-83ad-a36705076c6c","6a97ef75-f3aa-4b8e-bc16-4dab84a17aef","22d51f1a-382f-4ffb-a693-bca81a8a99ca","1c3b6aa6-6926-4416-9dbb-3c046995b95d","071ba8e8-3b70-46e4-8819-6e8849c2b155","24b87079-4b59-426a-87f3-15ec4f8e765e","31653d67-a94d-4a08-b83d-e75a6a3c2a27","2bb53527-5f41-4c0c-95e1-6573270f3793","74b2bf47-1782-4e59-88c8-088799e53dbd","84b011a7-1f4e-411c-9631-22ab8c8a1f34","0b2a58ad-c6ed-4101-9a7d-63c594e54b94"],"title":""},"1dd86cf1-b783-4d3c-85e2-51d7d95f4fd7":{"collapsed":false,"color":"green","date":1701062505349,"id":"1dd86cf1-b783-4d3c-85e2-51d7d95f4fd7","locked":false,"tabIds":["55183cc9-dae6-4c91-a6a2-e76d480225c7","b5b86fc2-a1e0-49f9-81e5-67636302edc1"],"title":""},"1e058eed-f99a-41d2-a640-8fee9ce91b78":{"collapsed":false,"color":"green","date":1698547429951,"id":"1e058eed-f99a-41d2-a640-8fee9ce91b78","locked":false,"tabIds":["b62a90c2-a4ca-400d-a748-d332284a5edc"],"title":""},"1eb8168c-94a6-484d-aa8f-ec9ed711ab4b":{"collapsed":false,"color":"green","date":1701805619861,"id":"1eb8168c-94a6-484d-aa8f-ec9ed711ab4b","locked":false,"tabIds":["9c77a595-462c-4935-be11-a0b1bac08002","c492e52f-0d83-4aff-b21a-cec1c79f4a6b","f47e4dc7-dc7c-4f13-a4d9-810bd91c9ea6","3b107d3b-7733-4823-ba55-172c61b3d17a","a7d935c1-a556-4d6e-90d3-ec3484295423","7fc89588-a742-42c1-aa2f-d0cb5777efc3","56bcc703-19e7-4f2d-9bdd-755ce14ff055","2c54f308-34db-44f5-a002-3de943f26327","501d248b-c197-417a-8d63-5e29d5984dd0","20bd45b3-5502-4680-a152-97d7c335206f","682872ea-a9cd-414d-b636-84a11fb7207e","d3fd2204-646b-43a1-ba83-15a9d006d69c","31219425-24ef-4276-812e-a417c5e9a2f6","fbbfdd7c-9d97-4937-bdcc-6b82f84dba6c","129206dd-6c52-4972-8a1f-c4d4757b9751"],"title":""},"1f412214-3abf-41e2-8d06-f6b0e4690ef9":{"collapsed":false,"color":"green","date":1698547429951,"id":"1f412214-3abf-41e2-8d06-f6b0e4690ef9","locked":false,"tabIds":["36d0a788-fde6-4c80-93f6-ce92c2fea5ff","23530fa5-7310-46a6-99d6-5a2dd27dbd74","5b35623d-e002-4597-92e0-ca78b4894c65"],"title":""},"1fa6c2d9-538e-4fd0-af4c-0a606dd75676":{"collapsed":false,"color":"green","date":1702262478102,"id":"1fa6c2d9-538e-4fd0-af4c-0a606dd75676","locked":false,"tabIds":["052e5e66-5968-48c7-8c45-04601a56a0ba"],"title":""},"204233fb-5a43-40b9-aa54-06962bc1286b":{"collapsed":false,"color":"green","date":1698547429951,"id":"204233fb-5a43-40b9-aa54-06962bc1286b","locked":false,"tabIds":["ee618d2d-db05-429a-a19c-370faa1ecdc5","d6c9ff11-7e9f-4280-9b97-c37783e8bbde"],"title":""},"205eb848-bc5b-4335-acf6-ef32ff1727c1":{"collapsed":false,"color":"green","date":1710534442163,"id":"205eb848-bc5b-4335-acf6-ef32ff1727c1","locked":false,"tabIds":["cc706f41-df72-4513-9c15-e28969b282cd","ffd3fb69-8009-4af4-b959-a6bb4cf07d7e"],"title":""},"20a1f313-a905-4a36-886b-e5234ae4d814":{"collapsed":false,"color":"green","date":1698547429951,"id":"20a1f313-a905-4a36-886b-e5234ae4d814","locked":false,"tabIds":["ada0e270-a9ce-4ef4-9013-2c460edf3329","0191f095-074d-4785-bd38-d102713935e6","b95973d5-20e1-4c13-b64a-e6042844ba30","40992ab3-c8e0-4540-a647-fb61caa83791"],"title":""},"21a3f349-d615-4ee9-998a-8727edb6641f":{"collapsed":false,"color":"green","date":1698547429951,"id":"21a3f349-d615-4ee9-998a-8727edb6641f","locked":false,"tabIds":["c4a37d15-8883-492f-a22f-5b1cd0f3e411","fb372b96-5622-45e1-bbee-8c8020dd6fc3","d710cb67-3c6c-4b49-81ae-94e494759d69","977ffbcf-31df-49f2-a783-197fb35057ac","e38e382f-22a1-404c-8a18-f163176c3fc5","72601d89-abc8-4732-b03c-c63cc67d4b95","1159066d-f3e9-49f9-98f4-eb32be1f1943"],"title":"sink"},"239f0e0d-7f42-4ada-a19b-734fd64ea237":{"collapsed":false,"color":"green","date":1698547429951,"id":"239f0e0d-7f42-4ada-a19b-734fd64ea237","locked":false,"tabIds":["0a03da23-5541-43f5-8fc8-24f66642438d","d3feb378-df27-43bc-8cfe-274335769c87","bd481916-2e81-4c88-9b06-ae8d69379a43"],"title":""},"2535bf12-e80f-408b-a302-45bdddca05e1":{"collapsed":false,"color":"green","date":1698547429951,"id":"2535bf12-e80f-408b-a302-45bdddca05e1","locked":false,"tabIds":["a2a94d73-1917-48cb-9f8e-854bbc39b68e","21caf4a9-67d9-4360-8e26-201859559a90","0d27e46e-728c-48f0-ac4f-e182148c12c9","cf4d3d16-1452-4591-b180-d5e27d56ca5a"],"title":""},"26006ce8-3f0b-4dc3-b2cd-6e4073221750":{"collapsed":false,"color":"green","date":1704671305935,"id":"26006ce8-3f0b-4dc3-b2cd-6e4073221750","locked":false,"tabIds":["6c3de9e3-ac6f-41d7-8be8-d0f7d52c0977","a9c83c85-8b71-4474-8fee-f71357bcd323","8b80c09f-6202-4df1-a5fe-74a099c4304c","ad7e8db2-656f-4673-a88e-19cb7335722d","034547ae-2c31-4fd3-9c8f-b03b7481944a"],"title":""},"269b7213-d325-46c8-8aba-ebc42664bcbb":{"collapsed":false,"color":"green","date":1711398694175,"id":"269b7213-d325-46c8-8aba-ebc42664bcbb","locked":false,"tabIds":["4e164bb0-0018-483a-a9ae-bda984740e63"],"title":""},"2759e379-7c7b-4bf2-acae-0904256169b4":{"collapsed":false,"color":"green","date":1702764052289,"id":"2759e379-7c7b-4bf2-acae-0904256169b4","locked":false,"tabIds":["92e48bfc-b1b4-4e0d-96d5-82636c0935d9","37008d9a-d0c2-4306-a2e8-a20d91e15124"],"title":""},"28d83ac7-858c-4bf5-98b5-659476698cf3":{"collapsed":false,"color":"green","date":1698547429951,"id":"28d83ac7-858c-4bf5-98b5-659476698cf3","locked":false,"tabIds":["ff88914e-12c1-4b4f-8af4-bc408e2463e9","d3765705-d0af-4820-805a-e5c71c09d38a","89694dc3-61df-46b5-ac87-fe0a02640433","b6f847c6-5bcb-47c7-ad4f-b7432cf61844","84a9f355-f5a9-4dcc-9281-75d01f0b5f1a"],"title":""},"297347b2-b970-4ef6-ad48-7347180867a7":{"collapsed":false,"color":"green","date":1698547429951,"id":"297347b2-b970-4ef6-ad48-7347180867a7","locked":false,"tabIds":["963586df-5d60-42d6-acfa-a674eb85c3b5","acc607c5-98c9-4b99-8884-6aea1d309498"],"title":""},"29a64d92-96a4-433b-b0d2-53a6e75b1ec7":{"collapsed":false,"color":"green","date":1698547429951,"id":"29a64d92-96a4-433b-b0d2-53a6e75b1ec7","locked":false,"tabIds":["316a6c19-bf9d-4740-94a9-382f29edb226","51822f43-a1de-4f67-8c38-1201cc0ad995","aaf29799-5e50-435b-925b-fd1eebd5d52f","415e45b4-2d78-401a-9759-344c33425759","0c3c869c-a205-4fc9-9f81-75632156681e"],"title":""},"2a240ee3-6ebf-428f-97c7-6655716f22c5":{"collapsed":false,"color":"green","date":1698547429951,"id":"2a240ee3-6ebf-428f-97c7-6655716f22c5","locked":false,"tabIds":["9bc93df3-cd47-4f29-bcbe-19c4906abdc9","a0f54ee8-2787-460d-9c5d-83521c03dab5","179d842c-af1f-4bbe-8333-a18f8417df0f"],"title":""},"2a53f72e-d7fa-40d5-813f-1692804af9c0":{"collapsed":false,"color":"green","date":1698547429951,"id":"2a53f72e-d7fa-40d5-813f-1692804af9c0","locked":false,"tabIds":["01c1b5cd-a43f-460d-a2ec-8d42284b477e","e6a53655-aada-453d-a17c-0224b83b6f5b","fb9854b8-0a26-4173-ade4-02fe7fb7c3fd"],"title":""},"2b082bb2-5db1-4f3c-95f1-309c93995ee6":{"collapsed":false,"color":"green","date":1710060978296,"id":"2b082bb2-5db1-4f3c-95f1-309c93995ee6","locked":false,"tabIds":["8919a406-e2e2-42e9-9d03-5c6d86c46201","3068e208-97bd-4518-8e4b-3489455752e2","c875821c-c523-4853-ad65-b899d5026220","b7d4efb5-4497-4ed5-a22c-5a141e2cae72","6b75f4ab-34bf-4f7d-a0e6-18079e8e685b","a28cb657-7add-45f6-8d67-070a7dcbd382","e816fb20-ed33-4117-a868-7b7264cf0ab3","0a1742f3-8c4e-4ace-a451-8a47f545981a","49592e41-5c84-4784-85fa-34f7ce25a46a","8518bbda-362c-4264-8ce5-2bf0ced6412a","802c089b-4290-4594-a076-4319ca4d2472","cdf3ac08-a19b-404e-b75f-47ef387205ff","0761e1ed-a452-48b4-9de8-14afad97e00b","4e725864-c9ad-426a-abd2-e622a4528f29","1bbc0920-322b-4641-a7e4-4d93c1caeb1a","5790eb59-4da7-46ec-b80c-7138b717f447","23beba8c-d209-4864-a1c2-5554bcee4cc7","4c097cd9-3f8d-43f3-8e09-6d46334e5f92","35b82e01-4904-4956-b868-0478b14c9eef","584abf5e-46fb-4313-a128-1929a026bf41","eeda4a4a-a0be-4259-8372-edf00f2646e6","0882ecdc-e36d-4860-818a-920e56913500"],"title":""},"2b9360e0-8191-4a0e-b8e9-8a47cc983edf":{"collapsed":false,"color":"green","date":1708313004587,"id":"2b9360e0-8191-4a0e-b8e9-8a47cc983edf","locked":false,"tabIds":["5646cdbe-e9df-4aff-83ad-b032d62cb707","dd82ee09-2b2f-45b7-9934-3793e8026850"],"title":""},"2e28be70-433a-43ef-a018-ad872e9f3105":{"collapsed":false,"color":"green","date":1698547429951,"id":"2e28be70-433a-43ef-a018-ad872e9f3105","locked":false,"tabIds":["6bc08b3e-c829-4be0-9a0a-f8f76f57a3a0","bb9b3804-9c5d-409e-9a3e-7c7e0a1c6da3","5785b6b3-7e46-4e72-a821-1737606f52e0","92ba2442-a6ed-429a-b55f-f9bd6af379ed","ec5fc6a9-7cc7-4c62-ada6-bb21ff9323ef","dd2939ae-18f8-4472-8a0f-4136a63c1bfb"],"title":""},"2e73d7c6-b081-40c9-8a2a-51188abdb506":{"collapsed":false,"color":"green","date":1698547429951,"id":"2e73d7c6-b081-40c9-8a2a-51188abdb506","locked":false,"tabIds":["06ecd707-93b0-4822-979e-e336cf6d18fe"],"title":""},"2e85c3b8-5c0e-494d-be34-de49f45eae09":{"collapsed":false,"color":"green","date":1699828874934,"id":"2e85c3b8-5c0e-494d-be34-de49f45eae09","locked":false,"tabIds":["ef370858-5e6c-4f19-aa04-6a94f8f99f64"],"title":""},"2ee716f6-dc9e-4c4f-a776-2ac6760508c8":{"collapsed":false,"color":"green","date":1698547429951,"id":"2ee716f6-dc9e-4c4f-a776-2ac6760508c8","locked":false,"tabIds":["02f7c53f-8462-4836-8db0-09d390f7c4b2","606d7549-101b-482c-b99f-d9f2e02a242c","1e966eb9-4b98-4d09-afc4-918b41441460"],"title":""},"2fa25d92-86ea-463c-91a4-38140efd73da":{"collapsed":false,"color":"green","date":1698547429951,"id":"2fa25d92-86ea-463c-91a4-38140efd73da","locked":false,"tabIds":["a88dea16-e21a-4634-a8d1-2641911ed34c","1587cfad-6446-4ecc-8469-cb0d57cd80be","d58cfd66-7d17-4a48-8495-8aa9910ed668","761be789-80b0-4feb-9dae-1ae34bf3b868"],"title":""},"3025623d-18d2-46e5-8639-ce1b694b6ded":{"collapsed":false,"color":"green","date":1711995653925,"id":"3025623d-18d2-46e5-8639-ce1b694b6ded","locked":false,"tabIds":["cf10c556-bff7-492b-8c52-7da71f879e37"],"title":""},"30eea461-fe51-4cfb-ac28-7b80f02f3a74":{"collapsed":false,"color":"green","date":1698547429951,"id":"30eea461-fe51-4cfb-ac28-7b80f02f3a74","locked":false,"tabIds":["6d570b7b-1209-479d-8d0c-6d9611057c5c"],"title":""},"31380387-79c5-423f-b971-2e744a27be0f":{"collapsed":false,"color":"green","date":1698547429951,"id":"31380387-79c5-423f-b971-2e744a27be0f","locked":false,"tabIds":["0de6c6b6-59bd-4369-80c1-b62adb99d3c9","b71cee4f-c083-4e7d-824a-d1210e5c2b41"],"title":""},"32501a60-94a1-46b9-94ef-b8ba215c20d6":{"collapsed":false,"color":"green","date":1698547429951,"id":"32501a60-94a1-46b9-94ef-b8ba215c20d6","locked":false,"tabIds":["d4c4716f-07fc-4865-9535-58e6f6964ce0","3c849b72-b3fa-468a-b5c3-f460a419d293"],"title":""},"32ecd4eb-1676-43ba-a3ec-de73646adaaa":{"collapsed":false,"color":"green","date":1698547429951,"id":"32ecd4eb-1676-43ba-a3ec-de73646adaaa","locked":false,"tabIds":["455f0f2a-083c-45aa-a7f7-7444154f9d22","eba900e5-15af-4985-9495-fdd4d5d4c60c"],"title":""},"34b0955e-e720-426e-9bcc-96ea6959d06f":{"collapsed":false,"color":"green","date":1698547429951,"id":"34b0955e-e720-426e-9bcc-96ea6959d06f","locked":false,"tabIds":["7c89265e-aefc-4a91-9668-57f7cf4c7474","a9c10b94-9d29-4739-9bc6-a14c7ad19d52","b25ca8ca-4797-4cdc-aa73-6e5854f96d9c","3fce421b-afc0-4488-b8ce-7486db3a784d","fdd22754-9a43-4e54-9578-0974be8bfd44","3d867364-de7a-4cd7-8dfe-2e6096c0f142","3e0494ee-e263-4a4a-8d29-71cfe8c57615","01069b98-ee05-49de-9b34-6af35a6b07ca","3acf5bc1-e61b-427d-b723-161e3e519c54","9d3aab25-51cf-4775-b6e4-e810e77a99cf"],"title":""},"34ec7d64-6c18-4a5e-831c-a023c0afc93a":{"collapsed":false,"color":"green","date":1711176069732,"id":"34ec7d64-6c18-4a5e-831c-a023c0afc93a","locked":false,"tabIds":["c8fd2ace-1846-4b10-9964-6ab70102faee","b278bf30-96cd-4af1-b650-72ee2854afbe","5b43d514-2f89-4df2-8118-25aaf642d5e4","e789d36f-c0cc-47b3-9336-6c3fed56e518","dd3c88d7-0b5e-46a8-9bac-43008d840145","8f486662-1817-462d-9fb6-b3c4d336353b","1ee342b1-96b3-4a49-9c4d-4a9a13c49986","fb0af0e6-745b-43fd-9096-75e96afad332","341f5ce0-0ff6-4e45-b060-aaf8d1786fc0","dc91eeb0-a430-4451-9612-7eae692ac5e2","f309759e-402e-4a78-b02a-28cf725bf8ef","c724c17c-093f-4cbe-8ffa-f557115b148d","5fb0d103-019e-4abe-96f0-9dde163802f2"],"title":""},"35dc884d-ef7b-40ee-842e-2f399fa132d9":{"collapsed":false,"color":"green","date":1698547429951,"id":"35dc884d-ef7b-40ee-842e-2f399fa132d9","locked":false,"tabIds":["d76d9785-f991-48a5-91e4-facaaab3430c","d015700a-4f55-499b-b7ae-5e482dd84233","438ac4d4-6ad7-4678-8bae-ba01f0847692"],"title":"hugging"},"3631bf4b-9f9a-4749-b963-b390530d732f":{"collapsed":false,"color":"green","date":1698547429951,"id":"3631bf4b-9f9a-4749-b963-b390530d732f","locked":false,"tabIds":["d9c67fec-1530-4023-b052-214cc8eb653f","847a1b99-dc80-4cc6-9640-519a8e40befb","4ca32fee-d25f-4d9e-ad44-5a171de0ffc5","699423e2-8053-4584-bb87-73de0013b8a8","415d8578-8b2e-494b-87a6-dd571bb76ffc","fa0f2473-7e8d-484b-8398-8f9a8116496d","d76d6c30-6120-4ff2-aeb7-dabf50e7a16c","31237155-9261-42eb-8ca1-f7d6946fb089","9279a752-1327-41dc-8ae3-9c5b1b089635","8aa817d4-a608-46e9-a6c9-367f46a4a3e3","8750a9de-7651-4445-8860-edc5a71b5318","7767f239-889b-4c9e-885f-916f8d76eeeb","7434fd61-c787-4c32-aee6-a13beca0b81f","618650d2-6a00-4833-b560-d22003f60f64","6f36f836-9366-4237-ae53-065ce30cd7d8","7bebc7b3-798d-405a-88fe-a93eef88deb8","de4a2fbf-3974-4e2e-8f10-0529b1d3e364","9c6c7744-bc55-46f8-b1b2-fa196b7b7a3b","95086fab-bef6-4fde-945b-4f301d7b7290","5a33af87-8a82-4c27-b30f-c1f7f41b9861","18030260-7ef8-4f38-95d1-c3309b1d1b4c","b794ad53-48ce-46a0-84e9-1d599fbc5fb3","9568cb92-eec5-4fae-b196-4a049fe0f790"],"title":""},"37c677af-2b42-4631-a64e-3a92d4983c55":{"collapsed":false,"color":"green","date":1698547429951,"id":"37c677af-2b42-4631-a64e-3a92d4983c55","locked":false,"tabIds":["dcc91dc2-d8d4-4953-bc85-5b0c9c893399"],"title":""},"384c2fb3-8777-4f76-ac98-8d0229e15d99":{"collapsed":false,"color":"green","date":1698547429951,"id":"384c2fb3-8777-4f76-ac98-8d0229e15d99","locked":false,"tabIds":["1ef11ea0-063a-4de9-8f39-dacad3fb3953","ef9596a3-8e88-46b9-916f-fb8c073d72db","ee44bd45-d2da-4c3d-9cc2-e98cf23ba28f","09b281cd-5ba1-43b8-a212-030599918751","790d924c-f402-4053-a1d3-bdc6d0cff4fc","b7ab3abd-a706-4d11-aa29-a3d0f4d6f3d3","3961a9ec-37d3-4e66-9305-96fab9d8b5d2","596cc7d2-62cd-428a-8e3d-0d632652eea7","ac34802d-c1b8-40f2-a672-0af255881913","f9c40d02-4f41-4998-8d75-e772466019ce","a2122eb0-0cb1-4a23-929b-18b54718b103","0054b298-6a95-45fc-8d1f-6971c3b67da0"],"title":""},"387c412a-abb4-4c80-99ea-fa724eb1e25a":{"collapsed":false,"color":"green","date":1709619966834,"id":"387c412a-abb4-4c80-99ea-fa724eb1e25a","locked":false,"tabIds":["96244c4e-1221-4f63-99b3-95bb5c65c91c","3dcfdc16-661d-4196-8a4b-e5572fad8e97","cbf4aaa1-b4e8-4aa7-aa53-b25406cb4edc"],"title":""},"39200a88-ae53-46a6-abb3-d6fb42826fcd":{"collapsed":false,"color":"green","date":1707798462729,"id":"39200a88-ae53-46a6-abb3-d6fb42826fcd","locked":false,"tabIds":["7eda712f-54b3-4116-8808-b3f8aca1c8c2","91b0ab53-863b-413d-b411-7d114a0bcf8a","e4746daa-caa3-490a-885e-dbbfc619339e","331da261-dceb-450f-bcfb-aed8df5dc216","bfc472bc-c86f-4d02-b423-4d4535348c6e","8224a4a3-e001-4d05-8153-eb6cb94952e5"],"title":""},"39567a2b-4b18-479d-8739-f5eac38bc0a3":{"collapsed":false,"color":"green","date":1698547429951,"id":"39567a2b-4b18-479d-8739-f5eac38bc0a3","locked":false,"tabIds":["dce20756-1372-46f2-a100-1e0bbc4cfc3d","216a973f-127f-47b8-9de3-6db37cd16f2a"],"title":""},"39cf79d1-df04-4623-a111-b679f39eebdc":{"collapsed":false,"color":"green","date":1699484405037,"id":"39cf79d1-df04-4623-a111-b679f39eebdc","locked":false,"tabIds":["20b3d3db-677a-4d07-ab96-ae169fcb07e1","ceda37eb-6a2a-4d4f-9d7a-514eb63ec941","bea34725-9670-41d6-b639-51b78d6a10ca","5d0c459e-e347-4f1f-9693-fc13af9acc8f","9096da03-f413-495c-9144-400d3bb87030","d1eec573-c753-4c4a-88fd-ab0d438b8ab4","eec5f64e-8c6c-4f33-8a22-6885b65de97a","2ecf9614-a8b0-4e6e-928b-f7f92f0cbab4","308e0c75-73fb-44ee-8028-e2f4a5b76a01","c19e0700-c6c7-4313-bcb5-ac3b00ff138a","c7fd96c5-0918-4b6d-8c5c-25c542aa554d","a1199307-1a69-4e84-a9dc-8ccca5ba2b52","481a684e-0adc-4b13-8ee1-ea18b51ad4a1","144066c3-7892-4416-ae64-20bd03c492ab"],"title":""},"3a402f12-a334-4a0c-845b-641428ae7b78":{"collapsed":false,"color":"green","date":1698547429951,"id":"3a402f12-a334-4a0c-845b-641428ae7b78","locked":false,"tabIds":["5edb0760-63b1-492d-bb27-10cfbed5d6d2","62bde13a-f10d-411d-ad38-a95272b280b3","3c8a03e6-5705-4d56-97a1-a5f645cac505"],"title":""},"3a92d9ae-beeb-4265-933f-b6c0110dbc56":{"collapsed":false,"color":"green","date":1698547429951,"id":"3a92d9ae-beeb-4265-933f-b6c0110dbc56","locked":false,"tabIds":["c889c11a-8af1-4aa5-a0c1-0bb7882ce92b","43d07f6c-1096-42e7-830c-1fae0e6ceaae","093a0ba3-9fdb-4920-8096-1478a73d0638","1462ece9-22fa-4cd1-a1f5-cc71c53a1243","cd2f9d62-1c91-47fb-8e64-ccb203f611cb"],"title":""},"3abdb192-fe38-42e0-86f4-7010046314e3":{"collapsed":false,"color":"green","date":1698547429951,"id":"3abdb192-fe38-42e0-86f4-7010046314e3","locked":false,"tabIds":["93612b1f-cb2d-494f-87fb-e653192016ad"],"title":""},"3c5b02a5-839a-4ec5-9033-fcece0a7e9b9":{"collapsed":false,"color":"green","date":1698547429951,"id":"3c5b02a5-839a-4ec5-9033-fcece0a7e9b9","locked":false,"tabIds":["d8f95278-c801-4c07-835f-026b32df5c92","44bba762-99b6-450d-b192-447c6afa47fc","2dd3c032-97f4-47a5-9094-9cfed73fde42"],"title":""},"3ca7719c-7e34-4b95-8abc-d4f456c6ad75":{"collapsed":false,"color":"green","date":1698547429951,"id":"3ca7719c-7e34-4b95-8abc-d4f456c6ad75","locked":false,"tabIds":["4a8d6ea4-3f08-466d-9b2e-ddf0c6c81870"],"title":""},"3d6daf19-54ca-47f5-81bf-8b293a2dd7a9":{"collapsed":false,"color":"green","date":1711995714989,"id":"3d6daf19-54ca-47f5-81bf-8b293a2dd7a9","locked":false,"tabIds":["40f76221-8a75-46f3-9911-8afd7b5f7b2d"],"title":""},"3e38d2a7-a487-4866-a991-c894bf966598":{"collapsed":false,"color":"green","date":1700560071982,"id":"3e38d2a7-a487-4866-a991-c894bf966598","locked":false,"tabIds":["2b795794-1b0a-44d8-931f-289da14334e8"],"title":""},"3e9fc564-7675-4577-a101-b32bc9e524b5":{"collapsed":false,"color":"green","date":1698547429951,"id":"3e9fc564-7675-4577-a101-b32bc9e524b5","locked":false,"tabIds":["2fc64f98-18d2-4ca8-8554-eb1b82ab17ec","53fbad97-6785-46ca-ad8e-0b0c8bab408d","58d6f3dd-f8c4-4dad-a9b3-ddbae049e48d"],"title":"recomp"},"3efd29b6-0ba9-46c4-b93e-282df77ba719":{"collapsed":false,"color":"green","date":1698547429951,"id":"3efd29b6-0ba9-46c4-b93e-282df77ba719","locked":false,"tabIds":["026816dd-b582-464b-b7e3-7c4c74a09daa","a6d708b7-4d20-4e85-902f-22efb5f35de2","ed504e3f-25c0-4259-9185-7e05b7eeba54"],"title":""},"3f14242b-32a8-46b8-b08f-b1c6c77134f6":{"collapsed":false,"color":"green","date":1698547429951,"id":"3f14242b-32a8-46b8-b08f-b1c6c77134f6","locked":false,"tabIds":["d015261d-53c6-4165-b396-0ca88a27b516","6b8ace50-8169-4fe2-aa69-d9ebe2f91355","3735fcbe-c4c3-43d0-87a0-81e7695f041a"],"title":""},"3f2284a1-d5aa-4225-bc34-0841f34b022b":{"collapsed":false,"color":"green","date":1698547429951,"id":"3f2284a1-d5aa-4225-bc34-0841f34b022b","locked":false,"tabIds":["cf4ed58e-b64e-4fd4-bb24-a7696146e1bc","4d90f2cb-4ad6-49a4-b70f-98745696bfd9","4603f258-5c0b-4fd0-912c-00f3a249b627","226bc329-8fed-4fb9-9e5b-e94280de3800","ad3c19c9-20ce-4772-8579-7a10b3df7c4f","33a849b9-6127-4d46-bae3-94b72106dc6c","d7572dfd-3f77-4ec2-b1e7-e79a2de6e2f3"],"title":"slam"},"4144c93b-55a9-4425-8121-f311dea25ee9":{"collapsed":false,"color":"green","date":1711385228880,"id":"4144c93b-55a9-4425-8121-f311dea25ee9","locked":false,"tabIds":["0f24ef4b-908a-413d-b163-164a2e0eec5f"],"title":""},"42342e22-0ddb-4fbd-913a-a06cb4a65061":{"collapsed":false,"color":"green","date":1698547429951,"id":"42342e22-0ddb-4fbd-913a-a06cb4a65061","locked":false,"tabIds":["7b1154ce-81ea-49f9-9b74-cebe38b0e61c","860d9144-7a8d-4fe2-9dd6-c50f0afaea6c","a09637f2-cad2-4256-aee9-c17ee003966e","cd1986f4-2600-4ff1-a69c-05c486a0dbd8","ed746543-82bd-4d2a-9908-22c5847db491"],"title":""},"42aecd57-f47c-43a8-8238-38da39dd46fc":{"collapsed":false,"color":"green","date":1698547429951,"id":"42aecd57-f47c-43a8-8238-38da39dd46fc","locked":false,"tabIds":["fab02f30-74aa-43d8-ab88-70bf2f9d51d5"],"title":""},"42d5432a-b40b-4704-905c-2389fbbf99bb":{"collapsed":false,"color":"green","date":1698547429951,"id":"42d5432a-b40b-4704-905c-2389fbbf99bb","locked":false,"tabIds":["45e6796f-2e39-4395-b730-183db243d019","8749b66f-b5fb-481b-8f99-009c8a3ea6b5","e2c4a9cb-8221-4af2-ad18-5a6b5cab6c71"],"title":""},"44416fdc-7907-425e-9734-4ad72a7a6c4a":{"collapsed":false,"color":"green","date":1698547429951,"id":"44416fdc-7907-425e-9734-4ad72a7a6c4a","locked":false,"tabIds":["2516172f-9f91-4064-b4b8-0fc9e669d67a","8109e103-8ad4-4270-ada9-bdacc25262de"],"title":""},"44e22da3-2bb3-4d50-8f27-099638cd453e":{"collapsed":false,"color":"green","date":1698547429951,"id":"44e22da3-2bb3-4d50-8f27-099638cd453e","locked":false,"tabIds":["8854e20c-092b-4cfc-a2af-8330f5feca29"],"title":""},"4524af27-7c64-4e24-be85-6013688c63fe":{"collapsed":false,"color":"green","date":1707710873901,"id":"4524af27-7c64-4e24-be85-6013688c63fe","locked":false,"tabIds":["2d77110d-cb21-4d77-8e78-ab5867ea7ae4","4f92a692-ed19-4b3c-8b80-bda3da891b32","f78e123a-2945-4d31-a1c9-5e5b2300543d","9811f2f0-7d30-4cd2-bcca-e326420f4bf0","3af03237-e2db-45a4-8eb2-5986b9c02e99","4ee76121-d760-4e63-abed-2ca99283f087","3fb6087a-3f76-4a9a-9ec7-69b62d15b05b","19a4775d-6524-4e8a-adcb-45160b516346","483a66ab-211b-4ed8-ba38-d1629b6f654b","9a3e49da-cff4-43bb-b25f-71c6eaf25951","4597b73e-f1b4-45b5-b3de-7c3dfa62fd48","9ba42614-ccb4-4d88-9d5b-09846092862e","1b2a9c1a-2434-4b1e-858f-43792d02ff7c","d7615a30-dd7d-48f2-a2eb-2c80760dd172","9ddd8796-2946-4b7a-b891-a59ab333e215","ac695dda-7d8e-4e8b-851f-3cca9a64e842","f8502f8f-761d-485a-aa4d-212c5bc723da","0da2e664-df05-4ada-b15d-081b101d4903","9129aa26-f320-4214-8ffc-707dace1ceb5"],"title":"github"},"457a7629-2958-4b9b-9993-2217ea5ec4d1":{"collapsed":false,"color":"green","date":1698547429951,"id":"457a7629-2958-4b9b-9993-2217ea5ec4d1","locked":false,"tabIds":["19fe3878-5c3a-4791-8a5f-cf5e9ca56c17","7d9c9ce1-ad6b-4523-8381-10652e318a91","7dd674eb-bca9-4103-b037-4a6c5a2ace67","a94efbac-494a-4d53-9e61-5b98293b117c","f0a40b40-42da-4744-9302-f10045614f7d"],"title":""},"4626dc9d-de3b-44db-8d27-4b3ea89e3f1f":{"collapsed":false,"color":"green","date":1698547429951,"id":"4626dc9d-de3b-44db-8d27-4b3ea89e3f1f","locked":false,"tabIds":["7132a6c2-b9ea-4033-9b13-69a002c9029f","af5bb978-1467-43c8-9e87-d73ee80e0c6d","93b5902a-0364-433c-a23b-0d78f32dec41","27ede712-5074-403d-980e-677da739da3a","57e0c6b6-c0d4-4123-85c0-64dfa94d55c5"],"title":""},"462ea1f2-e93c-4999-8611-ed88d7175e91":{"collapsed":false,"color":"green","date":1698547429951,"id":"462ea1f2-e93c-4999-8611-ed88d7175e91","locked":false,"tabIds":["510bd8a3-c1f2-4195-83a2-2cbd7cbf581f","77ec9296-d4a5-423f-8575-119c76bb64cb"],"title":""},"473b3789-eaf8-409a-a452-b276367bdc5a":{"collapsed":false,"color":"green","date":1698547429951,"id":"473b3789-eaf8-409a-a452-b276367bdc5a","locked":false,"tabIds":["c6e38d33-0e1b-4015-82e5-80c6d3d7b570","a007b058-6947-46d3-b4b3-931deeefb312","ac28ff87-1923-4a12-a502-27d613ee705f"],"title":""},"47d915b4-051a-430f-b3e7-96791dc4f3a9":{"collapsed":false,"color":"green","date":1698547429951,"id":"47d915b4-051a-430f-b3e7-96791dc4f3a9","locked":false,"tabIds":["9dab00a6-b4c3-4a2d-89bd-91d0fb1437ad","3268040e-a287-4672-90d7-626008885718"],"title":""},"4860388b-822f-45a8-81f6-cf3e0a44d240":{"collapsed":false,"color":"green","date":1711512699439,"id":"4860388b-822f-45a8-81f6-cf3e0a44d240","locked":false,"tabIds":["13850090-1bd6-4d44-80af-60cbc0b11f58","419a9846-1437-4a58-b63b-670e8ae629e9"],"title":""},"48aceb61-5be3-4c18-ad95-c49ddefad742":{"collapsed":false,"color":"green","date":1698547429951,"id":"48aceb61-5be3-4c18-ad95-c49ddefad742","locked":false,"tabIds":["03b12e6e-0849-4e8c-b0e1-6280e2fb3a14","535744af-82c3-4ce6-95ab-a00bfa4d2111"],"title":""},"48f32eff-95d7-455b-bbba-376f42321564":{"collapsed":false,"color":"green","date":1702761091135,"id":"48f32eff-95d7-455b-bbba-376f42321564","locked":false,"tabIds":["c498c501-3668-43f0-9878-ff1ab89d4d8b","c051997f-01eb-4b9b-95aa-528e1537bc93"],"title":""},"49f8cadd-5dec-4f89-b5e9-9d49942b7b99":{"collapsed":false,"color":"green","date":1698547429951,"id":"49f8cadd-5dec-4f89-b5e9-9d49942b7b99","locked":false,"tabIds":["aa39fe89-065e-45bc-9556-f18f0209ec7b"],"title":""},"4c1d943d-2c55-4133-a066-2f86cba9190e":{"collapsed":false,"color":"green","date":1698547429951,"id":"4c1d943d-2c55-4133-a066-2f86cba9190e","locked":false,"tabIds":["16f6e5b1-df51-44d9-8570-a3067c564407"],"title":""},"4de9f8a6-4ab5-4ca2-914b-63cee8228f19":{"collapsed":false,"color":"green","date":1698547429951,"id":"4de9f8a6-4ab5-4ca2-914b-63cee8228f19","locked":false,"tabIds":["eebf3462-f365-48a5-add3-5af7269dcb81","aecb330a-8da2-4034-ad1b-90aa3c6283a3","42a52177-b1b7-4cf4-8d40-6bf855f63f0d","bc863141-e62c-4261-a657-f1cf2a73089a","bf479fad-fca9-4efa-9d54-f8017a95609c","6ed1f909-d15f-4387-85bf-8846c3b02445","2afc1d9f-c1ef-485c-b769-fe9d193c24f7","80b2301f-d596-4188-b5b7-ec31c38d2975","143ad6d5-c484-4d8f-94f0-fd32e529529f","df55d1d1-16f7-4e35-b6f2-8f5bdfec9993","614c6e85-cf75-4d84-bb51-560566e5b4c1","639e52b0-c822-47bf-8a68-6f2e8319d74b","96f962d3-1416-4dcc-8768-60f255ba8e1f","73977942-0a40-49e3-a068-8f538087fe3f","037fd3bb-dddf-4d5f-a96e-9c5882df07e8","526d010f-00f9-4d79-818b-ec4b8f0308ec","c276f136-3710-48c3-8fe2-760321a85b55","174c4177-83cc-4b0d-8459-5f7954894095","cdee6d6b-73de-4342-9c0d-d0e6c118cb60","00106e46-905b-423b-be35-8e76a5a0ae6c","fa5b425b-1658-4511-bb0d-7facf0d68c20","9d45131c-1e7e-4707-9cbf-824c017a95d9","47da4332-397b-4341-8ac8-f2597264e5b2","7e29a184-4eb4-4df1-bb1d-2503e04bd2d1","3d996b78-ef42-40e3-91ce-f43025093e0a","a0a77edf-ba2f-4f76-b268-ac4f5264fd24","cc66b961-fbe2-450c-b6b7-657ef9174ce5","4abaa3f1-ca5d-4e10-8901-03448a8bf876","d0af8671-a573-4640-bad2-dbfba6f5ab12","9992a83d-64a7-4b76-a085-8293ef053448","a1de1f99-25f0-43ce-a396-59917fe299c1","622e1cf3-0bac-4bc2-a804-cbb663fb0aa8","867b55f1-497e-4b7a-800f-c2c740abcf43","ac4fb169-1d96-49a4-a92d-85da9ebb6333","dec6afb4-1993-4303-8605-70ac9bcfc79a","00f266bb-ab48-4954-8505-9f0bd83ab238","5a2bcef5-a6e2-4e2c-8746-d9bda227698a"],"title":"fus"},"4dfacf04-fba0-4f2b-be55-952c96b03051":{"collapsed":false,"color":"green","date":1708395219990,"id":"4dfacf04-fba0-4f2b-be55-952c96b03051","locked":false,"tabIds":["e8c4df53-e1ec-4a03-a18f-82a9149f47b5"],"title":""},"4e2243fe-2fbc-42ed-a783-c69909d5bdae":{"collapsed":false,"color":"green","date":1701801339854,"id":"4e2243fe-2fbc-42ed-a783-c69909d5bdae","locked":false,"tabIds":["a5c7754b-0546-483d-b3b5-2e57bb686203"],"title":""},"4e5de446-efaf-4019-934d-b52bb4b9498e":{"collapsed":false,"color":"green","date":1710217889089,"id":"4e5de446-efaf-4019-934d-b52bb4b9498e","locked":false,"tabIds":["2d5321e3-2bb7-4595-8b7a-fa0f5cc16e24"],"title":""},"4f1b0eb1-c699-47bc-b765-66451a09c4eb":{"collapsed":false,"color":"green","date":1698547429951,"id":"4f1b0eb1-c699-47bc-b765-66451a09c4eb","locked":false,"tabIds":["5273036d-3fe7-4b52-a33b-a6cedfb4e58b","78d24066-f389-4a14-947a-97df4c485f68","d3009d55-8dfe-495b-a01a-bbd2fe1e658e","72ead16f-f75c-4008-8383-3a7a5f1cdec3"],"title":""},"4f2bd6d5-eede-49b2-a681-ec9c57280a50":{"collapsed":false,"color":"green","date":1710035896759,"id":"4f2bd6d5-eede-49b2-a681-ec9c57280a50","locked":false,"tabIds":["e423e617-e4ac-48cf-bd73-d9c0ef45bc44","ffb90a50-770e-45b8-ba02-14ca10b89678","76349b5e-c433-4a13-b0b7-55626569f8dd","223d61ba-9f0c-447d-afb1-2a75a95d4b95","93766505-7c7b-452a-ba10-0661379c4958","f9f7ede2-8b1c-4f39-94a9-a6ef2f447271","436805d8-e5d4-4f41-ab79-30404a3b6e68","cf6a207a-6c90-4063-ba84-714ed6250428","210589c9-695c-4f75-9b02-56004489b93d","e8eb15cd-720f-45db-b354-41ef32d00fcb","8ef5aad2-683c-4182-b64d-4e0017cd8f57","96152890-8042-4d07-93fb-324991215b18","dffe99ba-1058-4788-8267-62c0f6ad9111","6b314714-7cf7-4c1f-8ec3-3febaaa0e32a","51fb3506-7003-4701-8aa3-b364400954f6","b1b1a3d5-26d4-4ea6-ac58-5a4c3a6afdee","e090a983-d19f-408f-9da5-e24db61f7ef7","401e259d-943c-4997-9748-8ce0f173a68f","68daca0f-ad50-4ee5-8ad3-154cf03351bf","317c5a57-33e8-4f6c-a995-9e13ec463fe3","a547e615-2d43-4a00-bf06-51e4e9f0b664","b1c4a230-b828-48eb-9f8a-c5460d46e1b4","96bf680c-ca4d-45bc-acff-ef90cb473228","1b9a61cd-c7a9-4b96-9ce9-286a4bdc2f85","c31a4188-7070-46f4-8d61-d633712179b1","99f73011-c0c8-4349-846b-1e1e124aeb41","a75a4f5d-f300-4614-841d-6eddcd502370"],"title":"hugging"},"4fa222fb-2140-448d-b84f-bcac60d20d23":{"collapsed":false,"color":"green","date":1698547429951,"id":"4fa222fb-2140-448d-b84f-bcac60d20d23","locked":false,"tabIds":["54d486c7-a606-424b-a845-c84ab6325b4a","f91a2350-1a0e-400f-a917-0d6138297e53"],"title":""},"50030438-f184-4b1b-81fd-c3ba9eff44db":{"collapsed":false,"color":"green","date":1709320490088,"id":"50030438-f184-4b1b-81fd-c3ba9eff44db","locked":false,"tabIds":["b4fe1d9f-bf68-483a-94f6-fca98ee21fec"],"title":""},"501e8146-9352-4470-9bc4-aa53f27260b0":{"collapsed":false,"color":"green","date":1701457179431,"id":"501e8146-9352-4470-9bc4-aa53f27260b0","locked":false,"tabIds":["a6e3b00a-bdc7-40dc-a0f4-5e1d84bdda18"],"title":""},"507422c6-4648-4069-8f0b-47e2c740d74f":{"collapsed":false,"color":"green","date":1698547429951,"id":"507422c6-4648-4069-8f0b-47e2c740d74f","locked":false,"tabIds":["6583b783-8cb7-4a13-a405-137ba74b5c72","18baa049-17af-4736-94e1-b10cc58b966c","f6275902-9d08-4077-bd64-25fc019ff273","03ec49bf-4c1e-4e7d-a0f0-2deff117bdd9"],"title":""},"50895397-2c4a-474c-94c7-9a694403753a":{"collapsed":false,"color":"green","date":1698547429951,"id":"50895397-2c4a-474c-94c7-9a694403753a","locked":false,"tabIds":["223c65b6-d8fe-4b4f-aae9-6a0576113d48","131f824d-008a-4bff-b82b-64c91d98a41f","b2883352-45a4-47d1-9a60-e2224edbc030","888e87d2-1fbe-4f88-bb06-0050d44fe908"],"title":""},"526ace24-6179-46de-b6f2-78367096527e":{"collapsed":false,"color":"green","date":1698547429951,"id":"526ace24-6179-46de-b6f2-78367096527e","locked":false,"tabIds":["bbb499e1-550c-4858-b789-de31b157350b","cfa9fe1a-df03-4b66-a698-db2308dddf73"],"title":""},"533e4c91-7abe-4e5a-ab7d-a3bce4bbdb1f":{"collapsed":false,"color":"green","date":1698547429951,"id":"533e4c91-7abe-4e5a-ab7d-a3bce4bbdb1f","locked":false,"tabIds":["4664c383-95ff-4155-a1d1-e73f77f6a9d9","d3b5e31e-89c7-45a6-a982-a455f9673ffc","b264252f-0340-4a76-9ac5-8fdfe996e77b","8e5ad8e1-3716-40a5-b6f3-dd9843ea6fc0","c61cad5c-680b-4047-8ade-8047e5af4522","c4b0ddc0-c644-45b3-8985-2e7dbbf0f6ec","75fc50cf-db4d-4442-9d3c-e9e57c94b9bc","45eebf00-c95b-49da-97aa-8e9a025bd0ca"],"title":""},"54a30ca5-65cb-4f86-a061-0699896bd4ff":{"collapsed":false,"color":"green","date":1702521111298,"id":"54a30ca5-65cb-4f86-a061-0699896bd4ff","locked":false,"tabIds":["754dda69-7d98-46dc-a959-6f8305a14e5f","baef84e8-85bb-4c94-9b9d-32147f87d4a9","0671521f-9253-4ffe-8b42-ba780b5a1afb","a2b7e2fb-6a91-4909-850b-db9ccd967724","de4a6a21-4dcf-4db2-80aa-4124a554c357"],"title":""},"5623357b-8566-476e-993b-065df3a63ee8":{"collapsed":false,"color":"green","date":1703204495682,"id":"5623357b-8566-476e-993b-065df3a63ee8","locked":false,"tabIds":["2c2165d3-9869-4be0-98ee-e6b106604956"],"title":""},"56280e21-499b-4600-9ab4-b71fa171b969":{"collapsed":false,"color":"green","date":1711512839007,"id":"56280e21-499b-4600-9ab4-b71fa171b969","locked":false,"tabIds":["5293bc84-9da1-4e13-b621-94383403f6c7","201e4899-7e67-44fe-8bf5-c8585224e6c3"],"title":""},"57910501-2565-4bd2-a50c-862bd1195b97":{"collapsed":false,"color":"green","date":1705607591094,"id":"57910501-2565-4bd2-a50c-862bd1195b97","locked":false,"tabIds":["5f2a5a31-f1bb-4d8f-a40a-9ef68cba2d8c","38a4f812-df80-44b6-9d08-7eaf56582d47","0d027331-433a-4bab-9cc0-3fbe73d735c1","ef126cd1-e414-42f6-be4a-907a0dc7cb14","cb743032-7221-46f2-8e23-ad7af56ab9ed"],"title":""},"58d3ed40-3995-4db2-a96c-bec671f4c9c8":{"collapsed":false,"color":"green","date":1710035878244,"id":"58d3ed40-3995-4db2-a96c-bec671f4c9c8","locked":false,"tabIds":["9e515664-33b1-4e58-905e-ef472649c3e0","63b57e9f-e80b-4757-a149-bce68f0daaac","e7ec0337-2569-4965-b894-199760565e3d","7a7dcb31-fbde-405b-be2f-2144c202f4b1","6b0044a5-ed0c-4874-90d6-cf3a928bc36c","de5f0d45-4ef5-4173-90cb-ed5aa9bdadb2","ad93287e-8cb4-4edf-8eb8-cab45dba6ca2","61fbe29f-e11b-4a8b-95ad-f12e61347cc1","a4758a5a-9ccc-4c08-9776-77695a27ec37","015beac7-d3db-4e93-ae87-6a752bab5b42","4d8528ff-0e28-4e22-a675-9573b5b33837","efe4f2a4-f218-4353-9a34-c31c39dd3be8","e7334f89-2a42-4809-b793-d663ac7bf5dc","8aff9be9-9628-4626-b9c9-80ceade3e90e","9f3da9f5-34af-4c0d-ac54-185749a52f5c","e8625aa4-9029-4839-b8d2-976e5f6cee60","cfd5dc36-a45f-472a-8874-52859b77b50a","7fc1c557-8f26-4522-957d-0f3e351716f7"],"title":""},"5955fc50-fcea-48cf-b744-5a3166a19eaa":{"collapsed":false,"color":"green","date":1712789378707,"id":"5955fc50-fcea-48cf-b744-5a3166a19eaa","locked":false,"tabIds":["32646ceb-3202-4236-bd19-959ec5a03ba2"],"title":""},"59d92716-6718-422b-9570-bb019726ce08":{"collapsed":false,"color":"green","date":1698547429951,"id":"59d92716-6718-422b-9570-bb019726ce08","locked":false,"tabIds":["0757851c-1b70-41a6-8222-2585602de7b4","0aca07c5-ab1c-4c97-9e0f-7b243d09477d","e2557fc8-48ea-4bfa-8b05-bb28bc59fd35","b2be4e0c-d5af-422f-8313-3f28f1ba861f"],"title":""},"59fc7eae-ed31-48e4-90b9-bab9dbb59dd8":{"collapsed":false,"color":"green","date":1698547429951,"id":"59fc7eae-ed31-48e4-90b9-bab9dbb59dd8","locked":false,"tabIds":["7cbe09af-74b5-4766-9e88-1dcd2c3d395b"],"title":""},"5a5dd430-e55c-4c79-864d-6b4f15f71255":{"collapsed":false,"color":"green","date":1711512681340,"id":"5a5dd430-e55c-4c79-864d-6b4f15f71255","locked":false,"tabIds":["fe64ced5-e590-4c93-a9e1-6c36619ea871","bad3f624-4bca-4aff-ad8a-9f0f43d949ba"],"title":""},"5d2066eb-62f0-40e1-a8c9-735ed1ce7a37":{"collapsed":false,"color":"green","date":1698547429951,"id":"5d2066eb-62f0-40e1-a8c9-735ed1ce7a37","locked":false,"tabIds":["18bb600f-d858-43e0-aea5-2bec3cb4c0ab","1d1c6226-f22d-41c7-a866-7bca8fc52546"],"title":""},"5d7e29b2-5e8f-491b-bf46-a4f699f524ac":{"collapsed":false,"color":"green","date":1698547429951,"id":"5d7e29b2-5e8f-491b-bf46-a4f699f524ac","locked":false,"tabIds":["9cf87265-1d62-4d57-a5eb-1fc14059790d","38d56644-1816-4130-a200-5da7f98f548a","587b9ddf-3c3b-49fb-b955-31bca2670a44"],"title":""},"5d873b5e-dee5-4577-a48d-e0d22534b270":{"collapsed":false,"color":"green","date":1705546217326,"id":"5d873b5e-dee5-4577-a48d-e0d22534b270","locked":false,"tabIds":["11729846-ebee-429a-9d18-e26e159a47aa","fcefa065-9df1-49eb-b292-fa33ac65495d"],"title":""},"5d886d94-7d1f-4334-bc5e-dfbb2bba9a52":{"collapsed":false,"color":"green","date":1701990426329,"id":"5d886d94-7d1f-4334-bc5e-dfbb2bba9a52","locked":false,"tabIds":["5034787e-3e08-4122-a214-95265cf738a5","6a597d87-23ea-4d9a-a290-9b4bd91044eb","4262572b-6b9f-4a9a-a838-3f746013dc0a","8ad2340b-82f5-4053-b79e-b5713e5fb3f8","33dcb637-092f-4933-8391-d31cef5326e7","1d5b49a3-ac3c-4d2f-bc86-237747d4bdc0"],"title":""},"5db528da-5c94-492d-a023-8746a8bdcc19":{"collapsed":false,"color":"green","date":1703108164722,"id":"5db528da-5c94-492d-a023-8746a8bdcc19","locked":false,"tabIds":["83f807f0-68c3-4486-9a15-b668665b803a","b958e72a-1377-4430-90e3-fb2ca48adcc3","38ec1379-bf58-4e7d-8989-4add5335048c","1f286fae-8751-4321-9831-ca415020d790","b1236b1d-b89a-4fc7-bb12-eaffc01ccef6","27ed23c5-c231-4c27-b486-b5f873f2a6c0","97065b15-d4f3-4379-8e1a-3edba60b7891","d9264fcd-88e9-4ea8-bc8a-692fe0ebe7e7","f45af863-78f8-4e9d-9a1f-5c1862030ff6","6f3fdb37-6f7b-457a-b4d5-802b62bcc235"],"title":""},"5e3f5c33-2922-4e44-83de-ca4a55d15a04":{"collapsed":false,"color":"green","date":1702494749906,"id":"5e3f5c33-2922-4e44-83de-ca4a55d15a04","locked":false,"tabIds":["493c98cd-11b3-47ae-8eef-4f8c4d50173a","9b1043ec-420e-44fa-8206-3d05724851b2","da3b6754-8460-4e1a-9e9f-06b54cfa8a41","9b7b9434-eb3f-452c-a59d-f15cedcf26ed","1afc7771-ab81-4919-82ca-b263392cac28","e4dc54eb-17c2-4e97-96e1-5535f350d38c","d28ace27-f79b-466e-94cc-6f94960dd2af","c2f1e397-da38-4d3e-b437-ee334355d2d9","f2c81bf7-11c1-4605-b1fe-89119cc21021","d214c87c-f0d7-4563-9fb3-c20da9b38c17","709ded56-8dd0-4f9a-ae2c-bb74aae5589f","c66e0400-d22d-4c4f-be14-3e63976b6792","2ddf56b0-5379-42fc-9cd7-012cd29832a6","229f91be-b7e1-4b08-b8f3-6249c18e56d3","b236660f-29c0-46ec-a621-18a9e13e68ed","47e016fa-e694-436f-963e-18725142da79","3b9fba3e-de3b-46eb-b1b9-021e5aec56f5","8360a0f5-0eec-4c7d-872d-9446378190cf","a3e98adf-6241-483d-8cf3-e6f95ed20957","638b32b8-e2d4-4a69-a7d5-669b63c247c5","6c9cb724-d419-410e-ad1f-c2d92072c812","3567ebc5-a706-40d2-861f-73b16adae55c","bc20f866-c7de-4e82-b465-b478e19ed9cc","6c6c59a4-62b0-42b3-9fe0-7a15acd4135c","4353484d-8332-4bff-8576-bc2bb33de2e9"],"title":""},"5fefc930-9f35-4b79-bfd7-3d819f42dcb3":{"collapsed":false,"color":"green","date":1698547429951,"id":"5fefc930-9f35-4b79-bfd7-3d819f42dcb3","locked":false,"tabIds":["8e1f98cf-25db-4684-a417-42c6499a11c0","a55cce89-a344-46cc-aa5e-a6050e3277a4","99de62e9-b006-4d2a-8ce7-0a4ac73aa1d8","cd8f5c15-b8d6-434e-9628-a870db958054","a8cb5e65-63b3-4633-b134-7266d7366022","446a816b-949c-40e7-ad98-ba2064b17039","748d0a1b-e506-4bb1-8127-46bbdc889a9e","9abf4e69-21d2-405e-bc85-1abc2e76afad","3ff9cd92-fe2a-4754-affe-569138e1567c"],"title":""},"6277735a-bee1-47e6-9cb9-6c9fe2692f99":{"collapsed":false,"color":"green","date":1698547429951,"id":"6277735a-bee1-47e6-9cb9-6c9fe2692f99","locked":false,"tabIds":["f64ff1cf-b4f8-428a-8a20-4325a7ddae83","687d8736-888d-4cbc-bf60-8dbfcb2a7583","eb84a4a4-55c2-456c-962e-2e3b0803994d"],"title":""},"62a2c842-f5ce-4754-8eee-331b059d30c5":{"collapsed":false,"color":"green","date":1712457067234,"id":"62a2c842-f5ce-4754-8eee-331b059d30c5","locked":false,"tabIds":["efa242c8-3265-4a45-afc5-35542cc655f1","4d65a79d-2a7b-4004-b09a-6c53ea78229b","8f19bb8c-7df4-4ded-afdf-7653ccb55eec"],"title":""},"63b6fec6-5b7c-4638-933a-689b395981d3":{"collapsed":false,"color":"green","date":1711858268372,"id":"63b6fec6-5b7c-4638-933a-689b395981d3","locked":false,"tabIds":["766ef7e5-7401-478c-9fd5-048b473b26b2"],"title":""},"6425d57f-ba6b-4fe0-a8de-2efc4bb1cbf5":{"collapsed":false,"color":"green","date":1701656505809,"id":"6425d57f-ba6b-4fe0-a8de-2efc4bb1cbf5","locked":false,"tabIds":["55a8a24d-c529-4771-91de-bfb13a4f1232"],"title":""},"65f14778-9373-4c65-ac8d-e1f5a06910c1":{"collapsed":false,"color":"green","date":1698547429951,"id":"65f14778-9373-4c65-ac8d-e1f5a06910c1","locked":false,"tabIds":["456b9048-0e2e-4a61-bb5d-5a30fd466e10","df497248-e0af-4537-bde2-31e4cf023e4d"],"title":""},"661fde0c-11bd-4f62-bdce-b76ae83e171c":{"collapsed":false,"color":"green","date":1698547429951,"id":"661fde0c-11bd-4f62-bdce-b76ae83e171c","locked":false,"tabIds":["643355aa-0bf1-4afe-8c4e-bcc7a32e1577"],"title":""},"67706324-e3fd-45b7-b7eb-b77883afee54":{"collapsed":false,"color":"green","date":1705520303377,"id":"67706324-e3fd-45b7-b7eb-b77883afee54","locked":false,"tabIds":["6a93ec3d-5360-443a-a01f-8cf71976e902"],"title":""},"67a72f4f-6dc9-4be4-a79c-c19fe469c4ce":{"collapsed":false,"color":"green","date":1698547429951,"id":"67a72f4f-6dc9-4be4-a79c-c19fe469c4ce","locked":false,"tabIds":["fffc1f95-0a4b-4759-bd2b-a433cd0e0e9a","7f24d63b-1fb8-47f6-b502-b30bf629f428","0e8fd0d0-4a84-4417-94ca-3a332f0b1b2b","f8ec3257-6092-48f2-87e7-46289cccacd1","5bd81609-8e9f-4991-9463-50297bdfe5ea"],"title":""},"6864f37a-c48e-4d95-be6e-030fc36934a6":{"collapsed":false,"color":"green","date":1711255064555,"id":"6864f37a-c48e-4d95-be6e-030fc36934a6","locked":false,"tabIds":["576071db-1923-4963-a148-7fe7d4847c54","41e8667d-f2b4-4155-9114-5b5155f21310","7e3014d2-344d-4b77-853a-a27c77cd394c","a5ccddd0-dd97-4bde-a1d4-788982062cdf","6d1740a0-ebdc-44aa-a2e8-ec4820e1e7d4","f54ae8c9-0703-4953-86b2-fdd6ab2a87d0","6d32735e-2dea-4df5-8c20-5c156de31143","83f04485-a292-48c0-b5ea-db76e1e102d5","9f2fc7b8-a1ec-4bc2-92cd-79febd448b27","56bd054d-9d25-4d6d-bd33-55c1f394bd1b","a6b80d23-d592-4995-bbef-40e50cc3c902","7f166644-a2e0-449f-8160-eb176fb8babb","63c90f5a-c4a1-47d1-989b-e9f634ece105","5a338bb7-fbee-4279-8a89-8dcf5573f3f0"],"title":""},"68a4a16c-0d34-42d9-af09-4d53be6903b1":{"collapsed":false,"color":"green","date":1698547429951,"id":"68a4a16c-0d34-42d9-af09-4d53be6903b1","locked":false,"tabIds":["eaf48806-3909-4ff7-87e2-15fa7d4eface","86a6a24d-6d72-47b0-b7b6-6861da356db9","39470500-4677-4b06-9949-b2ac689546a1","d7c684c8-8670-4d13-927d-11b4623c2262","d610a191-2aae-441a-95aa-a472192a3848","1ee1b201-eaf1-446c-9553-a5d0f05470c6","acd9ceb8-7d71-49ad-b5fe-14f8b0487431","afa3386b-9b85-46cb-b92b-71925e045c9f","c37892df-a525-494f-a595-fe99426cc450","7e94a762-be4d-4ac3-bad9-9d7a788d3e0a"],"title":""},"69339992-4c43-461b-8322-e355c0207795":{"collapsed":false,"color":"green","date":1698547429951,"id":"69339992-4c43-461b-8322-e355c0207795","locked":false,"tabIds":["3243be93-7919-4361-a1f2-67d753222034","ab717e4e-85f5-495d-a21a-818ba7242dc9","a9312f34-16a2-44d5-909b-52eaae8ac9fd"],"title":""},"6969428f-f37a-41a0-bcf7-169d0175b997":{"collapsed":false,"color":"green","date":1711346348709,"id":"6969428f-f37a-41a0-bcf7-169d0175b997","locked":false,"tabIds":["7d002c0e-99eb-43b8-b7e5-ce9a53af88f7","e96c92e8-5c30-431b-b545-3604f6235a01","ea870603-e510-46df-a4b3-95c4e8c4f12a","5ea8f130-84bb-4e52-9d4f-8a9ca1296d5c","cd60ecea-3433-4a0d-8fdf-16523a9ee437","7b3fe2a8-fc68-4c55-8613-a0ae3993b435","7a3945e0-dfb8-490e-a6a7-441de611e653","3a469613-bd89-48a6-b819-15ef1d5ecf8a","dae71a31-b7ab-4806-a0b4-81162bf9fbb4","a26d9b01-771c-4089-a357-0d4546051bdc","e6c4969d-521a-4589-85cb-1b493ad3a9f2","663abb32-dd9d-4389-a5c7-e5ab2be9454f","9601518b-9e8a-4243-bfa5-0e53732674b0","dab71eae-45b2-47c7-9ced-b445add7a468","be5b8c72-3e8d-4048-944b-fcdae2fc7f45","547eaeb3-b704-4593-8c90-44e7ad31070e","c5768efd-6ea8-40eb-8148-6ac67dce9b99","f743f225-a18e-4b1c-b957-7cfa09b6bd20","6642b31a-1640-43e1-bf23-135aab2413d7","dce23512-5d0d-49b0-91a3-a41eb7f00ef0","5cc85d80-ef13-4fe4-9e88-c041e84f1990","e99397ed-a168-4b7c-a439-5284169d8121"],"title":""},"69a02a67-24f0-49a2-a940-6b76d2f942f2":{"collapsed":false,"color":"green","date":1712454254399,"id":"69a02a67-24f0-49a2-a940-6b76d2f942f2","locked":true,"tabIds":["4e36ea12-7294-416f-8634-bbdf28f0be9d","030c52bb-eef0-4469-b307-a40e1ef340e7","ec9e1084-6b9b-49ef-923e-a8afb09f60d7","a340038f-9869-4198-939c-e802ddd64c14","a7cfa601-9c98-4385-969a-4d3c237f376e","2460ae9e-d937-4e9b-86e3-9301832bd380","255f536e-18d1-4fbd-a292-00f4dd3b8c11","d1049c6d-261e-49f0-a277-384321c1da7b","796ce604-99e6-428e-b884-9b3e36ba28a1","ccc618a1-7c3d-406e-afb6-904f0d2464fe","2b4f3727-d6c3-4309-9c25-eafbdaaf917f","0b64d5ec-dccd-4aad-897b-4fdcd7b9f4d4","5058c115-283f-4a29-b38c-f3940638b121","66f1d10b-43ec-466e-858d-91091a942aa1","1113ec32-7d4f-4495-b64a-4218f79f94f4","935346e5-1095-45cc-bd46-a4df5168a5cc","2836ced6-8a12-477e-8220-ae45581ff252","168cf37c-3c7e-431d-88bf-d6b8ac8fc6cd","cf65c35d-c3ad-41f9-af7a-f61a33cf2f48","58453007-1111-467b-b655-bacf9b2d2af3","b39b82c5-22b5-4b68-a4e5-b682b26c7b57","150431fa-6511-4c2d-9e83-51664e9c0155","ecf88057-1dd4-4de9-9af4-d043e0a19f53","e46a8d30-6145-401e-8951-96db5523ff04","7e22bdcc-337a-4324-93c9-20520f814202","7092251d-84e0-47e7-b78d-8b40c996b2ca","a7922bfe-f3de-4ec4-9501-f7763cf54512","56d4b3bc-8e0a-491d-b832-cd330556103b","87b809f4-bd30-472f-8709-11f58b71378d","5755dcf5-a0b2-4e18-9b9b-9a6ebda4de95","c1dd8690-cd89-4670-91f4-c403b3e93896","34b1da31-c8e0-475d-9750-c36ed1cb9c11","96df627a-17fd-4a72-a975-6204b7ced665","0385c906-fef7-4eaf-88d2-b67bd7dc211a","bc8e92da-d973-497f-a8db-b62e0e54cdf9","166a42c3-13d2-4fee-bd2c-3dd97f7bfb01","487f38ce-1932-4123-86e9-4686a7dafcd6","a26c5b2b-12d3-4e72-b274-6b99ddc122b2","ddf9439c-a9c0-4128-b643-457a58f1feb4","19e990c4-37fd-4856-85d9-1915364dfda6","53611b1b-0e1e-4595-a46f-63f2f44f7784","bf78c7c6-7d1a-41f6-8c93-cd518deba06b","d9d831cc-175d-49c9-9ada-bc60ab18733a","acf9c0b7-23bc-466a-bee6-18ef04d5dc97","6352837a-297d-43a5-8276-1d941d79ef25","7b966a82-20fd-4196-9aa0-d68b3baa86d6","c5c8a119-4853-4d6e-bbb6-700125674829","6e3e438c-94cb-4863-894e-436cafc1b225","0ac7c2ba-b0ea-4471-8189-695d02bcc2d2","2e47f208-853b-4c85-9614-28a9fd43bc08","70c915cf-3251-4fd4-b1c3-d467061b4440","c00629c5-5209-4ca4-9f56-a7f2519bb6b0","1ace8a1d-3efe-4d32-a5a6-8730ae8e3505"],"title":""},"69c75202-65b1-4744-a83e-39d930a2d3a9":{"collapsed":false,"color":"green","date":1698547429951,"id":"69c75202-65b1-4744-a83e-39d930a2d3a9","locked":false,"tabIds":["da00bf09-da92-4f3e-9320-57b3cb6e72ae"],"title":""},"6a319c70-9a3e-41b0-b5ab-4eb03fb0ae9f":{"collapsed":false,"color":"green","date":1706482440006,"id":"6a319c70-9a3e-41b0-b5ab-4eb03fb0ae9f","locked":false,"tabIds":["2f3b5fbc-aada-414a-a2c6-34df57c0ff38","9a50a0f6-c451-4122-b5b9-fe5fba7ca0f0","5d7bca29-53ac-4644-bd3b-64aeb76c5c53","ef9bdb3c-25c5-48e4-b5bc-91d0f4614167"],"title":""},"6a5a2c11-2ea9-4919-a242-a7b106862e7d":{"collapsed":false,"color":"green","date":1702924417322,"id":"6a5a2c11-2ea9-4919-a242-a7b106862e7d","locked":false,"tabIds":["4f28036d-0355-403f-8744-34ad75ce2410","77877adc-eb02-457a-aa59-9abf259c813d","8bae1fa2-0d5b-4724-8000-f1469576255b","63e2e076-0fdc-4b79-b59c-36dc7b51a9b4"],"title":"soft"},"6a946ba6-7ad8-4941-9519-ef3f3ac09f0e":{"collapsed":false,"color":"green","date":1711995532199,"id":"6a946ba6-7ad8-4941-9519-ef3f3ac09f0e","locked":false,"tabIds":["0212243b-449c-47e7-8266-65c97ebd16f7"],"title":""},"6b26c73d-b506-40de-bed5-866ccd5a9f95":{"collapsed":false,"color":"green","date":1698547429951,"id":"6b26c73d-b506-40de-bed5-866ccd5a9f95","locked":false,"tabIds":["5a44d850-0ced-4f52-a7c6-93d50a0b6fa5","3fbb1247-c64e-4bb3-9ee8-d8290017bd50","4ea7741c-a037-4fe2-8e21-8e2c950d871a","5389629c-c3a3-4a9c-b4e7-8c0c91e03338","7ec1d990-240b-4c72-b20c-4e13988744a3","c8295f25-011a-43ef-be61-3bb148236f16","0d7c4f30-0ee9-4435-9d0f-8d31f09029cc","a8902c80-7ea2-4c3d-ae02-f206010ba9c2"],"title":""},"6bba5b4a-a28b-4880-a018-0be8a399e88b":{"collapsed":false,"color":"green","date":1698547429951,"id":"6bba5b4a-a28b-4880-a018-0be8a399e88b","locked":false,"tabIds":["014586bd-1094-4138-8ca4-9f905b0ec715","b66db5e9-cfe9-4b56-ae63-b23c7983e6a0","67a1c3d7-262f-43f2-a778-378a642c7497","f2a30d31-5839-4368-9c8e-c08e95b8cd0b","f8822de3-b4d3-4289-9b8b-44285dde8f66"],"title":""},"6bcfcf2d-6222-4544-a3e8-67809966a5fa":{"collapsed":false,"color":"green","date":1698547429951,"id":"6bcfcf2d-6222-4544-a3e8-67809966a5fa","locked":false,"tabIds":["bb681d72-ab2a-419a-9da7-c692a030a268","9878566a-1862-4f24-9085-e92d3758418e","ba1fdea0-14fb-44db-9d4d-04fe1d0d2f1f","114f1e19-b17e-4cf5-9d20-f84ae3dc880d","f438d6e5-6e7d-4191-a360-e007188e7447","cf4ee064-58b3-4ba4-bb72-f35b87b45ea9","3aec21c2-b4ed-4c49-b06e-db9e7a32ca9c"],"title":""},"6c005a13-a990-46c5-b04b-52b48af19555":{"collapsed":false,"color":"green","date":1698547429951,"id":"6c005a13-a990-46c5-b04b-52b48af19555","locked":false,"tabIds":["aef6d6fa-37e5-4092-8997-ccfefc4fc395"],"title":""},"6c709e28-a4bb-457a-b4a7-9d24b7ca9a24":{"collapsed":false,"color":"green","date":1702070062698,"id":"6c709e28-a4bb-457a-b4a7-9d24b7ca9a24","locked":false,"tabIds":["40532e2c-885e-40af-b8f0-c1606bbb495b"],"title":""},"6d07ee8b-9f16-4d29-817d-ed2ec545a558":{"collapsed":false,"color":"green","date":1698547429951,"id":"6d07ee8b-9f16-4d29-817d-ed2ec545a558","locked":false,"tabIds":["ecd925dc-433e-4c9b-9d28-c96b6d880b0e","b57d411a-d693-4883-934d-711dc2b0b438","ecc5e1e9-e4ba-4299-9e79-4ed998e3430c","c2892429-e2ee-4f4a-8ae2-a16754aa8469","6d0a4767-5b8e-4deb-bdbf-6c58bfeba10a","bd132ecb-0e11-45f6-81eb-54122bc08d25"],"title":""},"6d154842-79c1-475d-83c2-1d96f4a96db1":{"collapsed":false,"color":"green","date":1709751731716,"id":"6d154842-79c1-475d-83c2-1d96f4a96db1","locked":false,"tabIds":["d6d8c219-f43f-4058-b6ce-f12764bd1c56","7ea6ea1f-3010-4f43-962e-cab01ef70108"],"title":""},"6e53e295-db6a-4635-bdbf-6cfa0bed93d4":{"collapsed":false,"color":"green","date":1705546231376,"id":"6e53e295-db6a-4635-bdbf-6cfa0bed93d4","locked":false,"tabIds":["214eac5c-795a-49ad-aac2-240d45e30a36","676c0e26-1a97-4207-a1e1-09e4b7ce1fac","4771461e-8a0c-405c-8b2e-43170e9de9b2","a1101238-35cd-438a-bd3c-d5f86ed63dbb","433dd18c-201b-48a3-bdd8-1cc3aade711f","de5ae3c5-7717-4154-96bf-6323447e731b","57fd2939-98db-4141-8b47-34dac0fe237b","50221986-f10c-45a8-b56c-04011c05a5bb","1fd4ebdd-2e8e-4a39-9e00-8d6aadae1a1d","31764a9d-a7df-497c-8ecb-0364704407c8","03f4b8af-4b57-4bfb-acdf-53173ce2190a","3b085852-da56-4059-a8e6-bbcfd0f5dcdc","162530b0-c288-42f1-9ed6-5896e008bdbe","d9359220-7f1e-4b3d-a847-3c684d715196","5fe20ddf-ea8d-4add-9cb8-67d6518a6103","00717da7-3939-4694-971a-f1f37c4fb56f","b1abb7a6-e546-4c6d-b68c-a17093685d2f","24d89ad9-8c62-4a3f-bf96-7a16a70c3135","a28f9d30-ae62-49be-abda-1d60e02e1dd6","a1c5807f-3c8e-4938-a6ec-d9a58ba55926","8f02a3a6-5333-4efc-b484-68775b6e2acf","5be0542d-df21-46ab-911a-d9899661c002","0222be4d-de12-4971-84d1-9d574533b51b","e2966d26-5235-458c-9901-3f7dfe5c041f","3d1c8b84-cdce-4d3b-af2d-db2f0c9af295","38831be0-5b38-4fd2-b5ce-fbf8bc752de2","436e5d32-927e-4b39-9012-0e8a1da9c4d2","f3f1af24-b065-4858-98ae-26584bc95f09","88a0d9ad-6880-4b89-9a9b-01121de7588d","21d35f9a-17e1-4520-a943-927854304387","f501d3e2-7f4b-4fca-8a56-3d8280b5e5f9","ecc23277-aebf-428e-8cdb-4399deae9e6c","513cf06e-d9ee-437f-bda6-f217e8cb2103","595af1ff-59a0-4f17-b621-ac5f42949490"],"title":""},"6ebae86c-4a21-4881-aa55-759cb98f25af":{"collapsed":false,"color":"green","date":1704079437683,"id":"6ebae86c-4a21-4881-aa55-759cb98f25af","locked":false,"tabIds":["5d7e0cbe-437e-439b-a121-cef07af2db6c","f4297e3d-ed44-4b1f-9254-018fb6bae757"],"title":""},"6f2ab800-982c-49f5-a694-9f72a3b550ed":{"collapsed":false,"color":"green","date":1698547429951,"id":"6f2ab800-982c-49f5-a694-9f72a3b550ed","locked":false,"tabIds":["2d926b14-05c5-4cea-9058-e70e0308081c","52bf9f48-c8fa-4afe-9ca6-4d99f018edf3","6e6c0e64-e987-4f9c-b8eb-0ee822fc446c","2d7ae04b-8b1b-44cb-9f2d-190f36022f17","81c87449-5085-4b3f-a4e0-b4702c3b8233","bd61ce02-8045-47b8-92df-dfb14c0b43f0","07b1a01a-b056-4b80-8b26-132131b433fa","dfd4f960-7f18-4360-971f-beed2dc654ca","b69e4f79-62b5-4196-b4e4-d769adbda90f","52f1a41c-1d26-4dd7-8e3d-a2444936e9d0","c36da87e-41d6-4ecf-97ee-8bf977f4b1e2","65bbdb98-a25b-4263-9d41-a2b2d3dba9d2","b371f6f0-b01c-4ee7-9fe1-708d1756856d"],"title":""},"701c33e0-aa0e-4b64-aeca-929df47897ec":{"collapsed":false,"color":"green","date":1698547429951,"id":"701c33e0-aa0e-4b64-aeca-929df47897ec","locked":false,"tabIds":["59fb7e24-043b-443d-b78b-4fe293b98cba","4310d073-f240-49db-bd70-6f3f04e96faa","30e8c90e-1b93-49c1-ab18-3a0162e1efda"],"title":""},"707b2565-c78f-4755-8a7a-320d3f0dc749":{"collapsed":false,"color":"green","date":1709642761524,"id":"707b2565-c78f-4755-8a7a-320d3f0dc749","locked":false,"tabIds":["9fc6b6de-009f-4b5e-aba5-b6da27d9b0d4","b6a1d52e-8491-430d-a4ef-98d1fc5b1360","a9593d2d-bc25-4df9-8437-ac0c295af358","76f725d6-7092-4851-883d-c184c7e579fa","a907d362-0b8b-47d4-95b7-0e0d324d4cf7","ac8fd655-8f3e-42ba-a891-0d958171b67b","09bbcb89-6ca2-40a6-a9e9-d2fc2a58017c","85cb13bd-ee81-4bf5-8eb7-354c2208162c","866b3b15-71ac-49ba-a621-f44ea03913cb","ad794b68-13df-44b4-804a-c880a94f3b27","177d045b-f66b-4bdc-8c47-1619ffae4879","27af9fb2-29fd-418b-8691-5a172dd39e13","c10c90aa-73d0-4658-a860-d2fab31a5e82","82da2322-af79-4667-b564-258d09d12358","7d9660fe-f1bb-4789-8ee0-1a35ad566941","06e08779-c2f3-4ff7-b1a5-525991086031","12994b68-40fa-4dbc-a655-c5bbb4b5ca6d","4f4eef69-e650-4357-8dd1-4984e55fa195","b826276a-cc1d-4b96-bd7a-00e0bc47d541","7a68d1a3-71da-44bd-b047-62b79d861ce9","93584556-bb9d-4ee5-8847-76925fa8e24c","424a755e-7de4-4741-8e35-073cd6262445","5b3ba212-13f8-4680-bdc1-de75a1c35303"],"title":""},"711e9191-6569-4082-bd64-b948aef8c9cd":{"collapsed":false,"color":"green","date":1698547429951,"id":"711e9191-6569-4082-bd64-b948aef8c9cd","locked":false,"tabIds":["d85dd492-8f49-4769-a96f-40b77fb28914","ba182eeb-c198-4991-9f39-c6df80d70906","1cfcbb62-8984-4bfe-aada-b53066642cb1","fe3cc76e-9a6e-441c-9fbe-3acb0b106cd2","9b827c0a-e05b-4534-8650-7e0dfab556e7","a9492998-1efa-4e6f-9263-42a716327f77"],"title":""},"718df102-b1ad-4c17-8b70-2b46436db36b":{"collapsed":false,"color":"green","date":1698547429951,"id":"718df102-b1ad-4c17-8b70-2b46436db36b","locked":false,"tabIds":["1c6dc7d9-f52f-4c2e-ba86-ea66cfcee8ca","c937334b-e4da-466f-a63d-10c763f94b66","fe4a391e-43f1-4289-b7d9-c827cf7dde8a"],"title":""},"719b4530-c79e-4c0d-b68e-88eb8a8d4967":{"collapsed":false,"color":"green","date":1698547429951,"id":"719b4530-c79e-4c0d-b68e-88eb8a8d4967","locked":false,"tabIds":["beeb28cd-0658-4052-92b1-a198b00af325","2c9c19fc-e161-40d7-b660-d2b697c437f8"],"title":""},"71d27d7f-ec64-4077-8a39-778c7866862d":{"collapsed":false,"color":"green","date":1698547429951,"id":"71d27d7f-ec64-4077-8a39-778c7866862d","locked":false,"tabIds":["286e7346-7725-46ee-bd0b-77d56ebf64cc","599603cf-09bd-4a84-9950-fc0b54205af0"],"title":""},"72e8e6c5-cd5f-455a-9c64-f5576065c825":{"collapsed":false,"color":"green","date":1708972992052,"id":"72e8e6c5-cd5f-455a-9c64-f5576065c825","locked":false,"tabIds":["870551bc-707d-44b8-a1e8-64a3c319f6e1","7fc05b39-992a-477c-bcc9-5df437b4bfa6"],"title":"hugging"},"7376bf8d-a042-4e28-8dff-ca6a98172b03":{"collapsed":false,"color":"green","date":1698547429951,"id":"7376bf8d-a042-4e28-8dff-ca6a98172b03","locked":false,"tabIds":["96d36051-cc5b-4a3a-8a57-6ef7cd59fa81","a9187d46-90e5-4f40-8175-7e27aecc3ae5","2acc3fa1-0fd6-4928-90c9-2bd9fba84c28"],"title":""},"74791eab-4309-4b8d-a7ca-0229b26f4143":{"collapsed":false,"color":"green","date":1698547429951,"id":"74791eab-4309-4b8d-a7ca-0229b26f4143","locked":false,"tabIds":["e839b1b2-9b7f-4f75-806f-e0ce96a861a6"],"title":""},"751b7c9c-f550-4cab-ae47-4e8140140fe7":{"collapsed":false,"color":"green","date":1698547429951,"id":"751b7c9c-f550-4cab-ae47-4e8140140fe7","locked":false,"tabIds":["d3665a8d-91e4-4f86-91ee-ffb0757d39d7"],"title":""},"754ac074-415a-4aa4-a9a2-6e7989b153f2":{"collapsed":false,"color":"green","date":1701878398187,"id":"754ac074-415a-4aa4-a9a2-6e7989b153f2","locked":false,"tabIds":["a2599b0a-0e01-45d7-b642-0de731380be8"],"title":""},"758c2e39-d5b4-43e2-9fd4-123865871381":{"collapsed":false,"color":"green","date":1702070041183,"id":"758c2e39-d5b4-43e2-9fd4-123865871381","locked":false,"tabIds":["77f9fe5e-c129-4e10-84a4-30eeebae1c21","fadff827-3449-46f2-b83c-75b85ad955fb"],"title":""},"768761b0-d841-49c1-944c-736b5bcc9284":{"collapsed":false,"color":"green","date":1698547429951,"id":"768761b0-d841-49c1-944c-736b5bcc9284","locked":false,"tabIds":["6ba3e731-692a-4325-a21d-d7e46f72c0dd"],"title":""},"76882e3b-1d65-45df-a5c1-e20b85137d9e":{"collapsed":false,"color":"green","date":1698547429951,"id":"76882e3b-1d65-45df-a5c1-e20b85137d9e","locked":false,"tabIds":["af6ab83a-ce1c-4c54-bb8f-8d8827c605e2","822aceb8-5c19-4454-8e9a-6152e5a6a296","3b5ef701-168d-4694-a205-eac6254194ad"],"title":""},"77172a63-2e60-4a6a-aacd-994fdeb0eee9":{"collapsed":false,"color":"green","date":1698547429951,"id":"77172a63-2e60-4a6a-aacd-994fdeb0eee9","locked":false,"tabIds":["5eb25819-230f-4dad-ab19-a2e49a72a336","257ac310-5496-40dd-9aca-eaf83add03dc","041106c9-0cfa-480b-b428-483f44194528","1f7a62b9-e11c-441f-b447-3104bbd9878e","b1511741-5751-4271-ba98-a21ea1bbd7a6","976485f7-5ee9-43bb-a5b2-4fc4e8920e61","c43ff2e7-b38f-455a-ae6e-5c78375b7fd3","238f9e03-a672-4aa6-89bd-6ecfc9bf719b"],"title":""},"77c0bc24-6846-4f52-abd7-09068a8b0c81":{"collapsed":false,"color":"green","date":1700936213037,"id":"77c0bc24-6846-4f52-abd7-09068a8b0c81","locked":false,"tabIds":["5931bbec-f86e-4d94-a710-fa5ad505df1d"],"title":""},"78757ab0-0caf-433f-acb2-40aa137fd6fc":{"collapsed":false,"color":"green","date":1698547429951,"id":"78757ab0-0caf-433f-acb2-40aa137fd6fc","locked":false,"tabIds":["25d0c14e-baeb-4499-9e31-eefdae811c3c","2646b953-24af-44b9-81a8-0694e8fc698c","1d90e86c-834b-4b38-a1af-11cc77834fc0"],"title":""},"79db6515-4525-4142-8aae-7d4c60410945":{"collapsed":false,"color":"green","date":1698547429951,"id":"79db6515-4525-4142-8aae-7d4c60410945","locked":false,"tabIds":["92e9ed35-ed19-4dcc-a0ee-34f92ead8cfa","eb3d2c81-9187-4572-bc81-feac47eee2c4","8d10893b-e29d-4823-823d-664c1c7d4e23","68f3600a-239d-4ef3-b17c-2e9b470647d9","7bdafd06-268f-4690-ada4-36ee5efd63ee","e103f111-6527-418f-96db-261451461298","173c264e-9209-429c-a1a1-653146da87bc","2d54eae4-fed1-4704-b278-de7d10797460","606f0641-a265-4024-b396-ab7668924d85","f906d180-ddef-4dbb-8353-17ad5b0c96ab","43c76fd5-f259-4e7a-a121-f04db644454d","1b337013-50e5-44cc-857b-55ef30bde64e"],"title":""},"79f4d86a-c8a1-4f52-a42e-605b23ba44dd":{"collapsed":false,"color":"green","date":1698547429951,"id":"79f4d86a-c8a1-4f52-a42e-605b23ba44dd","locked":false,"tabIds":["c93dfc43-c2cc-4a92-a418-1be4ed5d86b8","59e8c3f8-f965-4525-b900-506d22b4a712","ea07f017-2ad9-457a-ac2e-29ffa83c2e7a","7a104634-cdee-4e14-b2db-a83c5aa08703","eeddef85-9343-41e5-8bf8-29ecbb0a1be7","7deb143e-a402-4a0a-8575-53be9fe05be7","508f4302-148c-4c60-8fb8-9ab44fb853ab","4540a588-3bb2-4d29-8b97-71f007a383e7","25190dd3-50cb-4410-87b4-91da1656b9cf","8183e7d5-1a5b-47d4-b786-917cf7c1ac62","775724c0-b4ec-4660-b180-4f54eae437f1","dc110fd7-6063-4613-a873-012ca65f9ae1","8e5df407-af53-446b-9a68-4b04e9e68932","2837eb6a-9184-4f90-93a4-6dbaadedcb6b"],"title":""},"7aa6639c-f088-49dc-bc72-66364da449f1":{"collapsed":false,"color":"green","date":1698547429951,"id":"7aa6639c-f088-49dc-bc72-66364da449f1","locked":false,"tabIds":["5d2433e8-5ec9-4b16-b4c2-321762631eb4","adbe6e53-9dab-4407-a2a7-5f61da3e83bf"],"title":""},"7b940f80-4c86-462d-b24a-7ad474667494":{"collapsed":false,"color":"green","date":1713379376392,"id":"7b940f80-4c86-462d-b24a-7ad474667494","locked":false,"tabIds":["5677aaa0-718f-47b5-90a0-b6334f44db47","042ecd88-bb30-4a6e-bb41-1589880052f3","7bbfc71d-9ebd-4279-bace-e0424736519c","ee7f362d-4909-41e5-b35c-23cc147462b1","9aa3373c-8794-4646-8d18-a7dfe9c02003","29818b10-0de7-4d21-8709-5086b5ec67c6","2223eab2-9ae2-42c2-a997-ae90ccf34d5e"],"title":""},"7c4917d1-8e1c-430d-8f28-3d35eb12345a":{"collapsed":false,"color":"green","date":1698547429951,"id":"7c4917d1-8e1c-430d-8f28-3d35eb12345a","locked":false,"tabIds":["277376b2-0cff-4e33-b087-695419477c96"],"title":""},"7c667756-24e4-44ab-b2e5-b248dc5e18bb":{"collapsed":false,"color":"green","date":1705588052402,"id":"7c667756-24e4-44ab-b2e5-b248dc5e18bb","locked":false,"tabIds":["30392452-3bd0-4523-82ae-1bb01a0e4746","9da88e7d-cb0d-4180-9f0b-6441bc38f7ed","611d261f-9554-447a-ab8a-70fe3b5b82f3"],"title":""},"7c6e1ed1-9eb2-410a-baf8-aa58be819a97":{"collapsed":false,"color":"green","date":1711386272946,"id":"7c6e1ed1-9eb2-410a-baf8-aa58be819a97","locked":false,"tabIds":["5d6e485c-936c-4ba4-b06b-fb08566f07d6","8b070059-38e4-48f5-ab08-758913f67407","1e1b74d8-5624-4ce1-9b74-1632483b32d8"],"title":""},"7da9bfc7-b504-42d6-8b99-b3bedf5cdb57":{"collapsed":false,"color":"green","date":1704590248965,"id":"7da9bfc7-b504-42d6-8b99-b3bedf5cdb57","locked":false,"tabIds":["95c02ad0-0e09-4558-9108-c03916f0b432","25703dc7-d84a-44fa-93d5-7b37c5c960e1","dd04a2c7-2eb3-4a19-84de-ecef7f207aed","ea454c57-1428-4008-bac6-88247af196e1","bc67db1c-53da-4f26-8223-1a812ed11946","c5d60d98-e3f3-4733-8626-9bc760baa6c3","88c74955-685e-4433-8f4a-c1443720f186","9b38db6f-4513-4c1a-9311-ae69dae77cd9","12180479-1f1c-47e7-8eef-14a0c11ad796","9a784d23-2df5-4198-a4b5-5d965744f262","08ee2e17-f0c8-4937-a32c-02004d7ab4d6","8d98cf06-aa97-4d74-849b-5375fdd328cd","3f2f9adf-3c5a-4a71-ab3d-20373d62d2fb"],"title":""},"7e222ba2-2655-40c9-ac32-9f5d5862ea36":{"collapsed":false,"color":"green","date":1711170993071,"id":"7e222ba2-2655-40c9-ac32-9f5d5862ea36","locked":false,"tabIds":["6a28bf08-429f-41c0-bcc3-7ebb520e0d95","1d9fc928-0d97-4df8-93af-d6a2aabb0041","9da107a9-3061-499b-a304-1716424ad050","95732be6-d221-4861-a28f-8b45ec289f5c","0c657f75-83da-4235-a714-d7aa95c2edce"],"title":""},"7e4c6bed-76e5-4ca4-a401-380670552ce8":{"collapsed":false,"color":"green","date":1712368860081,"id":"7e4c6bed-76e5-4ca4-a401-380670552ce8","locked":false,"tabIds":["bfd1aefc-b1b4-476b-82a7-708c3acc4d15","3d8eed81-9cb4-4803-8e9e-2ec6d6bb4f79"],"title":""},"7f12bbea-2752-4280-9335-4af97330ea88":{"collapsed":false,"color":"green","date":1698547429951,"id":"7f12bbea-2752-4280-9335-4af97330ea88","locked":false,"tabIds":["5418d067-31ff-4c2e-9043-3728b1ce2234","fcd7ed61-0181-450a-8f63-be058e7ce8d8","31aa46e7-fe23-4dcd-819f-fc92f9aeba77","d15eb684-26ee-4a74-a47a-2739b7dafc22","86006621-1254-440e-92bc-547d04723afb","6521c917-d4f1-4c78-a531-7534d3aa833f","115ff84a-747d-497b-890d-ab8cd058017a","facfe755-ba3f-41ae-a73b-397f17bef499","e6b44118-05f1-4ff7-bdcd-02784dda0961","9359990d-b0e5-4d99-ae63-62d5b8483467","1905895f-4135-433d-b02d-b8cd653c54cc"],"title":""},"7f8aa8c9-d3a8-44ac-a776-460957cfb0c2":{"collapsed":false,"color":"green","date":1699061722177,"id":"7f8aa8c9-d3a8-44ac-a776-460957cfb0c2","locked":false,"tabIds":["a334900c-9299-4d2f-97e4-c338c8ee6fe7","7127064a-a759-4213-9094-aaa87c1ddcbc","1ca25453-d92a-4166-9e49-659ccf5a35e1"],"title":""},"7fb38a9a-4201-4705-9bf1-83c9d520b42b":{"collapsed":false,"color":"green","date":1698547429951,"id":"7fb38a9a-4201-4705-9bf1-83c9d520b42b","locked":false,"tabIds":["13988548-5e81-4b3a-bd6f-d1220538838f","e33f08c7-716d-450a-a5ca-7d0425f9e021","66281e14-f0f2-4632-9c64-a6761d852726","17e35b99-90bc-45d3-b87b-6b88d79225d2","cf1e9c5a-4b25-4b72-8ac9-237f160f1fc3","0c1ae56b-262f-486c-9010-4d8742a77e47","050f46e3-5cf2-475b-9999-0501adb7df91","d912e728-0190-403f-8b1f-c79bdef63036","ff08605e-4ccc-409d-9277-4b7d10e232be","71ce53ff-0c45-46bd-9f3e-a8d652484464","3ff48e84-c6e0-4969-b009-82502a6d723b","9cd527b5-3905-412e-8d52-a0be0df75af0","c2a94995-02b4-4443-803b-f2538c6d5a3a","f9c1a834-4ced-41f2-ab03-1730cef268ad","da67f714-5445-4ef0-8539-a17679027f82","bcc62768-578d-4470-9827-4dd360bf6189","bc1514ec-6ab0-4a8b-b20f-236406e67056","b3bec075-bf21-4955-8f9d-00e4d704e2c1","4bc7c8f8-009a-4df8-b3b5-e420e98647b7","a945a253-1611-42e8-bb79-29a6aac9e32b","acc5e3c3-9b4f-4280-8f62-39c78ec35d3b","0fc5ef45-8a07-44dd-8943-195a464b958e","8d96602b-78b7-4fba-ac28-c306e4650966","2173f0b4-b932-41a8-aa9f-eb6c03c72660","8103ce22-2392-4e89-b96c-d8948c7ce7d4","47f65177-b775-4439-b7e2-5c5521af8da8","881aff31-3943-4752-b071-b4aa105e7959","eaa885f3-e248-48c7-b4eb-7e368c535b43","0bb67b91-2579-462e-a5ba-3537985b90c6","7e331663-584e-48fd-b5b9-ca48e815d905","98584169-0c0e-480d-9edb-a0ba3f88b738","af64b13a-dd95-4965-ad7d-e1761f1a667e","64b41008-2927-4ac9-b1c5-39ec826838c0","7a1e4f27-163a-429b-9b90-550c9ad37276","d0486a6c-afe8-4e8f-986c-0192885989b0","58f3f478-55d2-435f-a29e-ff425b2f9db7","7dbcd202-e6ea-4ffe-a290-a413ffbd99e3","295e34ff-7c4b-46cd-9195-262fb1a7e683"],"title":""},"80bea87c-7a7d-42f9-b759-492a7d554efb":{"collapsed":false,"color":"green","date":1710035888320,"id":"80bea87c-7a7d-42f9-b759-492a7d554efb","locked":false,"tabIds":["7e605b00-1e8c-4165-b69a-df742df6020d","4bd86ccc-86b6-47f3-971a-ffdfa03c6bcb","6537466b-5df1-4c4d-bd29-7c076a50b74b","e81b8908-3b4b-4ca7-b3a6-a5c6d159dc41","b7546a52-394a-4541-9a93-7efc56ff149a","6babff64-cbdc-445e-b0fc-f7724d0b146d","c4d3c175-0a37-48db-9a2f-0fcb62b40ad8","e191b73e-6773-433f-bcde-4765c7680731","4cd62234-64a1-4c65-8047-e032d854e552","5193d233-779f-486c-a59d-f28d2a0be897","4301f355-c915-462b-b0ce-b83478805cc4","7fc9c64b-b17f-4643-a62e-83d93cc474e7","c6ac2b81-7afa-4a62-bc3b-3185fda344bc","3099db36-40b8-4407-9ae8-9d3dea507b35","134eeb60-b073-4c8a-a94f-77aa84328818","3fbf3026-2b7f-4642-a26d-08a2edf9ff1a","ea8a02ae-3884-46b6-a255-c6bb2b9f040f","b1ded8c4-3138-4b9f-ad3f-6362762dc23b","10048ccb-4ad0-47e1-afb2-fdbfc4021595","6de53084-bbf4-4b4a-a416-74ed469c905b","9bd79ee5-5ade-4083-952e-69c05142f267","4d6e6ab6-eb3a-422b-9936-ee31a80fe54f","c02ed538-a7bb-496f-b855-f092e6dc2de6","ce94acc9-3f81-49fa-ab81-b7140da5449f","72aaf879-26b7-4c82-a2e7-1b311b167d45","dbdb8a1c-52cb-417c-8ce7-6a56a9471842","c2e8d387-bddc-4f8d-ab38-ec813b61d049","20c6df43-34cd-41c0-8756-e0b0ed5f9003","ca843290-d994-4c67-afac-85c57d7effd0","1dd91b26-b215-4134-9b2d-53dd817806c5","3b91a462-1c25-45e8-bd71-d2a82ced6806","bc87b64a-4a0a-4fe7-b510-15bfd61437a9","8d5a4666-6814-4d8c-a5a7-8e93b9b4321e","87177ef2-8de8-4099-a567-bff83bd2e62f","557ee541-69e9-4c61-a12b-217db047615a","2e3fb0d7-0bc5-4f62-bdd5-c782265027ce"],"title":""},"81c7c462-9c6f-4cf9-9e94-02beefd41b54":{"collapsed":false,"color":"green","date":1698553158423,"id":"81c7c462-9c6f-4cf9-9e94-02beefd41b54","locked":false,"tabIds":["0fbc3d9a-ec3b-44ad-8d25-62360436d3e5","d5c60aeb-350d-46cf-b99b-dae3e72e8de6","793488b2-04e8-4000-a640-f8aa934a53d2","95a52022-820f-4763-9480-374c77bba7e2","e9a3c231-bef4-42a2-b8cb-93992837c989"],"title":""},"831fc343-7c53-4005-983a-0cfb249a23f3":{"collapsed":false,"color":"green","date":1698547429951,"id":"831fc343-7c53-4005-983a-0cfb249a23f3","locked":false,"tabIds":["52e99827-1034-4596-9572-2ec8e5219559","66980613-1a71-44ce-a8df-a4183759d253","edc057de-3e79-4649-b4d2-707942ff2b19","f6f4efc7-b501-47ed-bc8c-a41899ad9084"],"title":""},"83ec9527-8044-4d03-89f7-19569edb2c98":{"collapsed":false,"color":"green","date":1698547429951,"id":"83ec9527-8044-4d03-89f7-19569edb2c98","locked":false,"tabIds":["fb0307ee-079d-454c-9dfc-165669678a0e","612c2f24-780d-47bb-ade5-a3d6b2ce6a9b","b23c2784-ad82-4b29-ace9-54a57ce65759","146eed5b-eedf-4888-aee2-7051c76f6467","55388d6e-8f75-4240-aac4-348f068b4bc5"],"title":""},"848e2261-32fa-48dc-a71d-468245bf9a03":{"collapsed":false,"color":"green","date":1711995738249,"id":"848e2261-32fa-48dc-a71d-468245bf9a03","locked":false,"tabIds":["037759ff-8efe-49a3-977e-aa21f7186998","48f87b1e-7441-4a26-b275-c19c4f75bd1c"],"title":""},"84b588c5-2227-497b-a414-560c41108b15":{"collapsed":false,"color":"green","date":1698547429951,"id":"84b588c5-2227-497b-a414-560c41108b15","locked":false,"tabIds":["8f215cda-d79d-4650-a191-15caabe4e38c","94d059a9-35ec-4c4e-afa1-182ca1330111"],"title":""},"84e4d761-01ff-405d-ad18-cb363574381b":{"collapsed":false,"color":"green","date":1701457189689,"id":"84e4d761-01ff-405d-ad18-cb363574381b","locked":false,"tabIds":["706632eb-6e92-4fae-9c78-3082fd58ce82","459a5bc5-71d1-479d-a8a0-8e53abb67656"],"title":""},"8536aafd-5d8b-41ef-aa8c-a8d59bf0dd72":{"collapsed":false,"color":"green","date":1698547429951,"id":"8536aafd-5d8b-41ef-aa8c-a8d59bf0dd72","locked":false,"tabIds":["381e8bfd-5030-424a-9a0c-56faf78f7ede","1e9eb58d-6976-49b0-a083-d21d6159d65a","3221babb-f0c2-4f63-a21a-92339c1d0536"],"title":""},"865af253-6e50-4ad2-a59d-0ca7bbed1444":{"collapsed":false,"color":"green","date":1712457071633,"id":"865af253-6e50-4ad2-a59d-0ca7bbed1444","locked":false,"tabIds":["775c63fd-3bd2-4066-86c3-79a68f42572c","ddb01ec7-236b-4639-9939-57fb1da46424"],"title":""},"8679bb15-c649-469b-8eca-e2e8039b08d8":{"collapsed":false,"color":"green","date":1713324484139,"id":"8679bb15-c649-469b-8eca-e2e8039b08d8","locked":false,"tabIds":["c39ea286-ed32-4450-996d-8d8a24b8b024","2fc2f830-f1b0-4a98-b9de-54fb7ceb6d0a"],"title":""},"8733f2b3-185e-4dce-bd42-3cdc79f274c0":{"collapsed":false,"color":"green","date":1711512714228,"id":"8733f2b3-185e-4dce-bd42-3cdc79f274c0","locked":false,"tabIds":["df8f0fe3-1353-4423-ac34-8fbdcf75cbf2"],"title":""},"8851f087-f76b-4ca1-bbf7-808f7f6149e5":{"collapsed":false,"color":"green","date":1698547429951,"id":"8851f087-f76b-4ca1-bbf7-808f7f6149e5","locked":false,"tabIds":["ea890dbf-6c99-42ce-b24f-9e7fea4834e2","f658f451-657b-4bfc-8ce8-d1040e0d360d"],"title":""},"88b0782e-2093-4aab-bbdf-d8a54fb83f5e":{"collapsed":false,"color":"green","date":1711657429475,"id":"88b0782e-2093-4aab-bbdf-d8a54fb83f5e","locked":false,"tabIds":["7950d96b-07c3-431c-80b0-5009df210c38","522d0090-2c63-41cf-a879-91d52aba9692","14b4373e-57fa-480b-94be-12273b209192","ebbdd5a1-74cc-45b8-b15d-2ab8c8593978","aef419d3-ca36-463d-bb29-008188887d0a","8a7ed0bd-fbd1-43b6-abca-445670fdd8bb","e6bb4aad-6317-4ccb-8a30-1604d499ba41","f87b87e5-f518-4c00-9770-9f142a5d0e4c","d8c9c132-8462-433a-b82e-4ddb05eb2b44","aa1dfa7b-c95c-40ea-86dc-8c53a9ebcec5","dd93902e-d8df-4c92-a84d-6dc0f6a55572","66dff8e0-edde-4bf3-943e-c7fb30c9a82d","27f153d6-fd49-4eee-8faf-9fb2954ee352","a0a2c991-a14b-4b95-ba65-30bb0386f0f7","b0409585-6739-42cf-898f-b00c5afb1436","f40f6fd1-a6dc-4541-bfda-2e754c17a97b","5cdc9ec6-095d-4b3b-9eee-efafcd3e6bbd","f51dfa50-e0fe-4ae8-9acf-86d61bc53f92","85c64763-56fb-4f98-a17c-04d830b69a50","1500ce16-bce9-4200-9c71-51a8289b88a6","e198a0bc-2e77-4ac7-98f9-416a64c85102","c0898cd5-4346-4a6c-a825-03b32318697a","b91be660-94de-4cf6-8683-3c911cf38fe3","6cae0277-cf5e-4cb9-8a0f-7a51d8856214","76296eae-00ed-413b-bef0-089e60305a27","2fd06980-6382-4a8b-875a-3c1d4017b5da","acde1aad-53f3-40e1-ab94-527b038abc98","fb1107e6-ef0a-4398-90f3-1448263549ac","fa2cbf6d-000f-4e6d-be29-87e07cf66997","dfb7dae2-8d17-4186-9306-f4585036a9be","4993521f-ee01-43c1-a702-274c9ee4c92f","5aa68719-8547-4910-8ea1-c79fa0b3c5a2","00d40f35-6677-49d0-84ad-abef076c5cf7","0e354e57-1dd3-4c5a-852f-333f3549ca37","4155f415-3d62-48e3-818e-b268bcf6ada7"],"title":""},"89dd7655-17cf-4966-9972-dccb57fa1a23":{"collapsed":false,"color":"green","date":1698547429951,"id":"89dd7655-17cf-4966-9972-dccb57fa1a23","locked":false,"tabIds":["9735b38a-db46-491d-a7ec-13805da4ca23","a46b39fd-3feb-40a3-8ed3-317367ff92e0","6b5f1826-aa9a-47ee-8001-c95850b008a6","da7a483f-c909-4719-b7bc-5f163bc6a640"],"title":""},"8a8fdb7b-cb0c-478f-a303-1872c7ddca63":{"collapsed":false,"color":"green","date":1698547429951,"id":"8a8fdb7b-cb0c-478f-a303-1872c7ddca63","locked":false,"tabIds":["57e5a87a-46e1-4d24-b05a-3ac42d0dcdd6","34c70966-a118-43bb-8598-a7f002ed143d","b45f79c4-da18-4a23-bef6-425ad95e4570","d09f6b0c-2e15-41ed-bdcc-77cb3d03331d","e6e8f815-a9d8-465b-b5a8-9dd1130e02eb"],"title":""},"8b25b61e-075a-4251-a620-9c89e4aae30f":{"collapsed":false,"color":"green","date":1710220122722,"id":"8b25b61e-075a-4251-a620-9c89e4aae30f","locked":false,"tabIds":["a8d7f2c8-9849-4009-b325-a3b0c5c317dc"],"title":""},"8b57ff3a-c3ff-486d-aff7-a9233ba001d2":{"collapsed":false,"color":"green","date":1710220112014,"id":"8b57ff3a-c3ff-486d-aff7-a9233ba001d2","locked":false,"tabIds":["d5c4b3dc-f095-4e4b-8794-0313a3b26b11","5cc1a4f4-daed-4d7f-9304-d56c79e34550","7bc32c1c-4d93-447d-9e75-77df012738c1","f2dcb80c-4dd0-41d8-8e38-a70b6fb9fbd5","eefb602d-6ac5-4219-899c-4fc4e842ab9c","cce010b3-671e-48db-aadb-05ec5f023797","9d5c2dd3-eb85-4a8b-a587-055850a5b8be","6fa404f6-a498-4ab7-91e5-fa527a506dff","79b6cbf1-be23-4f10-990a-01ab6579168f","dc4c1288-c76f-4dd9-b032-a87c18e2620b","68a211fd-8c58-4240-8762-555f07df00ad","f7923bbd-aa27-41e9-ad7e-4d5ca803e375","c0c764d9-1cf4-4503-8760-036f9a8fe313","11970262-5841-41c7-9697-9ed770e35b83","2ad48625-f4a2-4391-9bfc-900aa398a2ff","cc3cace3-6472-4ffa-9b6d-26362bd22ac5","30cfae2f-9064-4f4d-ad1a-d23cbd546d0c","7f0a60ac-cf4a-493d-9dc3-cb73f50e3d20","087dd7f7-83d0-49f6-b839-8431b2d48eb0","3635469e-152a-4952-9262-307240731b7b","c924c979-0a65-4cf8-aa1a-277f7065db7f","a0d46181-caa8-477e-8eaa-3c9983a667d0","f7b747e6-1c18-45d5-8fa1-70f4cc8d7772","3fecefa3-add7-495d-a840-6ba4a6bffc9b","1a785165-7b77-45ef-98e3-572050d82a64","39081608-01b5-447d-b68c-f3075acaa9a0","d0efa1c1-c30e-4ea4-ab91-4b33d4e145a2","0cdfec59-48dc-4604-a783-858733cc01dd","d3c0dbd5-d8d4-4477-b434-a3fb39529842","1fe4dec3-4873-4578-a7a7-632a6f07dfbc","c4189adf-6865-4e4a-9bd0-fc6190a20e90","170c7de1-15c4-48be-9012-eb278a99c009","84116e49-39e9-4720-9483-00c4cce0ba65"],"title":""},"8cd3511c-30cf-47d5-95a4-50910abd9f77":{"collapsed":false,"color":"green","date":1708697252605,"id":"8cd3511c-30cf-47d5-95a4-50910abd9f77","locked":false,"tabIds":["54935cc5-6917-4e50-95ad-08b834cf86b8","a7ba7be9-1dd1-496c-8b28-33297276759e","77dd7d08-92c8-41e6-ac23-3c04aa26d070","dc360f80-b3d4-4ab4-bf70-663a36d90c2c","7aeb133b-87f8-4e35-8a74-49cc90bbb2f6","27b6c0c9-5560-4aa3-b8a3-416c77b1d950","b2ed54ea-1d2d-4b9b-8fd6-821b42b5aaee","401bfd76-2b35-4eb1-82b3-a902646e3c59","e55b6e60-b544-49fe-a2a0-d4162cdfc242","7acd1ffb-5acc-4bbc-abd7-1b6e9456701f","d749388e-11f9-463a-9c91-ed35ed64ffea","3cbc104a-6633-49a8-8807-b282d86258f6","9ab82417-9c9e-4a77-be7b-ee7a4e3bb650","16b153b3-be0f-4fc5-8104-4111850909d3","151da54b-93d3-48a1-a6c0-139483b36949","08afd1fc-6fbb-415c-971e-4767eac4d8b5"],"title":""},"8d2e5100-c82d-4f48-a078-5642acd1513d":{"collapsed":false,"color":"green","date":1712789374732,"id":"8d2e5100-c82d-4f48-a078-5642acd1513d","locked":false,"tabIds":["19707a1e-53cb-4f62-8316-08a4b83d80ea","f0acec57-d7a0-4478-81ca-257fad1a9790","50a9e263-7b46-4ca2-9521-7243cc37e892","db891d46-b961-461e-8088-083fed633001","171258d2-38db-4432-87de-7427093dd3ab","f7b48769-dc08-4201-b579-87cb49c78b72","5ab97902-45cd-4402-a9bb-e94fd69339fe","41e78ed4-dc89-4f28-8f42-ab548de50bfe","16340caf-e8eb-4391-b562-44c101a25cda","db650e89-12e1-4746-87d4-310edb3b1c98","18cade06-01f4-4365-8d7d-26bb6f25aefe","9aaefc30-dec5-4085-af57-c07abec6d0af","805a6464-2256-4708-86bc-6c9f650d0795","ea86ebfe-29d5-4a76-9d8d-4692ffd3c6ff","542f28fb-f8bb-44a1-b6b8-f11bd8c60568","9ea766cb-5f1f-4157-aa0b-ec98fc04a0ac","d074f017-2350-4b80-8aa8-c75346bf2fff","7aa97348-b3c1-4612-8337-76f0bd73adab","828cab97-402d-4df4-8b05-307cc7749109","5ed7c339-82c3-472f-afaf-7e91877082c4","38795709-4d62-44f6-a63c-e5a48717aed7"],"title":""},"8d71f4f5-2934-425f-ae9e-f15bf18f27a9":{"collapsed":false,"color":"green","date":1698547429951,"id":"8d71f4f5-2934-425f-ae9e-f15bf18f27a9","locked":false,"tabIds":["52c5734c-f027-4d7c-8e7f-5727796ed45a","8685d659-8f96-4a61-a3e9-1d6cacf33012"],"title":""},"8fbbfa40-c67b-473c-815e-dfe404d3894a":{"collapsed":false,"color":"green","date":1698547429951,"id":"8fbbfa40-c67b-473c-815e-dfe404d3894a","locked":false,"tabIds":["82674030-107c-4a60-93f0-ae14ddb5640c"],"title":""},"904163de-19a9-46ae-a36f-dd38edc2ec73":{"collapsed":false,"color":"green","date":1699394881456,"id":"904163de-19a9-46ae-a36f-dd38edc2ec73","locked":false,"tabIds":["4a10c229-c59d-444e-8f41-f7ad9c31bf04","19abf5dc-d5ce-4d2a-b908-1a1d004299fb","8c88ae29-357d-4fd9-b109-5365d7783ca1","a680346f-b20b-4d23-8ec4-de9ae1ec953a","1d66f400-0d52-4d14-8be1-6aeda4d3650b","b6b8912a-10b0-414e-bee7-fadcc2f984aa","4f9c6822-21be-47ad-bb7d-e0f97f812c7f","a8365043-17d1-4bd0-9e54-71668c6f2bf4","20559d99-54a9-4482-9a5d-123b2bf1f3da","dbf00824-d137-4312-af85-a286942b38b2","e4ae5d67-cb3c-4e54-8f4a-251f37e6451d","0aa9911c-9abd-43ea-b36b-d55065acb893","f2da88f9-02f7-4bf4-9c02-3b98d9e34618","8ba7d579-20e6-436f-b9fb-f9f6e440a62a","9359d77c-7f10-401c-833f-219e5b9c2c1c","5b6d529e-3ed2-433d-a16b-51b435b4da0e","6ff02d65-8d49-4648-9553-9c8940adbfdb","6214b748-d592-48aa-af1a-7f4c83f9bc06","28a05b01-3145-4ab1-8d09-c3e957c3ed89","32d20f62-7f07-4a22-8876-834359db92a2","156a830c-46a1-44c0-a044-b6f500e61134","51719e25-ba53-44f6-bd97-4be480a8d8a7"],"title":""},"90462918-bffc-4f9a-a0c9-b3443569d437":{"collapsed":false,"color":"green","date":1698547429951,"id":"90462918-bffc-4f9a-a0c9-b3443569d437","locked":false,"tabIds":["b41a2207-1bed-40fe-ab1e-4a955bde42c6","f745c269-0932-4aa4-a5e4-807f4b37fd64","2cf0b420-bd9f-4d6a-8fad-d8ea6a870b35"],"title":""},"90ac9f06-23d2-4b42-9c0c-b19643ff748f":{"collapsed":false,"color":"green","date":1698547429951,"id":"90ac9f06-23d2-4b42-9c0c-b19643ff748f","locked":false,"tabIds":["cf0fd6b9-1573-4234-afee-0d0ae9b13e00","f2d0f442-e643-437c-b43c-d43a00bf7f8b","dabd287b-c36e-4c3d-83ad-d94b4a53a52c"],"title":""},"91fe1317-12ef-463d-b0ee-62b8c3776430":{"collapsed":false,"color":"green","date":1711512689449,"id":"91fe1317-12ef-463d-b0ee-62b8c3776430","locked":false,"tabIds":["d24d9077-e8ef-4685-8eb4-7c2b3c5d01fc","d92ccab7-3b6b-4062-9819-39b8abd2c5e7"],"title":""},"925e8b0b-67da-454b-bcf1-ecb403702ac3":{"collapsed":false,"color":"green","date":1698547429951,"id":"925e8b0b-67da-454b-bcf1-ecb403702ac3","locked":false,"tabIds":["fc59d3a2-0286-47d4-b0d4-1f81f674e3d7","ffd85426-8bda-4c81-a6fa-d98dbf463966","e0471a57-9415-43f9-8b78-c1a25bc95a26"],"title":""},"92ecea77-69de-4e65-80d8-c436b9bbebae":{"collapsed":false,"color":"green","date":1698547429951,"id":"92ecea77-69de-4e65-80d8-c436b9bbebae","locked":false,"tabIds":["8cd0277d-77b8-405b-82b2-aaa1b161877a","701958a1-3dac-493f-991d-4ea701013f69","88ead5e8-89a0-47d1-adfa-b32e3771ce9d"],"title":""},"92f33881-8bc9-443f-ac37-6dd712565b37":{"collapsed":false,"color":"green","date":1702924867953,"id":"92f33881-8bc9-443f-ac37-6dd712565b37","locked":false,"tabIds":["8834c57b-2ceb-4d4c-b7c5-6ae86f15f67d","20e9cb38-cd8a-4ed9-9e3f-70f1fdc73507","7ce8cf88-b5a7-40f9-ad4d-3176e0368d06"],"title":""},"936f79f6-bc41-4926-9856-0130f6e23a97":{"collapsed":false,"color":"green","date":1710534427891,"id":"936f79f6-bc41-4926-9856-0130f6e23a97","locked":false,"tabIds":["89235314-a600-4aa5-bdd9-5395463113c1","1a7195ad-3fd8-4b64-9bb6-212579f2b84e","a5dfa9ef-35f8-4aae-9a8b-78a600dfb427","798adc65-aac0-421d-8894-80bbddc42f5c","84d2509b-4005-4e12-a552-88f65676b1f1","1e5148b7-9249-4bbe-882d-a2f074e38d37","dc0dd2f2-f872-44ff-9120-230128a33d41","1d365d76-47af-47d1-93c8-3e5cdd0e3abf","eea13735-4e7f-4b4a-9a94-172af96b145a","603992ed-f231-4c90-895d-e13c7680e71d","cf81db61-f8f6-4348-af5e-57bd951031ad","4cb2b7c2-9053-41ac-a807-d031c3d974a2","6ccb5da5-8f5b-4478-b1cf-808f9f3f99bc","f8a95621-b926-40b3-b616-bb1a521ecb30","05dfcbef-a15c-4bbc-b07c-25a503a934e7","e2c9ac7b-1568-4f98-9cc5-74f28d599c0e","3128e798-915b-402c-84fd-277153483814","a44873d8-5c9b-4230-ab4d-1d2bdaf755ca","5c563fb9-3aba-4dd2-8c18-dea2ccc6bb14","8a9cf8be-5449-4698-acff-f68085e06844","1b6ffcab-1f62-483e-a13f-4f3c21e24853","a80a8c64-36f5-48bc-bb86-26e93178f55b","cf45617c-9db1-460b-bd0d-531187ed5f87","479d63b4-5b80-4f35-b13c-d3c62043ca39","05998975-b11c-4e0a-8d0c-0588d589a8e0","68a9a7be-2655-414e-b30d-2b7ff276425a","3214bf7f-d4bd-48db-88a4-481534c6a1a4","88afd632-31bc-4fb6-a9d4-f514be1b532c","03d4c442-3973-4ff0-b48f-6f6f7709f5a7","fd029c22-382f-48ef-9798-57614a703a0b","1565578b-a1fc-4474-87fc-3dc1d17fc55f","1e95bb6e-47a7-48f7-b9b9-370700e6d26e","deeb8e6c-e905-4b70-b1d8-71166fe76f7a","be472e95-bd31-45e9-b5fd-ae72281e58bb","381c4a7e-a9ed-4f36-9697-05ad903f26a9","509344fc-e707-4ef6-94cd-38ecf11748fc","bf3a298b-1b9b-4bd8-aef2-ceaebce5f0a0","171619a2-215b-4857-b653-9410075dd063","754a712a-ff3f-4753-be5b-ec258b062989","a0f97380-c39e-4b05-893a-959fb4202f98","87d72195-dbe0-4759-a6c5-48e31e6564ac","02d02d8b-ac2f-4344-ba1e-9da290080fa4","714da372-dc29-417d-a35f-ae62841b55d8","a7f86832-b0ad-43f2-8d21-4983f571b769","f8bf7272-e94a-472e-b5f0-58269d2f8b15","09b0ca6e-c813-42ba-b55c-547709bf8ba8","6c6cf695-49f2-4b11-8f81-78cfc56a4c00","abcce4e4-905c-4a7d-9840-573804cb0137","6dcd2051-3342-4d99-a4c0-c59bf95731e9","5321fa53-3072-4b97-b289-88df536eb875","3f3b6461-a71a-4a84-92b3-6ae95363f5d8","4827574e-2226-4455-a739-7d81df740ed5","12434817-9863-41ad-ba20-8d8c1ef09d43","03ce0198-8a78-4bb4-8192-afc331aa6d46","0aff241c-0282-4001-8026-44d0b116b57b","15f9b05d-a01b-422c-a533-06998a8a698d","4100e486-b0b6-4d8c-b870-b63052ab18dd","72b83e96-9218-402b-b3bb-fbf80bb2ac95","9d1f8594-95df-4ce7-871e-ae2b4f8122b7","6d76aee7-c49c-4289-a2fe-4375ef6a15f1","95844e2f-e7fc-4e5c-9ae0-e75491760d74","b8c5c5cb-89c1-4455-b34a-91b372f050e0","0787a81d-aa13-4501-9e3e-2b82071c1d6e","942c1b86-11bc-4fbd-9cec-f81db8092e6c","dd882fa2-0e7a-4c49-8c21-e2fc8caa7533","49b595d5-282f-414b-ae80-21460eed3c9e","357a85b4-4838-4045-9436-906ec4461bb1","20278174-6c3e-487a-8d6b-f17132f41dd0","1b6d2437-87ee-4f94-838b-d5340e0ffda0","d42236d7-ccbe-4236-8010-6ac5dd5193a2","b221817c-671c-4a4d-a9b5-198ceeccb765"],"title":""},"9426ac7a-613f-4df3-8aba-092515465a66":{"collapsed":false,"color":"green","date":1698547429951,"id":"9426ac7a-613f-4df3-8aba-092515465a66","locked":false,"tabIds":["4a06fe37-7bf6-41fd-aa13-472dce7bf553","d124bef7-9829-454d-a262-b7c9a27527ad","175a513b-5b22-4817-8982-521a7ba24146"],"title":""},"955e4a01-68e4-49ed-9763-7840ae97bc21":{"collapsed":false,"color":"green","date":1711346380828,"id":"955e4a01-68e4-49ed-9763-7840ae97bc21","locked":false,"tabIds":["764206bd-ace3-49ec-8eeb-089a8214f270","c853f1f7-8536-4d1b-8d1b-2f26cf7c67b3","51c3c8a8-ee74-4c4c-a2a4-f8d9e6893e3b","c264cbda-9afa-4cb6-a1c4-a7f4a681a4b8","1b8b27cd-d871-45ec-b96a-c5788db41b1d","6110e5b8-b42e-467b-b19d-66092f1207c0","39fabcf1-ea5f-4d5c-8869-e9b2a984743f"],"title":""},"95b6f3cb-9f78-43be-bbde-16e3bb832674":{"collapsed":false,"color":"green","date":1701063577050,"id":"95b6f3cb-9f78-43be-bbde-16e3bb832674","locked":false,"tabIds":["5168ef7a-080d-409c-8436-bb4e8fd9d534"],"title":""},"9b7f8523-8249-4435-a46b-ee7a7922a71b":{"collapsed":false,"color":"green","date":1705693749500,"id":"9b7f8523-8249-4435-a46b-ee7a7922a71b","locked":false,"tabIds":["5d035f0f-fc95-4dfd-a442-25d19b257345","8d0e03c6-2d88-40d2-ac19-9f5f61ec24bd"],"title":""},"9b947ec2-67b4-44f2-b6c8-cf1a6a35196b":{"collapsed":false,"color":"green","date":1698547429951,"id":"9b947ec2-67b4-44f2-b6c8-cf1a6a35196b","locked":false,"tabIds":["2e155a96-9b32-407b-98a8-3e8dcc3e3a60"],"title":""},"9cbdffe2-fe87-4cd0-aa7d-4c879f8544df":{"collapsed":false,"color":"green","date":1698547429951,"id":"9cbdffe2-fe87-4cd0-aa7d-4c879f8544df","locked":false,"tabIds":["065a65be-c37f-43a2-ac70-b661e9fbd59b","6a2d4756-1c6b-42e8-bc6e-5fb75e8e220a","6c9bdaed-a5d4-4650-a8e6-3a0834445d3c","f824e2d0-9a33-4a83-86a3-e28ed3b2ce79","9e58594e-8771-4350-ad70-78ec4b32a96b","d02bd9af-929f-4b21-a8a3-e5dd760fecc4","387cf492-b5e5-4c6d-9986-a0f2150809fd"],"title":""},"9cc76e5f-1176-40cf-a502-2ee8ed73f270":{"collapsed":false,"color":"green","date":1698547429951,"id":"9cc76e5f-1176-40cf-a502-2ee8ed73f270","locked":false,"tabIds":["474919d2-8916-4c63-8d88-875b17cd39a2","b2d67acb-acc4-4e1a-9220-4aeaef35d216"],"title":""},"9d52f989-ba9d-4a44-88e7-c258557c6070":{"collapsed":false,"color":"green","date":1702761740952,"id":"9d52f989-ba9d-4a44-88e7-c258557c6070","locked":false,"tabIds":["c5c08a29-107a-464f-b2a4-906cc27855d9"],"title":""},"9e2a04cf-b00f-42df-9e00-e67471b2f1a5":{"collapsed":false,"color":"green","date":1698547429951,"id":"9e2a04cf-b00f-42df-9e00-e67471b2f1a5","locked":false,"tabIds":["9e5e4870-c755-42db-940f-e5e28b1d22c0","6224992f-cb9c-4a93-8149-8869a50ab9eb","12c2f774-867d-4618-9072-00d61cfc38b6"],"title":""},"9e4c0ede-8fde-4ebb-a169-48aa8dd148b6":{"collapsed":false,"color":"green","date":1698547429951,"id":"9e4c0ede-8fde-4ebb-a169-48aa8dd148b6","locked":false,"tabIds":["092fd9b1-f44b-4f02-a3d7-6fe832b24323","424b71b5-253c-4f92-8ba6-602aa0202374","67959314-e6d0-4f9d-a8d5-6b4c1663cf0b","1388392c-06a6-456c-b82b-d62405a2c894","87ca0348-9540-4e3c-b96d-63682734ec6f","9d07b2f9-90b0-4571-ba5e-00c10abd962e","1a781e15-5889-41eb-9e84-c05096d84970"],"title":""},"a0811b79-b686-4ba2-9a2c-b0895e5c1e45":{"collapsed":false,"color":"green","date":1702372579137,"id":"a0811b79-b686-4ba2-9a2c-b0895e5c1e45","locked":false,"tabIds":["6239fc54-e4a8-4134-948c-aedf2b95a48f","d3e55775-476f-4e0a-9ef7-51e932fdc4ae","b192fd39-b4f0-43ef-9ae2-a7f2e5a3d23b","6ad8aa25-e0e3-4a5c-8eee-f86798bede7a"],"title":""},"a0cc5e06-8f12-4173-b828-dc1f0a9b40c3":{"collapsed":false,"color":"green","date":1709324355160,"id":"a0cc5e06-8f12-4173-b828-dc1f0a9b40c3","locked":false,"tabIds":["73be16cb-7439-4979-8247-c906cecfd346","760e4695-4164-4c92-bc36-d3e5979b0f67","e702419a-5458-499a-af32-f9570b5966bf","3d571f65-2b12-4608-b3ff-14de54f9ce17","4709320f-4801-481d-b484-cc75ecc0c120","defc752d-7c68-4db5-92d2-77f41a3fb620","4327639d-032b-4f8c-aefd-68911f537f4e","c4eccd60-b44f-4e92-b644-238c0e3c590e","12921cfe-c23c-4a9d-a0d7-893968b0fe05","882da82a-07da-4863-9e30-f9ce14fa2394","1803ac10-d409-49d4-b33c-021b83e101c5","fab5d6df-edcf-4136-8e26-7bad66b3095a","87c3f06a-1562-42eb-9c05-6b56797dc859"],"title":""},"a0d37e74-3117-4143-a82c-1b900c4ed87f":{"collapsed":false,"color":"green","date":1710221844971,"id":"a0d37e74-3117-4143-a82c-1b900c4ed87f","locked":false,"tabIds":["35c2449e-dfb5-4a56-b205-cdc65c3b12d9"],"title":""},"a2a7ed34-7b12-46c8-98d4-4970bad96b82":{"collapsed":false,"color":"green","date":1699154796949,"id":"a2a7ed34-7b12-46c8-98d4-4970bad96b82","locked":false,"tabIds":["14ef4e62-897c-4f3f-834c-1e0064845ef4","f73f5a44-81e2-47ed-a5b3-7a5bbbf1a681","55a76010-2962-4682-ba29-0c55844dd96c","caf8b0a3-0c9d-4e29-87b6-c1ad27621c2f","819c5074-e39d-40d9-ac53-51265e7b4a4d","afddbba9-2b7e-4346-89cb-783034e06de7"],"title":""},"a3351ad9-0f4f-482f-b442-3fe94ad91ca7":{"collapsed":false,"color":"green","date":1698547429951,"id":"a3351ad9-0f4f-482f-b442-3fe94ad91ca7","locked":false,"tabIds":["b673535c-7423-4790-8205-7bc03141a572","a31c1794-def2-4b3a-91aa-8c041a64cff1"],"title":""},"a366f791-41fa-441b-99e8-7033e63ed84d":{"collapsed":false,"color":"green","date":1709914711137,"id":"a366f791-41fa-441b-99e8-7033e63ed84d","locked":false,"tabIds":["2db0c1d2-a748-4b15-a889-ea2378389c59"],"title":""},"a3782f1d-a56b-484c-88e4-c4095e5eddea":{"collapsed":false,"color":"green","date":1702924430190,"id":"a3782f1d-a56b-484c-88e4-c4095e5eddea","locked":false,"tabIds":["a4fffbab-e80e-4afe-80d8-5228833d405b","77864362-9a36-4618-8b31-5b58d7004eba","e29bddde-eb99-44eb-94a1-510e7eccf760","5f0ca100-842c-491f-b844-0eb1cb7023a7","db1ead76-992a-42ca-b644-fb5a061b3abc","4ce04b23-581c-4a8c-add6-16df96dc6417","ca521068-4860-4824-8b42-c1d0530d56c7","4d2d916c-fbbb-409e-9872-e0390b0e4054","aab7d139-dee6-40cb-b9c8-c346ed8ec3bf","c54e1de3-6df7-436f-bce1-f81f75504f99","070e5830-37f0-4e7f-ab72-b8abc1e0bbbf","93a5b2cf-f76e-4ed2-b782-e6affa228766","3df07850-5537-490f-ac89-aad182d9233b","93c4f549-dd15-4119-ba0a-1dbe8967f87c","13edbf9b-3efb-4789-b303-22f1841d375a","3aadad7e-290f-4fea-a56a-7026b16fefcc","fe95b612-5735-448f-92e1-3cf747616cac"],"title":""},"a37d7ad8-9ceb-483b-93cf-3a03f1446dc6":{"collapsed":false,"color":"green","date":1698547429951,"id":"a37d7ad8-9ceb-483b-93cf-3a03f1446dc6","locked":false,"tabIds":["b150dd68-98ca-4fd6-899e-231eec092beb","7a3b3ee3-1f99-46c5-bd28-26a273addabf","8d090620-953b-48a9-9bb8-3fe6bd0f3af8","b306808f-41a8-41eb-809c-9340c8245321","75d150c2-8848-4be5-86c0-37aec828003e","b934f372-100b-4c44-a998-8a69ddc687eb","8d8b53fa-4255-4e3c-8b58-07b9a1eb03fa"],"title":""},"a4abea67-b7d1-40d9-b09a-d773a80fd7fa":{"collapsed":false,"color":"green","date":1698547429951,"id":"a4abea67-b7d1-40d9-b09a-d773a80fd7fa","locked":false,"tabIds":["6206efbb-d3c5-45f8-b671-f4186f5c7438","72acbc26-0334-488b-84c8-c23c62706194","215f70f9-be22-4f3d-b8f4-6c8adfaae9a1"],"title":""},"a5a22c62-1f8c-4c8c-819a-132877d430b2":{"collapsed":false,"color":"green","date":1698547429951,"id":"a5a22c62-1f8c-4c8c-819a-132877d430b2","locked":false,"tabIds":["34c55d33-4671-476f-a8f7-be3c5e7b5860","69fec033-de23-4315-bc5d-a78db0da58b6","72167a42-e08f-4c43-993e-3e845313a6d5","2ad5886a-e140-4213-a493-684c4fb4a8be"],"title":""},"a71a4174-b34e-402e-ac6e-a75b74aebdbe":{"collapsed":false,"color":"green","date":1698547429951,"id":"a71a4174-b34e-402e-ac6e-a75b74aebdbe","locked":false,"tabIds":["44f6e37f-dcf7-48e2-ad38-93c6542e7246","831ab2f3-59da-4947-a371-2b80cb4f4063","7aa0d4a0-4d8a-4cca-b935-ae4817b17f0b","3b5b4ac3-e52b-45f6-8df0-7ebb224ccf0f","0968250e-5354-4934-aee7-0aaedde27edd","74b933c3-d6b1-4f8a-ae1a-7e5fc8626ca2","6400b961-2cee-4c05-bddc-e86274ead516"],"title":""},"a789e7a3-b44a-4d0e-b5f3-c576e459a627":{"collapsed":false,"color":"green","date":1698547429951,"id":"a789e7a3-b44a-4d0e-b5f3-c576e459a627","locked":false,"tabIds":["d3ba3124-dd78-406d-ae87-d481dc467c53","d1d6a02a-d4c4-4202-a684-1d5c7a43fc6c","97da05c0-cc3d-4c9e-8ca5-00f61d2bba69","b0ce7407-5b86-4b7d-80e4-beda305b5862","8cc7cda5-8306-4373-8173-9d1a4b7c5811","248916aa-c90c-4644-bf39-ec1baa5958ce","74c8199a-6edc-4e6d-ac29-dca94760a8bb","15ed8a65-8f38-4db5-8fc2-aa690473cbb6","97c4fa83-04b5-4e2e-a11b-1a1903f37b55","0c71db51-a4e3-469a-8f49-fe4dc8ebc742","e6479249-6d4f-498f-a374-1801e6c36848","e3dcd4de-8914-4633-9082-6be0d81ba8ea","d870b828-6dcc-4677-8fac-25201efc5874","53829bf7-8342-4d3b-a960-52c355b6c408","253ada38-2849-4633-97e0-12e78af6eb3f","f7b149dd-36cb-4bb4-abe6-1db51131af4c","dbf865d0-883e-4b8b-be7a-e4111a03462c","f2f05047-934d-4e50-bf54-2aa17ca00dda","4cb8f8a1-97a9-456b-a187-0792390b7e86"],"title":""},"a7bda4d5-fb94-4745-a06c-3243e121116b":{"collapsed":false,"color":"green","date":1698547429951,"id":"a7bda4d5-fb94-4745-a06c-3243e121116b","locked":false,"tabIds":["801ea190-6351-4fad-9811-19b9e9423010"],"title":""},"a8076f3d-0690-488f-b704-49fddaafef9e":{"collapsed":false,"color":"green","date":1711995656679,"id":"a8076f3d-0690-488f-b704-49fddaafef9e","locked":false,"tabIds":["baef21b8-82ad-4258-b6ae-2a8ec6d74a8d"],"title":""},"ab14dd4b-83eb-4be8-b7bd-d4c5d20d7ae5":{"collapsed":false,"color":"green","date":1698547429951,"id":"ab14dd4b-83eb-4be8-b7bd-d4c5d20d7ae5","locked":false,"tabIds":["536804d9-ca98-4a9b-a8dc-4a69a296cb6a","53885156-e93b-4320-9fab-6e935c8032f1","3ab50e68-619d-455d-b9e6-eacd86d59df4","92048e92-e35c-4f91-87ac-c07933995577","61f4d9b4-c9ba-445d-bf7b-ee250887949d","81569853-9574-4c26-8319-aac0519e2a38","33e8f1b8-c642-4769-8244-b0305c70e077"],"title":""},"abc12228-e4ec-4aa7-987a-e75852c80397":{"collapsed":false,"color":"green","date":1699828813971,"id":"abc12228-e4ec-4aa7-987a-e75852c80397","locked":false,"tabIds":["0acec050-ce1c-419d-89de-e007602f96f4"],"title":""},"abf95851-fc28-4039-9fd7-3e978263e1e2":{"collapsed":false,"color":"green","date":1698547429951,"id":"abf95851-fc28-4039-9fd7-3e978263e1e2","locked":false,"tabIds":["21f9942a-cb0e-46b3-90d4-c94f29063aa5","9e400d34-fe16-42e5-a7b7-34a36320634e","594eda2a-6128-4ea4-a057-615940cc2a18","2c46e708-26a2-4f3f-9958-65d3be43e46c","93a0c55d-7ffd-4bde-b7fd-80f7254b3e76","a0476c6e-fe58-4966-892d-c633b04191c3","924392eb-54ce-451c-b12a-f3f949459c9d","5a6afcfa-49d6-4dee-997a-74d3ca9ac80e","0d23ed9f-069c-4dd5-9287-dd53e8c16f3f","c9b543fc-a155-446c-b84d-8f8efb5b72bb","bdb49c60-27a1-477c-bd61-d9985bb0b98a"],"title":""},"ad23b2fe-fa22-4cea-bec2-2b69b6d41bc4":{"collapsed":false,"color":"green","date":1713464852161,"id":"ad23b2fe-fa22-4cea-bec2-2b69b6d41bc4","locked":false,"tabIds":["3565bdac-8acb-4330-98d8-248a29e9a46d","26e3028b-161b-42f3-81c1-bbf03f7682db"],"title":""},"adb8224f-2784-4af1-956a-ee7834bf2640":{"collapsed":false,"color":"green","date":1710060219423,"id":"adb8224f-2784-4af1-956a-ee7834bf2640","locked":false,"tabIds":["6cfbdc2f-380e-4a8d-bd7c-578012d6c72a","bcc4ff8d-aa02-4205-9c10-b995fb074563","3afd7439-b34e-494c-a7f9-d657732e0b9d","97b4545f-bf7b-4f6c-9d2e-a292a5ca6ce1","9762a2fb-37cb-49b0-b2fa-efdd0916330d","ed156bb9-8409-4010-867a-8f19b5380fb9","fc807498-7e25-4d80-a990-01f937b28283","562d36b0-6c2e-4b52-9b04-d6abcfb96397","d71b2c4a-e6fd-4d42-8442-bd414377e80a","8c40b998-0b59-4af1-bb19-ad236b2c7549","097e3f4f-989e-494b-96d3-174a704440d3","cc0f3beb-4ac5-4aa8-b21d-9fbd6ff7ceef","d8243774-8763-4b02-9767-9ed766d8844a","3ddebffc-1a0d-4923-8454-5b3212ed2206","189dd0e6-564e-4817-be0d-2974c618cc5e","133e3545-cce5-40c3-8eb5-c2f047fee752","abb3e490-cb85-4dc0-b2ca-9c2707c6aeba","8fe72408-0526-4129-9d55-1058968bcfb6","5dff1f71-a5ea-49dc-b6ec-bb355a425a87","cd97bef6-3691-4fd3-bdee-dcd8ca3f2151","d4f33f92-668d-4d4e-ac1f-4443687a9419","7b77534d-de24-40d1-90d9-f2c27c24e30f","9ab99abf-57f3-4836-9dc8-6e60a268fcd4"],"title":""},"ae2ee58b-1ca4-48c6-8a3e-79df627e09cb":{"collapsed":false,"color":"green","date":1711856836471,"id":"ae2ee58b-1ca4-48c6-8a3e-79df627e09cb","locked":false,"tabIds":["20e9f7ad-d425-4e32-8ee1-c7edd373acec","b4486090-8bdf-4e51-93d6-28900f75f404","2fa05351-de65-4fa0-82eb-3587b7326418","c0c580ae-fad5-4500-9e19-91ba8ca34637","740c5cea-352b-4825-bea2-42c4035c068c","d8b94bc7-c102-455f-8e46-ef4c9faf940b","35ca30b1-eaea-4113-923c-4e23e3f16c39","5d603eec-8a9b-4f49-b41a-1462224d48ed","6e9e5065-a29c-4ae7-88dd-be547578b3e7","6561b13a-d58b-4adc-b165-534f11374e40"],"title":""},"af15f00b-fcb1-4b97-930a-2323ddf8a792":{"collapsed":false,"color":"green","date":1698547429951,"id":"af15f00b-fcb1-4b97-930a-2323ddf8a792","locked":false,"tabIds":["98d181f4-40c3-4762-8f91-c1f169ed1f9f","6f7e6898-cf14-4402-8bbf-0be6ed6b7ede","54037c60-ca18-4cc8-8780-63020f612b86","a7d6b3d8-4e7b-487d-9a78-a88828600bd5","d677496a-0109-4336-b93e-937626a5a1cd","f8ac1493-3e17-457c-8751-17b34332c8e1","f49fe8e9-aaf7-4c21-87a3-dce872c4b241","2a8b98e4-a99f-4f10-b22c-df92128b121c","442b66d5-a659-4f18-a45c-e85a44de181e","12732f08-a17c-427e-ae58-6d55ff2068df"],"title":""},"af4b8c85-1ab0-401a-b4c0-e15ce54cb9b9":{"collapsed":false,"color":"green","date":1704489132216,"id":"af4b8c85-1ab0-401a-b4c0-e15ce54cb9b9","locked":false,"tabIds":["c74c8a32-0927-4d1a-8d03-ec2d6bc507a8","2523c8e8-a397-453b-adfd-464a2ce15958","9352ae2d-944c-46d8-bf8b-d6b12b25886c","5177c51e-66d6-420e-b898-b5d32769c31e","5b956494-5b6b-4678-883a-8000960a0d0d","67e3599f-8718-4917-9890-88b16e5f9b08","0f10b87c-68bd-42b1-91ed-643e1fa70552","aeb2807b-992d-4b5f-b3aa-c7fac4bad70e","f930d7b6-5558-48b2-a29d-efe98884d2a0"],"title":""},"b08dce47-b2f0-46f2-84a3-310e9827aace":{"collapsed":false,"color":"green","date":1711856766840,"id":"b08dce47-b2f0-46f2-84a3-310e9827aace","locked":false,"tabIds":["411f1306-7442-4622-bb6e-bc16c56a984d","f2959109-f530-45c8-82fe-2c0c0f432401","1d0e8991-ed93-496e-95e7-24ecfb83a8fd"],"title":""},"b18c43fa-e4e2-4fd2-bb42-3caad0c707ee":{"collapsed":false,"color":"green","date":1705974708062,"id":"b18c43fa-e4e2-4fd2-bb42-3caad0c707ee","locked":false,"tabIds":["4c3b1d0e-b05f-4a40-98d1-46f7efcb7842"],"title":""},"b1a701d9-a55b-4252-a3e7-d7a52edf7738":{"collapsed":false,"color":"green","date":1698547429951,"id":"b1a701d9-a55b-4252-a3e7-d7a52edf7738","locked":false,"tabIds":["09d50b0e-0c95-46af-9330-2ef5b128ee05","7a1804b6-fc99-4d0b-a48c-c8b45873c024","9739e432-c1fd-44c3-a407-81e816f9e91e","cb3e7e65-7c33-467a-bcee-64a3ba61e073","ea94d4bd-41bc-4f95-a636-7ff63085677d","fc38f5e6-a4e8-484a-8991-a47c9052c3ab"],"title":""},"b2292cd2-80ea-440f-a4e1-fe4833cd4148":{"collapsed":false,"color":"green","date":1698547429951,"id":"b2292cd2-80ea-440f-a4e1-fe4833cd4148","locked":false,"tabIds":["9e38025c-e02c-4c2f-92a0-fa00351a4aeb","936ddb76-f9d1-4d11-83fb-a159e7d60596"],"title":""},"b28f9316-22d7-4523-afd1-9a2f7cb9541d":{"collapsed":false,"color":"green","date":1698547429951,"id":"b28f9316-22d7-4523-afd1-9a2f7cb9541d","locked":false,"tabIds":["926caf2e-f344-4d77-a2ad-065edec5b137","3059da4e-4615-4fb6-8b96-c83aa4be966a"],"title":""},"b2a9312c-7c0b-42f4-9b4b-bf76866918cb":{"collapsed":false,"color":"green","date":1711987562290,"id":"b2a9312c-7c0b-42f4-9b4b-bf76866918cb","locked":false,"tabIds":["66c807ae-efc8-446d-bc53-1e89e22a7b22","b9754266-39da-4348-b0fc-dc340c95aa92","61cd6300-5ee8-4362-83c4-bc247a70dce3","f6adbea3-8f5d-4209-927e-90f92a4bb9a9","e506f569-0081-4c2d-83c4-a3ae949a3203","fbb2b2d3-5933-4eb7-9519-3ff651fb8faf","21e67989-f36a-49ff-88e1-3a966ffd3241","72c9c8af-3b32-451e-90c2-271e13a3b073","02249019-08e1-43ce-bb0d-75561f3a54bc"],"title":""},"b2d7df17-7c11-4912-a74f-e02d7cd50473":{"collapsed":false,"color":"green","date":1710059391944,"id":"b2d7df17-7c11-4912-a74f-e02d7cd50473","locked":false,"tabIds":["daf8a966-1031-411f-80ff-778ee3e1a4a0","8f5fd4a5-b64e-4cf2-9914-23a31f282bfc","4dd3ec68-3edd-4562-8029-47ce3f51630c","7cd2f34b-9b04-481c-8f81-420b14b4ee9e","72ea5fbc-a28b-4e39-ac45-c7d7b57bc748","a3638a17-fc21-462b-8dd0-48851b54c4c6","a55169be-da9c-47e8-a7f7-7d20f68616f6","36c39215-34ff-4940-89f8-a6db748081d0","78d878a7-f96a-4301-b089-f9335cf5e939","6ca619c4-cc83-47db-9a98-98267f75b41b","6aa03dd3-f50f-43b8-a9b1-69836e96e50e","080e5477-6f53-435b-a80a-167509347a84","5ab6fb63-3ad3-480f-9fd0-6a564c59fd3a","3d00076e-464a-47e1-be27-55b2a7fa7101","261ab86b-6669-47fb-81fe-9a9ab237a1a4"],"title":""},"b3d6e22d-adda-4ee9-8add-98cba171fbe9":{"collapsed":false,"color":"green","date":1703008715709,"id":"b3d6e22d-adda-4ee9-8add-98cba171fbe9","locked":false,"tabIds":["32bf022c-5c97-481e-b618-d1f066304acb","1eaba1b8-3543-4138-9544-85f50fd6be78","3791ffeb-9b98-4e68-bb4c-59deaa805b2b","0918f5e5-dd6b-4ecc-bc27-7f68dedbac6a","6c8bda29-80b8-424e-b81f-2be064bab38a"],"title":""},"b570c755-2f7c-4ad0-b448-e071bf39079c":{"collapsed":false,"color":"green","date":1698547429951,"id":"b570c755-2f7c-4ad0-b448-e071bf39079c","locked":false,"tabIds":["df07f701-d902-4a88-a486-f56ba6842f81","eb656022-428a-474c-9c16-a62f53e4fb3e","60302835-3cac-4a2c-b0b3-365bc5d7d0f7","b0f93922-1f7f-4a7c-9b78-6848454a72a6","b218604f-931f-4a7a-9860-d3f1abc4b191","a69c4b3c-0514-47d5-9520-672a8dbfbad3"],"title":""},"b5addc35-d3b7-4b54-b54a-9a09b0e9f8e3":{"collapsed":false,"color":"green","date":1698547429951,"id":"b5addc35-d3b7-4b54-b54a-9a09b0e9f8e3","locked":false,"tabIds":["728ba7ad-74c3-45dc-a6e7-542c9d7c5c8f"],"title":""},"b62831dd-bd7c-4883-848d-07837062e0e8":{"collapsed":false,"color":"green","date":1698547429951,"id":"b62831dd-bd7c-4883-848d-07837062e0e8","locked":false,"tabIds":["162ef0ca-b83f-4af0-bf8e-0c3b4c4e4b26","ec6be2ec-7cc8-40cb-b88a-85b348d4a7ed","2ad9434e-46b1-4d7e-8464-f992f7da4e07"],"title":""},"b6c95d24-8204-46f6-a216-9938225c9fea":{"collapsed":false,"color":"green","date":1700042259019,"id":"b6c95d24-8204-46f6-a216-9938225c9fea","locked":false,"tabIds":["ef1490ed-ae56-46d6-8469-eca7a185cdce"],"title":""},"b7029fd8-498f-4ba7-94be-a8c615443b5d":{"collapsed":false,"color":"green","date":1698547429951,"id":"b7029fd8-498f-4ba7-94be-a8c615443b5d","locked":false,"tabIds":["ec5ccaae-839a-4c76-b64e-86487d840181","b0661611-c049-4b62-97ac-18b33c2a819c","b577994f-4083-43c0-913b-d8031559c86f"],"title":""},"b7ce42ec-e6b9-4458-b76e-c45fb5a32a30":{"collapsed":false,"color":"green","date":1698547429951,"id":"b7ce42ec-e6b9-4458-b76e-c45fb5a32a30","locked":false,"tabIds":["9e5ee15f-194b-476e-b27c-637a02c3bbd8","bcc3ccb6-9690-4f1f-a08e-c4784cddcc66","24e1c7f4-92d5-4cc2-8532-d854de2cd8c9","286223ff-2fe0-4fbf-98c6-034859dec861","6e2d094f-20de-4a69-9f6f-fa85935ce7ea","899fd39f-f1c5-4ea6-be99-108b6a86cb83","69e68e65-c8fe-497c-8ecb-85cefb39aff7","7284c80c-c99e-45e0-bc80-91d47ecaa84b","638b91fe-8fef-4382-87a2-0daf1ef9b64d","a39bcd95-d06b-442e-9b7e-d2083c7580af","6f2e2377-4f40-41ad-8aa2-9e7411518aff","2f58d0bf-a57a-4312-a21f-9f3e029c3715","5ca6a1db-b63d-4b40-af23-7549dfc748fb","ddd89c8d-0117-4bca-995e-bbbf45fc5cb3","41d7a6a4-5fce-497d-80be-a96cf3ccdb6d","a2c0ffff-a97f-4507-9a51-c121e1584051","84c85910-d832-4a7e-ac42-4c63ef85e032","39c80302-902f-4689-afbc-c82ac81dd7db"],"title":""},"b85c3d80-6e45-4f06-ac66-78cbe1a0d4e1":{"collapsed":false,"color":"green","date":1698547429951,"id":"b85c3d80-6e45-4f06-ac66-78cbe1a0d4e1","locked":false,"tabIds":["ed7c1fa3-c516-48b6-8b8f-2df50b8d26cd","8342b36f-b509-4f43-b96f-6f5227d2d5fa","4abd8a52-027e-416f-8686-a55662cbca53","1885b752-3038-484b-81fa-8766ad15c704"],"title":""},"b9728cdb-86ed-4ee0-96ea-c8cc6e427018":{"collapsed":false,"color":"green","date":1698547429951,"id":"b9728cdb-86ed-4ee0-96ea-c8cc6e427018","locked":false,"tabIds":["d57a1349-2cab-4dc7-a10c-903f89f3d22d","9094c7a5-79bb-4cd2-a9a1-f6544cb12851","f52cd846-f4f7-450c-aa6b-1e452cc7b08d","466e39a9-a055-49e6-8fa1-56e2e3d1071f","fba88ecd-f0ad-4e44-89af-751bba64b2c5","b6925d26-5e6d-484d-ba4f-441b7036c21c","8552eeed-11e7-4de1-adf3-2a959df19a23"],"title":""},"ba1825a0-411c-4a52-b1d7-638d1dac1192":{"collapsed":false,"color":"green","date":1698547429951,"id":"ba1825a0-411c-4a52-b1d7-638d1dac1192","locked":false,"tabIds":["a373482e-23c1-447b-a881-09a612beaa45"],"title":""},"ba18d723-057a-4c83-80cf-161e44f93322":{"collapsed":false,"color":"green","date":1698547429951,"id":"ba18d723-057a-4c83-80cf-161e44f93322","locked":false,"tabIds":["3b9ff0f9-75cb-411e-9f10-e044f60b9d3c","9ebf2b5b-5d10-411e-ad05-442866b084b1","ba0383c1-052d-47cd-a26d-fd5f564b8b2e","df48cd39-815a-450d-a0d9-7be7a94452e5","af21ef0f-35dc-43b5-a4cf-5953e4b4b423","bfd013ed-3863-4f9f-a5d8-bf8132535be4","24bb3365-d662-43a2-a643-dabb72474343","aa3aaee9-51f1-4f0c-b35e-0c911878f350","19fb0397-d5cf-4c85-bba5-8031f3f37aa1","5825c935-8d14-44f4-81c6-066517c1e157","6bd6c6a2-b945-4ded-a878-cca33d528087","daf6ddc7-d1d4-457c-8e50-597eb47c996a","5502532f-a26b-4505-965f-7bb230913edc","3773d865-e217-4693-bdf8-e23f477cce1d","feba601a-dbac-4a31-a701-9ede211b01fa","3c9e4032-1210-4a84-b744-6e1f0a1bab84","afcc3465-920d-4909-bc88-ab3a8e5a99f5","cc54b6b9-402c-4f49-9122-737251dd1cfa","185ac316-2eac-4838-9d6e-5392b261b44c","3e7602b5-f16b-4431-bbb8-aba10803b460","6a8d9b9b-63dc-47a8-9022-d7bf19196e8d","4431d348-5ecb-4e40-9933-c473d1e128de","0ee24cf9-b0af-41dd-b99d-f8677778c676"],"title":""},"ba5e729b-c312-4c64-a63d-ccc6594f72c6":{"collapsed":false,"color":"green","date":1700699829927,"id":"ba5e729b-c312-4c64-a63d-ccc6594f72c6","locked":false,"tabIds":["2b54ba7e-18a5-43a7-bd15-8133c870815f"],"title":""},"bbcdb4f3-6a69-4c01-9dfe-528f41c5202c":{"collapsed":false,"color":"green","date":1698547429951,"id":"bbcdb4f3-6a69-4c01-9dfe-528f41c5202c","locked":false,"tabIds":["c37a4f86-764d-4363-a3e0-466d4144edee","9eddc582-2000-41d0-9abc-c8a61d0bec17"],"title":""},"be97a08a-0ec0-41f3-ae6d-26d186503fd7":{"collapsed":false,"color":"green","date":1700373997449,"id":"be97a08a-0ec0-41f3-ae6d-26d186503fd7","locked":false,"tabIds":["ac0831cb-a479-4f90-9e89-9d3c31b5390d","b8ac19f8-0079-4cb2-9053-dfb2463ac446","5389f66c-8a79-4d82-943a-7687a5aa223a","e53176a1-287e-4fa6-b072-16a50de544e9","d7218778-0827-47c6-9dfc-b2bf728bfc0c","29300a3f-4e8a-4db5-acf4-be0bdb6ff36f"],"title":""},"beefc811-23f1-4c39-af7b-f9281e058073":{"collapsed":false,"color":"green","date":1698547429951,"id":"beefc811-23f1-4c39-af7b-f9281e058073","locked":false,"tabIds":["3bfe29cd-da3e-44f5-9c28-d12e2501458c","42e8ea35-f8b8-4091-abb7-a8d9ccc33fa1"],"title":""},"bf2d1c3f-d0e8-415f-b07a-6a8ffd67befe":{"collapsed":false,"color":"green","date":1698547429951,"id":"bf2d1c3f-d0e8-415f-b07a-6a8ffd67befe","locked":false,"tabIds":["d4aa43eb-1518-42e1-a60e-a811e6a54815","65854bed-1a04-4e4d-9abf-7fa305c38012","2c4e5cc5-c760-4f35-991f-3cdb4d97fa59","80c8a0dc-963b-4276-93b5-342361793b2a"],"title":""},"bf3a3d82-2d75-481d-8ab5-1937f4b6165f":{"collapsed":false,"color":"green","date":1702202914212,"id":"bf3a3d82-2d75-481d-8ab5-1937f4b6165f","locked":false,"tabIds":["f7692d26-b829-4efe-848b-ae7a67a12c11","d596840d-4026-4ab3-a270-2c49264a6203","a2221f16-2e20-4012-a456-5068b9261317","19bbb56d-ee9b-4211-9389-0e9a2b8361b5","76f68b83-bb10-4831-9e87-eb09b4f31c26","2cc785b2-3a5a-402b-bdb5-d00ed018a3a8","ecba58cd-6772-432b-bf48-4d26353ee786","8dc4a2eb-f74a-423c-9c3c-da4e2fae7260","8517ab5d-d0e2-41a1-a7db-1c806eace623","68134338-ab1e-4e05-b17d-62cc8119dc70","25d9b142-fd61-49a3-a73e-799a8981a98d","a9125c6f-7855-451b-a107-bd52bbd2bc10","803f4cc1-1313-40b5-8d85-78488648dd9d","ac0af513-4341-41d8-986f-779060d4d052","66e456e0-2321-4049-8f96-ae731036ffc8","bce9a1d2-2105-4118-939b-e99af67dd53f","6b02b6da-593a-4782-9cfd-be26f471beac","32c71d76-5896-4147-8f91-84e644d33c79"],"title":""},"c0f550ed-0fbf-4966-8847-17aadb38dd87":{"collapsed":false,"color":"green","date":1698547429951,"id":"c0f550ed-0fbf-4966-8847-17aadb38dd87","locked":false,"tabIds":["81d0544c-79ec-494d-8338-cf059ce7eda8","e3d3d183-9ce8-4961-b30c-4cf191871a93"],"title":""},"c1a3bbde-bdda-4865-b782-9ba65246295f":{"collapsed":false,"color":"green","date":1698547429951,"id":"c1a3bbde-bdda-4865-b782-9ba65246295f","locked":false,"tabIds":["3eb98e95-7869-4493-bb45-a1c916186f58","e422689e-7ea2-4ba9-beb7-0dfd977b08d0","c8084f28-f9fe-4f84-8150-760c4e4ee891"],"title":"hugging"},"c2be2f31-81c7-4962-ba37-4e6e6af9d82a":{"collapsed":false,"color":"green","date":1698547429951,"id":"c2be2f31-81c7-4962-ba37-4e6e6af9d82a","locked":false,"tabIds":["219ea30e-8e68-4b8c-8d83-d94b9bb1ce5c","84aaa27d-b91d-49ac-9418-b6751111dac4","8f35bf76-b91d-46dc-9a73-a2a1a7083b8a","fbcee4a8-6a0b-45c8-b412-f8a73f38aafc","2381ec4e-7533-4c70-bc03-4b997a9a4cb1","85c5aa66-5dc0-4946-a9f3-30b06e98203a","104ca3d5-e21f-406d-9b29-7620292cc9e3","49a756b6-abcb-40d0-8383-1c619ed64572","558c35d3-8418-4491-b19c-3e28d6cae4e5","6d15b2a7-2b97-4ded-a082-06ce42082f74","6b332384-f732-4c72-a6c9-80d08b2d5a6a","8f317653-3cc7-40d4-81d1-86c8e165cc65","da6c575f-c0bb-4155-b4f4-7d19ddc373f5","a949d948-ac0c-44c8-887a-f1cdff91e47a"],"title":""},"c3dd29d4-2a3f-40b5-ab51-27693fc0592e":{"collapsed":false,"color":"green","date":1705976500511,"id":"c3dd29d4-2a3f-40b5-ab51-27693fc0592e","locked":false,"tabIds":["87de8db5-6cf0-49e5-ace3-664c05a21f66"],"title":""},"c44797d9-4bc5-4a38-8742-2b2d33233834":{"collapsed":false,"color":"green","date":1710035896759,"id":"c44797d9-4bc5-4a38-8742-2b2d33233834","locked":false,"tabIds":["7f66a341-66a8-4453-ba5c-9c623d77830e"],"title":""},"c706f34a-a906-4e3b-833f-9f3a49aa182e":{"collapsed":false,"color":"green","date":1713324615775,"id":"c706f34a-a906-4e3b-833f-9f3a49aa182e","locked":false,"tabIds":["90b09d09-71b2-4054-8bef-64caf223fd49"],"title":""},"c7c5195c-5712-4ecb-ad3c-966affb1a805":{"collapsed":false,"color":"green","date":1698547429951,"id":"c7c5195c-5712-4ecb-ad3c-966affb1a805","locked":false,"tabIds":["35a1225f-aa15-4c16-b176-ad7068b69a29","6fee6f47-d5a1-464a-a899-3e0db4668a6e","188fc90e-77d7-45b3-92c5-c5f271587dc1","2cdbdd17-5765-4748-9a76-07a5a498e7cc","192dd4da-d994-4036-909e-7a2e1a660075"],"title":""},"c91b1667-933b-4f41-891d-60a75e17c7e0":{"collapsed":false,"color":"green","date":1707680957638,"id":"c91b1667-933b-4f41-891d-60a75e17c7e0","locked":false,"tabIds":["67319a2d-4d66-4bc7-b1c1-001cc20a2986","d03780d9-31a1-401a-b18a-c37d4ed183e7"],"title":""},"ca04f1e4-46be-4553-bc19-af5b41fdc3ba":{"collapsed":false,"color":"green","date":1698547429951,"id":"ca04f1e4-46be-4553-bc19-af5b41fdc3ba","locked":false,"tabIds":["54b62ab3-2d8d-4a02-8aad-973178f20ebf"],"title":""},"ca846564-a506-495e-a811-5179b2747e24":{"collapsed":false,"color":"green","date":1698547429951,"id":"ca846564-a506-495e-a811-5179b2747e24","locked":false,"tabIds":["e7bd6b09-03d6-4259-a8b7-02f059426021"],"title":""},"ca8f2909-c217-4874-966f-42f4f07ed8ec":{"collapsed":false,"color":"green","date":1698547429951,"id":"ca8f2909-c217-4874-966f-42f4f07ed8ec","locked":false,"tabIds":["aa46c1bd-922f-400e-97c2-dcb40836133a"],"title":""},"caa6c7ff-959a-489f-9f5b-29a0694b623f":{"collapsed":false,"color":"green","date":1705298624945,"id":"caa6c7ff-959a-489f-9f5b-29a0694b623f","locked":false,"tabIds":["871f398d-78f4-45c7-b006-848aff0cb988","6880bd19-a67d-4c5d-8c59-faeae499f36a","8b6a86ec-94a3-4557-b71c-37588e37ea14","16c430d1-9864-4b00-b7df-9f7f8e6abf40","dfecc5cc-bc95-45e3-8024-53ca59df186b","49190e4b-feec-4587-989a-8558ab51e314","caa5950d-d192-411a-97e9-366adba2e0be","22c066f8-26df-494c-8ae7-27fe627e0ed5","e90a9489-09b7-43e3-9b35-5793ce93731a","02b5694d-a9a5-4b43-ad01-e12278023284","24018e97-9fe2-49e9-b355-f7962ee99629","4975c18b-8f6c-42f8-bfb0-b22dc68e96a5","8571f7b6-70d5-479e-81ae-4460f62e6328","fc662e90-ba09-4f40-9936-f677a7a448a8","b0a1700e-0d64-4573-9423-2c11123b6921","e7485b1b-4137-4b93-9639-57db49b384a3","dd796acb-f061-46fe-8e74-361281d1c2ca"],"title":""},"cb2f2e60-4865-4dbc-8d83-8427cd36567e":{"collapsed":false,"color":"green","date":1698547429951,"id":"cb2f2e60-4865-4dbc-8d83-8427cd36567e","locked":false,"tabIds":["dd40628d-bea8-43a5-bc8c-b79f846f9cfe","46b77938-fd40-432b-b8c8-303bad33994e","3bfe0923-381c-46c2-963f-61b379b1a8d3","5387a4cf-50e1-4be0-b77c-914852c31484","ae080bcb-1fab-4508-b35a-0d7110e28528","68bad277-bf49-4dd4-aca6-a85062f21f76","75beaf72-2385-4d3e-a6bd-e851cdf50be1","92d94431-5873-459b-89f9-5514e2267e60","44bf9227-20e9-47d7-806a-9339bb884cf3","abf5b369-3a1d-493e-a027-6bd57aea8572","a68b9d7c-6291-4de9-b985-ff5c53cc3645","347afbc9-6346-4bc8-86ee-88dd36430dfd","986bab0d-db64-40f8-bf23-dbccfc8beefd","6c66fb8d-5263-45bc-8442-b196654af675","b122139b-642f-4894-9d81-7256155b8e47"],"title":""},"cb7054d6-8f34-4e09-9abc-562acc15e03f":{"collapsed":false,"color":"green","date":1698547429951,"id":"cb7054d6-8f34-4e09-9abc-562acc15e03f","locked":false,"tabIds":["def0a083-c585-48e4-b46b-f90af653ca43"],"title":""},"cc4e9078-fea3-48a7-a62b-41e8f92804ed":{"collapsed":false,"color":"green","date":1708223931218,"id":"cc4e9078-fea3-48a7-a62b-41e8f92804ed","locked":false,"tabIds":["26f9a3fd-bfb2-48c8-9a82-6e36beff2c5f","7e7ea512-b868-4b60-8777-d245a841c870","0adaa8ef-1607-4e2a-9d79-a802a6acab0e"],"title":"在线"},"cf0110b6-ada4-4bb5-9bd1-6d2bd4ad0e1c":{"collapsed":false,"color":"green","date":1698547429951,"id":"cf0110b6-ada4-4bb5-9bd1-6d2bd4ad0e1c","locked":false,"tabIds":["17904826-a4dc-4e91-9401-3a0030a69225"],"title":""},"cf82b730-2ad9-41cf-b25d-e238dbec15d5":{"collapsed":false,"color":"green","date":1698763740394,"id":"cf82b730-2ad9-41cf-b25d-e238dbec15d5","locked":false,"tabIds":["57567886-a7d5-4a80-a623-1b019571a019","16f3dd59-d9b6-4efc-be80-edb1c165638a","d393e196-af49-4d37-be36-bf599572d4c8","fb07fcff-4322-4b4c-90f4-c653e7990efc"],"title":"github"},"d1923abb-00a9-41a0-a8ac-84e7e4589e23":{"collapsed":false,"color":"green","date":1709642936639,"id":"d1923abb-00a9-41a0-a8ac-84e7e4589e23","locked":false,"tabIds":["3cdd7d4b-77f9-43c7-b3ad-418f445275bc"],"title":""},"d2b2d4e7-0838-4413-83f8-562fe8cecb95":{"collapsed":false,"color":"green","date":1698547429951,"id":"d2b2d4e7-0838-4413-83f8-562fe8cecb95","locked":false,"tabIds":["d61d0b35-1e9e-4918-a70b-370c40ed581d","88ef246c-755d-4872-8d25-b45b9278019d"],"title":""},"d39fdeec-b4b5-4f09-9c68-1fb75a48550d":{"collapsed":false,"color":"green","date":1713324422755,"id":"d39fdeec-b4b5-4f09-9c68-1fb75a48550d","locked":false,"tabIds":["8887850c-e5ef-43dc-a913-c313192f7aa4","79a31136-4c7c-4dbd-aeea-22d386470aa3","928dbfb1-b2a4-43c4-bd2b-67c6ab21078b","7aee15e4-1e90-4ab7-8a85-f03db5c18dac","c96aec69-466b-4f59-9ada-83278c76f3a3","2bc9fded-16e7-4f90-b3b7-3edfee088aa1","2f34a5b7-b50a-4893-a5b8-533ff0091b40","f394b376-0874-4c10-85ba-1c855ca689f8","ba5fcc3b-b4e0-40ea-a764-415f495c6153","543e8d42-7f5f-4505-97b4-78223d2d79d5","86a0434e-4d98-490a-a1c8-7ae4d86b50f4","ac91febd-0327-4d2a-9c03-1061b8f46859","969c3202-87b4-40a4-b671-ef2ee8b4142b","37f156eb-fb2f-4d61-9dc7-89be07c7ca5b","13393972-aa6f-4432-986a-4f23907c9b31","efb5a566-9927-422d-9f8f-137ba75da03a","52ed82be-bf7f-425b-8003-2c03f7f08406","34730365-2f3d-4a63-8bcb-27f7a61d2e40","7f6e2be7-f6e2-40d7-a921-09a6cf9591c4","5487492a-c912-49a5-9752-f966a2656b81","46a39dd5-9986-4c52-b125-5c8c1d6234d3","866cff29-6cd4-42dc-acc9-26950ee9b20c","fa73cdb1-8836-4740-98b9-3f85b83df258","438f3955-c0a3-4204-93d9-757a1786cd1b","d59be67a-69e6-4405-b64e-288b1bf0876a","ae48d106-0af9-4f03-9341-1d752249e02f","e8bf78d1-66ff-43c1-90d7-ccc36d808cb4"],"title":""},"d4897693-8eb1-4b6a-8a93-881a7e3f2034":{"collapsed":false,"color":"green","date":1698547429951,"id":"d4897693-8eb1-4b6a-8a93-881a7e3f2034","locked":false,"tabIds":["760dcd17-97e7-4f90-b030-058765967e75","9a03ee71-52d9-4f00-ab43-5160db3cb854"],"title":""},"d6efbd88-8708-4bc4-95bf-a04a17f009bc":{"collapsed":false,"color":"green","date":1698547429951,"id":"d6efbd88-8708-4bc4-95bf-a04a17f009bc","locked":false,"tabIds":["f9b51c9c-3976-4b82-85cb-157d918f19d5"],"title":""},"d70c6a11-9f5b-4b19-b1d5-d29cd43c6aa5":{"collapsed":false,"color":"green","date":1698547429951,"id":"d70c6a11-9f5b-4b19-b1d5-d29cd43c6aa5","locked":false,"tabIds":["7b630346-9982-4b78-bf7e-5d19dd047586","6eb0872f-c77b-4b46-9372-e90f12eaface","cefeb889-cbf9-4063-b142-67e98dd81e7d","c9a122d0-9db0-4af0-a163-95a1ea02b53c"],"title":""},"d7853436-7b98-49b5-b547-1fb9fde86fb7":{"collapsed":false,"color":"green","date":1709497102326,"id":"d7853436-7b98-49b5-b547-1fb9fde86fb7","locked":false,"tabIds":["71eeee39-a0f8-482f-a2cb-69052fa7f785","2026bdaf-1aa2-4de9-bb69-924841ac8da6","8f858812-b550-42ae-b88d-a439787797b6"],"title":""},"d83079a6-56a0-42da-9404-332d6a6e2bd9":{"collapsed":false,"color":"green","date":1698547429951,"id":"d83079a6-56a0-42da-9404-332d6a6e2bd9","locked":false,"tabIds":["b527233f-f496-4cc4-a7f4-0eab2f758527","20a85fb8-c56f-420e-9671-460304d40bd5","f99ff99c-71d2-4abd-a947-d136c12dc213","1e4aabc6-38bf-4690-8d94-63f8a2c0c1c6","8e018858-0430-4ef1-ba2d-153e600277ce","bd2cf572-6365-4db6-bc9e-ac0202d4ced9"],"title":""},"d8c86e26-ab5f-4a69-a551-620cee5877d0":{"collapsed":false,"color":"green","date":1698547429951,"id":"d8c86e26-ab5f-4a69-a551-620cee5877d0","locked":false,"tabIds":["47de07f6-241a-42a5-afce-6ab25af58791","d6f286da-c628-4ec3-8fc4-31817bee3be3"],"title":""},"dce432d2-4928-4043-962d-0fd8338a685a":{"collapsed":false,"color":"green","date":1706772120732,"id":"dce432d2-4928-4043-962d-0fd8338a685a","locked":false,"tabIds":["31a02e84-2d37-44be-b034-000b9346f7b3"],"title":""},"dd6de396-38a3-4f3c-b699-875a44a85dec":{"collapsed":false,"color":"green","date":1700863974820,"id":"dd6de396-38a3-4f3c-b699-875a44a85dec","locked":false,"tabIds":["80ac90f8-67da-42f8-b7d3-d34c0c2b6ab1","12ddf44c-8548-49e9-be9a-1e3f146a2a0f","8623ca4a-d3cb-401d-a3ed-8a47ce4dcbc0","553bac8d-14a9-44cd-8a3a-f36a11cd2074","a296482f-ca31-45af-9a69-eedef2a0d4c8","3224d458-1e5f-485b-8934-fc01e70820da","fcf457f4-bf67-4a74-8e72-0a534642a86b","461c8fd6-ca48-4383-b9a1-abc10e4e45e2","ea9b0f3c-aeb2-4601-a2df-1be0381b17de","4911b657-196c-4eae-9d03-759769dd09a3","48424c3e-9393-4f96-b8d7-f9f7f4ff9ecd","4f30ed13-60ca-4d2a-879b-f598f07250a6","f51357af-c8b1-4466-95d1-901163454f10"],"title":""},"ddb12a56-9ab6-4d5d-8bc5-2d8183dd7498":{"collapsed":false,"color":"green","date":1703292726521,"id":"ddb12a56-9ab6-4d5d-8bc5-2d8183dd7498","locked":false,"tabIds":["ac4d2713-74d6-42aa-b231-f6b5b1b06423"],"title":"bilibili"},"de41ee7d-e823-445e-9d10-11683b348943":{"collapsed":false,"color":"green","date":1708973001198,"id":"de41ee7d-e823-445e-9d10-11683b348943","locked":false,"tabIds":["dbab204b-7dad-44e9-a9b7-861801625ef4","7d328e80-3d14-4acc-b31b-c6b632d8a0b6","d3da43ea-1b20-4a4e-891d-28d66185f930","83c9e30f-7b9d-4c63-a41b-96416bb4d410","827d300a-6185-494e-a4da-00ec6a26f779","937314c0-c0d7-463c-941f-14d013abc363","f2f9b5fb-7784-473d-82cf-42178f020d59","9e6cb536-1c96-4621-9057-bfaf366be1ee","b5a7ae0b-0a0f-4007-8c77-ba3c02ee33c4","8f1a52f3-f6e7-423b-9969-fbe204e68c91","61689ba5-a02e-4a00-8882-f8672f237af5","a785441f-79ab-4d5d-8af0-77f91fd5ab06","bfda56f2-e59a-4e65-99ce-c2925b9c6eb1","0b345c7b-7782-42ac-bd7b-1461b3d91ae9","63b1b010-05a6-4b6a-9d07-fc9aea3e4027","7ff4d38e-797c-4c86-9a8d-184f9514879e","108382a4-b649-4705-bd08-db90f7076f4b","49ec0e2c-1e42-4420-ad81-832768643346"],"title":""},"dee33520-8f73-4fcc-b573-3b47a443fe28":{"collapsed":false,"color":"green","date":1698547429951,"id":"dee33520-8f73-4fcc-b573-3b47a443fe28","locked":false,"tabIds":["2aa88bcf-e235-4606-bd1c-6671d84bdaaf"],"title":""},"df7695ac-1be4-44f5-9514-6be82d72386c":{"collapsed":false,"color":"green","date":1713329617941,"id":"df7695ac-1be4-44f5-9514-6be82d72386c","locked":false,"tabIds":["39bbf3d5-e080-408a-b23f-9d89f492b35f"],"title":""},"e0d6bb3d-80d6-416d-abd6-e312402f641f":{"collapsed":false,"color":"green","date":1698547405776,"id":"e0d6bb3d-80d6-416d-abd6-e312402f641f","locked":false,"tabIds":["c77f214c-44f0-482c-90bf-b0a01aa50918","5e4c1a47-b242-41d7-a5cd-80512bf0d81f"],"title":""},"e0f0d78c-83b5-46c6-a160-77840d8b8f7c":{"collapsed":false,"color":"green","date":1707680957638,"id":"e0f0d78c-83b5-46c6-a160-77840d8b8f7c","locked":false,"tabIds":["ce39c4fb-d291-4766-88e1-f0ee2aadb3e5","3b49b89e-d262-4235-bf15-a08f663b37eb","6f0563ab-48ab-40c2-8a8c-5d75a20d66ce","502ac76a-6327-4305-a576-4d8b85b28deb","9b5715a5-6d83-42a5-86a6-78057436e008","2b8d6ea0-47a2-4103-acff-0078e4a21ecb","667cdc10-b206-430c-92e0-1617484ead70","f453b916-987a-4536-acc8-0ebf44d2d75c","f89555e2-61fb-4051-be0e-944d2c355066","03e64c96-48cc-439e-b7d8-6a8bf3a4ade3","1eb5a845-5ab0-4b8e-8891-983b54885a76","34cef832-9742-4fdd-ae6a-f2a8058799c5","68023304-fb02-4b74-98f3-bbecd9bb6932","e3761bed-ea04-410f-ac81-1c4238b7111b","89b2520d-6cc9-4870-ae63-2e04f2986bb8","96d80cb2-9596-453a-b504-67f9c31e204b","48ed0928-3bbf-494e-9d7e-6e188b6e56bc","d15484f5-8458-4bd6-b101-23342cce49ad","9dd5af28-ad76-4b32-b32e-38b2eb3216f4","190bc495-a962-40db-b816-13b2fe57d15f","9286fbcf-b68b-4962-bd7a-8a03f4429c7f","1a142934-7899-43ce-8f7f-c436f9195477","09ffee9a-24e4-4ac2-a960-a7642d3382b0","2273891d-99f0-40a9-ad7a-ca8eb5744cac","0bf63945-9788-452f-8cea-fc01a3d9f13c","f4bd15a9-5bf0-43a5-ab6d-04a5600a811b","c6a7e124-56d8-4cd7-8f5b-dcf4a99646aa","7d444f3b-4978-4567-be08-27091e696f05","71f061ae-8540-4f8d-8fd6-3c26d0f069c1","66be895f-7909-482b-a812-5d8a2aeec187","884803d5-4855-4d65-989f-8066e29fa483","261bebbb-7c64-44b3-a8dd-4e824d5ae8e9","99d284f2-2637-4365-83d6-d11157ea6e92","ab8d2e6f-22d0-4ef6-82a2-cf4cc5d0f64b","76974c89-b044-4b43-9097-af2ca622e428","f953d662-6c3b-4172-a985-00c1918bd5fd","81ecd826-e5f1-4dca-a985-f43729144cfc","80cf50fa-cac2-4819-bcf9-3aa835c87d49","de609dad-9f3c-40b6-9b70-2f24369a2c28","46268940-fbeb-45b1-a185-eacf17c268f0","42ba8e0b-74e9-4abc-a646-6d03d1c21943","d4af6d3b-be1b-4d03-b0a2-efee239806b9","23649038-b77a-4fb2-8e38-853566bde230","75e1d38c-63f1-415e-9bd2-1c0e3eb93bc6","777e132b-cf01-496f-9190-677587aee5b5","3f7e1059-7e9a-409b-a4b2-80c32a6c97ac","0328a2ed-5a62-480b-8cfc-ee3835a3b8db","4b27ed0c-bbe5-4321-a509-dcc90d0aacc5","f3744e8f-8434-4a5e-af93-f9f2fbc784b1","0a4cff00-527a-49d3-84ac-e9106bd5d346","e4940624-db6c-4709-82ea-d9d4605d2606","cb48416c-a9e4-4be1-be13-7f64e316da86","5a3c66d7-2c92-4531-a8bf-3363181c46ce","d0a74205-8eb6-4098-8c45-0142c63cd734"],"title":""},"e1d06cd8-4883-49d7-ad58-7508af6cb695":{"collapsed":false,"color":"green","date":1698547429951,"id":"e1d06cd8-4883-49d7-ad58-7508af6cb695","locked":false,"tabIds":["2b56e65a-5383-42d6-9a7a-bb6941923dc8","3e3eaa1b-e0e1-4b0c-9b2c-a83011f94366","e2592844-f1ae-44e6-a4b6-a85a52ef57f7"],"title":""},"e22d691b-f4f2-41a2-b615-1081c9493efa":{"collapsed":false,"color":"green","date":1702597106878,"id":"e22d691b-f4f2-41a2-b615-1081c9493efa","locked":false,"tabIds":["ee618ce0-fb26-4efd-820f-6688e50007af"],"title":""},"e2424d3c-d694-4252-b3f8-87f0404e18ba":{"collapsed":false,"color":"green","date":1698547429951,"id":"e2424d3c-d694-4252-b3f8-87f0404e18ba","locked":false,"tabIds":["657b55b4-7397-4f53-b53f-a772a244afce"],"title":""},"e268804d-97eb-4757-9b45-bfab36a7845c":{"collapsed":false,"color":"green","date":1698547429951,"id":"e268804d-97eb-4757-9b45-bfab36a7845c","locked":false,"tabIds":["f1d63886-1904-4db9-86d4-853336bbb8a3","081d2a1a-fa7e-489e-9a5e-7a06dd887af2","17a01d3b-5269-4865-b65a-b2e5b4228fce","e8fc1f3c-bca4-40a6-98b5-bbbecafbd2be","415dc606-1639-4e3f-9f13-07f7ddead49a","e110d474-2f28-4ec7-9166-76d3208f0b91","f57ecca7-8d35-4c76-b9fd-3998d7cba37c","37a5ece8-55ee-4441-baf6-6a9d4c917733","975908a6-ef29-4c95-8664-d795f4448d78"],"title":""},"e2be63cc-68e0-4204-a613-30ead569d36b":{"collapsed":false,"color":"green","date":1713638495720,"id":"e2be63cc-68e0-4204-a613-30ead569d36b","locked":false,"tabIds":["32977b51-a1a0-4c49-81c6-80d2d2edf9b7","e029bb69-678e-402e-ba42-067357af5bd6","44bc36e7-636f-42a3-8157-f7e9752d08cb","c0508d45-5791-4447-86f5-6de739bc52a1","68981960-f1d7-4a91-8a45-b131b7a257c2","e5b0e5e6-1b9f-4c26-8a36-f0150282d162","4c0414fe-7b7d-4b1f-b868-4286b4b56101","8fc9d576-7311-4a5d-b409-7817f872a799","b3e29d68-0134-4c0b-998b-d2c800faf295","a3ce4743-f584-49c0-a5f1-bcf36c53560f","baa7f950-196b-42d5-adad-52c6300d8c39","fce97f28-1cff-4bb2-8c4b-7d8af0f6870c","04780f4b-fa29-49aa-aedd-3d5a51c8be75","529cd507-7ea0-4f31-b548-1014aa067ef3","670cc0b4-90fa-4626-b4f9-1a19a61b5cae"],"title":""},"e3d00566-dde8-42fa-bb8f-73846fc13947":{"collapsed":false,"color":"green","date":1698547429951,"id":"e3d00566-dde8-42fa-bb8f-73846fc13947","locked":false,"tabIds":["dc19fbe2-55cd-4921-bacc-7e6ad1e9cbcd","e7b9267d-573d-48c4-b12d-2f319e3451bc","ced49039-a246-4786-892e-aa17eba031de","c39e6e12-f9a1-45b4-a781-0e4813a1fe4c"],"title":""},"e4a74553-0f48-4b6b-91b2-be2ca94a31b2":{"collapsed":false,"color":"green","date":1698547429951,"id":"e4a74553-0f48-4b6b-91b2-be2ca94a31b2","locked":false,"tabIds":["abad647d-c43c-4c5b-aa83-ce9d49e8ef1c","b9f29d8f-4cce-42d7-93a5-acf5dc839f30","e5ae2fcd-db20-45bc-80a8-951c2cf44d01"],"title":""},"e5add331-5e70-4b5c-963b-a60ce5509cef":{"collapsed":false,"color":"green","date":1698547429951,"id":"e5add331-5e70-4b5c-963b-a60ce5509cef","locked":false,"tabIds":["dbc8e132-b0cb-484a-a436-66a4753b21f6","59d28fb8-5c2c-4fe9-9634-65437bfcf412","6ca676a0-86d0-40a5-9351-ae7507218c18","9a51f86c-803a-4482-8539-77da4837ba6a","37e4f217-bde4-40a9-9797-c2fec138b901","8881b76a-8c2d-49e6-9eaf-1c1a7bd3d124","06d8e16d-9817-470e-b691-ccc5c8ecae1c","5e4bbef8-d7cf-4cf6-aa97-0f5d43895582","68cc8b2f-5f07-4823-89e2-3372b193b423","5ef7921c-d314-4b82-89ca-881630956c92"],"title":""},"e5e8a87e-b118-4861-9204-f89dbfda19a6":{"collapsed":false,"color":"green","date":1698547429951,"id":"e5e8a87e-b118-4861-9204-f89dbfda19a6","locked":false,"tabIds":["bcc81d76-0dd2-4625-8e20-637f4f940af0","02bcca57-70cf-413a-8f6b-477050471a79","29ce30da-ac4d-488c-b65a-47074edda53b"],"title":""},"e73a6fa7-a9a5-4f07-8372-5041335889ab":{"collapsed":false,"color":"green","date":1702758520763,"id":"e73a6fa7-a9a5-4f07-8372-5041335889ab","locked":false,"tabIds":["f6406f75-fe1d-4720-8388-1b5feaf4c7e6","23853f21-af08-4c69-9cb5-7a8bee62d14f","965c2fb2-da09-43ad-bf0e-9968caeebbfb","9a2f7de1-f491-44d4-8f2e-f6b77d8f599f","31e7cc56-91b5-4368-982c-8e2738284bd6","d3ed8b23-fb1a-4860-9b8f-f324681a5438","a9107bd4-82e4-499f-84c6-3371d673b865"],"title":""},"e86e1526-bf51-4a32-b329-d55c0bb15b28":{"collapsed":false,"color":"green","date":1703292760601,"id":"e86e1526-bf51-4a32-b329-d55c0bb15b28","locked":false,"tabIds":["7aaac7d5-0064-4056-bb0a-d752c6153e11"],"title":""},"e8e67bd0-68fc-47cb-b4bf-1a0f02a4c964":{"collapsed":false,"color":"green","date":1709498051333,"id":"e8e67bd0-68fc-47cb-b4bf-1a0f02a4c964","locked":false,"tabIds":["e8919439-aba7-4180-9822-e9b9f1229388","b460599c-c0ce-4c33-9fe7-0a8bdbca8e5a","7dd4cce8-0543-4a48-9cec-7b8e26d5868b"],"title":""},"ead5747f-a49e-4d65-b9ac-1d682d076d59":{"collapsed":false,"color":"green","date":1711995651370,"id":"ead5747f-a49e-4d65-b9ac-1d682d076d59","locked":false,"tabIds":["cc83f25c-b069-47e9-9ce0-b4928649bd3f"],"title":""},"ece2d8f5-c70e-4be6-a578-b27978317a06":{"collapsed":false,"color":"green","date":1698547429951,"id":"ece2d8f5-c70e-4be6-a578-b27978317a06","locked":false,"tabIds":["1467313f-64d6-4834-8223-dbd96d89a06d","d321b268-a44b-43b2-ad15-5db7e2373bd9"],"title":""},"ee29eb57-d3ff-4923-88cb-041765e73fab":{"collapsed":false,"color":"green","date":1698547429951,"id":"ee29eb57-d3ff-4923-88cb-041765e73fab","locked":false,"tabIds":["a4593e73-66ce-4dd7-9cf1-44a0eaac042a","4f5d0205-23c4-4b7f-9f57-6a871e5a93eb","7d188662-4729-472c-b369-67a1201b9fff","75042416-e5f5-4763-bfb1-8cbbe6e28b2e","b83b818b-5166-4505-b2de-0617e3b95782","6b627272-4f1f-4822-9297-8cc4a469c85a","41aa4ef2-d525-4e5d-a4e6-4358b781537d","7ba8323a-9d30-45ea-9c36-f50d2a087fb4","2211d733-7345-4ada-bcf1-15ad6c5cd117","7793b247-f0ac-4cd5-9fcb-670ef3280929"],"title":""},"eea722d1-118e-44be-9f99-fe8f8c017b8a":{"collapsed":false,"color":"green","date":1704827212001,"id":"eea722d1-118e-44be-9f99-fe8f8c017b8a","locked":false,"tabIds":["da05e3c0-a0e0-4bc4-b0d4-2db437f82ffe","d257054d-e2c4-4548-8e14-79c8100b76f6","2fe9e075-f0e0-4eb0-b330-2636ceff2dde"],"title":"hugging"},"ef590093-a7df-4950-b77a-4b595c5feb32":{"collapsed":false,"color":"green","date":1711505804398,"id":"ef590093-a7df-4950-b77a-4b595c5feb32","locked":false,"tabIds":["42c6800f-a53e-48e2-a3f2-5b80958c4a54"],"title":""},"ef748de2-35b6-49cf-852a-53179a85d0a0":{"collapsed":false,"color":"green","date":1698547429951,"id":"ef748de2-35b6-49cf-852a-53179a85d0a0","locked":false,"tabIds":["a4d64de4-deaf-49ac-ba12-e1d3ff956614","b3cd67d7-710c-4e19-99b3-631e76e5fef1","0c252931-df21-4114-a54d-163c225aad63","0e76b6a7-047f-406b-a4aa-b3fad98386ea","b979df37-1275-442f-b410-131d6012227e","dbf209a0-60b2-4f0a-bc87-5cc66788e127","3b010ae6-b4d4-4079-bfb8-b951dadbb500"],"title":"github"},"efc20cbf-c8fb-49b3-a76d-3617a45bcf12":{"collapsed":false,"color":"green","date":1699830333240,"id":"efc20cbf-c8fb-49b3-a76d-3617a45bcf12","locked":false,"tabIds":["f8e269b0-9707-48b4-8c12-c239877bcd58","8d1d91e2-3d2b-4fbb-bbc8-c83fb51797dd","a5236af8-787f-4621-8a1d-f587ccbdd8d2","cc56f167-b0c6-4d2b-af2c-c1ddfa4a99dc","654f0785-88e6-4e03-b519-bada535d8bf3","7bdb3376-a2a4-4dee-8fca-b26019202b05","9a24c330-f10e-4a86-93e9-d14581f8dea5","bdefc8ae-df09-493c-b057-684164f23e36","07ee3c8d-d70b-46ea-8074-d7116ae9e740","f8a6aabf-4c99-44fb-82ee-4c5c4e7d549d","67c544b0-3b41-4858-a74a-e895942a7a56","2ab428e7-1909-4e58-8f10-0769c9c1a49e","e1860437-87ba-40e3-bcf5-d7b32b784d4c","c066d29a-1260-4692-8aa9-a8b8ca822bf2","a1e8ab2d-f1b2-49d2-b9a5-fe17def29094","b2be948e-ebf3-4f03-a201-68a2952849ce","223f174b-5ce2-4caa-a8fd-72a593b25465","840288b4-8530-46b4-bf8b-2d2fd3658cc4","0c9e16cb-3cd7-4c59-81ea-bc527bf834e5","20db8f2c-51fe-4d65-8319-41f50b91e03c","4d0a4288-37e8-4e03-bf46-5aea9faafac0","4307c4a8-68c5-4e24-97f2-70e9af48a369"],"title":""},"f06d6e07-de0a-4038-a34b-fd9ff20211ec":{"collapsed":false,"color":"green","date":1709613379188,"id":"f06d6e07-de0a-4038-a34b-fd9ff20211ec","locked":false,"tabIds":["0937d2a1-b0d0-4002-94bf-d35ced6b77e8","1bc3641f-2555-44de-b2af-573c6838b838","31cff877-c659-4471-a077-04b1ee1e3422","dfab040d-d1dc-4ef7-a65b-f4c9cdaaf03e","e6208b0d-880c-427b-b921-719a9e37ac77","064934a5-4895-468a-a356-4bfae5d731ad","a6e50119-952a-44f5-9e22-e1e2442969ad"],"title":"mathpi"},"f0cd197b-893f-49f8-88f8-f0588075e75c":{"collapsed":false,"color":"green","date":1702630646942,"id":"f0cd197b-893f-49f8-88f8-f0588075e75c","locked":false,"tabIds":["05913654-95bd-4ae0-8d77-683a36c9181b","3405943d-6264-4eea-b193-ee3f1b13eca0","d3071400-c92c-4a95-8a0b-d3c2e6f59fe7","2701c9c1-03cc-41a0-92d3-eb2cb29b5ffc"],"title":""},"f0ce68f3-19e1-4802-a7de-5b17fc1932e6":{"collapsed":false,"color":"green","date":1701935124061,"id":"f0ce68f3-19e1-4802-a7de-5b17fc1932e6","locked":false,"tabIds":["888ff935-bd19-401d-a5f6-3fb04a4e6bd6","18902794-f0bb-47cc-af92-836ee423e0a0","bed1209d-302c-4dc0-984f-771fe9bec136"],"title":""},"f17176c4-38c3-472f-b862-c757991a953b":{"collapsed":false,"color":"green","date":1698547429951,"id":"f17176c4-38c3-472f-b862-c757991a953b","locked":false,"tabIds":["52b6d19c-8a83-4fbb-adb8-782c50541f53","e3f88fd2-ad62-40ab-89cf-30919b94cd44","68264fa1-d328-4980-b68c-60ec3788386a","a5a32970-5fa9-4edd-b21c-ba3cd4f4f5e5","ef6d92b9-a4bc-46f7-8338-52418873131e","09bbfc3f-7050-42a8-a847-f4f44bfb5fee"],"title":""},"f1a0cf32-9450-41dc-acc8-ba81a0e45340":{"collapsed":false,"color":"green","date":1698547429951,"id":"f1a0cf32-9450-41dc-acc8-ba81a0e45340","locked":false,"tabIds":["117ae7d8-af9b-45aa-bb58-2581c77e61bd","28e5557d-60fd-4a4b-8996-169eec28f27f","d3e39182-3916-4946-b668-f2396c902855"],"title":""},"f216438f-c0b4-41b9-88ec-aa4e591fdad1":{"collapsed":false,"color":"green","date":1698547429951,"id":"f216438f-c0b4-41b9-88ec-aa4e591fdad1","locked":false,"tabIds":["4ad9ee0d-4340-4c3f-9d9e-8b101895555d","ff1007fa-7ad9-49bf-aaa5-c584c08bfcaf","cfdf8f04-78aa-4bac-86eb-0413e56d5d27","ff7ebdc3-da5f-4685-b6bd-a5108b6269ac","f2fee442-ae48-4512-8ebc-1b3a6877ed74","696315cf-c975-43c4-b6d5-2ad3dd7c3054","72e52a3e-0557-45c3-8443-c00cea1c937e","4bd28d0d-3224-4fcf-ae16-4332f4d198bb","a369ac59-0aab-4454-a625-507314d3b065","325a77eb-5f0c-43f4-914b-29db3f921d71","b5136288-f32e-482d-93bc-a61fdb0fc987","9925b09a-8e96-475b-9f33-2e1557005808"],"title":""},"f3886d01-6c00-4172-b106-e83907cc86e9":{"collapsed":false,"color":"green","date":1698547429951,"id":"f3886d01-6c00-4172-b106-e83907cc86e9","locked":false,"tabIds":["13f7c20c-fbdf-4c2f-a95b-fb063e2d6057","26b26444-8cbd-4246-b5fc-5cf404aee289","c6b01bdd-6532-4cef-8256-2998b5ac229e","d8db00e9-4388-4890-b39a-aca921a229ae","6b776c15-a1be-4d3d-b095-b94d633727d4","4149a3fb-6470-4cf2-adc6-d9905cd072c5"],"title":""},"f4456fa7-b3f6-47c8-b012-15915c961ba7":{"collapsed":false,"color":"green","date":1699660914503,"id":"f4456fa7-b3f6-47c8-b012-15915c961ba7","locked":false,"tabIds":["a71f25a3-19e9-4637-8cc7-f3d38a3dd308"],"title":""},"f5812bd4-8a56-41b5-9609-0545b341d41a":{"collapsed":false,"color":"green","date":1698547429951,"id":"f5812bd4-8a56-41b5-9609-0545b341d41a","locked":false,"tabIds":["e69482c7-81d5-4930-939b-7e600a8e7b2c","ac6b7cdc-26b5-4e36-8742-4afd309ca4c9","df652957-287b-4fe4-bcaa-c6a92e9ea57f"],"title":""},"f6646625-4dee-4e6e-8a36-08f21bce3e57":{"collapsed":false,"color":"green","date":1698547429951,"id":"f6646625-4dee-4e6e-8a36-08f21bce3e57","locked":false,"tabIds":["4713649e-b41e-4af5-92f4-56456401c3b0"],"title":""},"f71e6f32-3b09-4d78-9737-af88eee471d4":{"collapsed":false,"color":"green","date":1698547429951,"id":"f71e6f32-3b09-4d78-9737-af88eee471d4","locked":false,"tabIds":["3da0c35f-3563-45dc-aad6-e2283943bb10"],"title":""},"f7df140f-6512-4a3d-84f6-0ca4f707be2b":{"collapsed":false,"color":"green","date":1711385498322,"id":"f7df140f-6512-4a3d-84f6-0ca4f707be2b","locked":false,"tabIds":["6b5ed9d7-2c57-440f-bea0-dc5313dd3193"],"title":""},"f8253f25-c6d4-4e43-85fe-d872f8e9300b":{"collapsed":false,"color":"green","date":1711512660127,"id":"f8253f25-c6d4-4e43-85fe-d872f8e9300b","locked":false,"tabIds":["59191874-5601-413f-af10-79574e5de8e6"],"title":""},"f8cf3180-6bf4-42e7-8970-742637df9551":{"collapsed":false,"color":"green","date":1699660901451,"id":"f8cf3180-6bf4-42e7-8970-742637df9551","locked":false,"tabIds":["69d85cc5-2eac-487c-891a-3ce78f6648f7","06ec9d69-33f3-4c3f-9b46-1478db50b368","5e7def65-6c1d-429a-a9bb-1118c92dc5fc","e80c04a6-9015-4e7d-91c4-3e6d979f8d09","891f98cf-f610-4aca-b866-f6089b5878d8","59b67f0b-d572-4639-9935-d8b1058b9b32","8bc42cc0-77cf-440f-bd9d-ce13918b9f7d","960ae934-aa23-4559-a921-3af15dbf26a8","85f9866a-36da-462b-823c-140f8a57c8f1","5cbc547b-acea-4959-8776-2eb61e8ac86c","f72b7065-9e71-4737-8a82-437449d669ba","1a22b6d0-cc2a-4807-ae46-78028bdf06be"],"title":""},"f92b5723-d6a9-48f6-9ee3-2bb108d81a42":{"collapsed":false,"color":"green","date":1698547429951,"id":"f92b5723-d6a9-48f6-9ee3-2bb108d81a42","locked":false,"tabIds":["5a901e87-7a53-46fb-823f-9881a0cca937","64b21e7e-10c6-4d57-b5cf-4bc01c297256","06790174-9895-460e-9a0e-c279d493988c","d1d7d149-ab78-46c8-a6b0-c86dcd67a848","039e2090-24ab-4f32-9391-86c608b9311f","0211a236-bd04-4ea6-a2ed-041d2bff0033","988eff0e-7139-4088-a48a-3c8303ecbc8e","8ea4b73e-2e3c-4e34-bd80-09216ef6f2dc","b421f4a1-e3d7-4519-aac0-78710c8c8a67","125de8f2-3be8-45b4-a0c7-3f0ee9eec0cf"],"title":""},"f97253e0-7f91-4745-ada5-715cecf900a3":{"collapsed":false,"color":"green","date":1709402474605,"id":"f97253e0-7f91-4745-ada5-715cecf900a3","locked":false,"tabIds":["a6daf6af-d98a-4e7d-94d1-9cadb26239dd","4da779d6-9cb5-4ead-9c38-1205b70ca69f"],"title":""},"f9f7484f-f5aa-4998-b2d2-e81d38c86fb2":{"collapsed":false,"color":"green","date":1698547429951,"id":"f9f7484f-f5aa-4998-b2d2-e81d38c86fb2","locked":false,"tabIds":["2a726ebd-4890-4984-9a79-dc72b27588e2","87162daf-7a37-4125-a493-a8cb84f7566d","b14da689-d5d3-4bde-bb69-68a7acbfc977","0e3c963e-3a74-4772-8cfe-b5cc6f15a3b6","fd1545e0-9209-416f-bdf8-283821e4b2c2","e4a29e1b-b88e-40df-8481-ef98b2e78ccc","e44be1a9-8e74-4a1f-ac0f-4608d3f5d783","b051a1bc-fa03-425a-be7e-87e7b602e37a","29141794-9a50-4647-8b45-7da84b2970fc","3f0ab461-5310-469d-ba34-05205b987ed5","b2f1c846-d93e-4d2f-bdfa-f01713e0a41c","5e7ab637-fafc-4e39-8ca0-4b9dec366458"],"title":""},"faa04e71-2080-4730-a172-55e9b22ed67f":{"collapsed":false,"color":"green","date":1698547429951,"id":"faa04e71-2080-4730-a172-55e9b22ed67f","locked":false,"tabIds":["576ee8e3-3df7-419c-a221-256c3249bc50","413bf559-7810-458f-83cc-de383a1bb87b","b070e0c9-fa47-4c31-b02f-927b57c3fa64","02780c50-0332-41c3-af6f-690f696fce12","8ef91d4b-9089-49f3-8c66-dec917b5ca72","80e1fabd-3249-40f1-9c08-1862d270ed7b","29f80d34-eec3-48ac-9e9d-335c6d4c072f","97268f9f-e3c9-4be6-b330-620dfacdafe3","06dacab3-3302-40c2-be0b-3abf08b9ba8f","07d3e309-8c9b-4bcd-909b-0616cf39eb63","a6fd65a8-3697-4ce9-b106-e626eccf2e7d","7fb20421-c533-4c17-af84-d4dc97461671","d0b2baeb-8fbc-492d-b3b1-3a13f6496232","f3e0ddcc-0027-40bc-82aa-5557aa37569c","7e02dc29-07f4-4132-805f-fa570c91a4c6","565586ac-8fb0-4b7c-b61d-40865fbb4ca6","44e01b53-8cc4-4e79-842e-a901a6deea3a","f2b564da-e090-441b-9aac-cbd9b232af11","2cec668f-2bf4-4b24-87e3-8bf4070fce5b"],"title":""},"fb9280b7-427a-49ab-8f46-d66715441d65":{"collapsed":false,"color":"green","date":1705436856696,"id":"fb9280b7-427a-49ab-8f46-d66715441d65","locked":false,"tabIds":["03f456dc-80b0-4738-8c4b-2de583e122fc","c4536252-a3d0-4e8f-a4da-6421e9d16810","15f901a2-98ab-4a28-89c4-0327f866aadf","f1367f2c-cd80-41d3-b310-a43c1a73baf8","f959954e-09c0-4456-990c-7cea21a75fbf","1f16e825-14a7-42f9-8ec9-e5db9ea4d7da","c8189035-7837-42fb-9959-08d6978ab3f7","5382bf11-7e29-47ec-9246-4414afdf00c0","e96e3ab1-378b-4cd2-8775-938a5942fdbd"],"title":""},"fbe5673a-8e41-4f6e-8e1a-017b06c8bc62":{"collapsed":false,"color":"green","date":1698547429951,"id":"fbe5673a-8e41-4f6e-8e1a-017b06c8bc62","locked":false,"tabIds":["45c7b39d-d2d5-4d30-b6ec-8aeeeabe9783","a65d5a9c-b936-460b-a03c-cc2d0601cb4c","3c41d06b-3093-4f9c-9066-e6ad718c22fb","afdd4e93-3872-4bce-93b3-c5ed57b6b533","2fe4b230-6da6-496b-9d0b-3586acbf4739","47bd6d39-9063-4bea-b9ef-7a0560963164","08af76a6-4fc9-4b0f-82cd-384ce4fa51c4"],"title":""},"fcb353cd-3e3f-434c-bd2e-d2fa9dc84282":{"collapsed":false,"color":"green","date":1700150631661,"id":"fcb353cd-3e3f-434c-bd2e-d2fa9dc84282","locked":false,"tabIds":["5318c336-fd06-4e6c-b14d-9155b37085bf","ad7e455a-5fe5-437e-a9e9-6aed66d985ea","7a624ae6-b5fb-4016-9b61-4b2252b6da32","44bb7041-845a-4997-9efd-0216ab5f84be","8cdaac4c-d8bc-4484-97fb-9ae20baf0715","ebd71c1b-5c02-4120-b356-0c9634b7d4a2","73220080-5390-434b-9865-64b7a6bdf782"],"title":""},"fd1693a3-c0cc-4af6-b85e-f237a02ecc35":{"collapsed":false,"color":"green","date":1712960406599,"id":"fd1693a3-c0cc-4af6-b85e-f237a02ecc35","locked":false,"tabIds":["96e2c7e5-790e-44c5-b041-5aadefd54552","23472ca5-4e95-4dbc-93c3-2bca0770b4c8","6b69670a-0281-45bd-87fa-70efc1dcde9b","52932afd-1372-4431-8f3b-598e54b14607","7891dbb0-c522-40fe-ae49-6c3a6acc38dd","7f794915-34b9-41b6-a521-34f380c68c69","c280a938-ba31-4386-904e-552bde60bdb1","d0410231-e0bc-491f-9631-ba2b1702e750","037be2b9-57d1-458b-bb7e-fe6432725d7d","131cdd64-e5ce-43eb-875a-c3b5264fc545","f511bb73-f7ac-41a1-8bf3-b25b01886716","67781963-4adf-487b-a778-29c640da49f6"],"title":""},"fdc8bb7c-325c-4c1c-a05c-f9cfac064c96":{"collapsed":false,"color":"green","date":1698547429951,"id":"fdc8bb7c-325c-4c1c-a05c-f9cfac064c96","locked":false,"tabIds":["f56534d4-58a1-4df2-b505-2634d9262853","6ad88eb1-8a76-4adf-8332-37c122fe46fd","e0df4160-9494-4724-89d5-5715160055a5"],"title":""},"fe206578-7ee1-43b1-b838-a974e0f55cb6":{"collapsed":false,"color":"green","date":1698547429951,"id":"fe206578-7ee1-43b1-b838-a974e0f55cb6","locked":false,"tabIds":["9acb8811-2a9c-478e-9c06-6300d97e093d","9ba20deb-ab74-4c89-b28f-75b5538a3110"],"title":""},"ff5b4449-5139-4299-b472-7651592e187c":{"collapsed":false,"color":"green","date":1711407615122,"id":"ff5b4449-5139-4299-b472-7651592e187c","locked":false,"tabIds":["0ba188de-520e-4e91-953e-e76920a2ec43"],"title":""},"ffc01f37-845d-4c18-a468-dccefde1a8a5":{"collapsed":false,"color":"green","date":1705703682877,"id":"ffc01f37-845d-4c18-a468-dccefde1a8a5","locked":false,"tabIds":["209dc13f-e40a-4ecb-9816-dbcc3422507c","d909b7af-365b-4309-918d-737ed76649e9"],"title":"hugging"}},"tabs":{"00106e46-905b-423b-be35-8e76a5a0ae6c":{"favIconUrl":"fallback","id":"00106e46-905b-423b-be35-8e76a5a0ae6c","title":"Deep Learning with Label Differential Privacy - Arxiv-2102.06062","url":"https://arxiv.org/pdf/2102.06062.pdf","urlHash":2586074630},"0054b298-6a95-45fc-8d1f-6971c3b67da0":{"favIconUrl":"fallback","id":"0054b298-6a95-45fc-8d1f-6971c3b67da0","title":"Batch normalization和Instance normalization的对比？ - 知乎","url":"https://www.zhihu.com/question/68730628","urlHash":4155844497},"005bd8c8-e9e3-460e-9e57-e4d3fa7b8158":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"005bd8c8-e9e3-460e-9e57-e4d3fa7b8158","title":"中国社会历史中的道教 (豆瓣)","url":"https://book.douban.com/subject/35947252/","urlHash":2931179806},"00717da7-3939-4694-971a-f1f37c4fb56f":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"00717da7-3939-4694-971a-f1f37c4fb56f","title":"语言模型是如何感知时间的？「时间向量」了解一下","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650903502&idx=3&sn=e904cc4f856acc9d7b0510408d2afbe2&exportkey=n_ChQIAhIQtT8nakW2rjINnWWxa27J3BKWAgIE97dBBAEAAAAAAG28NZxaTqoAAAAOpnltbLcz9gKNyK89dVj0NjIS%2Fw9%2Bk1XOu8xqSt9yT%2FxzUhmxZqwuY5uUX7i%2Bjw%2BYY7MPTLeRfQ%2F3iswv%2B35l2VqTM5kzuqM2%2Bdvs7y1biqiN1%2B6QczZV9ICdzbJpJMZo0ZlL7WH6BteZMgODP70YSTuqtQwtEEUY%2BM1ZbMMaYbliCxioUIE1VurPWJ1qPvVdhlF1upbS4oTzhr9cIQMJ8nUJwzXI7WRmUvvWnJjlbWb27quwPKdDRd3KIsqKh9k3GVtu1JdGd7tIRooDcP9yHRMbTVgJz10yeZ9MqNKy%2B617ImiCt5f9wGOaM%2BAHOPbTvy9TBFdTPtjD5%2FP4LcK8&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsYHgtyhbt1LBb3Ci2I4BV%2BiV1f1qE%2BB1WpYUU8LhxSJeA%3D%3D&wx_header=0","urlHash":1226934114},"00d40f35-6677-49d0-84ad-abef076c5cf7":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"00d40f35-6677-49d0-84ad-abef076c5cf7","title":"MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action | PDF","url":"https://arxiv.org/pdf/2303.11381.pdf","urlHash":4286736320},"00f266bb-ab48-4954-8505-9f0bd83ab238":{"favIconUrl":"fallback","id":"00f266bb-ab48-4954-8505-9f0bd83ab238","title":"projections.pdf","url":"http://www.cs.tau.ac.il/~oriram/projections.pdf","urlHash":3117012172},"01069b98-ee05-49de-9b34-6af35a6b07ca":{"favIconUrl":"fallback","id":"01069b98-ee05-49de-9b34-6af35a6b07ca","title":"这是我们为你整理的“机核克苏鲁百科全书”","url":"https://www.gcores.com/collections/46?tab=articles&page=10","urlHash":2241970736},"011f5e08-c73a-405e-a35b-edcfc6ce9642":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"011f5e08-c73a-405e-a35b-edcfc6ce9642","title":"srush/Tensor-Puzzles: Solve puzzles. Improve your pytorch.","url":"https://github.com/srush/Tensor-Puzzles","urlHash":989317751},"014586bd-1094-4138-8ca4-9f905b0ec715":{"favIconUrl":"fallback","id":"014586bd-1094-4138-8ca4-9f905b0ec715","title":"EMNLP 最佳论文解读：来自信息瓶颈的新语言学理论 - 知乎","url":"https://zhuanlan.zhihu.com/p/91383421","urlHash":3680343252},"015beac7-d3db-4e93-ae87-6a752bab5b42":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"015beac7-d3db-4e93-ae87-6a752bab5b42","title":"Xiaojian Ma on X: \"🐍4K context LLaMA-2 =&gt; 256K context, only 400+600 steps ☢️256K =&gt; 2M context, zero-shot ??? Just WOW🤯🤯\" / X","url":"https://twitter.com/jeasinema/status/1760525261911847083","urlHash":3081564566},"0164304b-dd5d-4ea3-85e4-dc2aebed700a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"0164304b-dd5d-4ea3-85e4-dc2aebed700a","title":"elvis on X: \"Great overview of compression algorithms for LLMs. Covers compression algorithms like pruning, quantization, knowledge distillation, low-rank approximation, parameter sharing, and efficient architecture design. This space is moving so fast. This is just a nice overview… https://t.co/CQxMgw0Wih\" / X","url":"https://twitter.com/omarsar0/status/1752746770377974072?utm_source=substack&utm_medium=email","urlHash":550859081},"0191f095-074d-4785-bd38-d102713935e6":{"favIconUrl":"fallback","id":"0191f095-074d-4785-bd38-d102713935e6","title":"Membership Inference Attacks From First Principles","url":"https://arxiv.org/pdf/2112.03570.pdf","urlHash":1879851114},"01c1b5cd-a43f-460d-a2ec-8d42284b477e":{"favIconUrl":"fallback","id":"01c1b5cd-a43f-460d-a2ec-8d42284b477e","title":"如何评价王小波《绿毛水怪》这部作品? - 知乎","url":"https://www.zhihu.com/question/28961306","urlHash":1543631718},"0211a236-bd04-4ea6-a2ed-041d2bff0033":{"favIconUrl":"fallback","id":"0211a236-bd04-4ea6-a2ed-041d2bff0033","title":"判决","url":"https://app.yinxiang.com/Home.action#n=7bb066d2-da7f-4294-86be-ee24e46cb7bf&s=s70&b=b5787273-91e4-4403-ad4f-eaa924cbe09e&ses=4&sh=1&sds=5&","urlHash":55804790},"0212243b-449c-47e7-8266-65c97ebd16f7":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"0212243b-449c-47e7-8266-65c97ebd16f7","title":"Po-Nien Kung on X: \"Instruction-tuned models are scaling up in their training tasks! 🚀 🤔Curious how to choose novel tasks to enhance models effectively? Our #EMNLP2023 paper reveals that selecting prompt-sensitive (Ambiguous) tasks leads to better performance! 🧵(1/7) 📎https://t.co/JkxfAh7nNf https://t.co/4COfHxmIHI\" / X","url":"https://twitter.com/P_N_Kung/status/1726735673250791828","urlHash":3500110743},"0222be4d-de12-4971-84d1-9d574533b51b":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"0222be4d-de12-4971-84d1-9d574533b51b","title":"视觉大模型的两条出路","url":"https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&mid=2247494260&idx=1&sn=d758821a737c0e5617675fb78d3a8df8&exportkey=n_ChQIAhIQwJ7y%2FCRGyt2aMG0xf%2BR%2B0RKWAgIE97dBBAEAAAAAAIglBkGvXKgAAAAOpnltbLcz9gKNyK89dVj0mFgvvJw%2FVKbNwU3FH3qMzztMuUc5EK4B%2BKvZu5JDTCc1rZVwhOgfifv8QJyIAl7qbVrw5ZBfww1LiAQV%2F3HmZj5D56TEmcMU5DQ5O1B6z%2BQ1VjV5Ei43XcT9%2FNLvCccehwW%2BSlTt6OIekHdpM7J28MGLoYQStK%2FxQTwxLOQUy70nUu%2F3qeaWnBiX0WVtkC%2FjRqRyMO9S2XFiOnlWXU4z5d1fxndlWxMkSH5CJkA9oLA6NOl%2FRLx9HUHbaAfXGUV6HdRblrRFQhYc%2FRoRsKLI1M3lmxFPOFYrZYf2WlpUMoO%2BlstYIYpohfksV0fBsvJJ&acctmode=0&pass_ticket=wQ%2FBr%2FMnFk5LTRg%2BN7mGd7UB9rLY5GymBX1STXAKWZLHEVX605d%2FDp7JKNmBB9EN&wx_header=0","urlHash":1076017933},"02249019-08e1-43ce-bb0d-75561f3a54bc":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"02249019-08e1-43ce-bb0d-75561f3a54bc","title":"Language Model Inversion | PDF","url":"https://arxiv.org/pdf/2311.13647.pdf","urlHash":1026305225},"026816dd-b582-464b-b7e3-7c4c74a09daa":{"favIconUrl":"fallback","id":"026816dd-b582-464b-b7e3-7c4c74a09daa","title":"Efficient Methods for Natural Language Processing A Survey - Arxiv-2209.00099","url":"https://arxiv.org/pdf/2209.00099.pdf","urlHash":1078405399},"02780c50-0332-41c3-af6f-690f696fce12":{"favIconUrl":"fallback","id":"02780c50-0332-41c3-af6f-690f696fce12","title":"WGAN的成功，可能跟Wasserstein距离没啥关系 - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/8244","urlHash":1030191618},"02b5694d-a9a5-4b43-ad01-e12278023284":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"02b5694d-a9a5-4b43-ad01-e12278023284","title":"挑战Transformer的Mamba是什么来头？作者博士论文理清SSM进化路径","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650901741&idx=2&sn=5ea68d9eaa7ed0ed071ef6d63bcaa6a1&chksm=84e44893b393c1855be2f4e1ce1031cff3069c0faf7d797f8ec5c5de171e83a6d19b94792231&mpshare=1&scene=1&srcid=01157lOyE7Rd6S4BK8wTYEYJ&sharer_shareinfo=82a47594e6652b6528d8354ccae86826&sharer_shareinfo_first=82a47594e6652b6528d8354ccae86826&exportkey=n_ChQIAhIQmhq8xkFwdFpRMVQa6NXigRKWAgIE97dBBAEAAAAAACBVA%2BRhjEIAAAAOpnltbLcz9gKNyK89dVj0CRZKxw6khK8ODNHA9bWz1h0so7NswcRzDR9r6Bthd1iU5%2B%2B2dak9aSOs996k9l8GoHeHMoIZYDPGq0ldD%2Fn0QQVN8SQnYLN6stT0U7rcfuWUJWohnARc0UQQomxLLjSsnR9f12D0j43mb4ANN9YzKUfPdRWpJtUvUoznzGn7R02iu3UmoiUBA%2FaUYTLPN6opmqzVU4U3i1XrJ5z4fG78EWccxWA5O1LfOMAsxR4NNuBPV%2FDYm1wXfW5i9a7Y4pX6eM5mT9R5CBzwGFOcKuudDZIv6UC18DyHfrSJ4%2FvYYntdvLrmXNxlK%2FEsKwiAI1oX&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsbo3D7kvqSJnKX2AapwCRqM59UrdYZaBCoZBX8kndDozw%3D%3D&wx_header=0#rd","urlHash":1881236576},"02bcca57-70cf-413a-8f6b-477050471a79":{"favIconUrl":"fallback","id":"02bcca57-70cf-413a-8f6b-477050471a79","title":"The Mental States of Language Models","url":"https://machinethoughts.wordpress.com/2023/02/19/the-mental-states-of-language-models/","urlHash":356732956},"02d02d8b-ac2f-4344-ba1e-9da290080fa4":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"02d02d8b-ac2f-4344-ba1e-9da290080fa4","title":"S-LoRA/S-LoRA: S-LoRA: Serving Thousands of Concurrent LoRA Adapters","url":"https://github.com/S-LoRA/S-LoRA","urlHash":2548272210},"02f7c53f-8462-4836-8db0-09d390f7c4b2":{"favIconUrl":"fallback","id":"02f7c53f-8462-4836-8db0-09d390f7c4b2","title":"如何评价《我想吃掉你的胰脏》的原作小说以及衍生作品（漫画、真人电影、动画电影）？ - 知乎","url":"https://www.zhihu.com/question/309212728","urlHash":93146111},"030c52bb-eef0-4469-b307-a40e1ef340e7":{"favIconUrl":"https://www.google.com/favicon.ico","id":"030c52bb-eef0-4469-b307-a40e1ef340e7","title":"轩弦 莫比乌斯的圈套 epub - Google Search","url":"https://www.google.com/search?q=%E8%BD%A9%E5%BC%A6+%E8%8E%AB%E6%AF%94%E4%B9%8C%E6%96%AF%E7%9A%84%E5%9C%88%E5%A5%97+epub&newwindow=1&sca_esv=569212662&sxsrf=AM9HkKn4IwuIlRGdeBdUSxrm5SmM-rKGCQ%3A1695925496366&ei=-MQVZfT1FfSx5NoPjfyK6Ac&ved=0ahUKEwj00Zrm9s2BAxX0GFkFHQ2-An0Q4dUDCBA&uact=5&oq=%E8%BD%A9%E5%BC%A6+%E8%8E%AB%E6%AF%94%E4%B9%8C%E6%96%AF%E7%9A%84%E5%9C%88%E5%A5%97+epub&gs_lp=Egxnd3Mtd2l6LXNlcnAiIei9qeW8piDojqvmr5TkuYzmlq_nmoTlnIjlpZcgZXB1YkiGC1CcAVirCnABeACQAQCYAXSgAb8DqgEDNC4xuAEDyAEA-AEBwgIIEAAYogQYsAPCAgsQABiJBRiiBBiwA8ICBRAhGKAB4gMEGAEgQYgGAZAGBQ&sclient=gws-wiz-serp","urlHash":2599279123},"03270f44-4899-497d-8b5a-07afc7d62d96":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"03270f44-4899-497d-8b5a-07afc7d62d96","title":"日本推理名作选：浜尾四郎（卷一） (豆瓣)","url":"https://book.douban.com/subject/3783263/","urlHash":878410922},"0328a2ed-5a62-480b-8cfc-ee3835a3b8db":{"favIconUrl":"https://assets.squarespace.com/universal/default-favicon.ico","id":"0328a2ed-5a62-480b-8cfc-ee3835a3b8db","title":"2022 in Review: Top language AI research papers + interesting papers to read — Yi Tay","url":"https://www.yitay.net/blog/2022-best-nlp-papers","urlHash":1395318305},"034547ae-2c31-4fd3-9c8f-b03b7481944a":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"034547ae-2c31-4fd3-9c8f-b03b7481944a","title":"Adaptive Online Replanning with Diffusion Models | PDF","url":"https://arxiv.org/pdf/2310.09629.pdf","urlHash":2908732286},"0350e780-e65c-4188-b651-15c98998e7e0":{"favIconUrl":"fallback","id":"0350e780-e65c-4188-b651-15c98998e7e0","title":"LEACE Perfect linear concept erasure in closed form - Arxiv-2306.03819","url":"https://arxiv.org/abs/2306.03819?utm_source=substack&utm_medium=email","urlHash":1780351112},"037759ff-8efe-49a3-977e-aa21f7186998":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"037759ff-8efe-49a3-977e-aa21f7186998","title":"hao-ai-lab/LookaheadDecoding","url":"https://github.com/hao-ai-lab/LookaheadDecoding?tab=readme-ov-file","urlHash":603295186},"037be2b9-57d1-458b-bb7e-fe6432725d7d":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"037be2b9-57d1-458b-bb7e-fe6432725d7d","title":"elvis on X: \"It will get super interesting once more people and companies can afford to train LLMs from scratch or even easily and cost-effectively fine-tune the large existing ones. \"JetMoE-8B is trained with less than $ 0.1 million cost but outperforms LLaMA2-7B from Meta AI, who has… https://t.co/lBHYQOAaIz\" / X","url":"https://twitter.com/omarsar0/status/1775971009469768104?utm_source=substack&utm_medium=email","urlHash":1598000006},"037fd3bb-dddf-4d5f-a96e-9c5882df07e8":{"favIconUrl":"fallback","id":"037fd3bb-dddf-4d5f-a96e-9c5882df07e8","title":"Pix2Seq：谷歌大脑提出 CV 任务统一接口！","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247530816&idx=1&sn=78ff024c6dac20bf7e19474b7b9c1b61&exportkey=n_ChQIAhIQtfrl6IpwFofy5rnZ8aC5ixKWAgIE97dBBAEAAAAAAI4XLqn07p4AAAAOpnltbLcz9gKNyK89dVj0aNDPffWThQiQZGDU0vDr6BYX4eBBJGKVO0Wsla8LA2bW2ZeYqEUj4JSLyau7wRjxxh6rXv8qJsBPH6nlrSdjOV16kVaQ8WT8Yur3Xp5yXwB2SbZt5p1q%2BR0WczWIOxQ2dynJCuwHtsZEVaMNWZ4rNIu1JglyoZLx8bgn40K%2B53aRvZlf1Etrjk2nWJaGA%2BjDpMh4tCGthwZxxLDPWTUPtS93MzlLfOV1g5dAHwrBWRE%2BQM8DSqJ3EcpzVuY9SwkgXnL00K1EqE9gp4H1J1u0CIjtDoPZj6JkAwqRy8W7KzvC5MBu5f4Pp8yGXv4XEe5Q&acctmode=0&pass_ticket=dk1%2BYeI9KcxVieaewIrrrbKjqtemDbE%2BLsWThaEB6q15x66qZzt8QojaGoMhMPtJ&wx_header=0","urlHash":2314917294},"0385c906-fef7-4eaf-88d2-b67bd7dc211a":{"favIconUrl":"https://www.google.com/favicon.ico","id":"0385c906-fef7-4eaf-88d2-b67bd7dc211a","title":"真実を覆い隠す雨 - Google Search","url":"https://www.google.com/search?q=%E7%9C%9F%E5%AE%9F%E3%82%92%E8%A6%86%E3%81%84%E9%9A%A0%E3%81%99%E9%9B%A8","urlHash":1269206},"039e2090-24ab-4f32-9391-86c608b9311f":{"favIconUrl":"fallback","id":"039e2090-24ab-4f32-9391-86c608b9311f","title":"Zurau Aphorisms","url":"http://zurauaphorisms.blogspot.com/","urlHash":2762981992},"03b12e6e-0849-4e8c-b0e1-6280e2fb3a14":{"favIconUrl":"fallback","id":"03b12e6e-0849-4e8c-b0e1-6280e2fb3a14","title":"Meta Reinforcement Learning","url":"https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html","urlHash":3328321541},"03ce0198-8a78-4bb4-8192-afc331aa6d46":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"03ce0198-8a78-4bb4-8192-afc331aa6d46","title":"LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning | PDF","url":"https://arxiv.org/pdf/2401.01325.pdf","urlHash":1192060389},"03d4c442-3973-4ff0-b48f-6f6f7709f5a7":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"03d4c442-3973-4ff0-b48f-6f6f7709f5a7","title":"全球最强开源大模型一夜易主！谷歌Gemma 7B碾压Llama 2 13B，今夜重燃开源之战","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652446680&idx=1&sn=7453bcb6b07b3268a1aab06b133ed7df&chksm=f12a6b29c65de23f8768e9847fa95044d54e137af1b4edf55d55b0f19ba4a5b7718d37997e9a&mpshare=1&scene=1&srcid=0222wC1LE1b7M8i8tlLt2eF5&sharer_shareinfo=9c1062b0b4f0f0639e69201714b3127f&sharer_shareinfo_first=9c1062b0b4f0f0639e69201714b3127f&exportkey=n_ChQIAhIQ43j%2B2fTxYFze7M97hpSxJhKWAgIE97dBBAEAAAAAAI5nDOrv0xEAAAAOpnltbLcz9gKNyK89dVj0rVQgiSRBSkASVvZLVW%2F2Hg%2FGamEswxIedOD4rF8L3%2F2jziI1lf8b5vUI%2BH68I5U0ZgJZM2qGIaJfAtSwUtXF98suJK0ttXtrTLAuZqXvfvDh2zn8NWlnjiIVpCEgytT67DrkyKf7fU1gDB3aSxSocLV1scEfiz0Cl7ZFaA8oam%2FzLSjv1OBBxYlPJhW1lFzvqcjMJa%2FdIMbGlkdsWm9rUPrYYaXEzm2qSd9nHnJ%2BNE45ZXP%2BYCYWc6VoyjVEEdVadkKZCwCYpd9cSScXFWvLKuofgKmFw7teXm1IIs%2BrgH3PuGG3UjsT9UQXVhbPFumW&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HPHMFUkJnYoKfGH2CcQRGfwggKu9p4zG1q6kRAEg7v7Og%3D%3D&wx_header=0#rd","urlHash":2935097120},"03e64c96-48cc-439e-b7d8-6a8bf3a4ade3":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"03e64c96-48cc-439e-b7d8-6a8bf3a4ade3","title":"Stochastic Neural Networks for Hierarchical Reinforcement Learning | PDF","url":"https://arxiv.org/pdf/1704.03012.pdf","urlHash":2401186314},"03ec49bf-4c1e-4e7d-a0f0-2deff117bdd9":{"favIconUrl":"fallback","id":"03ec49bf-4c1e-4e7d-a0f0-2deff117bdd9","title":"Creating an encyclopedia from GPT-3 using B̶a̶y̶e̶s̶’̶ ̶R̶u̶l̶e̶ Gibbs sampling – Kyunghyun Cho","url":"https://kyunghyuncho.me/creating-an-encyclopedia-from-gpt-3-using-b%cc%b6a%cc%b6y%cc%b6e%cc%b6s%cc%b6%cc%b6-%cc%b6r%cc%b6u%cc%b6l%cc%b6e%cc%b6-gibbs-sampling/","urlHash":3956508861},"03f456dc-80b0-4738-8c4b-2de583e122fc":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"03f456dc-80b0-4738-8c4b-2de583e122fc","title":"Goal Driven Discovery of Distributional Differences via Language Descriptions | PDF","url":"https://arxiv.org/pdf/2302.14233.pdf","urlHash":3552795335},"03f4b8af-4b57-4bfb-acdf-53173ce2190a":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"03f4b8af-4b57-4bfb-acdf-53173ce2190a","title":"Anthropic 关于 RLHF 的研究","url":"https://mp.weixin.qq.com/s?__biz=MzI4ODAyMDIyMw==&mid=2455236930&idx=1&sn=7acd9d20f46b77a2b97ddbc1e06a4975&exportkey=n_ChQIAhIQ%2BlQZ62WL1F8VycEmA9cfERKWAgIE97dBBAEAAAAAACR6BSC9pBgAAAAOpnltbLcz9gKNyK89dVj0iEt%2BEkgdLa4jGTKwEsEv9pfkUmC2XPtrjhQcoyOKDiyXLIL%2Bj6ss2vArwmP6kJJuCJQf4J5jr5wbvpthBUYAktTQ94KAXW%2Bjb7lOPAMJe%2BU9JEItSH2cvmSDnxpfeoMbHgFEfowjD95D%2F4mgNMTGqwEa37u2%2BJKDlIhFJNjJf0P74QAyo7u9rakWRDlQDCML3d%2F6yckfxEBYYyfynx%2FrGh2hrny2YlFudh%2BZzFVNtxx4Xp2HnJnuYmRpJPGMmyDEbWYStM0fLySxT3e8xQK8dSFQeS0ea%2B6cWDcYmXna3Hr%2FSEnijrYArICearuXZVYL&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsYZcxJhRfbeeokgWKT94wsAIWsw48gWetNZNCNgjqRYCA%3D%3D&wx_header=0","urlHash":3649925632},"041106c9-0cfa-480b-b428-483f44194528":{"favIconUrl":"fallback","id":"041106c9-0cfa-480b-b428-483f44194528","title":"pytorch/captum: Model interpretability and understanding for PyTorch","url":"https://github.com/pytorch/captum","urlHash":4067385205},"042ecd88-bb30-4a6e-bb41-1589880052f3":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"042ecd88-bb30-4a6e-bb41-1589880052f3","title":"(1) AK on X: \"PockEngine: Sparse and Efficient Fine-tuning in a Pocket paper page: https://t.co/3xrd6WEV8F On-device learning and efficient fine-tuning enable continuous and privacy-preserving customization (e.g., locally fine-tuning large language models on personalized data). However,… https://t.co/JQ8xIqbqJ0\" / X","url":"https://twitter.com/_akhaliq/status/1718813833546891368","urlHash":3849477569},"04780f4b-fa29-49aa-aedd-3d5a51c8be75":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"04780f4b-fa29-49aa-aedd-3d5a51c8be75","title":"训练数据洗来洗去还是脏，能救吗？试试选择性语言建模，极大提高效率与性能","url":"https://mp.weixin.qq.com/s?__biz=MzkwMjUwNTg3OA==&mid=2247485489&idx=1&sn=ec8ebae9e12231133b63512218beede1&chksm=c0a53cc8f7d2b5deccae256b77a7546b703499e038617e94f0e64e1312c7153457438d2c9d9f&mpshare=1&scene=1&srcid=0417ejDrij1z4ZdDhmQztXYP&sharer_shareinfo=d7f53faae9e013d2f8a59585955c406e&sharer_shareinfo_first=d7f53faae9e013d2f8a59585955c406e&exportkey=n_ChQIAhIQR8BLUB9D09hTXl3PPSN4YhKWAgIE97dBBAEAAAAAANQCAf%2F7SRMAAAAOpnltbLcz9gKNyK89dVj0rjyO4ei21ZRwYKHC4%2F1%2BsiVpt24R%2FFyyCE%2BmtQjaFzSaRdq0bu3Ga5H%2BiOzSaybKeNv%2BxiSEYfXBoWfl71QlUmGXnUvaq8hGJUqCCvE%2B3qbyxMKmFqgE%2FTGC%2Bo5pbMFqXN6tsI007X70211CC19sjA13micQsNvN3Kz7U%2BW6wJytuCA9ZL9lubXk%2FFp4OS9Kv042rcHAzsWRAeS7sRMAVTCsgnR%2FBoF2mpk96KBalNNwUXKr8BIINVgRLRSlaO1YMR8mwGWnt1iQb8xJhHBsYbp0%2BbeE1%2FcoDHo6yuDQe4DsLQAPafWS4KQ81onmzg2M&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCPPKCT7TQkghyLAOTKTPuRJqpsIBZPchyFU%2Fe78LckqtQ%3D%3D&wx_header=0#rd","urlHash":1483847439},"04fbf839-fd6b-4710-a042-a1f9fdad3fdc":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"04fbf839-fd6b-4710-a042-a1f9fdad3fdc","title":"slangchain/docs/modules/graphs/examples/anthropic/agent_supervisor.ipynb at main · prof-frink-lab/slangchain","url":"https://github.com/prof-frink-lab/slangchain/blob/main/docs/modules/graphs/examples/anthropic/agent_supervisor.ipynb","urlHash":4233853479},"050f46e3-5cf2-475b-9999-0501adb7df91":{"favIconUrl":"fallback","id":"050f46e3-5cf2-475b-9999-0501adb7df91","title":"Poisoning Attacks on Algorithmic Fairness - Arxiv-2004.07401","url":"https://arxiv.org/pdf/2004.07401.pdf","urlHash":1952255056},"051bd9e1-9005-480e-afc6-0d2753657642":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"051bd9e1-9005-480e-afc6-0d2753657642","title":"langgraph/examples at main · langchain-ai/langgraph","url":"https://github.com/langchain-ai/langgraph/tree/main/examples","urlHash":1338619289},"052e5e66-5968-48c7-8c45-04601a56a0ba":{"favIconUrl":"https://www.google.com/favicon.ico","id":"052e5e66-5968-48c7-8c45-04601a56a0ba","title":"Augmented Language Models: a Survey - Google Search","url":"https://www.google.com/search?q=Augmented+Language+Models%3A+a+Survey&sourceid=chrome&ie=UTF-8","urlHash":3850753386},"0576bce8-f78c-4908-864e-ca54e94c5f78":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"0576bce8-f78c-4908-864e-ca54e94c5f78","title":"AutoGPTQ/auto_gptq/quantization/gptq.py at main · PanQiWei/AutoGPTQ","url":"https://github.com/PanQiWei/AutoGPTQ/blob/main/auto_gptq/quantization/gptq.py","urlHash":1194770376},"05913654-95bd-4ae0-8d77-683a36c9181b":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"05913654-95bd-4ae0-8d77-683a36c9181b","title":"The Capacity for Moral Self-Correction in Large Language Models | PDF","url":"https://arxiv.org/pdf/2302.07459.pdf","urlHash":1106141347},"05998975-b11c-4e0a-8d0c-0588d589a8e0":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"05998975-b11c-4e0a-8d0c-0588d589a8e0","title":"【LLM】AboutMe：预训练数据过滤器对预训练数据的影响","url":"https://mp.weixin.qq.com/s?__biz=Mzk0MTU5OTg1OQ==&mid=2247484918&idx=1&sn=a51c84a8bdc5c61c4ddb69cb2fe16da2&chksm=c2ceb8eaf5b931fca13cc9f197835f5c39ffe92ace91cf732eabd781cb7b81b71ddfb927fb57&mpshare=1&scene=1&srcid=0123jcaTekgEdIhEEZLZN2aw&sharer_shareinfo=39adaa7f68bf1e02bffeac3b9239eed2&sharer_shareinfo_first=39adaa7f68bf1e02bffeac3b9239eed2&exportkey=n_ChQIAhIQmC%2FKfhAGnsN7H2cTSAUEoRKWAgIE97dBBAEAAAAAAKJFCIA4xEUAAAAOpnltbLcz9gKNyK89dVj07lO5Xe0I4jEezgavo8%2BIb4J7FYthjkYO25kGuJR99cv93DE5X%2BhYAYO0Kb9YO9oXmtPNoTDexz2jIV7U7OmGoLQT09kIkxmqD27JJ1SQEkGLlYGQcOqj82TAy4PU8f%2FmY2am%2BBZmnYdmOAPwqF1YVAoD%2FJCOTI9NRxXgmZPRKyZk2yyS84p%2FeYRsBYYpIXXUAU6ZKAmLGZ%2F3XM0VZ%2B1ARV6hX%2BxJh%2FfIdBHjlFYuuCvE28nI5EE9tKTKNTXiazxXQSGDmPgCpuZwruDKbCxQY%2Fdrmw44P69klLJbHCBzC4hhycgO6NBV2mO5tzkxL2vw&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HPEfmOHn%2Byo%2B%2FkgClJdW5D6SOLXhwrC88nJ81lCPji5Mw%3D%3D&wx_header=0#rd","urlHash":495025627},"05c69fe5-6bfc-42a7-a1ba-55dace50c199":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"05c69fe5-6bfc-42a7-a1ba-55dace50c199","title":"ルームメイトと謎解きを (豆瓣)","url":"https://book.douban.com/subject/35778212/","urlHash":491877966},"05dfcbef-a15c-4bbc-b07c-25a503a934e7":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"05dfcbef-a15c-4bbc-b07c-25a503a934e7","title":"谷歌发现大模型「领悟」现象！训练久了突然不再死记硬背，多么痛的领悟","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247690983&idx=5&sn=5ddbf5a4a9812c9aeabfd6638fa3e113&exportkey=n_ChQIAhIQoZ%2BExLyhY0fpKlSStcZV8BKWAgIE97dBBAEAAAAAACqhEyYv9Y8AAAAOpnltbLcz9gKNyK89dVj0B5BpReEWwjjK9rM8781FKKnTig3LXbaFmGgElTZ6rIFzHtsvpf6r7dBKgxj3dYw3xz9YIYeD0bsL%2Bzt0GeMh5BXtescmoRlhOAXtDPGLM6OjL2zEVidrU%2FRO6%2FCRFVrvShzCTNWy07uYp4JGnInBMlZu%2B%2Bn7wkHBPDKgP6BBM6fX0oRqkHUuIVKg%2FWIjTtCNcJC6OOizw6fo8QVKQocLJeZKt1yIKJA4MmpyYGHufpms4xi7Siknrjgg6Tu6cGvztd35UBG906C6fZsT9DdwWsz%2FvVmO6EN8HIa2%2FhSuUQ22MluIja7qPut1L7OND71g&acctmode=0&pass_ticket=E5EaSHsOCnt7XxkU0drC7WITbf6uu2Jiackt9%2Bl8AqE0NyErzyPm4NsDTEOy0fMS&wx_header=0","urlHash":3750663116},"06237a0d-86b3-4fd4-8035-a22304622c53":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"06237a0d-86b3-4fd4-8035-a22304622c53","title":"srush/Transformer-Puzzles: Puzzles for exploring transformers","url":"https://github.com/srush/Transformer-Puzzles","urlHash":1689834824},"064934a5-4895-468a-a356-4bfae5d731ad":{"favIconUrl":"https://ssl.gstatic.com/colaboratory-static/common/095cc65b2646ba341848339df2ea0656/img/favicon.ico","id":"064934a5-4895-468a-a356-4bfae5d731ad","title":"diffusion_policy_state_pusht_demo.ipynb - Colaboratory","url":"https://colab.research.google.com/drive/1gxdkgRVfM55zihY9TFLja97cSVZOZq2B?usp=sharing#scrollTo=VrX4VTl5pYNq","urlHash":21323214},"065a65be-c37f-43a2-ac70-b661e9fbd59b":{"favIconUrl":"fallback","id":"065a65be-c37f-43a2-ac70-b661e9fbd59b","title":"Massive Language Models Can Be Accurately Pruned in One-Shot - Arxiv-2301.00774","url":"https://arxiv.org/pdf/2301.00774.pdf","urlHash":1414453216},"0671521f-9253-4ffe-8b42-ba780b5a1afb":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"0671521f-9253-4ffe-8b42-ba780b5a1afb","title":"AK on X: \"Prometheus: Inducing Fine-grained Evaluation Capability in Language Models paper page: https://t.co/6lVgGDDUjw Recently, using a powerful proprietary Large Language Model (LLM) (e.g., GPT-4) as an evaluator for long-form responses has become the de facto standard. However, for… https://t.co/q2otrK1yBf\" / X","url":"https://twitter.com/_akhaliq/status/1712639154301894882","urlHash":3771303633},"06790174-9895-460e-9a0e-c279d493988c":{"favIconUrl":"fallback","id":"06790174-9895-460e-9a0e-c279d493988c","title":"kafka all aphorisms - Google Search","url":"https://www.google.com/search?q=kafka+all+aphorisms&newwindow=1&sxsrf=AJOqlzVvvnrragkQYp1Zpln91qvUyUAOsw%3A1674234680412&ei=OMvKY8bYGLSg5NoP_NCQ2AU&ved=0ahUKEwjG1JWb0tb8AhU0EFkFHXwoBFsQ4dUDCBA&uact=5&oq=kafka+all+aphorisms&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIFCCEQoAE6CggAEEcQ1gQQsAM6BAgjECc6EQguEIMBEMcBELEDENEDEIAEOgUILhCABDoNCC4QsQMQxwEQ0QMQCjoECC4QQzoLCC4QsQMQxwEQ0QM6CAguEIAEELEDOhEILhCABBCxAxCDARDHARDRAzoFCAAQgAQ6CwgAELEDEIMBEJECOgUIABCRAjoNCC4QgAQQFBCHAhCxAzoLCAAQgAQQsQMQgwE6CwguEIMBELEDEIAEOggIABCABBCxAzoOCC4QsQMQgwEQxwEQrwE6CAguEIAEENQCOgsILhCABBCxAxCDAToICC4QgwEQsQM6DQgAEIAEEBQQhwIQsQM6BQguEJECOggIABCABBDLAToFCAAQhgM6BggAEBYQHkoECEEYAEoECEYYAFCuB1i4L2DKMGgEcAF4AIABoAGIAYESkgEENi4xNJgBAKABAcgBCMABAQ&sclient=gws-wiz-serp","urlHash":2218221050},"06d8e16d-9817-470e-b691-ccc5c8ecae1c":{"favIconUrl":"fallback","id":"06d8e16d-9817-470e-b691-ccc5c8ecae1c","title":"fmu2/NICE: PyTorch implementation of NICE","url":"https://github.com/fmu2/NICE","urlHash":2204734350},"06dacab3-3302-40c2-be0b-3abf08b9ba8f":{"favIconUrl":"fallback","id":"06dacab3-3302-40c2-be0b-3abf08b9ba8f","title":"nocotan/pytorch-lightning-gans: Collection of PyTorch Lightning implementations of Generative Adversarial Network varieties presented in research papers.","url":"https://github.com/nocotan/pytorch-lightning-gans","urlHash":361355112},"06e08779-c2f3-4ff7-b1a5-525991086031":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"06e08779-c2f3-4ff7-b1a5-525991086031","title":"Ollie Liu on X: \"New Preprint Alert! 📢 Classical decision theory has helped humans make rational decisions under uncertainty for decades. Can it do the same for Large Language Models? We present DeLLMa (“dilemma”), a Decision-making LLM assistant. 🔗 https://t.co/SH0mQw9CRL 1/🧵 https://t.co/ZDFreX2WVr\" / X","url":"https://twitter.com/olliezliu/status/1762507899912454388","urlHash":3689457373},"06ec9d69-33f3-4c3f-9b46-1478db50b368":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"06ec9d69-33f3-4c3f-9b46-1478db50b368","title":"如何度量数据的稀疏程度？ - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/9595","urlHash":3648254667},"06ecd707-93b0-4822-979e-e336cf6d18fe":{"favIconUrl":"fallback","id":"06ecd707-93b0-4822-979e-e336cf6d18fe","title":"SolidGoldMagikarp (plus, prompt generation) - LessWrong","url":"https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation","urlHash":4033083562},"070e5830-37f0-4e7f-ab72-b8abc1e0bbbf":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"070e5830-37f0-4e7f-ab72-b8abc1e0bbbf","title":"On Evaluating Adversarial Robustness | Abstract","url":"https://arxiv.org/abs/1902.06705","urlHash":2545026449},"071ba8e8-3b70-46e4-8819-6e8849c2b155":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"071ba8e8-3b70-46e4-8819-6e8849c2b155","title":"Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets | Abstract","url":"https://arxiv.org/abs/2201.02177","urlHash":1938956015},"0757851c-1b70-41a6-8222-2585602de7b4":{"favIconUrl":"fallback","id":"0757851c-1b70-41a6-8222-2585602de7b4","title":"Fine-Tuning Language Models with Just Forward Passes","url":"https://arxiv.org/pdf/2305.17333.pdf","urlHash":3909437601},"0761e1ed-a452-48b4-9de8-14afad97e00b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"0761e1ed-a452-48b4-9de8-14afad97e00b","title":"twitter.com/aormazabalo/status/1661330468720066560","url":"https://twitter.com/aormazabalo/status/1661330468720066560","urlHash":853061365},"0787a81d-aa13-4501-9e3e-2b82071c1d6e":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"0787a81d-aa13-4501-9e3e-2b82071c1d6e","title":"匿名论文提出奇招！增强大模型长文本能力居然还能这么做","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247715663&idx=2&sn=a31b7be12b0f5b1ad2e773ae5a5cce30&chksm=e8df3c3ddfa8b52b98a0f291de0bc0de197fbecd270b1e340939aa4596469b051c4126ee759b&mpshare=1&scene=1&srcid=0202dCtZwBODwakDIM3RX3YJ&sharer_shareinfo=e53a56c81419ef82dec7ca2ef209b636&sharer_shareinfo_first=e53a56c81419ef82dec7ca2ef209b636&exportkey=n_ChQIAhIQHrE8Gzfj12WhrC7YrMRM2hKWAgIE97dBBAEAAAAAALyZGAbNXK0AAAAOpnltbLcz9gKNyK89dVj0n%2BiwUFSZnPeu79AXM%2Fu5bStiBZz45Ireda3Hhr2qQ9PPPAHsJDnsq4E4rrDkU9nVIHp%2F9SC8NF6m9CyTePMzJKKUzCBFfmr2ub29oBUxTHjOv0oWr5HY9yQFDNIYVCAoh3pUywLEDNiqfkJYkJsNMaZSutbeqzh4AeIEsi8I9JAy%2FavouK9rcLORdzFkeO2H7GZgMgzZLwI6dEKjGDr9vWSTi0GzwClPuEDkSU4qWUTvFqUrA%2FxzUzs8wIjABsjjS6H%2FWlR7HQSe9EDB4uFLNycE1qP%2F4OM3M283G4wrrmbXN5RthJwZtorxenOo0M9B&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HMOpaZJSnrkgNg%2BuqfxK4WIstO40ao2ZStmAVkXQM3krg%3D%3D&wx_header=0#rd","urlHash":144506352},"07b1a01a-b056-4b80-8b26-132131b433fa":{"favIconUrl":"fallback","id":"07b1a01a-b056-4b80-8b26-132131b433fa","title":"ssd algorithm - 搜索结果 - 知乎","url":"https://www.zhihu.com/search?q=ssd%20algorithm&type=content","urlHash":981282303},"07d3e309-8c9b-4bcd-909b-0616cf39eb63":{"favIconUrl":"fallback","id":"07d3e309-8c9b-4bcd-909b-0616cf39eb63","title":"O-GAN：简单修改，让GAN的判别器变成一个编码器！ - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/6409/comment-page-1","urlHash":3362568743},"07ee3c8d-d70b-46ea-8074-d7116ae9e740":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"07ee3c8d-d70b-46ea-8074-d7116ae9e740","title":"Task-Specific Skill Localization in Fine-tuned Language Models | Abstract","url":"https://arxiv.org/abs/2302.06600","urlHash":457572457},"080e5477-6f53-435b-a80a-167509347a84":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"080e5477-6f53-435b-a80a-167509347a84","title":"twitter.com/zhangzhuosheng/status/1621666014382399490","url":"https://twitter.com/zhangzhuosheng/status/1621666014382399490","urlHash":3544442212},"081d2a1a-fa7e-489e-9a5e-7a06dd887af2":{"favIconUrl":"fallback","id":"081d2a1a-fa7e-489e-9a5e-7a06dd887af2","title":"BNNpriors A library for Bayesian neural network inference with different prior distributions - Arxiv-2105.06964","url":"https://arxiv.org/abs/2105.06964","urlHash":3713860448},"087dd7f7-83d0-49f6-b839-8431b2d48eb0":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"087dd7f7-83d0-49f6-b839-8431b2d48eb0","title":"Aligning Large Multimodal Models with Factually Augmented RLHF | Abstract","url":"https://arxiv.org/abs/2309.14525","urlHash":3669361810},"0882ecdc-e36d-4860-818a-920e56913500":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"0882ecdc-e36d-4860-818a-920e56913500","title":"twitter.com/hwchung27/status/1658904135268433921","url":"https://twitter.com/hwchung27/status/1658904135268433921","urlHash":540343950},"08af76a6-4fc9-4b0f-82cd-384ce4fa51c4":{"favIconUrl":"fallback","id":"08af76a6-4fc9-4b0f-82cd-384ce4fa51c4","title":"deep learning with label differential privacy - Google Search","url":"https://www.google.com/search?q=deep+learning+with+label+differential+privacy&oq=deep+learning+with+label+d&aqs=chrome.0.0i512j69i57j0i22i30j69i61.2665j0j1&sourceid=chrome&ie=UTF-8","urlHash":227756399},"08afd1fc-6fbb-415c-971e-4767eac4d8b5":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"08afd1fc-6fbb-415c-971e-4767eac4d8b5","title":"「文生图」再升级！学习个性化参照，无限生成多样图片，轻松设计玩具建筑","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652432856&idx=4&sn=a5cc922a05a90eb97ba9f322a552e4d2&chksm=f12b9d29c65c143f50a9b97d624d81284145273ad9d8044160ad429af64f299331ce5e754bd8&mpshare=1&scene=1&srcid=0120z29r7q9WHZ0bKqb5LSwe&sharer_shareinfo=edfc9ee405607f6f21adca2bd23f8143&sharer_shareinfo_first=9431b9bffd7b22dade2e26fb377e68f0&exportkey=n_ChQIAhIQ5WqTjkxqqdV62p4%2FNf1JcBKWAgIE97dBBAEAAAAAAFakM0WU%2FugAAAAOpnltbLcz9gKNyK89dVj07qLMQg1vfrimT4zIxeHXNEMCw7luOpvvcYPPdHJfpoScdUUuIdoaEQ2sVD89c3pi1fJXQPw9GRlIu2rQcT3UGfM2XvG8wkiHze3GGrX4AxLr2ABOqNqffuGdPrXd2vrJOSn0au3kSuhwD0YgE9%2BjoDsxVzEd1Orv0kP6vmd2qbGynipGKTRGTxI%2BvmHML8w3YxNn5inUHIH0axXgr4rXr%2BKF5t1hgQJXso20P2HxIdSWZ0GdQkN6ebtBRLorebHn6VQ0%2Fx6Z3hZ%2BeS8jQePbUhCNmRion7hOsdUJqcBSWQNg%2FwZ%2BJs1fMGLGTU702G%2B6&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HOF7Q5aEN3DhP7IZZvRyVxw344Ie3%2BFaPvh1fRvhvPTWw%3D%3D&wx_header=0#rd","urlHash":2140159186},"08d40414-513c-443d-9ecb-33776fea98d1":{"favIconUrl":"https://www.youtube.com/s/desktop/54055272/img/favicon_32x32.png","id":"08d40414-513c-443d-9ecb-33776fea98d1","title":"【不止遊戲】返校 台灣“白色恐怖”到達有多恐怖 - YouTube","url":"https://www.youtube.com/watch?v=m3NuvlIpqcs","urlHash":99626837},"08ee2e17-f0c8-4937-a32c-02004d7ab4d6":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"08ee2e17-f0c8-4937-a32c-02004d7ab4d6","title":"PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs | Abstract","url":"https://arxiv.org/abs/2305.12392","urlHash":2214914917},"0918f5e5-dd6b-4ecc-bc27-7f68dedbac6a":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"0918f5e5-dd6b-4ecc-bc27-7f68dedbac6a","title":"Awesome feedback datasets - a HuggingFaceH4 Collection","url":"https://huggingface.co/collections/HuggingFaceH4/awesome-feedback-datasets-6578d0dc8628ec00e90572eb","urlHash":3653758757},"092fd9b1-f44b-4f02-a3d7-6fe832b24323":{"favIconUrl":"fallback","id":"092fd9b1-f44b-4f02-a3d7-6fe832b24323","title":"Counterfactual Explanations without Opening the Black Box Automated Decisions and the GDPR - Arxiv-1711.00399","url":"https://arxiv.org/pdf/1711.00399.pdf","urlHash":2286032439},"0937d2a1-b0d0-4002-94bf-d35ced6b77e8":{"favIconUrl":"https://piazza.com/favicon.ico","id":"0937d2a1-b0d0-4002-94bf-d35ced6b77e8","title":"6.S953 (1 unread) | Piazza QA","url":"https://piazza.com/class/ls9elnngaid304/post/25","urlHash":2793695767},"093a0ba3-9fdb-4920-8096-1478a73d0638":{"favIconUrl":"fallback","id":"093a0ba3-9fdb-4920-8096-1478a73d0638","title":"What is the relationship between DGL and PyG? · Issue #1365 · pyg-team/pytorch_geometric","url":"https://github.com/pyg-team/pytorch_geometric/issues/1365","urlHash":2191638838},"0968250e-5354-4934-aee7-0aaedde27edd":{"favIconUrl":"fallback","id":"0968250e-5354-4934-aee7-0aaedde27edd","title":"The Lottery Ticket Hypothesis: A Survey - Rob’s Homepage","url":"https://roberttlange.github.io/posts/2020/06/lottery-ticket-hypothesis/","urlHash":1657626408},"097e3f4f-989e-494b-96d3-174a704440d3":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"097e3f4f-989e-494b-96d3-174a704440d3","title":"khalid on X: \"Super thrilled to share our paper \"BYOD! Self-Supervised Evaluation for LLMs\" 🎉 Evaluating current LLMs poses challenges due to the risk of eval data leakage into the train set. We explore the possibility of evaluating LLMs by measuring invariances agnostic to datasets!\" / X","url":"https://twitter.com/k_saifullaah/status/1674080869181472768","urlHash":3266118530},"09b0ca6e-c813-42ba-b55c-547709bf8ba8":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"09b0ca6e-c813-42ba-b55c-547709bf8ba8","title":"Long Range Arena: A Benchmark for Efficient Transformers | Abstract","url":"https://arxiv.org/abs/2011.04006","urlHash":143752713},"09b281cd-5ba1-43b8-a212-030599918751":{"favIconUrl":"fallback","id":"09b281cd-5ba1-43b8-a212-030599918751","title":"浅谈Transformer的初始化、参数化与标准化 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/8620","urlHash":1586472390},"09bbcb89-6ca2-40a6-a9e9-d2fc2a58017c":{"favIconUrl":"https://www.youtube.com/s/desktop/77953cee/img/favicon_32x32.png","id":"09bbcb89-6ca2-40a6-a9e9-d2fc2a58017c","title":"(1) Large Language Models (in 2023) - YouTube","url":"https://www.youtube.com/watch?v=dbo3kNKPaUA","urlHash":4188734945},"09bbfc3f-7050-42a8-a847-f4f44bfb5fee":{"favIconUrl":"fallback","id":"09bbfc3f-7050-42a8-a847-f4f44bfb5fee","title":"李航统计学习方法 - 知乎","url":"https://zhuanlan.zhihu.com/c_1213397558586257408","urlHash":3355368661},"09d50b0e-0c95-46af-9330-2ef5b128ee05":{"favIconUrl":"fallback","id":"09d50b0e-0c95-46af-9330-2ef5b128ee05","title":"On the Advance of Making Language Models Better Reasoners - Arxiv-2206.02336","url":"https://arxiv.org/pdf/2206.02336.pdf","urlHash":3975093384},"09ffee9a-24e4-4ac2-a960-a7642d3382b0":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"09ffee9a-24e4-4ac2-a960-a7642d3382b0","title":"Large Language Models are not Fair Evaluators | PDF","url":"https://arxiv.org/pdf/2305.17926v1.pdf","urlHash":1893898197},"0a03da23-5541-43f5-8fc8-24f66642438d":{"favIconUrl":"fallback","id":"0a03da23-5541-43f5-8fc8-24f66642438d","title":"Robust Fine-Tuning of Zero-Shot Models - CVPR-2022_23206643","url":"https://openaccess.thecvf.com/content/CVPR2022/papers/Wortsman_Robust_Fine-Tuning_of_Zero-Shot_Models_CVPR_2022_paper.pdf","urlHash":982911206},"0a1742f3-8c4e-4ace-a451-8a47f545981a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"0a1742f3-8c4e-4ace-a451-8a47f545981a","title":"twitter.com/sleepinyourhat/status/1643020516641632258","url":"https://twitter.com/sleepinyourhat/status/1643020516641632258","urlHash":2539806461},"0a4cff00-527a-49d3-84ac-e9106bd5d346":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"0a4cff00-527a-49d3-84ac-e9106bd5d346","title":"CV开启大模型时代！谷歌发布史上最大ViT：220亿参数，视觉感知力直逼人类","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652314125&idx=4&sn=e7faedcd08b8d6d979b3fce256e9a283&exportkey=n_ChQIAhIQNJ1DrUUhzFIHyMwXj2rNzxKWAgIE97dBBAEAAAAAAJUAJ%2BwrD0IAAAAOpnltbLcz9gKNyK89dVj0HWzc%2B3lFpVKpX3BHni7TSZiahscgjF5UELrcfUVUMcvmrLAZndWg%2BnCNBmPbXDpjxI7zYrav3GL%2BvD9%2BWJLKTUuo7n2gABg8Sq5ZlF3AC%2FPoMsM0UVOPXB7G1bVq%2FL2R29z7TBW3sTK3%2B8VFnh15OQnKDB4FgMaxzNXhuOEXDzLq6MI1PUGQzX4pI2SCJzCmMK%2FTggUrbD5Y40SWgpdUQCNGyYgZLWNSqCH2zeJ80VSG%2FZFcIXqpOydWUOBxLyes%2FgvhkZchmZQ1APqxUL%2B%2F0HU0tXtA3a57yMQzjQPzwk0fbgIIJkApzjq2MCUgxHKJ&acctmode=0&pass_ticket=DUWJdFUi1JDJOm6OXRe2ZUPZKRPw403wXxhVQ6QEDdtR1z3Q2hgU9Vhb1tW6Y6svLsjXpy0OBUwbg4CC6xM9xw%3D%3D&wx_header=0","urlHash":146996476},"0aa9911c-9abd-43ea-b36b-d55065acb893":{"favIconUrl":"fallback","id":"0aa9911c-9abd-43ea-b36b-d55065acb893","title":"The Paths Perspective on Value Learning","url":"https://distill.pub/2019/paths-perspective-on-value-learning/","urlHash":1038481379},"0ac7c2ba-b0ea-4471-8189-695d02bcc2d2":{"favIconUrl":"https://www.google.com/favicon.ico","id":"0ac7c2ba-b0ea-4471-8189-695d02bcc2d2","title":"方丈貴恵『アミュレット・ホテル』 - Google Search","url":"https://www.google.com/search?q=%E6%96%B9%E4%B8%88%E8%B2%B4%E6%81%B5%E3%80%8E%E3%82%A2%E3%83%9F%E3%83%A5%E3%83%AC%E3%83%83%E3%83%88%E3%83%BB%E3%83%9B%E3%83%86%E3%83%AB%E3%80%8F","urlHash":28456994},"0aca07c5-ab1c-4c97-9e0f-7b243d09477d":{"favIconUrl":"fallback","id":"0aca07c5-ab1c-4c97-9e0f-7b243d09477d","title":"微软新出热乎论文：Transformer扩展到10亿token","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650883010&idx=2&sn=7d072e1bcc5fbec921b44518b0e15c5e&chksm=84e487bcb3930eaae2f9cfbb427f6eece5f5b31aea36f00d8d7764b6feea0cf6cef95d49fc35&mpshare=1&scene=1&srcid=0717pYOpXjPh9AamPndRuDX0&sharer_sharetime=1689584547365&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQyS4dI72xi1WAIKy9JbmU8BKWAgIE97dBBAEAAAAAAM6rNUubi5wAAAAOpnltbLcz9gKNyK89dVj0UodiW9ZqkEQqddxeDJ2WYOBxgoyYzPM%2B6crrRchwOtK7J3rJ7l90stLXmzNyGIzeoFsSYgWkmZpEIhPl%2BMKDx6bBUgnW5QzvZK5K2KtCWYkAjjQjrsraAidS89pddFJ0dAemr9MAYT3S753KLWbbKya30nUGTaUSpmofB%2FKwyVrta5nDZOW12%2F4ioa%2F%2FYLx9aYS6m%2FluO54d9KJvqPbUryku48q7FPXAfUf40CXtvczRNUsddSwZofa9k7RfcmPaOzvnwt4DKNwByZaUv4bwNjAT%2B9DBUOva1zkgqyAGQXgRWN2LQ1H%2F2ARKg0sjh%2Bb6&acctmode=0&pass_ticket=yicayTHa%2BMwjXrira53M4VpSpIw%2BV4Ae3r0dz8pOqK6DFkJr93K8LamIhtiX2LzZ&wx_header=0#rd","urlHash":2299542987},"0acec050-ce1c-419d-89de-e007602f96f4":{"favIconUrl":"https://kexue.fm/usr/themes/geekg/favicon.ico","id":"0acec050-ce1c-419d-89de-e007602f96f4","title":"Transformer升级之路：5、作为无限维的线性Attention - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/8601","urlHash":968274711},"0adaa8ef-1607-4e2a-9d79-a802a6acab0e":{"favIconUrl":"https://connect-prd-cdn.unity.com/cdn-origin/images/favicons/favicon-32x32.png?v=2","id":"0adaa8ef-1607-4e2a-9d79-a802a6acab0e","title":"Learn game development w/ Unity | Courses & tutorials in game design, VR, AR, & Real-time 3D | Unity Learn","url":"https://learn.unity.com/","urlHash":181587509},"0aff241c-0282-4001-8026-44d0b116b57b":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"0aff241c-0282-4001-8026-44d0b116b57b","title":"datamllab/LongLM: LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning","url":"https://github.com/datamllab/LongLM","urlHash":1384361620},"0b2a58ad-c6ed-4101-9a7d-63c594e54b94":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"0b2a58ad-c6ed-4101-9a7d-63c594e54b94","title":"PKU-Alignment/PKU-SafeRLHF · Datasets at Hugging Face","url":"https://huggingface.co/datasets/PKU-Alignment/PKU-SafeRLHF","urlHash":3517506543},"0b345c7b-7782-42ac-bd7b-1461b3d91ae9":{"favIconUrl":"https://www.google.com/favicon.ico","id":"0b345c7b-7782-42ac-bd7b-1461b3d91ae9","title":"IS SYNTHETIC DATA FROM GENERATIVE MODELS READY FOR IMAGE RECOGNITION? - Google Search","url":"https://www.google.com/search?q=IS%20SYNTHETIC%20DATA%20FROM%20GENERATIVE%20MODELS%20READY%20FOR%20IMAGE%20RECOGNITION?","urlHash":2134917589},"0b64d5ec-dccd-4aad-897b-4fdcd7b9f4d4":{"favIconUrl":"data:image/vnd.microsoft.icon;base64,AAABAAEAICAAAAEAIACoEAAAFgAAACgAAAAgAAAAQAAAAAEAIAAAAAAAABAAABILAAASCwAAAAAAAAAAAAAAAAAASWTtHEhh5qZIYObmSGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDm5khh5qZJZO0cAAAAAElk7RxIYeXtSGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hh5e1JZO0cSGHmpkhg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hh5qZIYObmSGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDm5khg5f9IYOX/SGDl/0hg5f9IYOX/ipnu/5qn8P9qfen/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/TWTl/5qn8P+grfH/nKnx/3iJ6/9JYeX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f/Cyvb///////T2/f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f99juz//////////////////////8vS9/9LY+X/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/8LK9v///////f3+/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/2l96f+hrfH/o6/x/9HX+P///////////5Gg7/9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/wsr2///////9/f7/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/Vmzn////////////usP1/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f/Cyvb///////39/v9IYOX/SGDl/46d7v/+/v7//v7+//7+/v/+/v7//v7+//7+/v/+/v7/8fP9/8LK9v9keOn/SGDl/0hg5f9JYeX///////////+9xvX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/8LK9v///////f3+/0hg5f9IYOX/j53v////////////ydD3/6ax8v+msfL/prHy/6248//t8Pz//////+/x/P9dcuj/SGDl/0lh5f///////////73G9f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/wsr2///////9/f7/SGDl/0hg5f+Pne////////////+RoO//SGDl/0hg5f9IYOX/SGDl/5Kg7////////////56q8f9IYOX/SWHl////////////vcb1/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f/Cyvb///////39/v9IYOX/SGDl/4+d7////////////5Oh7/9JYeX/SWHl/0lh5f9JYeX/h5fu////////////ucL1/0hg5f9JYeX///////////+9xvX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/8LK9v///////f3+/0hg5f9IYOX/j53v//////////////////////////////////////////////////////+4wfX/SGDl/0lh5f///////////73G9f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/wsr2///////9/f7/SGDl/0hg5f+Pne/////////////g5Pr/xs32/8bN9v/Gzfb/xs32/9jd+f///////////7fB9P9IYOX/SWHl////////////vcb1/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f/Cyvb///////39/v9IYOX/SGDl/4+d7////////////5uo8P9IYOX/SGDl/0hg5f9IYOX/gZHt////////////t8D0/0hg5f9JYeX///////////+9xvX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/8LK9v///////f3+/0hg5f9IYOX/j53v////////////m6jw/0hg5f9IYOX/SGDl/0hg5f+Bke3///////////+2wPT/SGDl/0lh5f///////////73G9f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/wsr2///////9/f7/SGDl/0hg5f+Pne///////////////////////////////////////////////////////7W/9P9IYOX/SWHl////////////vcb1/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f/Cyvb///////39/v9IYOX/SGDl/4WV7f/l6Pv/5ej7/+Xo+//l6Pv/5ej7/+Xo+//l6Pv/5ej7/+Xo+//l6Pv/pbHy/0hg5f9JYeX///////////+9xvX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/2h86f96i+z/eozs/7S+9P/K0ff/p7Ly/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0lh5f///////////73G9f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9gdej///////////+8xfX/bYDq/5il8P+YpfD/mKXw/5il8P+YpfD/mKXw/5il8P+YpfD/mKXw/5il8P+YpfD/mafw////////////vcb1/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/7zF9f//////9fb9/1906P/P1fj///////////////////////////////////////////////////////////////////////////+9xvX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/oK3x/1Rq5v9/kOz///////z9/v99juz/SGDl/6u28//AyPb/wMj2/8DI9v/K0ff/4eX6/8DI9v/AyPb/wMj2/8DI9v/AyPb/wMj2/8DI9v/AyPb/wMj2/5Wj8P9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f/8/f7/9fb9/6248/9Uaub/TWTl/0hg5f9/kOz/6Ov7/+Hl+v9ccuf/SGDl/3WH6///////vMX1/1Fo5v9IYOX/SGDl/0hg5f/L0vf/9/j9/8TL9v9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/6Ov8f/6+/7//////87U+P9PZub/SGDl/7rD9f//////9fb9/05l5f9IYOX/YXXo/+7w/P//////3eL6/1lu5/9IYOX/TWTl//f4/f//////rbjz/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/22A6v/09v3//////9fc+f+Zp/D/9vf9///////Y3fn/j53v/5Si7/+Wo/D/Znrp/93i+v//////3uL6/5mn8P+yvPT///////////+yvPT/mafw/5mn8P96i+z/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/32O7P////////////////////////////////////////////////+cqfH/X3To//r7/v////////////////////////////////////////////Hz/f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/8zT9////////////2l86f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/usP1////////////iJju/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/jJvu////////////kZ/v/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9/kOz///////////+eqvH/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5uZIYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9KYeX/SmHl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYObmSGHmpkhg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hh5qZJZO0cSGHl7Uhg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYeXtSWTtHAAAAABJZO0cSGHmpkhg5uZIYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYOX/SGDl/0hg5f9IYObmSGHmpklk7RwAAAAAgAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAAE=","id":"0b64d5ec-dccd-4aad-897b-4fdcd7b9f4d4","title":"【自翻】似鸟鸡《叙述性诡计短篇集》——背靠背的恋人（上） - 简书","url":"https://www.jianshu.com/p/c0780af53a72","urlHash":234809507},"0b8db75c-760d-411b-838a-3dcedb8380de":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"0b8db75c-760d-411b-838a-3dcedb8380de","title":"elvis on X: \"LLMs for Mathematical Reasoning Introduces an overview of research developments in LLMs for mathematical reasoning. Discusses advancements, capabilities, limitations, and applications to inspire ongoing research on LLMs for Mathematics. https://t.co/KTRIastE62\" / X","url":"https://twitter.com/omarsar0/status/1753424518171738194?utm_source=substack&utm_medium=email","urlHash":3857025238},"0ba188de-520e-4e91-953e-e76920a2ec43":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"0ba188de-520e-4e91-953e-e76920a2ec43","title":"(1) Yam Peleg on X: \"Paper: Improve a model by training on it's own output. \"How the hell is this even possible?!?!!\" I hear you say. TL;DR: Select only the best generations of an LLM and train on them -&gt; Reinforcing only the \"good parts\" of the model. - By doing this every K training steps you… https://t.co/LHfcATdlVK\" / X","url":"https://twitter.com/Yampeleg/status/1693744585539780998","urlHash":2441442973},"0bb67b91-2579-462e-a5ba-3537985b90c6":{"favIconUrl":"fallback","id":"0bb67b91-2579-462e-a5ba-3537985b90c6","title":"THUYimingLi/backdoor-learning-resources: A list of backdoor learning resources","url":"https://github.com/THUYimingLi/backdoor-learning-resources","urlHash":88484885},"0be7d096-526a-4dc4-a693-51dd5d78a223":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"0be7d096-526a-4dc4-a693-51dd5d78a223","title":"莫比乌斯的圈套 (豆瓣)","url":"https://book.douban.com/subject/27104036/","urlHash":2473768529},"0bf63945-9788-452f-8cea-fc01a3d9f13c":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"0bf63945-9788-452f-8cea-fc01a3d9f13c","title":"T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models | PDF","url":"https://arxiv.org/pdf/2302.08453.pdf","urlHash":135087676},"0c1ae56b-262f-486c-9010-4d8742a77e47":{"favIconUrl":"fallback","id":"0c1ae56b-262f-486c-9010-4d8742a77e47","title":"Online Data Poisoning Attacks","url":"https://proceedings.mlr.press/v120/zhang20b.html","urlHash":1619149073},"0c2278b6-46e1-41b1-a76a-7004fecad37e":{"favIconUrl":"fallback","id":"0c2278b6-46e1-41b1-a76a-7004fecad37e","title":"Fast Text-Conditional Discrete Denoising on Vector-Quantized Latent Spaces - Arxiv-2211.07292","url":"https://arxiv.org/abs/2211.07292","urlHash":2809193253},"0c252931-df21-4114-a54d-163c225aad63":{"favIconUrl":"fallback","id":"0c252931-df21-4114-a54d-163c225aad63","title":"Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling","url":"https://arxiv.org/abs/2304.01373","urlHash":3269901312},"0c3c869c-a205-4fc9-9f81-75632156681e":{"favIconUrl":"fallback","id":"0c3c869c-a205-4fc9-9f81-75632156681e","title":"Why do Nearest Neighbor Language Models Work? - Arxiv-2301.02828","url":"https://arxiv.org/pdf/2301.02828.pdf","urlHash":1703434080},"0c3ea0b7-4086-403d-84cd-dd0b06675faa":{"favIconUrl":"fallback","id":"0c3ea0b7-4086-403d-84cd-dd0b06675faa","title":"Fine-Grained Human Feedback Gives Better Rewards for Language Model Training - Arxiv-2306.01693","url":"https://arxiv.org/abs/2306.01693?utm_source=substack&utm_medium=email","urlHash":2837685975},"0c657f75-83da-4235-a714-d7aa95c2edce":{"favIconUrl":"https://www.youtube.com/s/desktop/4feff1e2/img/favicon_32x32.png","id":"0c657f75-83da-4235-a714-d7aa95c2edce","title":"BLASPHEMOUS 2 All Cutscenes (Full Game Movie) 4K 60FPS Ultra HD - YouTube","url":"https://www.youtube.com/watch?v=3gOgaK3qQdw&t=1041s","urlHash":2488546683},"0c71db51-a4e3-469a-8f49-fe4dc8ebc742":{"favIconUrl":"fallback","id":"0c71db51-a4e3-469a-8f49-fe4dc8ebc742","title":"Copy is all you need","url":"https://mp.weixin.qq.com/s?__biz=Mzk0NzMwNjU5Nw==&mid=2247484860&idx=1&sn=73efa3f0c857395708bbf6153037c52c&exportkey=n_ChQIAhIQJYwl1%2FCQxgTrBZDnBtohIhKWAgIE97dBBAEAAAAAAJGaAH5dW7gAAAAOpnltbLcz9gKNyK89dVj05tYAi2nO2ud18ZfgZjIuD0t5gH9TnAIsfEUzsn6dwCwQ1ovyUxpjcCywhFTCAwHSuALHgpi7p0UT0pjcTVOTwJonosFBDw6ageeKrAvSrt4qO75zRj%2Fq7FDwsN752Hq2erSWDLLA0RkZ9HUrZR8Bx4wgOhC01Z8kzYfdmQ36OxQ%2F782xdMC0bkFPsmzWrurSqOyz%2Bn87SOM5NY47n1UG63s9qeU1YIm%2FSfHxWvYtVZ02oi229lszt3cJidG7h7lUPjN2vYno1lTN6P0fugDbVZZ%2BQKjFk0WjiMvvM3oO2JwdJe8CMC7QTLa46Q5EW37m&acctmode=0&pass_ticket=%2BFphIili%2B1KreJv1lDxc6elAT8BvbeyEV95BhuMgDi6GHDkxPXAXN3DJMsDGkTzR&wx_header=0","urlHash":1608664114},"0c9e16cb-3cd7-4c59-81ea-bc527bf834e5":{"favIconUrl":"fallback","id":"0c9e16cb-3cd7-4c59-81ea-bc527bf834e5","title":"Extending Context is Hard | kaiokendev.github.io","url":"https://kaiokendev.github.io/context","urlHash":3893613320},"0cdfec59-48dc-4604-a783-858733cc01dd":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"0cdfec59-48dc-4604-a783-858733cc01dd","title":"Towards Tracing Factual Knowledge in Language Models Back to the Training Data | Abstract","url":"https://arxiv.org/abs/2205.11482","urlHash":3928242576},"0d027331-433a-4bab-9cc0-3fbe73d735c1":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"0d027331-433a-4bab-9cc0-3fbe73d735c1","title":"rtaori/data_feedback: Code for the paper \"Data Feedback Loops: Model-driven Amplification of Dataset Biases\"","url":"https://github.com/rtaori/data_feedback","urlHash":3892036383},"0d23ed9f-069c-4dd5-9287-dd53e8c16f3f":{"favIconUrl":"fallback","id":"0d23ed9f-069c-4dd5-9287-dd53e8c16f3f","title":"Posters","url":"http://seba1511.net/posters/","urlHash":1890879919},"0d27e46e-728c-48f0-ac4f-e182148c12c9":{"favIconUrl":"fallback","id":"0d27e46e-728c-48f0-ac4f-e182148c12c9","title":"Aran Komatsuzaki on Twitter: \"How Good is Google Bard's Visual Understanding? An Empirical Study on Open Challenges https://t.co/xvL0bL6x8O https://t.co/QtiJHh6T9O\" / X","url":"https://twitter.com/arankomatsuzaki/status/1684728963933822976","urlHash":2841267845},"0d7c4f30-0ee9-4435-9d0f-8d31f09029cc":{"favIconUrl":"fallback","id":"0d7c4f30-0ee9-4435-9d0f-8d31f09029cc","title":"【萝卜日记第31期】所到之处，寸草不生——机动警察PATLABOR - 知乎","url":"https://zhuanlan.zhihu.com/p/149309480","urlHash":4050359297},"0da2e664-df05-4ada-b15d-081b101d4903":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"0da2e664-df05-4ada-b15d-081b101d4903","title":"rl-for-llms.md","url":"https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81","urlHash":950524729},"0de6c6b6-59bd-4369-80c1-b62adb99d3c9":{"favIconUrl":"fallback","id":"0de6c6b6-59bd-4369-80c1-b62adb99d3c9","title":"Denoising Diffusion Models for Plug-and-Play Image Restoration","url":"https://arxiv.org/pdf/2305.08995.pdf","urlHash":1168178943},"0e354e57-1dd3-4c5a-852f-333f3549ca37":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"0e354e57-1dd3-4c5a-852f-333f3549ca37","title":"What the DAAM: Interpreting Stable Diffusion Using Cross Attention | PDF","url":"https://arxiv.org/pdf/2210.04885.pdf","urlHash":2544145654},"0e3c963e-3a74-4772-8cfe-b5cc6f15a3b6":{"favIconUrl":"fallback","id":"0e3c963e-3a74-4772-8cfe-b5cc6f15a3b6","title":"多模态版Llama2上线，Meta发布AnyMAL","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650892042&idx=2&sn=d40da8f48a99fe0f64c3472fffd09a57&exportkey=n_ChQIAhIQmvfza%2FlTlLQ%2FpB%2F9riTkZBKWAgIE97dBBAEAAAAAAK9VEzHCk4kAAAAOpnltbLcz9gKNyK89dVj0WEEdRxJvCRWAXdJXMn2Vif6lIllOdADhVwmafvo8A%2FX6VAbCxzSyualZCFb7K9hr%2BO%2BjxT1a89hlzxPLqXUOlqpUuWoSpPcvrOjKsA8z88c90uLAtk1d7KdZajh5PjK6FBASoXKZFVWle0SBwDgR8bOD9M11Ovyq45DGLr53Uh7Hc2ALUs0pFM0bJJXSqlD8RVlYy8l7UW0hucA9eR5yq7lR6hNhCaScQPC%2B4W0%2FUhfBc78Q0eOylVlNvE8nu1J9MwkWupdsIos2o%2BVbcfA0nyb3osJk6PfuyifII0b8hq4gFlmp3Jq4jvnCXxhGMYWX&acctmode=0&pass_ticket=cnzl9cnGV6OV3kIDFqGJqqAUmT2sWteDO8osgg7SQQif7kVQ0bdlEWD0p83VEM21&wx_header=0","urlHash":1575243522},"0e76b6a7-047f-406b-a4aa-b3fad98386ea":{"favIconUrl":"fallback","id":"0e76b6a7-047f-406b-a4aa-b3fad98386ea","title":"Constitutional AI: Harmlessness from AI Feedback","url":"https://arxiv.org/abs/2212.08073","urlHash":1016491954},"0e8fd0d0-4a84-4417-94ca-3a332f0b1b2b":{"favIconUrl":"fallback","id":"0e8fd0d0-4a84-4417-94ca-3a332f0b1b2b","title":"Learning-from-Data-Solutions/Problems_Chap2.pdf at master · ppaquay/Learning-from-Data-Solutions","url":"https://github.com/ppaquay/Learning-from-Data-Solutions/blob/master/Problems_Chap2.pdf","urlHash":3380057720},"0ec32acd-329f-491e-94e5-c4ffda0c53e9":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"0ec32acd-329f-491e-94e5-c4ffda0c53e9","title":"三百年の謎匣 (豆瓣)","url":"https://book.douban.com/subject/27165658/","urlHash":2228924565},"0ee24cf9-b0af-41dd-b99d-f8677778c676":{"favIconUrl":"fallback","id":"0ee24cf9-b0af-41dd-b99d-f8677778c676","title":"Modular Deep Learning - Arxiv-2302.11529","url":"https://arxiv.org/abs/2302.11529?utm_source=substack&utm_medium=email","urlHash":1881635595},"0f10b87c-68bd-42b1-91ed-643e1fa70552":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"0f10b87c-68bd-42b1-91ed-643e1fa70552","title":"MABEL: Attenuating Gender Bias using Textual Entailment Data | PDF","url":"https://arxiv.org/pdf/2210.14975.pdf","urlHash":1774455779},"0f24ef4b-908a-413d-b163-164a2e0eec5f":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"0f24ef4b-908a-413d-b163-164a2e0eec5f","title":"The Internal State of an LLM Knows When It's Lying | Abstract","url":"https://arxiv.org/abs/2304.13734#:~:text=While%20Large%20Language%20Models%20(LLMs,information%20with%20a%20confident%20tone.","urlHash":433840597},"0f418d09-ffbc-4163-be1a-2319f92e96be":{"favIconUrl":"fallback","id":"0f418d09-ffbc-4163-be1a-2319f92e96be","title":"Thinking like Transformer","url":"https://srush.github.io/raspy/","urlHash":1882014712},"0fbc3d9a-ec3b-44ad-8d25-62360436d3e5":{"favIconUrl":"fallback","id":"0fbc3d9a-ec3b-44ad-8d25-62360436d3e5","title":"Automatic circuit discovery | Arthur’s Site","url":"https://arthurconmy.github.io/automatic_circuit_discovery/","urlHash":3943837480},"0fc5ef45-8a07-44dd-8943-195a464b958e":{"favIconUrl":"fallback","id":"0fc5ef45-8a07-44dd-8943-195a464b958e","title":"https://arxiv.org/pdf/1505.05424.pdf","url":"https://arxiv.org/pdf/1505.05424.pdf","urlHash":640126600},"10048ccb-4ad0-47e1-afb2-fdbfc4021595":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"10048ccb-4ad0-47e1-afb2-fdbfc4021595","title":"Polina Kirichenko on X: \"Excited to share our #NeurIPS paper analyzing the good, the bad and the ugly sides of data augmentation (DA)! DA is crucial for computer vision but can introduce class-level performance disparities. We explain and address these negative effects in: https://t.co/2OPrqNRF9z 1/9 https://t.co/UyQiZfixKe\" / X","url":"https://twitter.com/polkirichenko/status/1733274142810816713","urlHash":1191182645},"102130c1-289f-45aa-816b-fe65430a15ef":{"favIconUrl":"https://blog.langchain.dev/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png","id":"102130c1-289f-45aa-816b-fe65430a15ef","title":"Using Feedback to Improve Your Application: Self Learning GPTs","url":"https://blog.langchain.dev/self-learning-gpts/","urlHash":3530937764},"104ca3d5-e21f-406d-9b29-7620292cc9e3":{"favIconUrl":"fallback","id":"104ca3d5-e21f-406d-9b29-7620292cc9e3","title":"Explaining Patterns in Data with Language Models via Interpretable Autoprompting - Arxiv-2210.01848","url":"https://arxiv.org/abs/2210.01848","urlHash":3264692941},"108382a4-b649-4705-bd08-db90f7076f4b":{"favIconUrl":"fallback","id":"108382a4-b649-4705-bd08-db90f7076f4b","title":"malach20a.pdf","url":"https://proceedings.mlr.press/v119/malach20a/malach20a.pdf","urlHash":3595038854},"1113ec32-7d4f-4495-b64a-4218f79f94f4":{"favIconUrl":"https://www.google.com/favicon.ico","id":"1113ec32-7d4f-4495-b64a-4218f79f94f4","title":"里有数之人-米泽穗信《绕远路的雏人偶》 - Google Search","url":"https://www.google.com/search?q=%E9%87%8C%E6%9C%89%E6%95%B0%E4%B9%8B%E4%BA%BA-%E7%B1%B3%E6%B3%BD%E7%A9%97%E4%BF%A1%E3%80%8A%E7%BB%95%E8%BF%9C%E8%B7%AF%E7%9A%84%E9%9B%8F%E4%BA%BA%E5%81%B6%E3%80%8B","urlHash":3990479672},"114f1e19-b17e-4cf5-9d20-f84ae3dc880d":{"favIconUrl":"fallback","id":"114f1e19-b17e-4cf5-9d20-f84ae3dc880d","title":"无监督分词和句法分析！原来BERT还可以这样用 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/7476","urlHash":1994812270},"1159066d-f3e9-49f9-98f4-eb32be1f1943":{"favIconUrl":"fallback","id":"1159066d-f3e9-49f9-98f4-eb32be1f1943","title":"MIT Deep Learning Blogs ·","url":"https://minyoungg.github.io/MIT-deeplearning-blogs/blog/","urlHash":383112564},"115ff84a-747d-497b-890d-ab8cd058017a":{"favIconUrl":"fallback","id":"115ff84a-747d-497b-890d-ab8cd058017a","title":"on “learning to summarize” — LessWrong","url":"https://www.lesswrong.com/posts/5YaCtuSZzCNywgHrb/on-learning-to-summarize","urlHash":1201821500},"11729846-ebee-429a-9d18-e26e159a47aa":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"11729846-ebee-429a-9d18-e26e159a47aa","title":"大模型训练loss突刺原因和解决办法","url":"https://mp.weixin.qq.com/s?__biz=MzIwNDY1NTU5Mg==&mid=2247487501&idx=1&sn=d5ccc0a112e0e534332fc665041d9a33&chksm=973d8e8aa04a079c6db9c221796b3f36120ab80a3b125dd75c078d307302352dbf1774dbf9be&mpshare=1&scene=1&srcid=01159mB1PCESM37fikXS6o48&sharer_shareinfo=888969bb0aeb18be0e6fa33beb4afbc7&sharer_shareinfo_first=888969bb0aeb18be0e6fa33beb4afbc7&exportkey=n_ChQIAhIQzZFyUaxM9ZUxr291wzqWlBKWAgIE97dBBAEAAAAAAKo4BSU%2F09QAAAAOpnltbLcz9gKNyK89dVj0MTVyv83yZ%2F3LXx5BE6vwU2XGy29rjchxK4IC0WzqfrufrsRUpN8yev7I39AeQHaubd%2BsGAPfjfHpcyELhKMqAC%2Bu4UUlPcgKdk1MDY3N5A%2BoUFHWkIXgyXnPXfHH9qeqMdwEMVnBucyEto188olDNwncSY0N5U607nwJy1Fd24UGX%2FMxjmwGyYbLCNU3LJC5CDNaAeg%2BBFFDwyevGAqcDVc%2FxPrrcQMETq3IUmAfmaVIDIy3POAJ5JOgnHbIFq1hr%2FlVhhmckQp6upi1Sb2hgJMk8vJzBLDfdGS9TGJrBe%2FLj5r5hpsSAHNkD03X0FQ6&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsbPH9SoXtNXq95Zd16WBCbl4wTppTS3ImU%2FUQnPC5ajPQ%3D%3D&wx_header=0#rd","urlHash":1784887691},"117ae7d8-af9b-45aa-bb58-2581c77e61bd":{"favIconUrl":"fallback","id":"117ae7d8-af9b-45aa-bb58-2581c77e61bd","title":"觉醒年代中的好文章整理 - 知乎","url":"https://www.zhihu.com/column/c_1387802014982762496","urlHash":3976004274},"11970262-5841-41c7-9697-9ed770e35b83":{"favIconUrl":"fallback","id":"11970262-5841-41c7-9697-9ed770e35b83","title":"factscore.pdf","url":"https://martiansideofthemoon.github.io/assets/factscore.pdf","urlHash":3622291441},"12180479-1f1c-47e7-8eef-14a0c11ad796":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"12180479-1f1c-47e7-8eef-14a0c11ad796","title":"The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning | PDF","url":"https://arxiv.org/pdf/2205.03401.pdf","urlHash":335778792},"12434817-9863-41ad-ba20-8d8c1ef09d43":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"12434817-9863-41ad-ba20-8d8c1ef09d43","title":"Efficiently Modeling Long Sequences with Structured State Spaces | PDF","url":"https://arxiv.org/pdf/2111.00396.pdf","urlHash":3361365394},"125de8f2-3be8-45b4-a0c7-3f0ee9eec0cf":{"favIconUrl":"fallback","id":"125de8f2-3be8-45b4-a0c7-3f0ee9eec0cf","title":"A Report for An Academy by Franz Kafka","url":"https://www.kafka-online.info/a-report-for-an-academy.html","urlHash":2635128920},"12732f08-a17c-427e-ae58-6d55ff2068df":{"favIconUrl":"fallback","id":"12732f08-a17c-427e-ae58-6d55ff2068df","title":"Surface Form Competition Why the Highest Probability Answer Isn't Always Right - Arxiv-2104.08315","url":"https://arxiv.org/pdf/2104.08315.pdf","urlHash":72700574},"129206dd-6c52-4972-8a1f-c4d4757b9751":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"129206dd-6c52-4972-8a1f-c4d4757b9751","title":"Vision Transformers Need Registers | Abstract","url":"https://arxiv.org/abs/2309.16588?utm_source=substack&utm_medium=email","urlHash":2021692541},"12921cfe-c23c-4a9d-a0d7-893968b0fe05":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"12921cfe-c23c-4a9d-a0d7-893968b0fe05","title":"The Rise and Potential of Large Language Model Based Agents: A Survey | PDF","url":"https://arxiv.org/pdf/2309.07864.pdf","urlHash":3419928637},"12994b68-40fa-4dbc-a655-c5bbb4b5ca6d":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"12994b68-40fa-4dbc-a655-c5bbb4b5ca6d","title":"AK on X: \"Describing Differences in Image Sets with Natural Language paper page: https://t.co/BW5hZRCWgG How do two sets of images differ? Discerning set-level differences is crucial for understanding model behaviors and analyzing datasets, yet manually sifting through thousands of… https://t.co/Ym9uTZHCHy\" / X","url":"https://twitter.com/_akhaliq/status/1732220818556408137","urlHash":3593493462},"12c2f774-867d-4618-9072-00d61cfc38b6":{"favIconUrl":"fallback","id":"12c2f774-867d-4618-9072-00d61cfc38b6","title":"Distilling Multi-Step Reasoning Capabilities of Large Language Models into Smaller Models via Semantic Decompositions - Arxiv-2212.00193","url":"https://arxiv.org/pdf/2212.00193.pdf","urlHash":3206055938},"12ddf44c-8548-49e9-be9a-1e3f146a2a0f":{"favIconUrl":"https://plato.stanford.edu/favicon.ico","id":"12ddf44c-8548-49e9-be9a-1e3f146a2a0f","title":"Montague Semantics (Stanford Encyclopedia of Philosophy)","url":"https://plato.stanford.edu/entries/montague-semantics/","urlHash":3967742629},"130bf118-4946-46b1-9b5c-a8cc188588a5":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"130bf118-4946-46b1-9b5c-a8cc188588a5","title":"Aran Komatsuzaki on X: \"ODIN: Disentangled Reward Mitigates Hacking in RLHF Almost eliminates the reward correlation with length, and improves the obtained policy by a significant margin https://t.co/C8OKZh37xK https://t.co/IfYeZqaffa\" / X","url":"https://twitter.com/arankomatsuzaki/status/1757240002222727234","urlHash":2732434483},"131cdd64-e5ce-43eb-875a-c3b5264fc545":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"131cdd64-e5ce-43eb-875a-c3b5264fc545","title":"elvis on X: \"Knowledge-Augmented Planning for LLM Agents Proposes an approach to enhance the planning capabilities of LLMs through explicit action knowledge. It uses an action knowledge base and a knowledgeable self-learning phase to guide the model's action generation, mitigate planning… https://t.co/eKT002P9Dx\" / X","url":"https://twitter.com/omarsar0/status/1765408813467759037?utm_source=substack&utm_medium=email","urlHash":2203569988},"131f824d-008a-4bff-b82b-64c91d98a41f":{"favIconUrl":"fallback","id":"131f824d-008a-4bff-b82b-64c91d98a41f","title":"Out-of-Domain Robustness via Targeted Augmentations","url":"https://arxiv.org/pdf/2302.11861.pdf","urlHash":1668223418},"13393972-aa6f-4432-986a-4f23907c9b31":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"13393972-aa6f-4432-986a-4f23907c9b31","title":"AK on X: \"Are Emergent Abilities of Large Language Models a Mirage? present explanation in a simple mathematical model, then test it in three complementary ways: (1) make, test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with… https://t.co/BYDbDvqO62\" / X","url":"https://twitter.com/_akhaliq/status/1652871006208286720","urlHash":56526916},"133e3545-cce5-40c3-8eb5-c2f047fee752":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"133e3545-cce5-40c3-8eb5-c2f047fee752","title":"twitter.com/ChengleiSi/status/1666983953176174592","url":"https://twitter.com/ChengleiSi/status/1666983953176174592","urlHash":2205453027},"134eeb60-b073-4c8a-a94f-77aa84328818":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"134eeb60-b073-4c8a-a94f-77aa84328818","title":"Julie Kallini ✨ on X: \"Do LLMs learn impossible languages (that humans wouldn’t be able to acquire) just as well as they learn possible human languages? We find evidence that they don’t! Check out our new paper… 💥 Mission: Impossible Language Models 💥 ArXiv: https://t.co/6Xp2GtSabI 🧵 https://t.co/sE3NnWZgoj\" / X","url":"https://twitter.com/JulieKallini/status/1746992945738526985","urlHash":1749553897},"13850090-1bd6-4d44-80af-60cbc0b11f58":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"13850090-1bd6-4d44-80af-60cbc0b11f58","title":"AgentTuning: Enabling Generalized Agent Abilities for LLMs | Abstract","url":"https://arxiv.org/abs/2310.12823","urlHash":1405413746},"1388392c-06a6-456c-b82b-d62405a2c894":{"favIconUrl":"fallback","id":"1388392c-06a6-456c-b82b-d62405a2c894","title":"Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post Hoc Explanations - Arxiv-2206.01254","url":"https://arxiv.org/abs/2206.01254","urlHash":316126160},"13988548-5e81-4b3a-bd6f-d1220538838f":{"favIconUrl":"fallback","id":"13988548-5e81-4b3a-bd6f-d1220538838f","title":"How Robust are Randomized Smoothing based Defenses to Data Poisoning?","url":"https://arxiv.org/pdf/2012.01274.pdf","urlHash":1630797165},"13edbf9b-3efb-4789-b303-22f1841d375a":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"13edbf9b-3efb-4789-b303-22f1841d375a","title":"Estimating Large Language Model Capabilities without Labeled Test Data | PDF","url":"https://arxiv.org/pdf/2305.14802.pdf","urlHash":2771063623},"13f7c20c-fbdf-4c2f-a95b-fb063e2d6057":{"favIconUrl":"fallback","id":"13f7c20c-fbdf-4c2f-a95b-fb063e2d6057","title":"Lil'Log","url":"https://lilianweng.github.io/page/2/","urlHash":3401310067},"14002a12-6311-4e0f-9589-7fe8ca1bbdcc":{"favIconUrl":"fallback","id":"14002a12-6311-4e0f-9589-7fe8ca1bbdcc","title":"BEM 101","url":"https://css-tricks.com/bem-101/","urlHash":2144287586},"143ad6d5-c484-4d8f-94f0-fd32e529529f":{"favIconUrl":"fallback","id":"143ad6d5-c484-4d8f-94f0-fd32e529529f","title":"On the Efficacy of Adversarial Data Collection for Question Answering Results from a Large-Scale Randomized Study - Arxiv-2106.00872","url":"https://arxiv.org/pdf/2106.00872.pdf","urlHash":4246127400},"144066c3-7892-4416-ae64-20bd03c492ab":{"favIconUrl":"fallback","id":"144066c3-7892-4416-ae64-20bd03c492ab","title":"CS 285","url":"https://rail.eecs.berkeley.edu/deeprlcourse/","urlHash":3164723348},"1462ece9-22fa-4cd1-a1f5-cc71c53a1243":{"favIconUrl":"fallback","id":"1462ece9-22fa-4cd1-a1f5-cc71c53a1243","title":"图神经网络框架-PyTorch Geometric（PyG）的使用及踩坑","url":"https://posts.careerengine.us/p/6196f6ecae2a98248ad5e6c0","urlHash":3025361602},"1467313f-64d6-4834-8223-dbd96d89a06d":{"favIconUrl":"fallback","id":"1467313f-64d6-4834-8223-dbd96d89a06d","title":"Self-Supervised Representation Learning","url":"https://lilianweng.github.io/posts/2019-11-10-self-supervised/","urlHash":4182800922},"146eed5b-eedf-4888-aee2-7051c76f6467":{"favIconUrl":"fallback","id":"146eed5b-eedf-4888-aee2-7051c76f6467","title":"Meta-Learning Fast Weight Language Models - Arxiv-2212.02475","url":"https://arxiv.org/abs/2212.02475","urlHash":439878600},"14b4373e-57fa-480b-94be-12273b209192":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"14b4373e-57fa-480b-94be-12273b209192","title":"Transformers Agents","url":"https://huggingface.co/docs/transformers/main/transformers_agents","urlHash":3475786561},"14ef4e62-897c-4f3f-834c-1e0064845ef4":{"favIconUrl":"https://www.youtube.com/s/desktop/7ea5dfab/img/favicon_32x32.png","id":"14ef4e62-897c-4f3f-834c-1e0064845ef4","title":"(11) A Walkthrough of Interpretability in the Wild Part 1/2: Overview (w/ authors Kevin, Arthur, Alex) - YouTube","url":"https://www.youtube.com/watch?v=gzwj0jWbvbo","urlHash":1356609756},"1500ce16-bce9-4200-9c71-51a8289b88a6":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"1500ce16-bce9-4200-9c71-51a8289b88a6","title":"Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets | PDF","url":"https://arxiv.org/pdf/2203.12942.pdf","urlHash":1598610094},"150431fa-6511-4c2d-9e83-51664e9c0155":{"favIconUrl":"https://www.google.com/favicon.ico","id":"150431fa-6511-4c2d-9e83-51664e9c0155","title":"忧郁的热带 - Google Search","url":"https://www.google.com/search?q=%E5%BF%A7%E9%83%81%E7%9A%84%E7%83%AD%E5%B8%A6&oq=%E5%BF%A7%E9%83%81%E7%9A%84%E7%83%AD%E5%B8%A6&aqs=chrome.0.0i355i512j46i512j0i512l8.2213j0j1&sourceid=chrome&ie=UTF-8","urlHash":684765284},"151da54b-93d3-48a1-a6c0-139483b36949":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"151da54b-93d3-48a1-a6c0-139483b36949","title":"ICLR2024 | 分享 8篇Spotlight论文，涉及多模态大模型、大模型优化、RLHF等热门话题！","url":"https://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&mid=2247497364&idx=1&sn=fa19f0a73152df22cac225c5b0c52fc7&chksm=fac06148cdb7e85e66461ef39de2324ba2c3f6350d31b06c08e409f354fe776ba7de0d69645b&mpshare=1&scene=1&srcid=0120BkBHLbfV9ZCFbppGb3n3&sharer_shareinfo=a96da8301c2a672e41a1228500a82b55&sharer_shareinfo_first=a96da8301c2a672e41a1228500a82b55&exportkey=n_ChQIAhIQ0Y54tYRAIBXi6gI%2Bemn6phKWAgIE97dBBAEAAAAAAD4rBEwAs3QAAAAOpnltbLcz9gKNyK89dVj0nwLWYxoiOnl6JdQxa9goBT%2FA%2BhIlrxOzb2GIQ4AK%2BDaBxfcyLptmEnYrcuscXsggIFtc5va120R4OYbzM%2BHYGN9uNRekU6g%2Fa0S2OaAoCD77hBMUkKTfmOTuL7vJ8s57QbuhsHWukAiiGgWVp9B6d0%2BTx6rV8T9ghUOllYsGcX9FnodxNCvupEnI%2FQXqCCrt7S%2B4CuxjdL6wrTeJq8KTcmLfosC7NHzxpAfaNxbHUSOfAh3YRQ9N%2B1sgROBvHRRTfGkqaKfh1FZ1VA3smD4WRTAhi9%2F%2F2xChOSvzuVdzaPb%2FpfdprR7IUZqW90DEczi6&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HPepN3%2Bjj4Z0kCMS7U%2F8wzNxXhCXu7xueEEa5w38hGYiQ%3D%3D&wx_header=0#rd","urlHash":1190753338},"153d6b74-cad0-4d06-8e01-4f116df28e45":{"favIconUrl":"fallback","id":"153d6b74-cad0-4d06-8e01-4f116df28e45","title":"也来盘点一些最近的非Transformer工作 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/8431","urlHash":27703443},"1565578b-a1fc-4474-87fc-3dc1d17fc55f":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"1565578b-a1fc-4474-87fc-3dc1d17fc55f","title":"复旦NLP团队发布80页大模型Agent综述，一文纵览AI智能体的现状与未来","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650890550&idx=1&sn=b92ded779dfc401aaacf00a68e32e916&exportkey=n_ChQIAhIQdNtnC1zMZTIr3QXOQOaSeRKWAgIE97dBBAEAAAAAAGqxJQKZBvoAAAAOpnltbLcz9gKNyK89dVj0XvI%2FXPz7avZ4dSOO11t%2FHIfOK46XXmtaTcxRPeF17Ryg6X33YRa%2B3hCUtphUT6TzfrPBqERuQqsSkYiRzDTdYXwoMJGDJJ5O4jM1jeJkzaPNMN3hubOPoAPNhSEFQ1xdsAhNA9Lf8JBw5UzHU9hsfeMi0vfsXN%2BMm5BTn9MkZNt42omd8AxWh4cqivVgjT%2B05djep312WQFMjkkSmWrhi3cl98jq5cEe5AXaWtp2UZ14Y6OWnWH6tuR6KynNZeKtfUG3ipyK951JLrJGCXiramiuYvN9ZjEoFnCYcL0pxx15B454vUz86gsMc450vre1&acctmode=0&pass_ticket=WMVsjRG1OwocTlioPBUtkEV7LJYl7HIrRS6AFIknA%2BJfTu4UODHPkja0lGUETocd&wx_header=0","urlHash":1954446874},"156a830c-46a1-44c0-a044-b6f500e61134":{"favIconUrl":"https://dynalist.io/assets/icon/favicon.ico","id":"156a830c-46a1-44c0-a044-b6f500e61134","title":"The Indirect Object Identification Circuit - A Comprehensive Mechanistic Interpretability Explainer & Glossary - Dynalist","url":"https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=iWsV3s5Kdd2ca3zNgXr5UPHa","urlHash":3580899246},"1587cfad-6446-4ecc-8469-cb0d57cd80be":{"favIconUrl":"fallback","id":"1587cfad-6446-4ecc-8469-cb0d57cd80be","title":"Ethical and social risks of harm from Language Models - Arxiv-2112.04359","url":"https://arxiv.org/pdf/2112.04359.pdf","urlHash":4053790183},"15ed8a65-8f38-4db5-8fc2-aa690473cbb6":{"favIconUrl":"fallback","id":"15ed8a65-8f38-4db5-8fc2-aa690473cbb6","title":"万字长文带你全面解读视觉大模型","url":"https://mp.weixin.qq.com/s?__biz=MzU1MzY0MDI2NA==&mid=2247503454&idx=1&sn=e7c282d3d205433676b3a13176bd0b11&exportkey=n_ChQIAhIQTsvVdf1Y1K5Sii7SBYVJZxKWAgIE97dBBAEAAAAAAPljBegHa4kAAAAOpnltbLcz9gKNyK89dVj09HI0DX%2Fp0YAiJjvXbSdQk%2Bgk0HfXlZxJgSR6BFOuWSnTwat0RBq2nW5p43MzF35TTs7UluyXAdYpeiRWl1iDpfa%2BOnOT0JW%2FQzUOpv8zhoqoWhmVYjRkP6R5T%2Ft779AWdp5jHtqYSyfErZJ9qpK6kooY2HVsYE8Qvj%2BCP8RVCnz1pwBEUGF5fqfWFeKLLFzzIi0%2FSJjTNo9Qm%2BMv1sVqHudkyuy%2FrMX5rtpqTP69w4CgXVOdJyfhXa4secadofZXstnulUxKrTxWjNbk8Q2c5CL4W%2BGPHANfsFivype8fkvlLEz5ztqnX3rDN3X%2FOdPY&acctmode=0&pass_ticket=z2R2VQmzV4dfoOARD8CBhQHfeP1bobgycPf2GuHmouX4AshVT9MJBDXxnqaU72qh&wx_header=0","urlHash":1335882807},"15f901a2-98ab-4a28-89c4-0327f866aadf":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"15f901a2-98ab-4a28-89c4-0327f866aadf","title":"LLaMA Pro: Progressive LLaMA with Block Expansion | Abstract","url":"https://arxiv.org/abs/2401.02415?utm_source=substack&utm_medium=email","urlHash":763211304},"15f9b05d-a01b-422c-a533-06998a8a698d":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/favicon-32x32.png","id":"15f9b05d-a01b-422c-a533-06998a8a698d","title":"Reddit - Dive into anything","url":"https://www.reddit.com/r/LocalLLaMA/comments/18x8g6c/llm_maybe_longlm_selfextend_llm_context_window/","urlHash":2579367552},"162530b0-c288-42f1-9ed6-5896e008bdbe":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"162530b0-c288-42f1-9ed6-5896e008bdbe","title":"OpenAI破解对齐难题？超级对齐负责人Jan Leike采访实录：「可扩展监督」是良策","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652391793&idx=3&sn=621ed1ca927bc0ba1321264a11baefc5&chksm=f12b3d80c65cb496c6165ee5289aaccbb91fb5344400543fd9b79fd017fe06625157341d2b0d&mpshare=1&scene=1&srcid=0115TvxvaRrdMLgfVYoyb8T9&sharer_shareinfo=d8aa9fbfba2c6761ed64d69f5832f94d&sharer_shareinfo_first=d8aa9fbfba2c6761ed64d69f5832f94d&exportkey=n_ChQIAhIQs%2F0IjThtmAzbIDj%2FxzVZ5hKWAgIE97dBBAEAAAAAAOFUKMAr4rwAAAAOpnltbLcz9gKNyK89dVj0BvtImF0aD9Tssqi%2FgiANtlna%2FuoyTh3ApvbVkjnh08MESohClQvgk0M1x%2B93P1C2j4cvfIMxzQ%2FS3OPuFMciLuP6gLzjFgLmJca7ypTcbC4EYDMQRoLlUWkbBvfA3z1SzECAEhp5UzmaltIgNGCLEdQ2EsMe%2BDvm%2BED3LZMIgEV7g%2BnMMCZNl8mS3Gl%2BXUCudx0OoezpEXMplhqLp2aRiEw6ub1bAgadCJd763oswM3ODvCC9DViiWKhY4Zxsyy%2BKQFCZO2qAILynphycv5DX0Xpz6LfAYBCBMy7TZzeoi2nzHHeelaDXRWIlfoD9K1f&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsaFmopsQrkUHP8TJCo2qUyhpOk5wYo00ajM9y4TK5SShA%3D%3D&wx_header=0#rd","urlHash":532020291},"162ef0ca-b83f-4af0-bf8e-0c3b4c4e4b26":{"favIconUrl":"fallback","id":"162ef0ca-b83f-4af0-bf8e-0c3b4c4e4b26","title":"opendilab/awesome-diffusion-model-in-rl: A curated list of Diffusion Model in RL resources (continually updated)","url":"https://github.com/opendilab/awesome-diffusion-model-in-rl","urlHash":2680724817},"16340caf-e8eb-4391-b562-44c101a25cda":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"16340caf-e8eb-4391-b562-44c101a25cda","title":"(1) hardmaru on X: \"Promptbreeder: Self-Referential Self-Improvement via Prompt Evolution Get LLMs to invent their own mutation operators for evolving prompts. Outperforms Chain-of-Thought and Plan-and-Solve and gets SOTA on a bunch of stuff! 🔥 @chrisantha_f et al. 🐛🧠🪲 https://t.co/Djo1WukrrY https://t.co/NUPJhcPEoG\" / X","url":"https://twitter.com/hardmaru/status/1713026730888511738","urlHash":3622977876},"166a42c3-13d2-4fee-bd2c-3dd97f7bfb01":{"favIconUrl":"https://www.google.com/favicon.ico","id":"166a42c3-13d2-4fee-bd2c-3dd97f7bfb01","title":"园田修一郎《 作者よ欺かるるなかれ 》 - Google Search","url":"https://www.google.com/search?q=%E5%9B%AD%E7%94%B0%E4%BF%AE%E4%B8%80%E9%83%8E%E3%80%8A%20%E4%BD%9C%E8%80%85%E3%82%88%E6%AC%BA%E3%81%8B%E3%82%8B%E3%82%8B%E3%81%AA%E3%81%8B%E3%82%8C%20%E3%80%8B","urlHash":3054328253},"168cf37c-3c7e-431d-88bf-d6b8ac8fc6cd":{"favIconUrl":"https://www.99csw.com/favicon.ico","id":"168cf37c-3c7e-431d-88bf-d6b8ac8fc6cd","title":"唯一正确的时钟_法月纶太郎_在线阅读_九九藏书网","url":"https://www-99csw-com.translate.goog/book/6098/index.htm?_x_tr_sl=zh-CN&_x_tr_tl=en&_x_tr_hl=en&_x_tr_pto=sc","urlHash":1976929821},"16b153b3-be0f-4fc5-8104-4111850909d3":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"16b153b3-be0f-4fc5-8104-4111850909d3","title":"中文数据让LLM变笨？","url":"https://mp.weixin.qq.com/s?__biz=MzIwNDY1NTU5Mg==&mid=2247487730&idx=1&sn=90d266b678d6cd0443163babf0a83a0b&chksm=973d8e75a04a076381d6e7643b62306d864cc44228413bb1b0f87597cbb48192728b9b9337f2&mpshare=1&scene=1&srcid=0125LbQwYARHb2mVjfpftmQh&sharer_shareinfo=1b9f1ecbcde943ad37d1d515668d04e7&sharer_shareinfo_first=1b9f1ecbcde943ad37d1d515668d04e7&exportkey=n_ChQIAhIQNOxpnL43MjaVwT62GBlwdhKWAgIE97dBBAEAAAAAAM5CNnS4s1YAAAAOpnltbLcz9gKNyK89dVj0J%2Bh06qHYXeAF1%2BpWePm4WJCAls5OcUmjYBYYx2thp63jqn3NfKnBjY8KwWXz7%2BrxnPehoNRU%2FjSus2Mq8scuusfzSXtQTxaQaG8JdA%2F6jw2K%2B%2FSNyWib2siUYvG9FVRJQ5ZKbnp8fEcdcciaE6pQLejKxAGYLPIcpVbvMSsvjXqunqjiISiNfjsmWdQGP65912%2BsdxE2TFkESquLfofYjNdhcaXAr3b7qBOv3bJQyvIidXPol0GUqJnFPLn8sgxr1%2BpV2nFr4t5nEZlDOGz5Nl8bMqYK7OieR9LwyBjTpjpaGHjUt4QURjG3X0wiGOn9&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HNwdRq67A0HTirM%2FAIbn1jzjFmDolkh9qt6GhdiOj3YmQ%3D%3D&wx_header=0#rd","urlHash":3513942017},"16c430d1-9864-4b00-b7df-9f7f8e6abf40":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"16c430d1-9864-4b00-b7df-9f7f8e6abf40","title":"计算机视觉GPT时刻！UC伯克利三巨头祭出首个纯CV大模型，推理惊现AGI火花","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652414572&idx=1&sn=551cca6014bf26ebd5c67986eb4154bf&chksm=f12bd69dc65c5f8bc3e66921bc4c3be0ab97d90b926dccbbdada94062f8e9832d69221c644d8&mpshare=1&scene=1&srcid=0115SFQKrCrzqztFq9NurWus&sharer_shareinfo=137a100b1bb9076eca8196655f4cffb2&sharer_shareinfo_first=137a100b1bb9076eca8196655f4cffb2&exportkey=n_ChQIAhIQTgmuVuJgJZk%2BZAbUCH1%2FrhKWAgIE97dBBAEAAAAAAM5NCMt8kDMAAAAOpnltbLcz9gKNyK89dVj03n1V2zy0XJ4F%2Fx%2F6pkRtFkB9fNR6fm9hA8R0HvVfrCFCUak3Xv8U3oyqhNxSUAhIxb7hjJ1H7NlFRemsTgClDul5x2s0Su7srfgF%2FnrYOfel8%2FAgiPCWAoOS%2FmWQ6gOnD2KzyhuDsrJM7Pxgkawq2NtN8qnWdb4mjqwoV1tXHQTqS2G9HGrPpMGZXfeEfUtDnzl1xHHBsclHBkCpoPYQkv7ZQmtzrHshJ4aT%2Bu3v08m0XlpRLexY%2FNkwEfVSJ%2FORWSzGykzmvGInsHFD%2FJNgrkHgOs9E4cAHoMGcWpVVE2c%2BqkbUr6ZLyQilekzYdWVC&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsYH1VOCf84H8ED2HfNAZHLC%2Fz4q1MX9QtimizPZlkVLxw%3D%3D&wx_header=0#rd","urlHash":2379137372},"16f3dd59-d9b6-4efc-be80-edb1c165638a":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"16f3dd59-d9b6-4efc-be80-edb1c165638a","title":"被GPT带飞的In-Context Learning为什么起作用？模型在秘密执行梯度下降","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650864545&idx=2&sn=cba397f55eb950da0fd794ae67c5c050&chksm=84e53fdfb392b6c9e2a7e360ac6d61c174691bdfdf5641f25d6caeb6adca80c5e99b50651b67&mpshare=1&scene=1&srcid=011696retelBJro4j4DxJL0z&sharer_sharetime=1673842926153&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQyKpMkoydhR1O%2BR%2F5UIzinxKWAgIE97dBBAEAAAAAAKwuJ5WrLbsAAAAOpnltbLcz9gKNyK89dVj0tmoDHRRqo5kCj1Qv6bIEUtpG4xo7EVvv3iX%2Fb%2F8ozFmXeTvuvF9AaSh9kW6WsLa%2FWB%2B76MBcF60gaqPc4l0N3blv5CteML7PYB3LTqPUyuDkoY%2Fvefn87kOdnxmJ0LiWlaaiInoQ02OR4Nexh5xgpBwqkk7iQ4zBSz97fqoxYOKDWc6G8Wz0oouXZsBZtmjIAQQAJGP1GVpBVQMG17nU4cBfribHme7ypaBgS62buxbF0aBdf7rl%2BWvaCgmOcbJ1GOLTfAoqR6jCXE3wSNqND2ULHi70SLiZfmqkBiTNld8UpSlna9WMJtSwAGeaCUr%2B&acctmode=0&pass_ticket=3HIlKyjzTAFL%2FxFljj2tEtyLfkTobYOBU23FblbSLUrq2L6n%2FO86L57931qjUdyQl6P4jx9HpLS6%2FHWr%2BWDmUQ%3D%3D&wx_header=0#rd","urlHash":821324472},"16f6e5b1-df51-44d9-8570-a3067c564407":{"favIconUrl":"fallback","id":"16f6e5b1-df51-44d9-8570-a3067c564407","title":"Hierarchically Structured Meta-learning - Arxiv-1905.05301","url":"https://arxiv.org/pdf/1905.05301.pdf","urlHash":2838420066},"170c7de1-15c4-48be-9012-eb278a99c009":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"170c7de1-15c4-48be-9012-eb278a99c009","title":"Phillip Isola on X: \"This looks like one of those results that marks a phase transition in science: for years people have anticipated that synthetic data would eventually outperform / boost real, but an imagenet scale result has been elusive. Finally models are good enough that it works!\" / X","url":"https://twitter.com/phillip_isola/status/1648153015621242885","urlHash":4167506238},"171258d2-38db-4432-87de-7427093dd3ab":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"171258d2-38db-4432-87de-7427093dd3ab","title":"(1) elvis on X: \"Indirect Reasoning with LLMs Chain-of-thought (CoT) prompting and Self-Consistency follow direct reasoning frameworks to improve the performance of LLMs. While powerful in eliciting reasoning in LLMs, these techniques are often not enough for real-world tasks. To address… https://t.co/WIQKtuw8Ia\" / X","url":"https://twitter.com/omarsar0/status/1755254627866419707?utm_source=substack&utm_medium=email","urlHash":100910002},"171619a2-215b-4857-b653-9410075dd063":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"171619a2-215b-4857-b653-9410075dd063","title":"Mooler0410/LLMsPracticalGuide: A curated list of practical guide resources of LLMs (LLMs Tree, Examples, Papers)","url":"https://github.com/Mooler0410/LLMsPracticalGuide","urlHash":228595747},"173c264e-9209-429c-a1a1-653146da87bc":{"favIconUrl":"fallback","id":"173c264e-9209-429c-a1a1-653146da87bc","title":"JSC370 Data Science","url":"https://jsc370.github.io/","urlHash":1643488060},"174c4177-83cc-4b0d-8459-5f7954894095":{"favIconUrl":"fallback","id":"174c4177-83cc-4b0d-8459-5f7954894095","title":"chong-z/nlp-second-order-attack: [NAACL 2021] Code for \"Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation\"","url":"https://github.com/chong-z/nlp-second-order-attack","urlHash":1172140734},"175a513b-5b22-4817-8982-521a7ba24146":{"favIconUrl":"fallback","id":"175a513b-5b22-4817-8982-521a7ba24146","title":"BERTopic - BERTopic","url":"https://maartengr.github.io/BERTopic/api/bertopic.html","urlHash":352550152},"17630fd7-d8a0-491e-8c95-a6076e8cec40":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"17630fd7-d8a0-491e-8c95-a6076e8cec40","title":"PanQiWei/AutoGPTQ: An easy-to-use LLMs quantization package with user-friendly apis, based on GPTQ algorithm.","url":"https://github.com/PanQiWei/AutoGPTQ","urlHash":1937209074},"177d045b-f66b-4bdc-8c47-1619ffae4879":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"177d045b-f66b-4bdc-8c47-1619ffae4879","title":"elvis on X: \"Corrective RAG Proposes Corrective Retrieval Augmented Generation (CRAG) to improve the robustness of generation in a RAG system. The core idea of this paper is to implement a self-correct component for the retriever and improve the utilization of retrieved documents for… https://t.co/3AkCGwoENb\" / X","url":"https://twitter.com/omarsar0/status/1752173216942944556","urlHash":469891518},"17904826-a4dc-4e91-9401-3a0030a69225":{"favIconUrl":"fallback","id":"17904826-a4dc-4e91-9401-3a0030a69225","title":"An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models - ACL-ACL-2022_2022.acl-long.132","url":"https://aclanthology.org/2022.acl-long.132/","urlHash":3059786398},"179d842c-af1f-4bbe-8333-a18f8417df0f":{"favIconUrl":"fallback","id":"179d842c-af1f-4bbe-8333-a18f8417df0f","title":"Retrieval-Augmented Multimodal Language Modeling - Arxiv-2211.12561","url":"https://arxiv.org/pdf/2211.12561.pdf","urlHash":2931378193},"17a01d3b-5269-4865-b65a-b2e5b4228fce":{"favIconUrl":"fallback","id":"17a01d3b-5269-4865-b65a-b2e5b4228fce","title":"Harry24k/bayesian-neural-network-pytorch: PyTorch implementation of bayesian neural network.","url":"https://github.com/Harry24k/bayesian-neural-network-pytorch","urlHash":3528647978},"17a60040-f88f-48bb-a70a-b59b7ef8e52d":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"17a60040-f88f-48bb-a70a-b59b7ef8e52d","title":"ジョン・ディクスン・カーの最終定理 (豆瓣)","url":"https://book.douban.com/subject/35152470/","urlHash":762468700},"17e35b99-90bc-45d3-b87b-6b88d79225d2":{"favIconUrl":"fallback","id":"17e35b99-90bc-45d3-b87b-6b88d79225d2","title":"Run Error · Issue #6 · neulab/RIPPLe","url":"https://github.com/neulab/RIPPLe/issues/6","urlHash":2591285155},"18030260-7ef8-4f38-95d1-c3309b1d1b4c":{"favIconUrl":"fallback","id":"18030260-7ef8-4f38-95d1-c3309b1d1b4c","title":"Raise a Child in Large Language Model Towards Effective and Generalizable Fine-tuning - ACL-EMNLP-2021_2021.emnlp-main.749","url":"https://aclanthology.org/2021.emnlp-main.7/","urlHash":2625890113},"1803ac10-d409-49d4-b33c-021b83e101c5":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"1803ac10-d409-49d4-b33c-021b83e101c5","title":"Paitesanshi/LLM-Agent-Survey","url":"https://github.com/Paitesanshi/LLM-Agent-Survey","urlHash":4273829858},"18477f6b-3d21-4d10-9867-08f41f6ed814":{"favIconUrl":"fallback","id":"18477f6b-3d21-4d10-9867-08f41f6ed814","title":"stochastic computational graph - Google Search","url":"https://www.google.com/search?q=stochastic+computational+graph&oq=stochastic+computational+graph&aqs=chrome..69i57j0i22i30j0i390l5.4455j0j1&sourceid=chrome&ie=UTF-8","urlHash":1908934904},"185ac316-2eac-4838-9d6e-5392b261b44c":{"favIconUrl":"fallback","id":"185ac316-2eac-4838-9d6e-5392b261b44c","title":"A Survey on Model Compression for Large Language Models - Arxiv-2308.07633","url":"https://arxiv.org/abs/2308.07633?utm_source=substack&utm_medium=email","urlHash":1812526842},"1885b752-3038-484b-81fa-8766ad15c704":{"favIconUrl":"fallback","id":"1885b752-3038-484b-81fa-8766ad15c704","title":"Task-aware Retrieval with Instructions - Arxiv-2211.09260","url":"https://arxiv.org/pdf/2211.09260.pdf","urlHash":3589633474},"188fc90e-77d7-45b3-92c5-c5f271587dc1":{"favIconUrl":"fallback","id":"188fc90e-77d7-45b3-92c5-c5f271587dc1","title":"Deduplicating Training Data Mitigates Privacy Risks in Language Models - Arxiv-2202.06539","url":"https://arxiv.org/abs/2202.06539","urlHash":2374847554},"18902794-f0bb-47cc-af92-836ee423e0a0":{"favIconUrl":"https://transformer-circuits.pub/favicon.ico","id":"18902794-f0bb-47cc-af92-836ee423e0a0","title":"Softmax Linear Units","url":"https://transformer-circuits.pub/2022/solu/index.html#section-3-2","urlHash":3795716327},"189dd0e6-564e-4817-be0d-2974c618cc5e":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"189dd0e6-564e-4817-be0d-2974c618cc5e","title":"twitter.com/arankomatsuzaki/status/1702503994864861318","url":"https://twitter.com/arankomatsuzaki/status/1702503994864861318","urlHash":2450478232},"18baa049-17af-4736-94e1-b10cc58b966c":{"favIconUrl":"fallback","id":"18baa049-17af-4736-94e1-b10cc58b966c","title":"ICL: Why Can GPT Learn In-Context? (2022) - KiKaBeN","url":"https://kikaben.com/why-gpt-icl/","urlHash":4224450172},"18bb600f-d858-43e0-aea5-2bec3cb4c0ab":{"favIconUrl":"fallback","id":"18bb600f-d858-43e0-aea5-2bec3cb4c0ab","title":"CosyneTutorial_RL_2023_Stachenfeld.ipynb - Colaboratory","url":"https://colab.research.google.com/drive/1jEiDNA1q98n1Wrw_uBEFvpuV9BGW_yxW","urlHash":1000839436},"18cade06-01f4-4365-8d7d-26bb6f25aefe":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"18cade06-01f4-4365-8d7d-26bb6f25aefe","title":"SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer | PDF","url":"https://arxiv.org/pdf/2110.07904.pdf","urlHash":3788011121},"18ead723-0e39-4b1a-a17e-132563612edc":{"favIconUrl":"data:image/png;base64,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","id":"18ead723-0e39-4b1a-a17e-132563612edc","title":"World Models","url":"https://worldmodels.github.io/","urlHash":1809654784},"1905895f-4135-433d-b02d-b8cd653c54cc":{"favIconUrl":"fallback","id":"1905895f-4135-433d-b02d-b8cd653c54cc","title":"Perfectly Normal","url":"https://www.perfectlynormal.co.uk/blog-eindex","urlHash":4092433859},"190bc495-a962-40db-b816-13b2fe57d15f":{"favIconUrl":"https://dl.acm.org/pb-assets/head-metadata/favicon-32x32-1574252172003.png","id":"190bc495-a962-40db-b816-13b2fe57d15f","title":"Hierarchical Reinforcement Learning: A Comprehensive Survey: ACM Computing Surveys: Vol 54, No 5","url":"https://dl.acm.org/doi/abs/10.1145/3453160","urlHash":889642243},"192dd4da-d994-4036-909e-7a2e1a660075":{"favIconUrl":"fallback","id":"192dd4da-d994-4036-909e-7a2e1a660075","title":"Correcting Robot Plans with Natural Language Feedback - Arxiv-2204.05186","url":"https://arxiv.org/abs/2204.05186","urlHash":4190942143},"19707a1e-53cb-4f62-8316-08a4b83d80ea":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"19707a1e-53cb-4f62-8316-08a4b83d80ea","title":"(1) Quanquan Gu on X: \"The quality of human-generated prompts is crucial for the accuracy of LLM responses, with suggestions given by #OpenAI that underscores the need for precise, detailed, and specific queries. But do humans know if their questions are clear enough for LLMs? 🤔We have our doubts.… https://t.co/gn1HYXjmeN\" / X","url":"https://twitter.com/QuanquanGu/status/1722364426702270857","urlHash":2776901494},"19a4775d-6524-4e8a-adcb-45160b516346":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"19a4775d-6524-4e8a-adcb-45160b516346","title":"CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations | PDF","url":"https://arxiv.org/pdf/2310.11501.pdf","urlHash":1802392994},"19abf5dc-d5ce-4d2a-b908-1a1d004299fb":{"favIconUrl":"fallback","id":"19abf5dc-d5ce-4d2a-b908-1a1d004299fb","title":"Thread: Differentiable Self-organizing Systems","url":"https://distill.pub/2020/selforg/","urlHash":576098075},"19bbb56d-ee9b-4211-9389-0e9a2b8361b5":{"favIconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","id":"19bbb56d-ee9b-4211-9389-0e9a2b8361b5","title":"More Recent Progress in the Theory of Neural Networks — LessWrong","url":"https://www.lesswrong.com/posts/nRu92PXLrdwqdtQmn/more-recent-progress-in-the-theory-of-neural-networks-1","urlHash":3010932530},"19e990c4-37fd-4856-85d9-1915364dfda6":{"favIconUrl":"https://www.99csw.com/favicon.ico","id":"19e990c4-37fd-4856-85d9-1915364dfda6","title":"酒徒_刘以鬯_在线阅读_九九藏书网","url":"https://www.99csw.com/book/10418/index.htm","urlHash":842098460},"19fb0397-d5cf-4c85-bba5-8031f3f37aa1":{"favIconUrl":"fallback","id":"19fb0397-d5cf-4c85-bba5-8031f3f37aa1","title":"Compositional Foundation Models for Hierarchical Planning - Arxiv-2309.08587","url":"https://arxiv.org/abs/2309.08587?utm_source=substack&utm_medium=email","urlHash":512459723},"19fe3878-5c3a-4791-8a5f-cf5e9ca56c17":{"favIconUrl":"fallback","id":"19fe3878-5c3a-4791-8a5f-cf5e9ca56c17","title":"WILDS A Benchmark of in-the-Wild Distribution Shifts - Arxiv-2012.07421","url":"https://arxiv.org/abs/2012.07421","urlHash":1625515451},"1a142934-7899-43ce-8f7f-c436f9195477":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"1a142934-7899-43ce-8f7f-c436f9195477","title":"The False Promise of Imitating Proprietary LLMs | PDF","url":"https://arxiv.org/pdf/2305.15717.pdf","urlHash":19093058},"1a22b6d0-cc2a-4807-ae46-78028bdf06be":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"1a22b6d0-cc2a-4807-ae46-78028bdf06be","title":"标签 熵 下的文章 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/tag/%E7%86%B5/3/","urlHash":994504345},"1a2df807-9282-4080-99c0-b7c094db4335":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"1a2df807-9282-4080-99c0-b7c094db4335","title":"法隆寺 (豆瓣)","url":"https://book.douban.com/subject/35644185/","urlHash":3826884474},"1a7195ad-3fd8-4b64-9bb6-212579f2b84e":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"1a7195ad-3fd8-4b64-9bb6-212579f2b84e","title":"仅用200条样本，训出超越MiniGPT-4的模型！这款数据选择器值得拥有","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247560064&idx=2&sn=1031830cc905221621d1c0a63b1cbeed&chksm=970ec356a0794a40524d598706ac8badedab3ccc867f4018ff18bbc9eb80872fd96cbd889ab2&mpshare=1&scene=1&srcid=1001BV0IxaPJBTJk8YPTG1ou&sharer_shareinfo=493d317ba6a62d383e9b14c9e6e7d7b2&sharer_shareinfo_first=493d317ba6a62d383e9b14c9e6e7d7b2&exportkey=n_ChQIAhIQ6JGcUxvZWkAmtAl8flgMDRKWAgIE97dBBAEAAAAAAA2gBF9tU5EAAAAOpnltbLcz9gKNyK89dVj0%2Bh%2BnzgeAYwY7XGy%2BQ%2B5wGoEhjYualCpJ4x70M27OjmEyo4nv33%2BtlOHrIqT0%2BgIvDltmY99hMAe2ieQ8cu58s1wzQNNHBoFwphQhPsjHkff%2BIgaZywDREcQQHZtEHqwAaJVEaQBteUSdLKB6UMBxwVj6yDWeG5ctkpAtGsXqSfMpHCMoyvQqWYuxgiwNP4rxBsAkskhAr%2BPEds6QYiuGiwmQvtQb2DpFGMsl3kY9YiCk6oYWyjqna%2BRwiMrhOXErKcCP9BQPqVc782d0VEPumLyJHhu2XzZJsj1MsdIpIEkZxIhXClc0ZtPOySb1PnEz&acctmode=0&pass_ticket=y%2FB5%2FQ9UiCOclb5O8a9npwPBDtsKvM4lkBdIM3ap0nSLrBHEQd85IcBrK8t8yATy&wx_header=0#rd","urlHash":2013736477},"1a781e15-5889-41eb-9e84-c05096d84970":{"favIconUrl":"fallback","id":"1a781e15-5889-41eb-9e84-c05096d84970","title":"What Can Transformers Learn In-Context? A Case Study of Simple Function Classes - Arxiv-2208.01066","url":"https://arxiv.org/pdf/2208.01066.pdf","urlHash":2265608119},"1a785165-7b77-45ef-98e3-572050d82a64":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"1a785165-7b77-45ef-98e3-572050d82a64","title":"Understanding Finetuning for Factual Knowledge Extraction from Language Models | PDF","url":"https://arxiv.org/pdf/2301.11293.pdf","urlHash":2408867087},"1ace8a1d-3efe-4d32-a5a6-8730ae8e3505":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"1ace8a1d-3efe-4d32-a5a6-8730ae8e3505","title":"喪鐘為你而鳴 (豆瓣)","url":"https://book.douban.com/subject/35565915/","urlHash":3453908092},"1afc7771-ab81-4919-82ca-b263392cac28":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"1afc7771-ab81-4919-82ca-b263392cac28","title":"Greg Brockman on X: \"We're using GPT-4 to interpret the neurons in GPT-2. Step towards our alignment plan of using AI to automate alignment research (https://t.co/ARrIzlbLUX). GPT-2 neuron map released here: https://t.co/IqzMc0gvpi\" / X","url":"https://twitter.com/gdb/status/1655984059057840130","urlHash":2732721886},"1b095f1a-8bd3-4641-92de-076d39c15d62":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"1b095f1a-8bd3-4641-92de-076d39c15d62","title":"Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning | Abstract","url":"https://arxiv.org/abs/2306.14565","urlHash":73103392},"1b2a9c1a-2434-4b1e-858f-43792d02ff7c":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"1b2a9c1a-2434-4b1e-858f-43792d02ff7c","title":"Probing Neural Network Comprehension of Natural Language Arguments | PDF","url":"https://arxiv.org/pdf/1907.07355.pdf","urlHash":120504766},"1b337013-50e5-44cc-857b-55ef30bde64e":{"favIconUrl":"fallback","id":"1b337013-50e5-44cc-857b-55ef30bde64e","title":"Minimizing Expectations","url":"https://www.cs.toronto.edu/~cmaddis/courses/sta4273_w21/","urlHash":1224834892},"1b6d2437-87ee-4f94-838b-d5340e0ffda0":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"1b6d2437-87ee-4f94-838b-d5340e0ffda0","title":"YaRN: Efficient Context Window Extension of Large Language Models | PDF","url":"https://arxiv.org/pdf/2309.00071.pdf","urlHash":4017413531},"1b6ffcab-1f62-483e-a13f-4f3c21e24853":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"1b6ffcab-1f62-483e-a13f-4f3c21e24853","title":"大模型 | 还在多个数据集直接混在一起训？预训练、SFT、OOD数据都能用的训练策略","url":"https://mp.weixin.qq.com/s?__biz=MzI3NjUwMzQwNQ==&mid=2247485436&idx=1&sn=d0a71b0eb1617928994f230b699872ac&exportkey=n_ChQIAhIQny2WunMngShDphi60tBT3xKWAgIE97dBBAEAAAAAAJgqBYQWH%2FsAAAAOpnltbLcz9gKNyK89dVj0aRLvsD2KrfPp37ZBxTFweUqENkrKZn4D%2BBZawwZA2aUat4j0Dvzh4zyYNGg9J8sA8fKW5%2FTdNGOoqVQJ9a4mElDRux3T7CdL%2F3BrvwKWMq215TTV0VEOEBCpw3cg33Fw9QsRLwdU%2FklEGXA%2FvADkX3Xy35FZ5%2BlVZZokyioepCFD9yeZfvZqJW%2B1uQskHkaK1LlD%2FsuNTl7mwQ%2Fu%2FPwkCFjKE2WjcTMIYqRoujzcPy4crU%2B6aXASWf944AtmNZnAAxJNpTXMk8mQawp0xU1jYoBKR2K4B7mdz%2BH%2BVFeTy6lXSg%2FicymMrQdXiTINL%2FPk&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsbaPBprPFagySZlPnB%2F%2Bg7nlOOY%2F9olWi1TBfOdMVKqGg%3D%3D&wx_header=0","urlHash":4070007436},"1b800271-f261-497a-9202-4121ff59cab2":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"1b800271-f261-497a-9202-4121ff59cab2","title":"Large Language Models are not Fair Evaluators | Abstract","url":"https://arxiv.org/abs/2305.17926","urlHash":242264450},"1b8b27cd-d871-45ec-b96a-c5788db41b1d":{"favIconUrl":"fallback","id":"1b8b27cd-d871-45ec-b96a-c5788db41b1d","title":"Natural Language Descriptions of Deep Visual Features","url":"https://milan.csail.mit.edu/","urlHash":2364641325},"1b9a61cd-c7a9-4b96-9ce9-286a4bdc2f85":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"1b9a61cd-c7a9-4b96-9ce9-286a4bdc2f85","title":"Aran Komatsuzaki on X: \"Google presents How to Train Data-Efficient LLMs Models trained on ASK-LLM data consistently outperform full-data training—even when we reject 90% of the original dataset, while converging up to 70% faster https://t.co/YfF2okE5Vg https://t.co/xcqs1E3nlx\" / X","url":"https://twitter.com/arankomatsuzaki/status/1758318072732225586","urlHash":2731104757},"1bbc0920-322b-4641-a7e4-4d93c1caeb1a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"1bbc0920-322b-4641-a7e4-4d93c1caeb1a","title":"twitter.com/wyu_nd/status/1661174382889250816","url":"https://twitter.com/wyu_nd/status/1661174382889250816","urlHash":3411616325},"1bc3641f-2555-44de-b2af-573c6838b838":{"favIconUrl":"fallback","id":"1bc3641f-2555-44de-b2af-573c6838b838","title":"blog | Peter E. Holderrieth","url":"https://www.peterholderrieth.com/blog/","urlHash":3905366733},"1c150cc8-b016-4494-87f3-2a7f078ea8a7":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/badged-favicon-32x32.png","id":"1c150cc8-b016-4494-87f3-2a7f078ea8a7","title":"(5) Landmark Attention Oobabooga Support + GPTQ Quantized Models! : LocalLLaMA","url":"https://www.reddit.com/r/LocalLLaMA/comments/148prx3/landmark_attention_oobabooga_support_gptq/","urlHash":1436242790},"1c3b6aa6-6926-4416-9dbb-3c046995b95d":{"favIconUrl":"https://pair.withgoogle.com/images/favicon/favicon-32x32.png","id":"1c3b6aa6-6926-4416-9dbb-3c046995b95d","title":"Do Machine Learning Models Memorize or Generalize?","url":"https://pair.withgoogle.com/explorables/grokking/#:~:text=At%20first%20only%20training%20accuracy,model%20learns%20a%20general%20solution.","urlHash":1094389418},"1c40a923-3c73-4aac-a6a7-a95a300932e6":{"favIconUrl":"https://blog.langchain.dev/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png","id":"1c40a923-3c73-4aac-a6a7-a95a300932e6","title":"Multi Needle in a Haystack","url":"https://blog.langchain.dev/multi-needle-in-a-haystack/","urlHash":2653427703},"1c6dc7d9-f52f-4c2e-ba86-ea66cfcee8ca":{"favIconUrl":"fallback","id":"1c6dc7d9-f52f-4c2e-ba86-ea66cfcee8ca","title":"Focal Modulation Networks - Arxiv-2203.11926","url":"https://arxiv.org/abs/2203.11926","urlHash":3449575813},"1ca25453-d92a-4166-9e49-659ccf5a35e1":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"1ca25453-d92a-4166-9e49-659ccf5a35e1","title":"Towards Tracing Factual Knowledge in Language Models Back to the Training Data | PDF","url":"https://arxiv.org/pdf/2205.11482.pdf","urlHash":706977001},"1cfcbb62-8984-4bfe-aada-b53066642cb1":{"favIconUrl":"fallback","id":"1cfcbb62-8984-4bfe-aada-b53066642cb1","title":"Robustness Implies Privacy in Statistical Estimation - Arxiv-2212.05015","url":"https://arxiv.org/abs/2212.05015","urlHash":2594596657},"1d0e8991-ed93-496e-95e7-24ecfb83a8fd":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"1d0e8991-ed93-496e-95e7-24ecfb83a8fd","title":"CLS on X: \"8. https://t.co/UHA1DnGj2O Xue et al. (@elgreco_winter) propose reverse Chain-of-Thought: first prompt LLM to reconstruct the problem given the generated solution; then detect inconsistencies between the reconstructed and the original problems.\" / X","url":"https://twitter.com/ChengleiSi/status/1664024907972222978","urlHash":528611695},"1d1c6226-f22d-41c7-a866-7bca8fc52546":{"favIconUrl":"fallback","id":"1d1c6226-f22d-41c7-a866-7bca8fc52546","title":"Reasoning about the Dynamic Context of a Still Image - Google Search","url":"https://www.google.com/search?q=Reasoning+about+the+Dynamic+Context+of+a+Still+Image&oq=Reasoning+about+the+Dynamic+Context+of+a+Still+Image&aqs=chrome..69i57j0i22i30.298j0j1&sourceid=chrome&ie=UTF-8","urlHash":936192650},"1d365d76-47af-47d1-93c8-3e5cdd0e3abf":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"1d365d76-47af-47d1-93c8-3e5cdd0e3abf","title":"贾佳亚团队开源全球首个70B长文本大语言模型，读论文看小说直接ProMax","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247698308&idx=2&sn=83350777be8fe29d2bea8c610f2e3218&exportkey=n_ChQIAhIQG3NnBBOTL4EcUyqN4EERnBKWAgIE97dBBAEAAAAAAAycN1SLv7MAAAAOpnltbLcz9gKNyK89dVj0oCSkL2X0u1UyMkQkkKb0s0FHJ60n4xNORAp43E3cnB4xoCayEaQxXWfURBogpJjWMbbvlIaGtlPKcTc18MYCo60Hz4rhAfh7Ipsnw%2FbLI06ILYSWD6ZAKkvR7ozg8p%2BvhXANi3W2Ybtk0A3WIXd4nzfU64wYueeznJBKRTNqhU0yWT%2FKStbmlRciGMNicX3HJHMtYTz7UxSg0PSp6unO2vJWdwPNRDYJOM1UsFykqZNBOJv9%2BSvA2LahVY6U%2FALbQPJ2c4USdJvqOz9JFBeD4asAzyTTpNH71hMNyylq%2FZ2dyFpEtKqJ2g55Fo95z3rS&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsZusaBtRQ%2BcaFF8lbn3WqMeyShqqNVhwTGN9FCXjhPs6Q%3D%3D&wx_header=0","urlHash":3108186280},"1d5b49a3-ac3c-4d2f-bc86-237747d4bdc0":{"favIconUrl":"https://pair.withgoogle.com/images/favicon/favicon.ico","id":"1d5b49a3-ac3c-4d2f-bc86-237747d4bdc0","title":"AI Explorables | PAIR","url":"https://pair.withgoogle.com/explorables/","urlHash":3327688935},"1d66f400-0d52-4d14-8be1-6aeda4d3650b":{"favIconUrl":"fallback","id":"1d66f400-0d52-4d14-8be1-6aeda4d3650b","title":"Understanding Convolutions on Graphs","url":"https://distill.pub/2021/understanding-gnns/","urlHash":1978980647},"1d90e86c-834b-4b38-a1af-11cc77834fc0":{"favIconUrl":"fallback","id":"1d90e86c-834b-4b38-a1af-11cc77834fc0","title":"2022年度小结：科研、ChatGPT与疫情 - 知乎","url":"https://zhuanlan.zhihu.com/p/594107879","urlHash":2612510898},"1d9fc928-0d97-4df8-93af-d6a2aabb0041":{"favIconUrl":"https://cdn.semanticscholar.org/3cf37988806f7507/img/darkmode/favicon-32x32.png","id":"1d9fc928-0d97-4df8-93af-d6a2aabb0041","title":"[PDF] Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision | Semantic Scholar","url":"https://www.semanticscholar.org/paper/Weak-to-Strong-Generalization%3A-Eliciting-Strong-Burns-Izmailov/6b97aa78bcdb88548c44e7e1671c0ed37ed37976","urlHash":2123626049},"1dd91b26-b215-4134-9b2d-53dd817806c5":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"1dd91b26-b215-4134-9b2d-53dd817806c5","title":"Micah Goldblum on X: \"I’m thrilled to announce the first issue of a community survey on the state and future of deep learning! We asked folks their opinions on benchmarking, transformers, interpretability, theories of deep learning, and directions we should be working on. 1/3 https://t.co/gVY1a8h9IL\" / X","url":"https://twitter.com/micahgoldblum/status/1737135155364388878","urlHash":3227431860},"1e1b74d8-5624-4ce1-9b74-1632483b32d8":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"1e1b74d8-5624-4ce1-9b74-1632483b32d8","title":"Sasha Rush on X: \"A gentle intro to LLM scaling, and research into how to effectively scale with limited data. (https://t.co/AK3LKbOMZX) Scaling is interesting, if scary topic. But I think you can understand the core conclusions with high-school math and 3-4 slides.\" / X","url":"https://twitter.com/srush_nlp/status/1690057149810909187","urlHash":157130716},"1e4aabc6-38bf-4690-8d94-63f8a2c0c1c6":{"favIconUrl":"fallback","id":"1e4aabc6-38bf-4690-8d94-63f8a2c0c1c6","title":"徐土豆 - 知乎","url":"https://www.zhihu.com/people/FesianXu","urlHash":1262064695},"1e5148b7-9249-4bbe-882d-a2f074e38d37":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"1e5148b7-9249-4bbe-882d-a2f074e38d37","title":"大模型搞“人肉搜索”，准确率高达95.8%！研究作者：已提醒OpenAI谷歌Meta","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247699867&idx=3&sn=ec2b68bd3b9f56376aef30d28ebac903&exportkey=n_ChQIAhIQmywLK3mt%2F49OECz0lG8G7hKWAgIE97dBBAEAAAAAACcaOXBWRfYAAAAOpnltbLcz9gKNyK89dVj0QrTZGWaCYBvnF4z9dKBD36CSpq1fCXZqG9vqM84zgrKZ4nHbwj%2FoyiHOQBoXkQCkGg0RtwudCogs%2Bo4yqMhpRTIIFKkkjSHlOMFqvySgzjhGaDfRMsKmxTGCOijN4%2Bxb42UfAljxYdDltm3RB0Hhnj%2FE5uSpsvLIg58b3%2BqYpO9qMMcB1dGm0GMEQUqOBD8JLfwZFVepM5Y%2FxOEtswnUVge5R0cjKOk7%2BrZ8JeWZhDtEuIATCzWVlbJb1NXlPqmD5gt6QLJmRSxqJGgYG1cB3VwULRv7NQg3ncDY8R%2BASV7dMP0nVwIrPXX01jCg%2FrSl&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsahnVeuqLR1LhFyLDnTLcg7VBTXGgojAH2AiyP1a%2Bsm3A%3D%3D&wx_header=0","urlHash":743847098},"1e7dc795-2743-4147-b4cf-ec1307590ce7":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"1e7dc795-2743-4147-b4cf-ec1307590ce7","title":"AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration | PDF","url":"https://arxiv.org/pdf/2306.00978.pdf","urlHash":572436101},"1e95bb6e-47a7-48f7-b9b9-370700e6d26e":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"1e95bb6e-47a7-48f7-b9b9-370700e6d26e","title":"从第一性原理看大模型Agent技术","url":"https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&mid=2247495233&idx=1&sn=a6f99f5ed298dc4dad8477979d0c19a8&exportkey=n_ChQIAhIQzzn3PzgG9Ums0HuEnvDIGRKWAgIE97dBBAEAAAAAAAFEL2b%2FINUAAAAOpnltbLcz9gKNyK89dVj06TRDruV5QGIvdM5e0ZmSDEwaj3okBe8qCy8Tm1XwfMOqy88MpLc6i7Q%2FlgJZOaVnNP4yinQf3RL%2F1V1b%2BzHKLK1iWe4O9OhFM8FnYMSFrBeJFYOVAO1YoZJ3Soo%2FwyEmftbThWwYHbfFKxt1HSEDgypPYsb%2BvvJPu%2FL4dOLetD6BeZg3crjiit02tj8oIllocUyL4rCafkJLkx2xypLtWp5bkBGkEZukywt8UR48NbwbZ8T27IhflX5L82JnxISC1OklRqUKLK%2FcLtmEK%2BF4FI4B7JrFyf9Gx22Lyez3ARZ9%2Fw0z8sosh%2FUU6AJcWJRF&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsY0778umch5zpLwhrz8oSj2pZz4cTlI4DhD7V2fQNj0iA%3D%3D&wx_header=0","urlHash":63782213},"1e966eb9-4b98-4d09-afc4-918b41441460":{"favIconUrl":"fallback","id":"1e966eb9-4b98-4d09-afc4-918b41441460","title":"对《我想吃掉你的胰脏》的纯粹非理性批判 - 知乎","url":"https://zhuanlan.zhihu.com/p/55581506","urlHash":3222116831},"1e9eb58d-6976-49b0-a083-d21d6159d65a":{"favIconUrl":"fallback","id":"1e9eb58d-6976-49b0-a083-d21d6159d65a","title":"Principles for Productive Group Meetings","url":"https://bounded-regret.ghost.io/principles-for-productive-group-meetings/","urlHash":1197986801},"1eaba1b8-3543-4138-9544-85f50fd6be78":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"1eaba1b8-3543-4138-9544-85f50fd6be78","title":"Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers | Abstract","url":"https://arxiv.org/abs/2110.13985","urlHash":2731479579},"1eb5a845-5ab0-4b8e-8891-983b54885a76":{"favIconUrl":"https://skrl.readthedocs.io/en/latest/_static/favicon.ico","id":"1eb5a845-5ab0-4b8e-8891-983b54885a76","title":"Agents - skrl (1.0.0)","url":"https://skrl.readthedocs.io/en/latest/api/agents.html","urlHash":130605363},"1ee1b201-eaf1-446c-9553-a5d0f05470c6":{"favIconUrl":"fallback","id":"1ee1b201-eaf1-446c-9553-a5d0f05470c6","title":"《美国讲稿》提到的所有人名与书名（美国讲稿）书评","url":"https://book.douban.com/review/9648748/","urlHash":1071242823},"1ee342b1-96b3-4a49-9c4d-4a9a13c49986":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"1ee342b1-96b3-4a49-9c4d-4a9a13c49986","title":"Rosanne Liu on X: \"What's the real difference between \"pre-training\" and \"finetuning\" these days? It used to be that the 2 phases have totally different objectives, tasks, data, and even modifications of model (new heads). But in LLMs it seems to mean just new data? Why not call it \"more training\"?\" / X","url":"https://twitter.com/savvyRL/status/1710379981724115097","urlHash":2270094796},"1ef11ea0-063a-4de9-8f39-dacad3fb3953":{"favIconUrl":"fallback","id":"1ef11ea0-063a-4de9-8f39-dacad3fb3953","title":"Coming up with research ideas. “What project should I do next?” is a…","url":"https://medium.com/@marcotcr/coming-up-with-research-ideas-3032682e5852","urlHash":3349730268},"1f16e825-14a7-42f9-8ec9-e5db9ea4d7da":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"1f16e825-14a7-42f9-8ec9-e5db9ea4d7da","title":"Fact Finding: Attempting to Reverse-Engineer Factual Recall on the Neuron Level (Post 1) — AI Alignment Forum","url":"https://www.alignmentforum.org/s/hpWHhjvjn67LJ4xXX/p/iGuwZTHWb6DFY3sKB?utm_source=substack&utm_medium=email","urlHash":3161292222},"1f286fae-8751-4321-9831-ca415020d790":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"1f286fae-8751-4321-9831-ca415020d790","title":"jhejna/cpl: Code for Contrastive Preference Learning (CPL)","url":"https://github.com/jhejna/cpl","urlHash":4203122756},"1f7a62b9-e11c-441f-b447-3104bbd9878e":{"favIconUrl":"fallback","id":"1f7a62b9-e11c-441f-b447-3104bbd9878e","title":"Algorithm Descriptions · Captum","url":"https://captum.ai/docs/attribution_algorithms","urlHash":1633522347},"1fd4ebdd-2e8e-4a39-9e00-8d6aadae1a1d":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"1fd4ebdd-2e8e-4a39-9e00-8d6aadae1a1d","title":"让大模型忘记哈利波特，微软新研究上演Llama 2记忆消除术，真·用魔法打败魔法（doge）","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247702711&idx=4&sn=b7079cb6e2497cfd1f558331a7241aa7&chksm=e8df6fc5dfa8e6d325c26b5854396456ae93af59b6d263f03be86247d1e946e2d3760485b4de&mpshare=1&scene=1&srcid=0115BBUKo4nTkBKkC5deLsPE&sharer_shareinfo=020437fa2113287131fce0b94331ec61&sharer_shareinfo_first=020437fa2113287131fce0b94331ec61&exportkey=n_ChQIAhIQ1ebAyLSUMegg%2BLHZLuAJ%2BhKWAgIE97dBBAEAAAAAAIuWEZrUOiwAAAAOpnltbLcz9gKNyK89dVj00ZopxjAgT6FtrKu5G5tggo8hmOF02DFccn8%2BTcZiPb2VLSG01tCsZo8T2aOmn5knGO68TzdkOgYWrtREWOThQ%2BVffVPP0q4002tRGNNQfkO645A0MU1BPB3vHszkH9tQ%2BHyF5W%2B%2BDU%2Frv0wF5QY4YxWt8G2BzQ1kTV75NocJFpmiawl1L8lXtqGEbcFKbyB%2FxA3%2BA%2F8BBmYzb2HZb%2BSGp4WcW0qLSVsYvg8Fjuv0AW4GypBcWyIBR8bYyBlrV0FNB1%2Fq2f6BQRceWLIQrbTAY1pMvHLSwJe4cEtvq0Xj%2FFQKp3cWOnMam3Ng%2FZmMTtCo&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsZhjl3pbgETEmVYxnEB3THyTSrNvsDiMFBhBkFq5aCeEA%3D%3D&wx_header=0#rd","urlHash":2085597786},"1fe4dec3-4873-4578-a7a7-632a6f07dfbc":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"1fe4dec3-4873-4578-a7a7-632a6f07dfbc","title":"Calibrating Factual Knowledge in Pretrained Language Models | PDF","url":"https://arxiv.org/pdf/2210.03329.pdf","urlHash":322070424},"201e4899-7e67-44fe-8bf5-c8585224e6c3":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"201e4899-7e67-44fe-8bf5-c8585224e6c3","title":"(1) AK on X: \"BAAI presents Soaring from 4K to 400K Extending LLM's Context with Activation Beacon paper page: https://t.co/0aVsxla06W experimental studies show that Activation Beacon is able to extend Llama-2-7B's context length by x 100 times (from 4K to 400K), meanwhile achieving a… https://t.co/hplU57PX6Z\" / X","url":"https://twitter.com/_akhaliq/status/1744567162847551715","urlHash":4031715666},"2026bdaf-1aa2-4de9-bb69-924841ac8da6":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"2026bdaf-1aa2-4de9-bb69-924841ac8da6","title":"(2) elvis on X: \"Advancing LLM Agents through Action Learning Can LLM agents be improved by learning new actions through direct interaction with the environment? This work explores open-action learning for language agents through an iterative learning strategy that creates and improves actions… https://t.co/6STBOlZb1K\" / X","url":"https://twitter.com/omarsar0/status/1762533498492010761?utm_source=substack&utm_medium=email","urlHash":4264517721},"20278174-6c3e-487a-8d6b-f17132f41dd0":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"20278174-6c3e-487a-8d6b-f17132f41dd0","title":"YaRN: Efficient Context Window Extension of Large Language Models | Abstract","url":"https://arxiv.org/abs/2309.00071?utm_source=substack&utm_medium=email","urlHash":1444358259},"20559d99-54a9-4482-9a5d-123b2bf1f3da":{"favIconUrl":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA99JREFUeNrsG4t1ozDMzQSM4A2ODUonKBucN2hugtIJ6E1AboLcBiQTkJsANiAb9OCd/OpzMWBJBl5TvaeXPiiyJetry0J8wW3D3QpjRh3GjneXDq+fSQA9s2mH9x3KDhN4foJfCb8N/Jrv+2fnDn8vLRQOplWHVYdvHZYdZsBcZP1vBmh/n8DzEmhUQDPaOuP9pFuY+JwJHwHnCLQE2tnWBGEyXozY9xCUgHMhhjE2I4heVWtgIkZ83wL6Qgxj1obfWBxymPwe+b00BCCRNPbwfb60yleAkkBHGT5AEehIYz7eJrFDMF9CvH4wwhcGHiHMneFvLDQwlwvMLQq58trRcYBWfYn0A0OgHWQUSu25mE+BnoYKnnEJoeIWAifzOv7vLWd2ZKRfWAIme3tOiUaQ3UnLkb0xj1FxRIeEGKaGIHOs9nEgLaaA9i0JRYo1Ic67wJW86KSKE/ZAM8KuVMk8ITVhmxUxJ3Cl2xlm9Vtkeju1+mpCQNxaEGNCY8bs9X2YqwNoQeGjBWut/ma0QAWy/TqAsHx9wSya3I5IRxOfTC+leG+kA/4vSeEcGBtNUN6byhu3+keEZCQJUNh8MAO7HL6H8pQLnsW/Hd4T4lv93TPjfM7A46iEEqbB5EDOvwYNW6tGNZzT/o+CZ6sqZ6wUtR/wf7mi/VL8iNciT6rHih48Y55b4nKCHJCCzb4y0nwFmin3ZEMIoLfZF8F7nncFmvnWBaBj7CGAYA/WGJsUwHdYqVDwAmNsUgAx4CGgAA7GOOxADYOFWOaIKifuVYzmOpREqA21Mo7aPsgiY1PhOMAmxtR+AUbYH3Id2wc0SAFIQTsn9IUGWR8k9jx3vtXSiAacFxTAGakBk9UudkNECd6jLe+6HrshshvIuC6IlLMRy7er+JpcKma24SlE4cFZSZJDGVVrsNvitQhQrDhW0jfiOLfFd47C42eHT56D/BK0To+58Ahj+cAT8HT1UWlfLZCCd/uKawzU0Rh2EyIX/Icqth3niG8ybNroezwe6khdCNxRN+l4XGdOLVLlOOt2hTRJlr1ETIuMAltVTMz70mJrkdGAaZLSmnBEqmAE32JCMmuTlCnRgsBENtOUpHhvvsYIL0ibnBkaC6QvKcR7738GKp0AKnim7xgUSNv1bpS8QwhBt8r+EP47v/oyRK/S34yJ9nT+AN0Tkm4OdB9E4BsmXM3SnMlRFUrtp6IDpV2eKzdYvF3etm3KhQksbOLChGkSmcBdmcEwvqkrMy5BzL00NZeu3qPYJOOuCc+5NjcWKXQxFvTa3NoXJ4d8in7fiAUuTt781dkvuHX4K8AA2Usy7yNKLy0AAAAASUVORK5CYII=","id":"20559d99-54a9-4482-9a5d-123b2bf1f3da","title":"Activation Atlas","url":"https://distill.pub/2019/activation-atlas/","urlHash":1294293000},"209dc13f-e40a-4ecb-9816-dbcc3422507c":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"209dc13f-e40a-4ecb-9816-dbcc3422507c","title":"Fast Inference of Mixture-of-Experts Language Models with Offloading | Abstract","url":"https://arxiv.org/abs/2312.17238?utm_source=substack&utm_medium=email","urlHash":425549123},"20a85fb8-c56f-420e-9671-460304d40bd5":{"favIconUrl":"fallback","id":"20a85fb8-c56f-420e-9671-460304d40bd5","title":"Yutong-Zhou-cv/Awesome-Text-to-Image: (ෆ`꒳´ෆ) A Survey on Text-to-Image Generation/Synthesis.","url":"https://github.com/Yutong-Zhou-cv/Awesome-Text-to-Image","urlHash":2654274280},"20b3d3db-677a-4d07-ab96-ae169fcb07e1":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"20b3d3db-677a-4d07-ab96-ae169fcb07e1","title":"google-deepmind/tracr","url":"https://github.com/google-deepmind/tracr","urlHash":2136546235},"20bd45b3-5502-4680-a152-97d7c335206f":{"favIconUrl":"https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/cfbf5bc5-47d4-4f4a-b133-23bd12a7d7c2/favicon.ico?format=100w","id":"20bd45b3-5502-4680-a152-97d7c335206f","title":"Adversarial Diffusion Distillation — Stability AI","url":"https://stability.ai/research/adversarial-diffusion-distillation?utm_source=substack&utm_medium=email","urlHash":2426093307},"20c6df43-34cd-41c0-8756-e0b0ed5f9003":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"20c6df43-34cd-41c0-8756-e0b0ed5f9003","title":"Weihua Hu on X: \"🚀🎉 Excited to announce 🌟 PyTorch Frame 🌟 - our new open-source initiative in PyTorch! Dive into multi-modal tabular deep learning like never before! Link: https://t.co/EA1lxSAYZV #PyTorch #OpenSource (1/6) https://t.co/1SyO1Mk4Pj\" / X","url":"https://twitter.com/weihua916/status/1736693330115977404","urlHash":459966860},"20db8f2c-51fe-4d65-8319-41f50b91e03c":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"20db8f2c-51fe-4d65-8319-41f50b91e03c","title":"Scalable Rule-Based Representation Learning for Interpretable Classification | PDF","url":"https://arxiv.org/pdf/2109.15103.pdf","urlHash":2144811926},"20e9cb38-cd8a-4ed9-9e3f-70f1fdc73507":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"20e9cb38-cd8a-4ed9-9e3f-70f1fdc73507","title":"Papers We've Read - a HuggingFaceH4 Collection","url":"https://huggingface.co/collections/HuggingFaceH4/papers-weve-read-6570985b12f162153b2a7008","urlHash":2982448945},"20e9f7ad-d425-4e32-8ee1-c7edd373acec":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"20e9f7ad-d425-4e32-8ee1-c7edd373acec","title":"Alex Tamkin 🦣 on X: \"What can go wrong when a language model's task is ambiguous? We look at this in our #ICLR2023 paper, inspired by a real-world GPT-3 failure! Task Ambiguity in Humans and Language Models https://t.co/xLuCy1pKac 1/ https://t.co/CTZvuTVWWW\" / X","url":"https://twitter.com/AlexTamkin/status/1628452768016117761","urlHash":4267155936},"210589c9-695c-4f75-9b02-56004489b93d":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"210589c9-695c-4f75-9b02-56004489b93d","title":"John Hewitt on X: \"If you're adding new tokens to Gemma, you're likely running into the \"all logits are negative, so randomly init embedding with a logit of ~0 dominates the softmax\" problem! Averaging existing embeddings solves this by bounding KL from initial model. See: https://t.co/EFwc66OOSy\" / X","url":"https://twitter.com/johnhewtt/status/1761056178988073319","urlHash":3381080885},"21237e0a-bfce-431c-bfd3-791a2b134391":{"favIconUrl":"fallback","id":"21237e0a-bfce-431c-bfd3-791a2b134391","title":"Hugging Face Reads, Feb. 2021 - Long-range Transformers","url":"https://huggingface.co/blog/long-range-transformers","urlHash":2929488401},"214eac5c-795a-49ad-aac2-240d45e30a36":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"214eac5c-795a-49ad-aac2-240d45e30a36","title":"Weixin Official Accounts Platform","url":"https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzIwNDY1NTU5Mg==&action=getalbum&album_id=2191627003538259968&scene=173&from_msgid=2247486002&from_itemidx=1&count=3&nolastread=1#wechat_redirect","urlHash":2984111685},"215f70f9-be22-4f3d-b8f4-6c8adfaae9a1":{"favIconUrl":"fallback","id":"215f70f9-be22-4f3d-b8f4-6c8adfaae9a1","title":"我们可以无损放大一个Transformer模型吗（一） - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/8444","urlHash":3538866480},"216a973f-127f-47b8-9de3-6db37cd16f2a":{"favIconUrl":"fallback","id":"216a973f-127f-47b8-9de3-6db37cd16f2a","title":"Can Neural Network Memorization Be Localized?","url":"https://proceedings.mlr.press/v202/maini23a/maini23a.pdf","urlHash":82496373},"2173f0b4-b932-41a8-aa9f-eb6c03c72660":{"favIconUrl":"fallback","id":"2173f0b4-b932-41a8-aa9f-eb6c03c72660","title":"https://arxiv.org/pdf/1912.02292.pdf","url":"https://arxiv.org/pdf/1912.02292.pdf","urlHash":2894226882},"21790ec5-fefb-44ce-8fe5-2b3db590eaae":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"21790ec5-fefb-44ce-8fe5-2b3db590eaae","title":"秋露宫超豪华别墅血洗事件","url":"https://www.douban.com/note/699540049/?_i=9319240oZQdRGV,1224204oZQdRGV","urlHash":2489581833},"219ea30e-8e68-4b8c-8d83-d94b9bb1ce5c":{"favIconUrl":"fallback","id":"219ea30e-8e68-4b8c-8d83-d94b9bb1ce5c","title":"THUYimingLi/machine_unlearning: Existing Literature about Machine Unlearning","url":"https://github.com/THUYimingLi/machine_unlearning","urlHash":773660079},"21caf4a9-67d9-4360-8e26-201859559a90":{"favIconUrl":"fallback","id":"21caf4a9-67d9-4360-8e26-201859559a90","title":"SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning","url":"https://arxiv.org/pdf/2308.00436.pdf","urlHash":2807733303},"21d35f9a-17e1-4520-a943-927854304387":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"21d35f9a-17e1-4520-a943-927854304387","title":"马毅团队新作！微调多模态大模型会「灾难性遗忘」，让性能大减","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652385812&idx=2&sn=326d6c259ca7491af814798254b30889&chksm=f12b46e5c65ccff3888061ec1538e50813c6c015e86bafe47e64193878f8ce898177786dd186&mpshare=1&scene=1&srcid=1001lRwBtCnO6LqIgLZExEmO&sharer_shareinfo=a1b16eb82ed44979cb4d9e5ba0b6c57c&sharer_shareinfo_first=a1b16eb82ed44979cb4d9e5ba0b6c57c&exportkey=n_ChQIAhIQcY9I8fh77X7JdVX0vJly7BKWAgIE97dBBAEAAAAAAPtZApMqn5oAAAAOpnltbLcz9gKNyK89dVj0CcFs2A3QbnVwMHq72IqLzdgcmwAI3ItGaCQzehyAgFB1NJKqTvWyIxl6mEPNAughk2zDbvU2XT%2F%2Bnf5dqVrxR3IiZ4d%2FFI5BArdZZ2lx2xUa4V4do6%2FI9kFsxw4PLSuypeIhuSG67P%2F47QuFju8YaGL2OU1AVypuHaSfTWa%2BKxSSXdaoJ6QkLh2%2BthXnMmhpUFJTKwPsB8Aj%2FfhbNAou6ItImE8E8G8i4KinF0xzIVxsRzY6UPgAwnrq4T%2BB%2Bs7zt%2BsL775u8ehfm5cipvDudCDFXAtmmMOUDBF5gO54u7YZkq7%2BPdyVfpNFsTeXypYp&acctmode=0&pass_ticket=O6iagKt%2BeZnQj1baDpMcLLE5iGKfx30P7oT2fXBVkF5DnEmkZle%2BhR%2FaeKgVMLeH&wx_header=0#rd","urlHash":1653750505},"21e67989-f36a-49ff-88e1-3a966ffd3241":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"21e67989-f36a-49ff-88e1-3a966ffd3241","title":"Stealing Part of a Production Language Model | PDF","url":"https://arxiv.org/pdf/2403.06634.pdf","urlHash":2847004046},"21f9942a-cb0e-46b3-90d4-c94f29063aa5":{"favIconUrl":"fallback","id":"21f9942a-cb0e-46b3-90d4-c94f29063aa5","title":"[Meta-Learning]对Reptile的深度解析 - 知乎","url":"https://zhuanlan.zhihu.com/p/239929601","urlHash":1128924813},"2211d733-7345-4ada-bcf1-15ad6c5cd117":{"favIconUrl":"fallback","id":"2211d733-7345-4ada-bcf1-15ad6c5cd117","title":"Better Robustness by More Coverage Adversarial Training with Mixup Augmentation for Robust Fine-tuning - Arxiv-2012.15699","url":"https://arxiv.org/pdf/2012.15699.pdf","urlHash":1373929064},"2223eab2-9ae2-42c2-a997-ae90ccf34d5e":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"2223eab2-9ae2-42c2-a997-ae90ccf34d5e","title":"(1) Edoardo Ponti on X: \"We scaled sparse fine-tuning (SFT) to LLMs (such as Llama 2) by making it both parameter- and memory-efficient! (q)SFT instruction tuning performance is often better than (q)LoRA with comparable speed and memory load. Paper: https://t.co/sYQwWjjgxJ Code:… https://t.co/ix9sRJaCT9\" / X","url":"https://twitter.com/PontiEdoardo/status/1752323361726681496","urlHash":184537102},"223c65b6-d8fe-4b4f-aae9-6a0576113d48":{"favIconUrl":"fallback","id":"223c65b6-d8fe-4b4f-aae9-6a0576113d48","title":"Human Preference Score v2: A Solid Benchmark for Evaluating Human Preferences of Text-to-Image Synthesis","url":"https://arxiv.org/pdf/2306.09341.pdf","urlHash":3884743833},"223d61ba-9f0c-447d-afb1-2a75a95d4b95":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"223d61ba-9f0c-447d-afb1-2a75a95d4b95","title":"Ravsehajsinghpuri/Multi-Variant-Instructions","url":"https://github.com/Ravsehajsinghpuri/Multi-Variant-Instructions","urlHash":2607606737},"223f174b-5ce2-4caa-a8fd-72a593b25465":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"223f174b-5ce2-4caa-a8fd-72a593b25465","title":"lucidrains/local-attention: An implementation of local windowed attention for language modeling","url":"https://github.com/lucidrains/local-attention","urlHash":2799030329},"226bc329-8fed-4fb9-9e5b-e94280de3800":{"favIconUrl":"fallback","id":"226bc329-8fed-4fb9-9e5b-e94280de3800","title":"Cheap and Quick Efficient Vision-Language Instruction Tuning for Large Language Models - Arxiv-2305.15023","url":"https://arxiv.org/abs/2305.15023","urlHash":725680623},"2273891d-99f0-40a9-ad7a-ca8eb5744cac":{"favIconUrl":"https://www.google.com/favicon.ico","id":"2273891d-99f0-40a9-ad7a-ca8eb5744cac","title":"LM is not a fair evaluator - Google Search","url":"https://www.google.com/search?q=LM+is+not+a+fair+evaluator&rlz=1C1GCEA_enUS1059US1059&oq=LM+is+not+a+fair+evaluator&aqs=chrome..69i57.3993j0j7&sourceid=chrome&ie=UTF-8","urlHash":3058110541},"229f91be-b7e1-4b08-b8f3-6249c18e56d3":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"229f91be-b7e1-4b08-b8f3-6249c18e56d3","title":"Jack Hessel on X: \"@srush_nlp @tomgoldsteincs I like the DPO/sequence likelihood version as a ranking task. The loss function that falls out of policy gradient also has a nice/direct interpretation as well (here's a slide ive used in talks before, based on this line of code) https://t.co/BmTiuWkJVU https://t.co/RHPS22BPxU\" / X","url":"https://twitter.com/jmhessel/status/1730671215894032882","urlHash":2677389657},"22b6f428-2781-4d07-a9d5-69f1539a534f":{"favIconUrl":"fallback","id":"22b6f428-2781-4d07-a9d5-69f1539a534f","title":"Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting | PDF","url":"https://arxiv.org/pdf/2305.14755.pdf","urlHash":1037491329},"22c066f8-26df-494c-8ae7-27fe627e0ed5":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"22c066f8-26df-494c-8ae7-27fe627e0ed5","title":"陈丹琦团队新作：5%成本拿下SOTA，“羊驼剪毛”大法火了","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247698889&idx=2&sn=871c3e3b9dcdc8c70004c8df9f497bc4&exportkey=n_ChQIAhIQqr8ODELVTW9zwpWoaBC3khKWAgIE97dBBAEAAAAAAFoHBHYPFswAAAAOpnltbLcz9gKNyK89dVj08JV9nohOwFJAYo1mWJoWxRu5uo6DciH37li2wfmvRo7BvdOAxpVOi4%2F586fVP9vwxVin3gqui7vBB3tsWjmbm9bDXaOe2QlkpwPdW52dhgw111vnX5nzETxleKJcbcw7XEoYongWLppjb2RXOwMaACokHz5XWQElNEmTUoG0lNWGOjxEom0Xxlzsvrlj034JFqwmDisOX4%2FICSV2k%2Fg8akIDczlGuVAVCm57klxTWxDsfyPrA5ga8BhsJLYliU%2BnbefSsbWzp1iy2Bz5uRkR7vjs1pp3qNmBu9ZLkVg8bK075xyzWqHlgIhUsR74BiF1&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsb0aXHwC%2F0Ed%2F3OyiohCYFhihvRWPvekpJ2E2b6cq2S4Q%3D%3D&wx_header=0","urlHash":1654440355},"22d51f1a-382f-4ffb-a693-bca81a8a99ca":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"22d51f1a-382f-4ffb-a693-bca81a8a99ca","title":"HALOs/assets/report.pdf at main · ContextualAI/HALOs","url":"https://github.com/ContextualAI/HALOs/blob/main/assets/report.pdf?utm_source=substack&utm_medium=email","urlHash":2842223618},"22ef94be-b42c-48a1-aed1-fb12e4fd0be5":{"favIconUrl":"fallback","id":"22ef94be-b42c-48a1-aed1-fb12e4fd0be5","title":"呼吸 : 焦虑是自由引起的眩晕_特德·姜_在线阅读_九九藏书网","url":"https://www.99csw.com/book/10305/371569.htm","urlHash":2039331102},"23472ca5-4e95-4dbc-93c3-2bca0770b4c8":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"23472ca5-4e95-4dbc-93c3-2bca0770b4c8","title":"Sumit on X: \"Is Cosine-Similarity of Embeddings Really About Similarity? Netflix cautions against blindly using cosine similarity as a measure of semantic similarity between learned embeddings, as it can yield arbitrary and meaningless results. 📝https://t.co/rbtsmXQ19s https://t.co/HUUWJuc6XO\" / X","url":"https://twitter.com/_reachsumit/status/1767045820384477575?utm_source=substack&utm_medium=email","urlHash":3825953258},"23530fa5-7310-46a6-99d6-5a2dd27dbd74":{"favIconUrl":"fallback","id":"23530fa5-7310-46a6-99d6-5a2dd27dbd74","title":"mcnemar's test vs chi square - Google Search","url":"https://www.google.com/search?q=mcnemar%27s+test+vs+chi+square&newwindow=1&ei=dnpVY6S_EKim5NoPovyOuAE&oq=McNemar%27s+test+vs&gs_lcp=Cgdnd3Mtd2l6EAEYADIFCAAQgAQyBQgAEIAEMgUIABCABDIGCAAQFhAeMgYIABAWEB4yBggAEBYQHjIGCAAQFhAeMgYIABAWEB4yBQgAEIYDMgUIABCGAzoECAAQRzoECAAQQ0oECE0YAUoECEEYAEoECEYYAFDiBVjyCWDRFWgAcAJ4AIABhwGIAd8CkgEDMC4zmAEAoAEByAEIwAEB&sclient=gws-wiz","urlHash":4089254520},"23649038-b77a-4fb2-8e38-853566bde230":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"23649038-b77a-4fb2-8e38-853566bde230","title":"Training Trajectories of Language Models Across Scales | Abstract","url":"https://arxiv.org/abs/2212.09803","urlHash":2334017397},"2381ec4e-7533-4c70-bc03-4b997a9a4cb1":{"favIconUrl":"fallback","id":"2381ec4e-7533-4c70-bc03-4b997a9a4cb1","title":"Augmented Language Models a Survey - Arxiv-2302.07842","url":"https://arxiv.org/abs/2302.07842","urlHash":764442800},"23853f21-af08-4c69-9cb5-7a8bee62d14f":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"23853f21-af08-4c69-9cb5-7a8bee62d14f","title":"Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models | PDF","url":"https://arxiv.org/pdf/2312.06585.pdf","urlHash":572548062},"238f9e03-a672-4aa6-89bd-6ecfc9bf719b":{"favIconUrl":"fallback","id":"238f9e03-a672-4aa6-89bd-6ecfc9bf719b","title":"interpretable-kdd16.pdf","url":"https://www-cs-faculty.stanford.edu/people/jure/pubs/interpretable-kdd16.pdf","urlHash":2816870237},"23beba8c-d209-4864-a1c2-5554bcee4cc7":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"23beba8c-d209-4864-a1c2-5554bcee4cc7","title":"twitter.com/arankomatsuzaki/status/1660850204633972736","url":"https://twitter.com/arankomatsuzaki/status/1660850204633972736","urlHash":2602155391},"24018e97-9fe2-49e9-b355-f7962ee99629":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"24018e97-9fe2-49e9-b355-f7962ee99629","title":"如果我搬出RLHF+GAN这个设定，你如何应对","url":"https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&mid=2247495391&idx=1&sn=51407a77e2d0277d958adaf533f6ca5b&exportkey=n_ChQIAhIQVhFWzJe6Z6CNs9XBBKWgchKWAgIE97dBBAEAAAAAAKjfAEd%2BEioAAAAOpnltbLcz9gKNyK89dVj0XCVvGvCSFc8Pxv3vOAbrOEXbNPfVaA5nIOgrfpG%2F4WSaN45FnGj0k%2BTBuNUi6bMjq5PqrNmTpX867P7OEPaNq8nsU7CzXqyChYMOdRTR%2BSTbyLJBZE7zZSIC2hnJwsy1%2FFKnlHba7NWFQuPLXxlCE1F%2BNOAr48UJoKsbuX6FymxjPBqT%2FD7Dm3P1ytnjzAWL4lmokbby7TECO47twC2PfW6nDgkgZ%2BellkWq7LsqUl2t0Zp138seoZK9UZhdYJyUrZWbiCeB9zP4nPf0yv96Eeo4W6lCiEo%2Fn6fbrUb0YB8QIfiae5KdjfTIaPNac0HG&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsYrKcpTCxxq92hTBI%2BAlqhiRSwbO%2BTx7xPdsIbSjx27Pw%3D%3D&wx_header=0","urlHash":2346245096},"242dc478-8924-4f33-8b4c-eaf06216bf95":{"favIconUrl":"fallback","id":"242dc478-8924-4f33-8b4c-eaf06216bf95","title":"再谈类别不平衡问题：调节权重与魔改Loss的对比联系 - 科学空间|Scientific Spaces","url":"https://www.spaces.ac.cn/archives/7708/comment-page-1","urlHash":83719307},"24512467-2b96-4833-8ced-fe717f59cbe4":{"favIconUrl":"https://blog.langchain.dev/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png","id":"24512467-2b96-4833-8ced-fe717f59cbe4","title":"JSON agents with Ollama & LangChain","url":"https://blog.langchain.dev/json-based-agents-with-ollama-and-langchain/","urlHash":1253808673},"2460ae9e-d937-4e9b-86e3-9301832bd380":{"favIconUrl":"https://99csw.com/favicon.ico","id":"2460ae9e-d937-4e9b-86e3-9301832bd380","title":"视线_石泽英太郎_在线阅读_九九藏书网","url":"https://99csw.com/book/10759/index.htm","urlHash":3882256111},"248916aa-c90c-4644-bf39-ec1baa5958ce":{"favIconUrl":"fallback","id":"248916aa-c90c-4644-bf39-ec1baa5958ce","title":"一张图转3D质量起飞！GitHub刚建空仓就有300+人赶来标星","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247687565&idx=4&sn=2df7d06ae91848523e63df743d2a120c&exportkey=n_ChQIAhIQOrXdhhwAjMM5Qz79jh0xOxKWAgIE97dBBAEAAAAAAHCCA1UeA0YAAAAOpnltbLcz9gKNyK89dVj0I%2FlyD0YDuvE0RpM9N5Z6pIl7JuwdY8lzGq2xua9o3CVFrTsV6UhuMXpxaYi50lipij6VQrI2XmiwucsBa430%2BrZyTMXyLtkCPNnoEveBmvTGVFjHc8Zd6Ui2bZf5uLEfCGIPVVTjjpLSKdPNW%2BuyGvxI0ln5u2XUvKt99gg5QJfuW64hKbZgV9G%2Bc20BkgXPozDgFNidnQF8CgMU1wY%2B%2BU%2Frw50g3K6EzKk0ZxKquQy3AhmdJU4bjyYxQJJzzv8APYesSUAe4F782vxGwcwC925yrHukh5XlU57VaGYnQ6HuLd45xGEPWkIHF9bfjPg2&acctmode=0&pass_ticket=3%2FbwJXy0theLisDWsCzThrgf0%2FuJgpnJ7GPhENnqSJYm1zcWdYNxlHd4%2BaXSy7Qo&wx_header=0","urlHash":473689322},"24b87079-4b59-426a-87f3-15ec4f8e765e":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"24b87079-4b59-426a-87f3-15ec4f8e765e","title":"Vaidehi Patil on X: \"🚨Can Sensitive Information Be Deleted From LLMs? We show that extraction attacks recover 18-38% of \"deleted\" knowledge! Our attack+defense framework has whitebox+blackbox attacks. New defense objectives lower attacks to 2%! https://t.co/xluew4BBoS @peterbhase @mohitban47 🧵 https://t.co/0YPxeuTuEE\" / X","url":"https://twitter.com/vaidehi_patil_/status/1708897361974686088","urlHash":4042724321},"24bb3365-d662-43a2-a643-dabb72474343":{"favIconUrl":"fallback","id":"24bb3365-d662-43a2-a643-dabb72474343","title":"(1) LLM Security on X: \"TrustGPT: A Benchmark for Trustworthy and Responsible Large Language Models paper: https://t.co/h3XSVuluRn \"TrustGPT provides a comprehensive evaluation of LLMs in three crucial areas: toxicity, bias, and value-alignment. Initially, TrustGPT examines toxicity in language models… https://t.co/Cw1P8jqCPU\" / X","url":"https://twitter.com/llm_sec/status/1702623535384924581","urlHash":1777299294},"24d89ad9-8c62-4a3f-bf96-7a16a70c3135":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"24d89ad9-8c62-4a3f-bf96-7a16a70c3135","title":"吃“有毒”数据，大模型反而更听话了！来自港科大&华为诺亚方舟实验室","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247701019&idx=5&sn=de7b3deaa9b55932507b285621e2beed&exportkey=n_ChQIAhIQuhAmLXKBdHI%2BEbC33tmkORKWAgIE97dBBAEAAAAAAH6YCmBgrt4AAAAOpnltbLcz9gKNyK89dVj0OJuc%2FBVqpU9hfoj4odcO1N1XZLt3%2B4PxER4gthQifVhFgk9mnBt%2BStVUW30susOqVnKZBLDstydfOKEl70wzF0dusQqUs0C8hh%2FOgNmoyw2y02h2MuWLR%2F1B5tRwgxNCJrh9Td4BvClG7koou3dw8gI5yvq4rglVTBVSf0XayF9nH2Q%2FBkuWXQXb5tnhwY0V6N%2BnNmNuTwbtT3siYQsF5y1d%2FcU%2Fr22kXQcGK6VUh1EwCKgo6%2Flsm9wy6CnVQuzBW0n452boixvxv1DuA6y2GVU1M7ccH56f2J7ILaVEBrTQIMmphfWUTlZeLSWDNw%2FF&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsaoWkQ4SCrr7pLymlxATAbeFyrvWxQ57yJxu6doQoZdLA%3D%3D&wx_header=0","urlHash":845627319},"24e1c7f4-92d5-4cc2-8532-d854de2cd8c9":{"favIconUrl":"fallback","id":"24e1c7f4-92d5-4cc2-8532-d854de2cd8c9","title":"BYOL - Google Search","url":"https://www.google.com/search?q=BYOL&oq=BYOL&aqs=chrome..69i57j69i61&sourceid=chrome&ie=UTF-8","urlHash":2015415758},"2516172f-9f91-4064-b4b8-0fc9e669d67a":{"favIconUrl":"fallback","id":"2516172f-9f91-4064-b4b8-0fc9e669d67a","title":"lime learning inductive bias for primitives of mathematical reasoning - Google Search","url":"https://www.google.com/search?q=lime+learning+inductive+bias+for+primitives+of+mathematical+reasoning&oq=lime+learning+ind&aqs=chrome.4.69i57j0i546l2j0i546i649j0i546l2.5197j0j1&sourceid=chrome&ie=UTF-8","urlHash":206437050},"25190dd3-50cb-4410-87b4-91da1656b9cf":{"favIconUrl":"fallback","id":"25190dd3-50cb-4410-87b4-91da1656b9cf","title":"Symmetric Cross Entropy for Robust Learning with Noisy Labels - Arxiv-1908.06112","url":"https://arxiv.org/pdf/1908.06112.pdf","urlHash":709361584},"2523c8e8-a397-453b-adfd-464a2ce15958":{"favIconUrl":"fallback","id":"2523c8e8-a397-453b-adfd-464a2ce15958","title":"rltheorybook_AJKS.pdf","url":"https://shamulent.github.io/RL_2023/Reading/rltheorybook_AJKS.pdf","urlHash":3322811178},"253ada38-2849-4633-97e0-12e78af6eb3f":{"favIconUrl":"fallback","id":"253ada38-2849-4633-97e0-12e78af6eb3f","title":"召唤GPT4多重人格，实力超群大幅减少幻觉！微软UIUC新工作释放大模型认知协同能力","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247556426&idx=2&sn=2e14503460741f03afaf148ac33c6ebd&exportkey=n_ChQIAhIQESIO%2FwOON0orCRoUgMyswhKWAgIE97dBBAEAAAAAANXoAGu0Rx4AAAAOpnltbLcz9gKNyK89dVj0FiyD2TkMI6uicXMVe5hH3OtQfCwS1dlDmL%2F%2Fp%2FT%2FsbMr%2FZtUX5QN6vIW3OiqqD8YoOd53vF67bHYoPZX4X1BJRBQyK03GpC8gTKHpA5PpimIKgfbNeDVM30Am08A4KdqJ7T6G4h2rU4330IiPJQ0Z6wBKFX94qn457WAKpzdkxUJ6nM9OUBDMSmbayDKBtODt9qhPH6hqXfclR6EEwczHCJaU%2Bt9Uk8KwCNMdIOxrxAWxqEZ7djnIj6U5CgO0Ji7InAyru%2F6qoz8N1HTJ6FMvNp6vfRv%2F7m3%2F1tjfF%2Fot5%2Bk9lsBv%2B4vPKsJByz7Yxb2&acctmode=0&pass_ticket=2mEzLpRzSheYPZ%2FtxjQtBQ4mE0ha1Mdn3bPcjO28vn574bepoVvmqGqL6Bv8GJtn&wx_header=0","urlHash":3593805695},"255decb8-0260-4e1a-926b-095d1ff9fb1f":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"255decb8-0260-4e1a-926b-095d1ff9fb1f","title":"GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers | PDF","url":"https://arxiv.org/pdf/2210.17323.pdf","urlHash":123243916},"255f536e-18d1-4fbd-a292-00f4dd3b8c11":{"favIconUrl":"https://www.99csw.com/favicon.ico","id":"255f536e-18d1-4fbd-a292-00f4dd3b8c11","title":"不速之客的自助餐:遴选主菜 谋杀游戏_克里斯蒂安娜·布兰德_在线阅读_九九藏书网","url":"https://www.99csw.com/book/8195/286414.htm","urlHash":444396881},"25703dc7-d84a-44fa-93d5-7b37c5c960e1":{"favIconUrl":"https://aclanthology.org/aclicon.ico","id":"25703dc7-d84a-44fa-93d5-7b37c5c960e1","title":"Is Attention Explanation? An Introduction to the Debate - ACL Anthology","url":"https://aclanthology.org/2022.acl-long.269/","urlHash":633980975},"257ac310-5496-40dd-9aca-eaf83add03dc":{"favIconUrl":"fallback","id":"257ac310-5496-40dd-9aca-eaf83add03dc","title":"Language Models (Mostly) Know What They Know - Arxiv-2207.05221","url":"https://arxiv.org/abs/2207.05221","urlHash":2466978355},"25d0c14e-baeb-4499-9e31-eefdae811c3c":{"favIconUrl":"fallback","id":"25d0c14e-baeb-4499-9e31-eefdae811c3c","title":"DataMUX Data Multiplexing for Neural Networks - Arxiv-2202.09318","url":"https://arxiv.org/abs/2202.09318","urlHash":874670835},"25d9b142-fd61-49a3-a73e-799a8981a98d":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"25d9b142-fd61-49a3-a73e-799a8981a98d","title":"Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models | PDF","url":"https://arxiv.org/pdf/2311.09210.pdf","urlHash":3769537510},"261ab86b-6669-47fb-81fe-9a9ab237a1a4":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"261ab86b-6669-47fb-81fe-9a9ab237a1a4","title":"Weizhu Chen on X: \"A recent work to augment ChatGPT with External Knowledge and Automated Feedback: https://t.co/Ks0MktU6Y5. Big shout-out to the main contributors @JianfengGao0217, @pengbaolin2019 and @MichelGalley. https://t.co/9D6xQs4xHZ\" / X","url":"https://twitter.com/WeizhuChen/status/1630109284074930176","urlHash":1981421500},"261bebbb-7c64-44b3-a8dd-4e824d5ae8e9":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"261bebbb-7c64-44b3-a8dd-4e824d5ae8e9","title":"Generating Images with Multimodal Language Models | PDF","url":"https://arxiv.org/pdf/2305.17216.pdf","urlHash":2933304113},"2646b953-24af-44b9-81a8-0694e8fc698c":{"favIconUrl":"fallback","id":"2646b953-24af-44b9-81a8-0694e8fc698c","title":"拆解追溯 GPT-3.5 各项能力的起源","url":"https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756","urlHash":4273695001},"26b26444-8cbd-4246-b5fc-5cf404aee289":{"favIconUrl":"fallback","id":"26b26444-8cbd-4246-b5fc-5cf404aee289","title":"Learning with not Enough Data Part 3: Data Generation","url":"https://lilianweng.github.io/posts/2022-04-15-data-gen/","urlHash":1583934982},"26e3028b-161b-42f3-81c1-bbf03f7682db":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"26e3028b-161b-42f3-81c1-bbf03f7682db","title":"1bitLLM/bitnet_b1_58-3B · Hugging Face","url":"https://huggingface.co/1bitLLM/bitnet_b1_58-3B","urlHash":2001866528},"26f9a3fd-bfb2-48c8-9a82-6e36beff2c5f":{"favIconUrl":"https://connect-prd-cdn.unity.com/cdn-origin/images/favicons/favicon-32x32.png?v=2","id":"26f9a3fd-bfb2-48c8-9a82-6e36beff2c5f","title":"Get started in the Unity Editor - Unity Learn","url":"https://learn.unity.com/tutorial/get-started-in-the-unity-editor?uv=2021.3&pathwayId=5f7bcab4edbc2a0023e9c38f&missionId=5f77cc6bedbc2a4a1dbddc46&projectId=612f5bfdedbc2a1b4376ce65#6375344eedbc2a3b09474962","urlHash":663361683},"2701c9c1-03cc-41a0-92d3-eb2cb29b5ffc":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"2701c9c1-03cc-41a0-92d3-eb2cb29b5ffc","title":"The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks | PDF","url":"https://arxiv.org/pdf/2306.17844.pdf","urlHash":836213611},"277376b2-0cff-4e33-b087-695419477c96":{"favIconUrl":"fallback","id":"277376b2-0cff-4e33-b087-695419477c96","title":"Captum · Model Interpretability for PyTorch","url":"https://captum.ai/api/search.html?q=SHAP","urlHash":3905932111},"27af9fb2-29fd-418b-8691-5a172dd39e13":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"27af9fb2-29fd-418b-8691-5a172dd39e13","title":"Richard Sutton on X: \"Yes, the agent architectures that Yann LeCun and I work on are both instances of “the common model of the intelligent agent”. And it’s not just an AI thing. You can find the same ideas in psychology, economics, control theory, and neuroscience. See https://t.co/F1HgND82vo\" / X","url":"https://twitter.com/RichardSSutton/status/1752945334358286482","urlHash":2850519083},"27b6c0c9-5560-4aa3-b8a3-416c77b1d950":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"27b6c0c9-5560-4aa3-b8a3-416c77b1d950","title":"最透彻的大模型PPO原理和源码解读","url":"https://mp.weixin.qq.com/s?__biz=MzIwNDY1NTU5Mg==&mid=2247487773&idx=1&sn=67e43c40deac758e6b9c98c095f46d97&chksm=973d8f9aa04a068c1f9761d5f5d8b024e49b3bee96044ed1fccc99676dc86625384687fa6a9f&mpshare=1&scene=1&srcid=02067ECgDCzwDZClnAoQQucm&sharer_shareinfo=bc99e430cae32ed3a9284054e37833af&sharer_shareinfo_first=bc99e430cae32ed3a9284054e37833af&exportkey=n_ChQIAhIQ3iuwvF9VVb0L1aOYHDJyxhKWAgIE97dBBAEAAAAAACyHFBk4Xm4AAAAOpnltbLcz9gKNyK89dVj0zfez%2Bnn2UdeAPdoq%2F%2BZDqGoHNGQlIfL8uOLL9i2ZF3LDnb6gmh94U8QMxgIP4QDUhQ14vZ1OLJ%2ByjM%2F%2Bx0bzzbYkdu9whvEZO7SCSEt8XZ5XA4b3j5nSpc6Rvmz4jqjRIkx0JyATrrvt9Y4ZEzs4%2BkQVpS8fgVNZSLTskuFx6C7BX2nPfgt%2FgcS3nUCa6nUxZ0q3T4pzH7TJVK3MoTmO0boR7JNuwRRsLDr%2BuPPgE4dtKJsfawfLGo%2FuoDO%2FF%2Fk7HSSTh7Rv3ttm9432Iq4JEcA27Y2sTVElVQ5sFp8rxNo%2Bzif%2B5gfE4J8piI8llWfP&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HMJNJhBWQ0wf5EP32TjmdcUhfvsFmxLZLQD%2BgoLBTD%2BIg%3D%3D&wx_header=0#rd","urlHash":1756831322},"27ed23c5-c231-4c27-b486-b5f873f2a6c0":{"favIconUrl":"https://g.csdnimg.cn/static/logo/favicon32.ico","id":"27ed23c5-c231-4c27-b486-b5f873f2a6c0","title":"v_JULY_v_十五大经典算法研究,微软面试100题系列,程序员编程艺术-CSDN博客","url":"https://blog.csdn.net/v_JULY_v?type=blog","urlHash":1472012191},"27ede712-5074-403d-980e-677da739da3a":{"favIconUrl":"fallback","id":"27ede712-5074-403d-980e-677da739da3a","title":"jang23a.pdf","url":"https://proceedings.mlr.press/v203/jang23a/jang23a.pdf","urlHash":4237918717},"27f153d6-fd49-4eee-8faf-9fb2954ee352":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"27f153d6-fd49-4eee-8faf-9fb2954ee352","title":"Tao Yu on X: \"🚀Instructor🚀embeddings recently hit 2M downloads on @huggingface! Now, excited to introduce 🚀GritLM🚀, the first SINGLE LM achieving SoTA in BOTH text embedding (MTEB) &amp; generative tasks (BBH etc)! Great team effort w. @Muennighoff &amp; @hongjin_su! 📰: https://t.co/S16u93J15E👇 https://t.co/ffgUFR7xOT\" / X","url":"https://twitter.com/taoyds/status/1758435944863273019","urlHash":3987499386},"2836ced6-8a12-477e-8220-ae45581ff252":{"favIconUrl":"https://www.google.com/favicon.ico","id":"2836ced6-8a12-477e-8220-ae45581ff252","title":"埃舍尔世界-柄刀一 - Google Search","url":"https://www.google.com/search?q=%E5%9F%83%E8%88%8D%E5%B0%94%E4%B8%96%E7%95%8C-%E6%9F%84%E5%88%80%E4%B8%80","urlHash":3654969164},"2837eb6a-9184-4f90-93a4-6dbaadedcb6b":{"favIconUrl":"fallback","id":"2837eb6a-9184-4f90-93a4-6dbaadedcb6b","title":"First Steps Toward Understanding the Extrapolation of Nonlinear Models to Unseen Domains - Arxiv-2211.11719","url":"https://arxiv.org/pdf/2211.11719.pdf","urlHash":1173094081},"286223ff-2fe0-4fbf-98c6-034859dec861":{"favIconUrl":"fallback","id":"286223ff-2fe0-4fbf-98c6-034859dec861","title":"自监督黑马SimCLRv2来了！提出蒸馏新思路，可迁移至小模型，性能精度超越有监督 - 知乎","url":"https://zhuanlan.zhihu.com/p/150358540","urlHash":3274178440},"286e7346-7725-46ee-bd0b-77d56ebf64cc":{"favIconUrl":"fallback","id":"286e7346-7725-46ee-bd0b-77d56ebf64cc","title":"本雅明 暴力批判 - Google Search","url":"https://www.google.com/search?q=%E6%9C%AC%E9%9B%85%E6%98%8E+%E6%9A%B4%E5%8A%9B%E6%89%B9%E5%88%A4&newwindow=1&sxsrf=AB5stBj8VbNTmRzLKOn1vG8mlfoffHYX2g%3A1688327266782&ei=YtShZIuvL4Tu5NoPoZyroAs&ved=0ahUKEwiL6ICY5fD_AhUEN1kFHSHOCrQQ4dUDCBA&uact=5&oq=%E6%9C%AC%E9%9B%85%E6%98%8E+%E6%9A%B4%E5%8A%9B%E6%89%B9%E5%88%A4&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQA0oECEEYAVDWA1jyGGDDGmgBcAB4AIABUYgBvwSSAQE4mAEAoAEBwAEB&sclient=gws-wiz-serp","urlHash":3705392883},"28a05b01-3145-4ab1-8d09-c3e957c3ed89":{"favIconUrl":"https://dynalist.io/assets/icon/favicon.ico","id":"28a05b01-3145-4ab1-8d09-c3e957c3ed89","title":"Techniques - A Comprehensive Mechanistic Interpretability Explainer & Glossary - Dynalist","url":"https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=8m6oU03bXO60iaRnGzFHBHN9","urlHash":316016851},"28b7ade5-a20a-4277-b33c-eeee58007b75":{"favIconUrl":"fallback","id":"28b7ade5-a20a-4277-b33c-eeee58007b75","title":"RELIC Retrieving Evidence for Literary Claims - Arxiv-2203.10053","url":"https://arxiv.org/abs/2203.10053","urlHash":11006067},"28e5557d-60fd-4a4b-8996-169eec28f27f":{"favIconUrl":"fallback","id":"28e5557d-60fd-4a4b-8996-169eec28f27f","title":"奇文赏析 民主至上——评陈独秀的《爱国心与自觉心》 - 道客巴巴","url":"https://www.doc88.com/p-0062457643161.html?r=1","urlHash":3339573599},"28ef920d-1c66-4c4a-802a-94d9d0ee5ff1":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"28ef920d-1c66-4c4a-802a-94d9d0ee5ff1","title":"毒入りコーヒー事件 (豆瓣)","url":"https://book.douban.com/subject/36459448/","urlHash":1739297672},"29141794-9a50-4647-8b45-7da84b2970fc":{"favIconUrl":"fallback","id":"29141794-9a50-4647-8b45-7da84b2970fc","title":"大模型训练感知量化开山之作：LLM-QAT","url":"https://mp.weixin.qq.com/s?__biz=MzU3Mzg5ODgxMg==&mid=2247485376&idx=1&sn=a9f80a3ae49790205f391c41ba592d19&chksm=fd3bee93ca4c67851582b1611957cfe3d82e4b341b70cc3ebd664db204ceaabd50e5c81bd3a5&mpshare=1&scene=1&srcid=1001YJWuTTgOJzJ41f576Mtx&sharer_shareinfo=f6cc0f257e0b30c428ea59dd0808adcd&sharer_shareinfo_first=f6cc0f257e0b30c428ea59dd0808adcd&exportkey=n_ChQIAhIQhbECPdI%2FoN2v9C3%2BBeeEZBKWAgIE97dBBAEAAAAAAIErAmPhuUUAAAAOpnltbLcz9gKNyK89dVj014i2YzsRLO3Rg%2FKQo5kEluxVf5VfmqViL19fFYljhyvs2CYSYt6tr4qSGnjBQ%2BDZXT8QaJ0bVeuKBFSzRENNP1qTwI54OLG7yqW09HCV1ZEVr336mxXZCSRKtLhCE79RObB3ZPiucfZDMqB3nDL1gTMnhxD9YC%2FhtqRR%2BJ76H14K0vGjkvYEWKwC2m6DLYBmEcn9xYxHB17f9mvjg7knuuc5uU9bfeb6gvJAwgK703PJLOeGEFMrMTcthvSsKPwvrqX4wtiKUz1uLbsyzaRrqfZMu42argyRuh1BJgdnf%2FjW6HGYhdnn%2BJ0nlRcqeY34&acctmode=0&pass_ticket=tpe%2FCFUrzS0lwczAj7ov5YwT1ao02ZP1n59cAnOMALMelGzAIYC2wyAlQVl4Uo2R&wx_header=0#rd","urlHash":4259549140},"29300a3f-4e8a-4db5-acf4-be0bdb6ff36f":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"29300a3f-4e8a-4db5-acf4-be0bdb6ff36f","title":"Do pretrained Transformers Really Learn In-context by Gradient Descent? | Abstract","url":"https://arxiv.org/abs/2310.08540","urlHash":2006322349},"295e34ff-7c4b-46cd-9195-262fb1a7e683":{"favIconUrl":"fallback","id":"295e34ff-7c4b-46cd-9195-262fb1a7e683","title":"Box4Types/README.md at main · yasumasaonoe/Box4Types","url":"https://github.com/yasumasaonoe/Box4Types/blob/main/box4et/README.md","urlHash":2409768041},"29818b10-0de7-4d21-8709-5086b5ec67c6":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"29818b10-0de7-4d21-8709-5086b5ec67c6","title":"(1) Amir Bar on X: \"Finally, our work was inspired by previous works in NLP by @RoeeHendel (\"In-context learning creates task vectors\") and @ericwtodd (\"Function Vectors in Large Language Models\"). The main differences are in the domain (vision) and the search algorithm (REINFORCE). (5/5)\" / X","url":"https://twitter.com/_amirbar/status/1778156019253977571","urlHash":4263430873},"29ce30da-ac4d-488c-b65a-47074edda53b":{"favIconUrl":"fallback","id":"29ce30da-ac4d-488c-b65a-47074edda53b","title":"Guiding Pretraining in Reinforcement Learning with Large Language Models - Arxiv-2302.06692","url":"https://arxiv.org/abs/2302.06692","urlHash":3090522042},"29f80d34-eec3-48ac-9e9d-335c6d4c072f":{"favIconUrl":"fallback","id":"29f80d34-eec3-48ac-9e9d-335c6d4c072f","title":"生成对抗网络 - 知乎","url":"https://www.zhihu.com/column/c_171450570","urlHash":1598338566},"2a2018ae-02ec-4117-b288-182865fa028d":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"2a2018ae-02ec-4117-b288-182865fa028d","title":"Aran Komatsuzaki on X: \"Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent Self-Evolution When combined with GPT-3.5, the performance with the proposed method matches that of raw GPT-4 across various agent tasks https://t.co/s1fRCL6qb5 https://t.co/ub8oqP2QGm\" / X","url":"https://twitter.com/arankomatsuzaki/status/1751107866713334176","urlHash":2229035819},"2a726ebd-4890-4984-9a79-dc72b27588e2":{"favIconUrl":"fallback","id":"2a726ebd-4890-4984-9a79-dc72b27588e2","title":"kitlm: 领域知识融入语言模型，1.5倍的性能改善，开源源代码","url":"https://mp.weixin.qq.com/s?__biz=MzI3NTQ5MjA4OQ==&mid=2247488088&idx=1&sn=c43f3c53cb161df183fc380906d2752c&exportkey=n_ChQIAhIQE%2Fay9rWshq6toC4QlOJ0QhKWAgIE97dBBAEAAAAAAK79GsUb3QYAAAAOpnltbLcz9gKNyK89dVj04BSL%2BFBJ%2FmBTRi0OAzu802U9%2BxTsFR7gYSIazXNwfmg4Zzt4%2BODEVBseysPj%2BoSFMPblymahyv3mdG2MOIvS024%2B%2Fj0i7dr%2FcOhHqYvrhm3gyPy2XTeH5UfS2EyLCgZMfatF16gqjFbLpY%2FbXDJwLK5bNnNXy%2BqrhOpNBfi52lntA%2B7jsOOSn4cDhv4NRfVhOs1k9m1lawG%2F1ENnsfQ03o3ug2I0%2FJhbMe2VETCYc5Zu5cnFew%2BJJWNxbBu89XCz%2FZGuTwqt888orsMRKwmFAPcq3E2WEuEWJIsiyi07qK4QMDrUEKOJG4QXHbCIegH2&acctmode=0&pass_ticket=%2B9l7jF1WeBVqRif8qdrQ8NhMoX05PaT1Gl79RYoxqfSn1vjgedgNhZnj1zf%2Bt2OC&wx_header=0","urlHash":427362846},"2a8b98e4-a99f-4f10-b22c-df92128b121c":{"favIconUrl":"fallback","id":"2a8b98e4-a99f-4f10-b22c-df92128b121c","title":"BertNet Harvesting Knowledge Graphs with Arbitrary Relations from Pretrained Language Models - Arxiv-2206.14268","url":"https://arxiv.org/pdf/2206.14268.pdf","urlHash":1495567366},"2aa88bcf-e235-4606-bd1c-6671d84bdaaf":{"favIconUrl":"fallback","id":"2aa88bcf-e235-4606-bd1c-6671d84bdaaf","title":"雨石记资讯","url":"https://posts.careerengine.us/author/5f4c50ffd1f9823b82ea2eb8/posts?from=authorDetailSidePanel","urlHash":425695688},"2ab428e7-1909-4e58-8f10-0769c9c1a49e":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"2ab428e7-1909-4e58-8f10-0769c9c1a49e","title":"Performer：用随机投影将Attention的复杂度线性化 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/7921","urlHash":2474120444},"2ac796da-d12a-4c95-a03b-d6c5d85c96ee":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"2ac796da-d12a-4c95-a03b-d6c5d85c96ee","title":"srush/GPTWorld: A puzzle to learn about prompting","url":"https://github.com/srush/GPTWorld","urlHash":3617833468},"2acc3fa1-0fd6-4928-90c9-2bd9fba84c28":{"favIconUrl":"fallback","id":"2acc3fa1-0fd6-4928-90c9-2bd9fba84c28","title":"lecture9.dvi","url":"https://www.di.ens.fr/~fbach/learning_theory_class/lecture9.pdf","urlHash":3205176385},"2ad48625-f4a2-4391-9bfc-900aa398a2ff":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"2ad48625-f4a2-4391-9bfc-900aa398a2ff","title":"LM vs LM: Detecting Factual Errors via Cross Examination | PDF","url":"https://arxiv.org/pdf/2305.13281.pdf","urlHash":2873270042},"2ad5886a-e140-4213-a493-684c4fb4a8be":{"favIconUrl":"fallback","id":"2ad5886a-e140-4213-a493-684c4fb4a8be","title":"learn2learn kronecker - Google Search","url":"https://www.google.com/search?q=learn2learn+kronecker&oq=learn2learn+kronecker&aqs=chrome..69i57j69i60.4601j0j1&sourceid=chrome&ie=UTF-8","urlHash":3545692251},"2ad9434e-46b1-4d7e-8464-f992f7da4e07":{"favIconUrl":"fallback","id":"2ad9434e-46b1-4d7e-8464-f992f7da4e07","title":"Constitutional AI: Harmlessness from AI Feedback","url":"https://arxiv.org/pdf/2212.08073.pdf","urlHash":2356097480},"2afc1d9f-c1ef-485c-b769-fe9d193c24f7":{"favIconUrl":"fallback","id":"2afc1d9f-c1ef-485c-b769-fe9d193c24f7","title":"Learnable Boundary Guided Adversarial Training - Arxiv-2011.11164","url":"https://arxiv.org/pdf/2011.11164.pdf","urlHash":3271905200},"2b4f3727-d6c3-4309-9c25-eafbdaaf917f":{"favIconUrl":"https://www.google.com/favicon.ico","id":"2b4f3727-d6c3-4309-9c25-eafbdaaf917f","title":"无之馆 - Google Search","url":"https://www.google.com/search?q=%E6%97%A0%E4%B9%8B%E9%A6%86","urlHash":394595564},"2b54ba7e-18a5-43a7-bd15-8133c870815f":{"favIconUrl":"https://browse.arxiv.org/favicon.ico","id":"2b54ba7e-18a5-43a7-bd15-8133c870815f","title":"Graph Neural Prompting with Large Language Models | PDF","url":"https://browse.arxiv.org/pdf/2309.15427.pdf","urlHash":743937764},"2b56e65a-5383-42d6-9a7a-bb6941923dc8":{"favIconUrl":"fallback","id":"2b56e65a-5383-42d6-9a7a-bb6941923dc8","title":"conceptfusion - Google Search","url":"https://www.google.com/search?q=conceptfusion&rlz=1C1GCEA_enUS1059US1059&oq=conceptfusion&aqs=chrome.0.69i59.1950j0j7&sourceid=chrome&ie=UTF-8","urlHash":1757339156},"2b795794-1b0a-44d8-931f-289da14334e8":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"2b795794-1b0a-44d8-931f-289da14334e8","title":"Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models | Abstract","url":"https://arxiv.org/abs/2311.00871","urlHash":1508134479},"2b8d6ea0-47a2-4103-acff-0078e4a21ecb":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"2b8d6ea0-47a2-4103-acff-0078e4a21ecb","title":"Randomized Prior Functions for Deep Reinforcement Learning | PDF","url":"https://arxiv.org/pdf/1806.03335.pdf","urlHash":666844452},"2bb53527-5f41-4c0c-95e1-6573270f3793":{"favIconUrl":"fallback","id":"2bb53527-5f41-4c0c-95e1-6573270f3793","title":"Accuracy on the Line: On the Strong Correlation Between Out-of-Distribution and In-Distribution Generalization","url":"https://proceedings.mlr.press/v139/miller21b/miller21b.pdf","urlHash":1008101716},"2bc9fded-16e7-4f90-b3b7-3edfee088aa1":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"2bc9fded-16e7-4f90-b3b7-3edfee088aa1","title":"Can We Edit Factual Knowledge by In-Context Learning? | Abstract","url":"https://arxiv.org/abs/2305.12740","urlHash":4249128363},"2bddea93-8e0a-4978-9281-ee36842934ef":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"2bddea93-8e0a-4978-9281-ee36842934ef","title":"Exploring the Benefits of Training Expert Language Models over Instruction Tuning | Abstract","url":"https://arxiv.org/abs/2302.03202","urlHash":444105762},"2c0c88a0-7e3e-4fb4-ad4f-6668650145d1":{"favIconUrl":"https://blog.langchain.dev/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png","id":"2c0c88a0-7e3e-4fb4-ad4f-6668650145d1","title":"Self-Reflective RAG with LangGraph","url":"https://blog.langchain.dev/agentic-rag-with-langgraph/","urlHash":4040975574},"2c2165d3-9869-4be0-98ee-e6b106604956":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"2c2165d3-9869-4be0-98ee-e6b106604956","title":"Awesome SFT datasets - a HuggingFaceH4 Collection","url":"https://huggingface.co/collections/HuggingFaceH4/awesome-sft-datasets-65788b571bf8e371c4e4241a","urlHash":3680713153},"2c46e708-26a2-4f3f-9958-65d3be43e46c":{"favIconUrl":"fallback","id":"2c46e708-26a2-4f3f-9958-65d3be43e46c","title":"google-research/sam","url":"https://github.com/google-research/sam","urlHash":1227799236},"2c4e5cc5-c760-4f35-991f-3cdb4d97fa59":{"favIconUrl":"fallback","id":"2c4e5cc5-c760-4f35-991f-3cdb4d97fa59","title":"Normalization is dead, long live normalization! · The ICLR Blog Track","url":"https://iclr-blog-track.github.io/2022/03/25/unnormalized-resnets/","urlHash":1296971202},"2c54f308-34db-44f5-a002-3de943f26327":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"2c54f308-34db-44f5-a002-3de943f26327","title":"MART: Improving LLM Safety with Multi-round Automatic Red-Teaming | Abstract","url":"https://arxiv.org/abs/2311.07689?utm_source=substack&utm_medium=email","urlHash":2367568875},"2c9c19fc-e161-40d7-b660-d2b697c437f8":{"favIconUrl":"fallback","id":"2c9c19fc-e161-40d7-b660-d2b697c437f8","title":"Collections: Why No Roman Industrial Revolution? – A Collection of Unmitigated Pedantry","url":"https://acoup.blog/2022/08/26/collections-why-no-roman-industrial-revolution/","urlHash":1114196726},"2cc785b2-3a5a-402b-bdb5-d00ed018a3a8":{"favIconUrl":"https://vaclavkosar.com/images/icons/favicon-32x32.png","id":"2cc785b2-3a5a-402b-bdb5-d00ed018a3a8","title":"How Deep Neural Networks Learn","url":"https://vaclavkosar.com/ml/How-Deep-Neural-Networks-Learn","urlHash":2698436352},"2cdbdd17-5765-4748-9a76-07a5a498e7cc":{"favIconUrl":"fallback","id":"2cdbdd17-5765-4748-9a76-07a5a498e7cc","title":"https://arxiv.org/pdf/2301.03044.pdf","url":"https://arxiv.org/pdf/2301.03044.pdf","urlHash":1689890449},"2cec668f-2bf4-4b24-87e3-8bf4070fce5b":{"favIconUrl":"fallback","id":"2cec668f-2bf4-4b24-87e3-8bf4070fce5b","title":"RSGAN：对抗模型中的“图灵测试”思想 - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/6110","urlHash":1749644481},"2cf0b420-bd9f-4d6a-8fad-d8ea6a870b35":{"favIconUrl":"fallback","id":"2cf0b420-bd9f-4d6a-8fad-d8ea6a870b35","title":"Cut and Learn for Unsupervised Object Detection and Instance Segmentation","url":"http://people.eecs.berkeley.edu/~xdwang/projects/CutLER/","urlHash":3175779812},"2d5321e3-2bb7-4595-8b7a-fa0f5cc16e24":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"2d5321e3-2bb7-4595-8b7a-fa0f5cc16e24","title":"Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping | PDF","url":"https://arxiv.org/pdf/2402.14083.pdf","urlHash":1561515062},"2d54eae4-fed1-4704-b278-de7d10797460":{"favIconUrl":"fallback","id":"2d54eae4-fed1-4704-b278-de7d10797460","title":"CSC412 Winter 2020: Probabilsitic Machine Learning","url":"https://probmlcourse.github.io/csc412/","urlHash":3588062970},"2d77110d-cb21-4d77-8e78-ab5867ea7ae4":{"favIconUrl":"fallback","id":"2d77110d-cb21-4d77-8e78-ab5867ea7ae4","title":"43119db5d59f07cc08fca7ba6820179a-Paper-Datasets_and_Benchmarks.pdf","url":"https://proceedings.neurips.cc/paper_files/paper/2022/file/43119db5d59f07cc08fca7ba6820179a-Paper-Datasets_and_Benchmarks.pdf","urlHash":603032340},"2d7ae04b-8b1b-44cb-9f2d-190f36022f17":{"favIconUrl":"fallback","id":"2d7ae04b-8b1b-44cb-9f2d-190f36022f17","title":"写给小白的YOLO介绍 - 知乎","url":"https://zhuanlan.zhihu.com/p/94986199","urlHash":1768810976},"2d926b14-05c5-4cea-9058-e70e0308081c":{"favIconUrl":"fallback","id":"2d926b14-05c5-4cea-9058-e70e0308081c","title":"深入浅出Yolo系列之Yolov5核心基础知识完整讲解 - 知乎","url":"https://zhuanlan.zhihu.com/p/172121380","urlHash":3072881722},"2db0c1d2-a748-4b15-a889-ea2378389c59":{"favIconUrl":"https://largeworldmodel.github.io/static/globe.png","id":"2db0c1d2-a748-4b15-a889-ea2378389c59","title":"Large World Models","url":"https://largeworldmodel.github.io/","urlHash":3789762259},"2dc09caf-51f2-4fa1-9e97-4863942b59e3":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"2dc09caf-51f2-4fa1-9e97-4863942b59e3","title":"The Generative AI Paradox: \"What It Can Create, It May Not Understand\" | PDF","url":"https://arxiv.org/pdf/2311.00059.pdf","urlHash":4211640752},"2dd3c032-97f4-47a5-9094-9cfed73fde42":{"favIconUrl":"fallback","id":"2dd3c032-97f4-47a5-9094-9cfed73fde42","title":"李航统计学习方法（第六章） - 知乎","url":"https://zhuanlan.zhihu.com/p/114284754","urlHash":1190961972},"2ddf56b0-5379-42fc-9cd7-012cd29832a6":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"2ddf56b0-5379-42fc-9cd7-012cd29832a6","title":"Peter J. Liu on X: \"People are realizing RLHF can be easy with DPO and SLiC-HF. If you were wondering how they compare, the answer is they are pretty similar and our paper (https://t.co/Iz4fWnYcYo led by @Terenceliu4444) shows the math. The biggest question is whether you should train a preference… https://t.co/jbSXonvjvP\" / X","url":"https://twitter.com/peterjliu/status/1711789322326999482","urlHash":985085086},"2e155a96-9b32-407b-98a8-3e8dcc3e3a60":{"favIconUrl":"fallback","id":"2e155a96-9b32-407b-98a8-3e8dcc3e3a60","title":"BradyFU/Awesome-Multimodal-Large-Language-Models: :sparkles::sparkles:Latest Papers and Datasets on Multimodal Large Language Models, and Their Evaluation.","url":"https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models","urlHash":4067010624},"2e3fb0d7-0bc5-4f62-bdd5-c782265027ce":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"2e3fb0d7-0bc5-4f62-bdd5-c782265027ce","title":"Shizhe Diao on X: \"Can we align LLMs to honesty via instruction finetuning? Can we instruct LLMs to say I Don't Know? Can uncertainty learning improve prediction ability? Excited to share R-Tuning, Refusal-Aware Instruction Tuning to tackle hallucination in LLMs. Paper: https://t.co/DWZ1nTPCwb https://t.co/5HdKzXT71o\" / X","url":"https://twitter.com/shizhediao/status/1741120400992465338","urlHash":63790474},"2e47f208-853b-4c85-9614-28a9fd43bc08":{"favIconUrl":"https://www.google.com/favicon.ico","id":"2e47f208-853b-4c85-9614-28a9fd43bc08","title":"手代木正太郎『涜神館殺人事件』 豆瓣 - Google Search","url":"https://www.google.com/search?q=%E6%89%8B%E4%BB%A3%E6%9C%A8%E6%AD%A3%E5%A4%AA%E9%83%8E%E3%80%8E%E6%B6%9C%E7%A5%9E%E9%A4%A8%E6%AE%BA%E4%BA%BA%E4%BA%8B%E4%BB%B6%E3%80%8F+%E8%B1%86%E7%93%A3&newwindow=1&sca_esv=594833718&sxsrf=AM9HkKlTD3aKOtKDsWG6TPYTxaI9M_mqDQ%3A1704084318479&ei=XkOSZdrwHISo5NoP4rSU6AU&ved=0ahUKEwjal-HjsLuDAxUEFFkFHWIaBV0Q4dUDCBE&uact=5&oq=%E6%89%8B%E4%BB%A3%E6%9C%A8%E6%AD%A3%E5%A4%AA%E9%83%8E%E3%80%8E%E6%B6%9C%E7%A5%9E%E9%A4%A8%E6%AE%BA%E4%BA%BA%E4%BA%8B%E4%BB%B6%E3%80%8F+%E8%B1%86%E7%93%A3&gs_lp=Egxnd3Mtd2l6LXNlcnAiNOaJi-S7o-acqOato-WkqumDjuOAjua2nOelnumkqOauuuS6uuS6i-S7tuOAjyDosYbnk6NIzw9QowVYnA5wAXgAkAEAmAFwoAGPBaoBAzcuMbgBA8gBAPgBAcICCBAAGIAEGKIE4gMEGAEgQYgGAQ&sclient=gws-wiz-serp","urlHash":304827070},"2ecf9614-a8b0-4e6e-928b-f7f92f0cbab4":{"favIconUrl":"https://cdn.semanticscholar.org/b5fbde4a4847434e/img/darkmode/favicon-32x32.png","id":"2ecf9614-a8b0-4e6e-928b-f7f92f0cbab4","title":"Benchmarking Interpretability Tools for Deep Neural Networks | Semantic Scholar","url":"https://www.semanticscholar.org/paper/Benchmarking-Interpretability-Tools-for-Deep-Neural-Casper-Li/284e59cad4f3dd613bc81e00eb8e02eac8723530","urlHash":2695063751},"2f34a5b7-b50a-4893-a5b8-533ff0091b40":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"2f34a5b7-b50a-4893-a5b8-533ff0091b40","title":"Inspecting and Editing Knowledge Representations in Language Models | Abstract","url":"https://arxiv.org/abs/2304.00740","urlHash":976576391},"2f3b5fbc-aada-414a-a2c6-34df57c0ff38":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"2f3b5fbc-aada-414a-a2c6-34df57c0ff38","title":"RLCD: Reinforcement Learning from Contrast Distillation for Language Model Alignment | PDF","url":"https://arxiv.org/pdf/2307.12950.pdf","urlHash":2102870981},"2f4e9c1e-0ca1-4880-ac20-0c9f3d190a75":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"2f4e9c1e-0ca1-4880-ac20-0c9f3d190a75","title":"A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions | Abstract","url":"https://arxiv.org/abs/2311.05232?utm_source=substack&utm_medium=email","urlHash":1016166019},"2f58d0bf-a57a-4312-a21f-9f3e029c3715":{"favIconUrl":"fallback","id":"2f58d0bf-a57a-4312-a21f-9f3e029c3715","title":"Perfectly Balanced Improving Transfer and Robustness of Supervised Contrastive Learning - Arxiv-2204.07596","url":"https://arxiv.org/abs/2204.07596","urlHash":855581447},"2fa05351-de65-4fa0-82eb-3587b7326418":{"favIconUrl":"https://iclr-blog-track.github.io/public/favicon.ico","id":"2fa05351-de65-4fa0-82eb-3587b7326418","title":"An Understanding of Learning from Demonstrations for Neural Text Generation · The ICLR Blog Track","url":"https://iclr-blog-track.github.io/2022/03/25/text-gen-via-lfd/#mle-vs-gold","urlHash":3785072203},"2fc2f830-f1b0-4a98-b9de-54fb7ceb6d0a":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"2fc2f830-f1b0-4a98-b9de-54fb7ceb6d0a","title":"JasonForJoy/Model-Editing-Hurt: Model Editing Can Hurt General Abilities of Large Language Models","url":"https://github.com/JasonForJoy/Model-Editing-Hurt","urlHash":1423523078},"2fc64f98-18d2-4ca8-8554-eb1b82ab17ec":{"favIconUrl":"fallback","id":"2fc64f98-18d2-4ca8-8554-eb1b82ab17ec","title":"Measuring Robustness to Natural Distribution Shifts in Image Classification - Arxiv-2007.00644","url":"https://arxiv.org/pdf/2007.00644.pdf","urlHash":23611130},"2fc9d625-5f7e-4723-8137-fdfc267d6e27":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"2fc9d625-5f7e-4723-8137-fdfc267d6e27","title":"Sungnyun Kim on X: \"Our recent paper suggests a new frontier on distilling LLMs: 1️⃣ skew KL: sota performances on various instruction-following tasks 2️⃣ adaptive off-policy: 4.3x speedup compared to GKD Check it out for how we did 👀👀\" / X","url":"https://twitter.com/kim_sungnyun/status/1756908892544749680","urlHash":132449811},"2fd06980-6382-4a8b-875a-3c1d4017b5da":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"2fd06980-6382-4a8b-875a-3c1d4017b5da","title":"Self-Consuming Generative Models Go MAD | PDF","url":"https://arxiv.org/pdf/2307.01850.pdf","urlHash":1490155264},"2fe4b230-6da6-496b-9d0b-3586acbf4739":{"favIconUrl":"fallback","id":"2fe4b230-6da6-496b-9d0b-3586acbf4739","title":"Distributionally Robust Neural Networks for Group Shifts On the Importance of Regularization for Worst-Case Generalization - Arxiv-1911.08731","url":"https://arxiv.org/pdf/1911.08731.pdf","urlHash":2371155087},"2fe9e075-f0e0-4eb0-b330-2636ceff2dde":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"2fe9e075-f0e0-4eb0-b330-2636ceff2dde","title":"Llemma: An Open Language Model For Mathematics | Abstract","url":"https://arxiv.org/abs/2310.10631","urlHash":3278163393},"30392452-3bd0-4523-82ae-1bb01a0e4746":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/badged-favicon-32x32.png","id":"30392452-3bd0-4523-82ae-1bb01a0e4746","title":"(1) Chess-GPT, a 50M parameter LLM, plays 1500 ELO chess. We can visualize its internal board state, and it accurately estimates the ELO rating of the players in a game. : LocalLLaMA","url":"https://www.reddit.com/r/LocalLLaMA/comments/1904e2t/chessgpt_a_50m_parameter_llm_plays_1500_elo_chess/","urlHash":4025803055},"3059da4e-4615-4fb6-8b96-c83aa4be966a":{"favIconUrl":"fallback","id":"3059da4e-4615-4fb6-8b96-c83aa4be966a","title":"DiffusionDet Diffusion Model for Object Detection - Arxiv-2211.09788","url":"https://arxiv.org/pdf/2211.09788.pdf","urlHash":842128431},"306329b8-f3d6-4d47-acf1-7172bd95af80":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"306329b8-f3d6-4d47-acf1-7172bd95af80","title":"桜と富士と星の迷宮 (豆瓣)","url":"https://book.douban.com/subject/26673173/","urlHash":688325647},"3068e208-97bd-4518-8e4b-3489455752e2":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"3068e208-97bd-4518-8e4b-3489455752e2","title":"twitter.com/nearcyan/status/1630769218512904192","url":"https://twitter.com/nearcyan/status/1630769218512904192","urlHash":2943752312},"308e0c75-73fb-44ee-8028-e2f4a5b76a01":{"favIconUrl":"https://cdn.semanticscholar.org/b5fbde4a4847434e/img/darkmode/favicon-32x32.png","id":"308e0c75-73fb-44ee-8028-e2f4a5b76a01","title":"Neural Comprehension: Language Models with Compiled Neural Networks | Semantic Scholar","url":"https://www.semanticscholar.org/paper/Neural-Comprehension%3A-Language-Models-with-Compiled-Weng-Zhu/3693683c4e0405819fae7115ad680f769eb83534","urlHash":923049196},"3099db36-40b8-4407-9ae8-9d3dea507b35":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"3099db36-40b8-4407-9ae8-9d3dea507b35","title":"Hugo Laurençon on X: \"Is synthetic data the future of AI? Introducing WebSight - a multimodal dataset featuring 823,000 pairs of synthetically generated HTML/CSS codes along with screenshots of the corresponding rendered websites, to fine-tune GPT4-V-like models. 🌐💻 Details in the thread ⬇️ https://t.co/xSWQIQ5Tgu\" / X","url":"https://twitter.com/HugoLaurencon/status/1746950099089883382","urlHash":2009737125},"30cfae2f-9064-4f4d-ad1a-d23cbd546d0c":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"30cfae2f-9064-4f4d-ad1a-d23cbd546d0c","title":"Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity | Abstract","url":"https://arxiv.org/abs/2310.07521?utm_source=substack&utm_medium=email","urlHash":152483568},"30e8c90e-1b93-49c1-ab18-3a0162e1efda":{"favIconUrl":"fallback","id":"30e8c90e-1b93-49c1-ab18-3a0162e1efda","title":"Compositional Explanations of Neurons - Arxiv-2006.14032","url":"https://arxiv.org/abs/2006.14032","urlHash":3992808010},"31219425-24ef-4276-812e-a417c5e9a2f6":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"31219425-24ef-4276-812e-a417c5e9a2f6","title":"Aligning Large Multimodal Models with Factually Augmented RLHF | Abstract","url":"https://arxiv.org/abs/2309.14525?utm_source=substack&utm_medium=email","urlHash":3031955766},"31237155-9261-42eb-8ca1-f7d6946fb089":{"favIconUrl":"fallback","id":"31237155-9261-42eb-8ca1-f7d6946fb089","title":"SIGUA Forgetting May Make Learning with Noisy Labels More Robust - PMLR-2020-han20c","url":"http://proceedings.mlr.press/v119/han20c/han20c.pdf","urlHash":1893252855},"3128e798-915b-402c-84fd-277153483814":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"3128e798-915b-402c-84fd-277153483814","title":"用其他模型产生的数据训练会导致模型坍缩","url":"https://mp.weixin.qq.com/s?__biz=MzkwMjUwNTg3OA==&mid=2247484130&idx=1&sn=6dfb8e88019e1b6ee68cafa7f7768991&exportkey=n_ChQIAhIQP17R%2BS%2F1b4i0o4vOO8%2BNgRKWAgIE97dBBAEAAAAAAEP9FdFTFJkAAAAOpnltbLcz9gKNyK89dVj0lo9u3zOA7oJF45cjoRs75mE0m4w5wEdud2lVH9FH%2FDiIV9962nKxuK9GVBqfr2cjOfBji9ZPEAtsRT06SGdqarqkEFnmKZaQpIL8EmdW0wgAEOrYdpMy5Zrx0UjcjsUC91cwLHxszSVK2bQUGJMCZECYkiRr4952uz9Wlx%2BuNhtDkU3feXgIRtKv%2BdCplvKNcAEXoDItlv4lOJPAEkAsfbrrMm%2FCF8o0mfbQgVJg4c0YaVM6mxOUV0wXfpCeaUJdRypogF8RSWmLfeo3rp9cddQlStJ99nvjMWz9c0NuXHdcG1jPIHMNHC4jcTVEKwFn&acctmode=0&pass_ticket=RZ6Z3aR94R93fey3rukC%2FMLnsAjwDiE7XGgGQaEQ%2BbkxN3dJzfdNlbXq4wxS9S1N&wx_header=0","urlHash":211416505},"31360250-3255-4b29-8311-02f79e8205af":{"favIconUrl":"fallback","id":"31360250-3255-4b29-8311-02f79e8205af","title":"Revisiting Simple Neural Probabilistic Language Models - Arxiv-2104.03474","url":"https://arxiv.org/pdf/2104.03474.pdf","urlHash":2296494620},"31653d67-a94d-4a08-b83d-e75a6a3c2a27":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"31653d67-a94d-4a08-b83d-e75a6a3c2a27","title":"A General Framework for Defending Against Backdoor Attacks via Influence Graph | Abstract","url":"https://arxiv.org/abs/2111.14309","urlHash":436708820},"316a6c19-bf9d-4740-94a9-382f29edb226":{"favIconUrl":"fallback","id":"316a6c19-bf9d-4740-94a9-382f29edb226","title":"https://probml.github.io/pml-book/book2.html","url":"https://probml.github.io/pml-book/book2.html","urlHash":1712956738},"31764a9d-a7df-497c-8ecb-0364704407c8":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"31764a9d-a7df-497c-8ecb-0364704407c8","title":"用RLHF 2%的算力让LLM停止有害输出，字节提出LLM遗忘学习","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650900310&idx=6&sn=de1899cf4260998e45e6f371858ac291&exportkey=n_ChQIAhIQ8Ldc6l2evi1TZurA7bcngBKWAgIE97dBBAEAAAAAAM%2FJLdjRabcAAAAOpnltbLcz9gKNyK89dVj0MgjloxHccxrXL7wSjBHHib%2F29%2BceYqJn3nuXby4dx4GCU29RdFp2q96YSXURIBi7Tuow9CqhcYkUDAfru%2F3h6rocyxI2NGJK4JjfGmdd2dka2ImeYyRNZImCE2LhhRVyilegruQHRkV%2FXmZGhF3Sz5F2pZMMfj6dTkeEJqDv7ikc34Y6QhYSKS6Dk4x5GNE5za3iGlI2RY8%2FJWuw8ayxRcJu6XR19zl8awghOnUgfHunCsaNHPv7CemBs17bxUCu%2BpKCOOudWX7cGztkOp45R8lfDkmwOZ0vBkoYmQSPHLixtGj%2B58Cw5UAjSBbfDPkR&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsYRQImARpQ5rvZrHGq%2FksKFIX%2FU5Cmc4nOX%2BLxQ6p0vVQ%3D%3D&wx_header=0","urlHash":1035138092},"317c5a57-33e8-4f6c-a995-9e13ec463fe3":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"317c5a57-33e8-4f6c-a995-9e13ec463fe3","title":"Cheng Qian on X: \"📢Release our work on agent self-evolution! We propose the ICE experience learning strategy that makes agent deployment significantly more effective and efficient. ICE is also integrated into XAgent 2.0 about to be released soon! Find out more here: https://t.co/Xk7iFOkCCW https://t.co/TAU2Xyabox\" / X","url":"https://twitter.com/qiancheng1231/status/1751049659441913982","urlHash":429805940},"31a02e84-2d37-44be-b034-000b9346f7b3":{"favIconUrl":"https://static.zhihu.com/heifetz/favicon.ico","id":"31a02e84-2d37-44be-b034-000b9346f7b3","title":"有哪些瘦脸的好习惯? - 知乎","url":"https://www.zhihu.com/question/308391227/answer/1405152302","urlHash":4182195290},"31aa46e7-fe23-4dcd-819f-fc92f9aeba77":{"favIconUrl":"fallback","id":"31aa46e7-fe23-4dcd-819f-fc92f9aeba77","title":"[Interim research report] Taking features out of superposition with sparse autoencoders — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/z6QQJbtpkEAX3Aojj/interim-research-report-taking-features-out-of-superposition","urlHash":1810680943},"31cff877-c659-4471-a077-04b1ee1e3422":{"favIconUrl":"fallback","id":"31cff877-c659-4471-a077-04b1ee1e3422","title":"ItoSDE_Tutorial","url":"https://www.peterholderrieth.com/blog/2023/Diffusion-Models-with-Stochastic-Differential-Equations-A-Introduction-with-Self-Contained-Mathematical-Proofs/","urlHash":3011118170},"31e7cc56-91b5-4368-982c-8e2738284bd6":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"31e7cc56-91b5-4368-982c-8e2738284bd6","title":"Towards Understanding Sycophancy in Language Models | PDF","url":"https://arxiv.org/pdf/2310.13548.pdf","urlHash":168389151},"3214bf7f-d4bd-48db-88a4-481534c6a1a4":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"3214bf7f-d4bd-48db-88a4-481534c6a1a4","title":"普林斯顿博士生高天宇指令微调进展速览：数据、算法和评估","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650905013&idx=5&sn=49ef34e18a26d4776a558954fc11ba55&chksm=84e45dcbb393d4dd51b9888fd77a57adb05d1545803e18e70e75d041d319b07bd3ec722bacc9&mpshare=1&scene=1&srcid=0122QKufVvqKumv9HheNLGUp&sharer_shareinfo=191d3a32ad705ec0f092f68c697ee343&sharer_shareinfo_first=191d3a32ad705ec0f092f68c697ee343&exportkey=n_ChQIAhIQSAAwHLTplI%2FC2hGMAmQQAxKWAgIE97dBBAEAAAAAAEo1GcndAuoAAAAOpnltbLcz9gKNyK89dVj0jf6Ruff6Qq8KxykgCxUWZ7tSNZW8ayV30oVjEpECUIaPLAY3IgBFLP49zfSkjGg6HU0AJB8s5ZLXR%2Fz4LtBWTJa%2BOUu%2BseqA08P9v%2FBeyHsEc8w8GNi1lXT7rM19UVkOaNq7BycuQMgNPETddzAB7MggkiMaFyLMOA143AtIJoxDOvgicy2LVvk2DPkU2CdR%2FMmvkbT%2BGlD86zBpUuATX8EZwnhLRt5ZFPmZ7b4AsztVonh1rXdVuCMrhCwN2JvbSDh9FuAPMxDUWfPGdDTJZKNwG4hExWRAJs5cZJhJDDTVpWe%2FnyA9xBO%2BT5lNq151&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HPLy6y4Ap7NNtHdTKq%2FCzoE1CGkIa634xbzG9aN50r%2BDQ%3D%3D&wx_header=0#rd","urlHash":1591979156},"3221babb-f0c2-4f63-a21a-92339c1d0536":{"favIconUrl":"fallback","id":"3221babb-f0c2-4f63-a21a-92339c1d0536","title":"AnnoLLM Making Large Language Models to Be Better Crowdsourced Annotators - Arxiv-2303.16854","url":"https://arxiv.org/pdf/2303.16854.pdf","urlHash":3542283317},"3224d458-1e5f-485b-8934-fc01e70820da":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"3224d458-1e5f-485b-8934-fc01e70820da","title":"ram_plus_swin_large_14m.pth · xinyu1205/recognize-anything-plus-model at main","url":"https://huggingface.co/xinyu1205/recognize-anything-plus-model/blob/main/ram_plus_swin_large_14m.pth","urlHash":2799567205},"3243be93-7919-4361-a1f2-67d753222034":{"favIconUrl":"fallback","id":"3243be93-7919-4361-a1f2-67d753222034","title":"On Discriminative vs. Generative Classifiers A comparison of logistic regression and naive Bayes - NeurIPS-2001_7b7a53e2","url":"https://proceedings.neurips.cc/paper/2001/file/7b7a53e239400a13bd6be6c91c4f6c4e-Paper.pdf","urlHash":1696807142},"325a77eb-5f0c-43f4-914b-29db3f921d71":{"favIconUrl":"fallback","id":"325a77eb-5f0c-43f4-914b-29db3f921d71","title":"The (Un)reliability of saliency methods","url":"https://arxiv.org/abs/1711.00867","urlHash":2178895764},"32646ceb-3202-4236-bd19-959ec5a03ba2":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"32646ceb-3202-4236-bd19-959ec5a03ba2","title":"Top-label calibration and multiclass-to-binary reductions | PDF","url":"https://arxiv.org/pdf/2107.08353.pdf","urlHash":1519411554},"3268040e-a287-4672-90d7-626008885718":{"favIconUrl":"fallback","id":"3268040e-a287-4672-90d7-626008885718","title":"近三十年清代“采生折割人”律研究综述-【维普官方网站】-www.cqvip.com-维普网","url":"http://www.cqvip.com/qk/85637a/20182/675211016.html","urlHash":4232721855},"32977b51-a1a0-4c49-81c6-80d2d2edf9b7":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"32977b51-a1a0-4c49-81c6-80d2d2edf9b7","title":"ControlNet作者重磅新作LayerDiffusion：利用扩散模型生成透明图像，比肩Adobe商用软件！","url":"https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&mid=2247593932&idx=3&sn=4f43bc47714042994c6d640cfb2005c7&chksm=f9a01d43ced79455694c94d5e0ef44b9924c264ef9da2be9b1c9ebd793b2374352c7a515c43a&mpshare=1&scene=1&srcid=0308mhJ10qy25Lvcnag0mBBs&sharer_shareinfo=ac87d5f856f10283cd3175a63b7dca5d&sharer_shareinfo_first=ac87d5f856f10283cd3175a63b7dca5d&exportkey=n_ChQIAhIQOTAsDp0Q6WUThxpMiePRNhKWAgIE97dBBAEAAAAAAKSrI1Yl3vgAAAAOpnltbLcz9gKNyK89dVj0QXTZea2VQWhqvvgtGIoAf1pW1m75tDqidKiC10qGtIK78dTNAeIl03rqlkDwYE8QWhFLx86j2c8ayGUwZQq4zYOtOAxokmDppUx55iTyhJ13%2B5dLLVb2XMYy3Cb90sef01c9pCAsavWsF3OI5PSSFWG%2B%2BX3D6p51uEoXvqSnPNSuU%2BHaZ0R9d0IFuWH6mn6s7IyC8%2FEF0FJRTx2od4raFM9BameoKbTOmrd3R8a%2BiWdpxXlcsZhgdsSX0ra0%2F8S4Vq1aDMBYKUtqt5h62vil24xOSw6yuTBo2vXTijxg7NoinLEN2hkniCoBLfpvzj5%2B&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCO89RXTJw5fDwUNKLD5%2Fz0B%2BfQjSSZMyOlqd2iDpUKCXg%3D%3D&wx_header=0#rd","urlHash":3219028572},"32bf022c-5c97-481e-b618-d1f066304acb":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"32bf022c-5c97-481e-b618-d1f066304acb","title":"Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning | Abstract","url":"https://arxiv.org/abs/2305.14160","urlHash":2020528599},"32c71d76-5896-4147-8f91-84e644d33c79":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"32c71d76-5896-4147-8f91-84e644d33c79","title":"Mamba: Linear-Time Sequence Modeling with Selective State Spaces | PDF","url":"https://arxiv.org/pdf/2312.00752.pdf","urlHash":184406291},"32d20f62-7f07-4a22-8876-834359db92a2":{"favIconUrl":"https://dynalist.io/assets/icon/favicon.ico","id":"32d20f62-7f07-4a22-8876-834359db92a2","title":"SoLU - A Comprehensive Mechanistic Interpretability Explainer & Glossary - Dynalist","url":"https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=NnlcCwpsX2yJpu4js1EnluiF","urlHash":2515648704},"331da261-dceb-450f-bcfb-aed8df5dc216":{"favIconUrl":"https://wikiwandv2-19431.kxcdn.com/icons/favicon.ico","id":"331da261-dceb-450f-bcfb-aed8df5dc216","title":"Critique of Judgment - Wikiwand","url":"https://www.wikiwand.com/en/Critique_of_Judgment","urlHash":144712006},"33a849b9-6127-4d46-bae3-94b72106dc6c":{"favIconUrl":"fallback","id":"33a849b9-6127-4d46-bae3-94b72106dc6c","title":"hkchengrex/Tracking-Anything-with-DEVA: [ICCV 2023] Tracking Anything with Decoupled Video Segmentation","url":"https://github.com/hkchengrex/Tracking-Anything-with-DEVA","urlHash":2526690955},"33dbfa98-3ee0-4bac-8b0c-7122a83253c9":{"favIconUrl":"fallback","id":"33dbfa98-3ee0-4bac-8b0c-7122a83253c9","title":"Can Language Models Solve Graph Problems in Natural Language?","url":"https://arxiv.org/pdf/2305.10037.pdf","urlHash":3163845229},"33dcb637-092f-4933-8391-d31cef5326e7":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"33dcb637-092f-4933-8391-d31cef5326e7","title":"Measuring Forgetting of Memorized Training Examples | PDF","url":"https://arxiv.org/pdf/2207.00099.pdf","urlHash":2565754220},"33e8f1b8-c642-4769-8244-b0305c70e077":{"favIconUrl":"fallback","id":"33e8f1b8-c642-4769-8244-b0305c70e077","title":"cloneofsimo/consistency_models: Unofficial Implementation of Consistency Models in pytorch","url":"https://github.com/cloneofsimo/consistency_models","urlHash":880472561},"3405943d-6264-4eea-b193-ee3f1b13eca0":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"3405943d-6264-4eea-b193-ee3f1b13eca0","title":"Eliciting Human Preferences with Language Models | Abstract","url":"https://arxiv.org/abs/2310.11589","urlHash":1500837913},"341f5ce0-0ff6-4e45-b060-aaf8d1786fc0":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"341f5ce0-0ff6-4e45-b060-aaf8d1786fc0","title":"Yam Peleg on X: \"Same concept as register tokens. Models use useless tokens (especially special tokens) as storage for computation. Wait until someone finds out you can just add &lt;pad&gt; token every 128 tokens during training and it improves the score.\" / X","url":"https://twitter.com/Yampeleg/status/1709396407587672082","urlHash":4210350751},"34730365-2f3d-4a63-8bcb-27f7a61d2e40":{"favIconUrl":"https://www.google.com/favicon.ico","id":"34730365-2f3d-4a63-8bcb-27f7a61d2e40","title":"EMERGENCE OF MAPS IN THE MEMORIES OF BLIND NAVIGATION AGENTS - Google Search","url":"https://www.google.com/search?q=EMERGENCE+OF+MAPS+IN+THE+MEMORIES+OF+BLIND+NAVIGATION+AGENTS&sourceid=chrome&ie=UTF-8","urlHash":4176621186},"347afbc9-6346-4bc8-86ee-88dd36430dfd":{"favIconUrl":"fallback","id":"347afbc9-6346-4bc8-86ee-88dd36430dfd","title":"google-research/perturbations at master · google-research/google-research","url":"https://github.com/google-research/google-research/tree/master/perturbations","urlHash":1611159676},"3493e6a3-9a9e-4a4d-a513-450a914f3d0e":{"favIconUrl":"fallback","id":"3493e6a3-9a9e-4a4d-a513-450a914f3d0e","title":"Hiera A Hierarchical Vision Transformer without the Bells-and-Whistles - Arxiv-2306.00989","url":"https://arxiv.org/abs/2306.00989?utm_source=substack&utm_medium=email","urlHash":1826605662},"34b1da31-c8e0-475d-9750-c36ed1cb9c11":{"favIconUrl":"https://www.google.com/favicon.ico","id":"34b1da31-c8e0-475d-9750-c36ed1cb9c11","title":"And Then There Were (N-One) - Google Search","url":"https://www.google.com/search?q=And%20Then%20There%20Were%20(N-One)","urlHash":1295388165},"34c55d33-4671-476f-a8f7-be3c5e7b5860":{"favIconUrl":"fallback","id":"34c55d33-4671-476f-a8f7-be3c5e7b5860","title":"呼吸 特德姜 - Google Search","url":"https://www.google.com/search?q=%E5%91%BC%E5%90%B8+%E7%89%B9%E5%BE%B7%E5%A7%9C&oq=%E5%91%BC%E5%90%B8te+de+jiang+%7C&aqs=chrome.1.69i57j0i333.8110j0j1&sourceid=chrome&ie=UTF-8","urlHash":642592519},"34c70966-a118-43bb-8598-a7f002ed143d":{"favIconUrl":"fallback","id":"34c70966-a118-43bb-8598-a7f002ed143d","title":"Navigating the Grey Area Expressions of Overconfidence and Uncertainty in Language Models - Arxiv-2302.13439","url":"https://arxiv.org/pdf/2302.13439.pdf","urlHash":589163778},"34cef832-9742-4fdd-ae6a-f2a8058799c5":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"34cef832-9742-4fdd-ae6a-f2a8058799c5","title":"Rethinking Experience Replay: a Bag of Tricks for Continual Learning | PDF","url":"https://arxiv.org/pdf/2010.05595.pdf","urlHash":2424834354},"35013ac2-e1c3-4b25-98da-821d8154c7e8":{"favIconUrl":"fallback","id":"35013ac2-e1c3-4b25-98da-821d8154c7e8","title":"GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking","url":"https://arxiv.org/pdf/2305.15066.pdf","urlHash":4043363155},"3565bdac-8acb-4330-98d8-248a29e9a46d":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"3565bdac-8acb-4330-98d8-248a29e9a46d","title":"BitNet: Scaling 1-bit Transformers for Large Language Models | Abstract","url":"https://arxiv.org/abs/2310.11453","urlHash":549543490},"3567ebc5-a706-40d2-861f-73b16adae55c":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"3567ebc5-a706-40d2-861f-73b16adae55c","title":"Nathan Lambert on X: \"Tomorrow's my ICML tutorial on reinforcement learning from human feedback with @TolokaAI. 930am local time, Ballroom B (go to the 4th floor, towards the left when you walk in). Come for the @huggingface merch, stay for the education. Slides are here: https://t.co/6DtFgJEf7X https://t.co/tuhQrtLXfK\" / X","url":"https://twitter.com/natolambert/status/1683319745842642945","urlHash":1022938109},"357a85b4-4838-4045-9436-906ec4461bb1":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"357a85b4-4838-4045-9436-906ec4461bb1","title":"arxiv.org/pdf/2104.08691.pdf","url":"https://arxiv.org/pdf/2104.08691.pdf","urlHash":1260387249},"35a1225f-aa15-4c16-b176-ad7068b69a29":{"favIconUrl":"fallback","id":"35a1225f-aa15-4c16-b176-ad7068b69a29","title":"RobustLR Evaluating Robustness to Logical Perturbation in Deductive Reasoning - Arxiv-2205.12598","url":"https://arxiv.org/pdf/2205.12598.pdf","urlHash":3544476164},"35b82e01-4904-4956-b868-0478b14c9eef":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"35b82e01-4904-4956-b868-0478b14c9eef","title":"twitter.com/PanLiangming/status/1660846727056986112","url":"https://twitter.com/PanLiangming/status/1660846727056986112","urlHash":96536694},"35c2449e-dfb5-4a56-b205-cdc65c3b12d9":{"favIconUrl":"https://toolemu.com/images/favicon.png","id":"35c2449e-dfb5-4a56-b205-cdc65c3b12d9","title":"ToolEmu: Identifying the Risks of LM Agents with an LM-Emulated Sandbox","url":"https://toolemu.com/","urlHash":3492286664},"35ca30b1-eaea-4113-923c-4e23e3f16c39":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"35ca30b1-eaea-4113-923c-4e23e3f16c39","title":"Score-based Generative Modeling in Latent Space | Abstract","url":"https://arxiv.org/abs/2106.05931","urlHash":2620019411},"3635469e-152a-4952-9262-307240731b7b":{"favIconUrl":"https://www.google.com/favicon.ico","id":"3635469e-152a-4952-9262-307240731b7b","title":"Counterfactual Explanations Can Be Manipulated - Google Search","url":"https://www.google.com/search?q=Counterfactual+Explanations+Can+Be+Manipulated&sourceid=chrome&ie=UTF-8","urlHash":1878447328},"369b9833-0e82-4e0a-8e5b-ec08795fe182":{"favIconUrl":"https://blog.langchain.dev/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png","id":"369b9833-0e82-4e0a-8e5b-ec08795fe182","title":"Enhancing RAG-based application accuracy by constructing and leveraging knowledge graphs","url":"https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/","urlHash":3427936265},"36c39215-34ff-4940-89f8-a6db748081d0":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"36c39215-34ff-4940-89f8-a6db748081d0","title":"twitter.com/jerryjliu0/status/1718368662955204739","url":"https://twitter.com/jerryjliu0/status/1718368662955204739","urlHash":3074775735},"36d0a788-fde6-4c80-93f6-ce92c2fea5ff":{"favIconUrl":"fallback","id":"36d0a788-fde6-4c80-93f6-ce92c2fea5ff","title":"McNemar's test - Wikiwand","url":"https://www.wikiwand.com/en/McNemar%27s_test","urlHash":111888120},"37008d9a-d0c2-4306-a2e8-a20d91e15124":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"37008d9a-d0c2-4306-a2e8-a20d91e15124","title":"Fine-Tuning Language Models with Advantage-Induced Policy Alignment | Abstract","url":"https://arxiv.org/abs/2306.02231","urlHash":941217670},"3735fcbe-c4c3-43d0-87a0-81e7695f041a":{"favIconUrl":"fallback","id":"3735fcbe-c4c3-43d0-87a0-81e7695f041a","title":"The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers","url":"https://openreview.net/forum?id=guetrIHLFGI","urlHash":2588008601},"3773d865-e217-4693-bdf8-e23f477cce1d":{"favIconUrl":"fallback","id":"3773d865-e217-4693-bdf8-e23f477cce1d","title":"FLASK Fine-grained Language Model Evaluation based on Alignment Skill Sets - Arxiv-2307.10928","url":"https://arxiv.org/abs/2307.10928?utm_source=substack&utm_medium=email","urlHash":3956499265},"3791ffeb-9b98-4e68-bb4c-59deaa805b2b":{"favIconUrl":"https://wikiwandv2-19431.kxcdn.com/icons/favicon.ico","id":"3791ffeb-9b98-4e68-bb4c-59deaa805b2b","title":"State-space representation - Wikiwand","url":"https://www.wikiwand.com/en/State-space_representation#Moving_object_example","urlHash":2587122113},"37a5ece8-55ee-4441-baf6-6a9d4c917733":{"favIconUrl":"fallback","id":"37a5ece8-55ee-4441-baf6-6a9d4c917733","title":"Reconstructing Training Data from Trained Neural Networks - Arxiv-2206.07758","url":"https://arxiv.org/abs/2206.07758","urlHash":2524180902},"37e4f217-bde4-40a9-9797-c2fec138b901":{"favIconUrl":"fallback","id":"37e4f217-bde4-40a9-9797-c2fec138b901","title":"Pytorch Nice - Implementation of non-linear independent components estimation (NICE) in pytorch - (pytorch-nice)","url":"https://opensourcelibs.com/lib/pytorch-nice","urlHash":225299344},"37f156eb-fb2f-4d61-9dc7-89be07c7ca5b":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"37f156eb-fb2f-4d61-9dc7-89be07c7ca5b","title":"Emergent and Predictable Memorization in Large Language Models | Abstract","url":"https://arxiv.org/abs/2304.11158","urlHash":3272917445},"381c4a7e-a9ed-4f36-9697-05ad903f26a9":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"381c4a7e-a9ed-4f36-9697-05ad903f26a9","title":"今日arXiv最热NLP大模型论文：清华提出LongAlign，打破长上下文对齐瓶颈，数据、训练策略、评估基准一网打尽","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247575312&idx=1&sn=5ab53d8164eb73860027b73cd4ed26d2&chksm=970e8fc6a07906d0e3ad894581a4b76b5e86170114c3ae00eeb1a3c17fef0542326bd298fc24&mpshare=1&scene=1&srcid=0215BVMdbndd55th1VACCDLv&sharer_shareinfo=a3543f8bebeb73659bacee4f9540e12e&sharer_shareinfo_first=a3543f8bebeb73659bacee4f9540e12e&exportkey=n_ChQIAhIQpKuWI6cVyZzGAhrKxqgSVhKWAgIE97dBBAEAAAAAAD0eN80Bc0cAAAAOpnltbLcz9gKNyK89dVj06%2BHHdeOawB6GHbecjdYArzkI48OanVy5TmpUxBof6fdM5pY%2BGIZ%2FTaSGpfcsg%2B6dK8DhhxHrtik%2Bm3DB2mOVCACLNZDtC62PH90pLMRz9qkLBJ6WagTTCsBvjfn2vNnoKirTbn%2FaSFynpdIVyQm32BiQ0vqq%2F97YTnNVvh%2FmoR8zQKuG45IkM8ZdEgGSidYhf%2Bb04vSvkQlKxpbzM0m89veIW9cRz42TEMxeDDhIaPT0iK1MXseiGKevAYHJjqbVQJBcKYymvXlntELQHncr3FCadqxa%2BzVBQfVmaxFNRJT6oQP8MVPVHT%2FkhEVDpA0p&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HOsDzA08cs6fIqZ149R%2FhYf%2Bt1VKvFQo9%2Bmxfssw7eU%2Bg%3D%3D&wx_header=0#rd","urlHash":2600329602},"381e8bfd-5030-424a-9a0c-56faf78f7ede":{"favIconUrl":"fallback","id":"381e8bfd-5030-424a-9a0c-56faf78f7ede","title":"LMPriors Pre-Trained Language Models as Task-Specific Priors - Arxiv-2210.12530","url":"https://arxiv.org/pdf/2210.12530.pdf","urlHash":2940472093},"38719923-1623-4b02-84ff-dce329c4aad5":{"favIconUrl":"https://blog.langchain.dev/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png","id":"38719923-1623-4b02-84ff-dce329c4aad5","title":"Plan-and-Execute Agents","url":"https://blog.langchain.dev/planning-agents/","urlHash":2473934618},"38795709-4d62-44f6-a63c-e5a48717aed7":{"favIconUrl":"fallback","id":"38795709-4d62-44f6-a63c-e5a48717aed7","title":"Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning","url":"https://proceedings.neurips.cc/paper/2021/hash/86b3e165b8154656a71ffe8a327ded7d-Abstract.html","urlHash":354043103},"387cf492-b5e5-4c6d-9986-a0f2150809fd":{"favIconUrl":"fallback","id":"387cf492-b5e5-4c6d-9986-a0f2150809fd","title":"Meta-SGD Learning to Learn Quickly for Few-Shot Learning - Arxiv-1707.09835","url":"https://arxiv.org/abs/1707.09835","urlHash":4035783228},"38831be0-5b38-4fd2-b5ce-fbf8bc752de2":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"38831be0-5b38-4fd2-b5ce-fbf8bc752de2","title":"最强LLaMA突然来袭！只改一个超参数，实现上下文3.2万token，多个任务打败ChatGPT、Claude 2","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247697635&idx=1&sn=9cdb5237077dbc4500856ef1d02c9464&exportkey=n_ChQIAhIQYy3VfwSk1VlKP6IsOxTfuhKVAgIE97dBBAEAAAAAAKwkCYQaG7YAAAAOpnltbLcz9gKNyK89dVj0LJHdLrbONH3erxpaMB5M6SkGwZoG1IZa%2F%2FN5eTV4mVygPcAI0qCX5SwbSEzm87a41gmYmMZA91y6t9sX4roJdqsz7tTDrNqljASpelKO16BnivzlP99CbKMNITQY9ghBAg8NsGidTjgJJeJJVcuhx1rdaeicZSGribF2EUD%2Bi5PgLRfmqljy6ccg56cjV6CYoKA7Bf%2BL%2BdO5F1JlmRFDy7VEtOogew8BQUm0zEx%2BWUWznWbFxFWEthD3Ky0X9db2ppRGJg54EaSSyB%2FioYE01ww2FnOhBqirj4pCYJIltArLmwksjcYz0TGvFaET9Ac%3D&acctmode=0&pass_ticket=20%2BKeQwEXqszFmkE54BHDq1PLm01kOLBFYbjZyzDVtV%2F%2BJTq8zZeT6xMZtYVrbpB&wx_header=0","urlHash":1412843515},"38a4f812-df80-44b6-9d08-7eaf56582d47":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"38a4f812-df80-44b6-9d08-7eaf56582d47","title":"Data Feedback Loops: Model-driven Amplification of Dataset Biases | PDF","url":"https://arxiv.org/pdf/2209.03942.pdf","urlHash":3874194658},"38d56644-1816-4130-a200-5da7f98f548a":{"favIconUrl":"fallback","id":"38d56644-1816-4130-a200-5da7f98f548a","title":"Scaling Laws vs Model Architectures How does Inductive Bias Influence Scaling? - Arxiv-2207.10551","url":"https://arxiv.org/abs/2207.10551","urlHash":4063188829},"38ec1379-bf58-4e7d-8989-4add5335048c":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"38ec1379-bf58-4e7d-8989-4add5335048c","title":"Contrastive Preference Learning: Learning from Human Feedback without RL | PDF","url":"https://arxiv.org/pdf/2310.13639.pdf","urlHash":412217186},"38fa38ce-e7d0-4c37-9090-157cc708502d":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"38fa38ce-e7d0-4c37-9090-157cc708502d","title":"AutoGPTQ/auto_gptq/quantization/quantizer.py at main · PanQiWei/AutoGPTQ","url":"https://github.com/PanQiWei/AutoGPTQ/blob/main/auto_gptq/quantization/quantizer.py","urlHash":167623112},"39081608-01b5-447d-b68c-f3075acaa9a0":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"39081608-01b5-447d-b68c-f3075acaa9a0","title":"Factual Probing Is [MASK]: Learning vs. Learning to Recall | Abstract","url":"https://arxiv.org/abs/2104.05240","urlHash":1419187119},"39470500-4677-4b06-9949-b2ac689546a1":{"favIconUrl":"fallback","id":"39470500-4677-4b06-9949-b2ac689546a1","title":"为什么读经典 (豆瓣)","url":"https://book.douban.com/subject/10555550/","urlHash":465844565},"3961a9ec-37d3-4e66-9305-96fab9d8b5d2":{"favIconUrl":"fallback","id":"3961a9ec-37d3-4e66-9305-96fab9d8b5d2","title":"Learning with Instance Bundles for Reading Comprehension - Arxiv-2104.08735","url":"https://arxiv.org/pdf/2104.08735.pdf","urlHash":1756769087},"39bbf3d5-e080-408a-b23f-9d89f492b35f":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"39bbf3d5-e080-408a-b23f-9d89f492b35f","title":"(3) elvis on X: \"Knowledge Conflicts for LLMs It's great to see a nice overview of the common issue of knowledge conflict when working with LLMs. The survey paper categorized these conflicts into context-memory, inter-context, and intra-memory conflict. It also provides insights into causes… https://t.co/DrPWenXcGM\" / X","url":"https://twitter.com/omarsar0/status/1768288774532858003?utm_source=substack&utm_medium=email","urlHash":4101860646},"39c80302-902f-4689-afbc-c82ac81dd7db":{"favIconUrl":"fallback","id":"39c80302-902f-4689-afbc-c82ac81dd7db","title":"CVPR2021自监督学习论文: 理解对比损失的性质以及温度系数的作用 - 知乎","url":"https://zhuanlan.zhihu.com/p/357071960","urlHash":3868160633},"39fabcf1-ea5f-4d5c-8869-e9b2a984743f":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"39fabcf1-ea5f-4d5c-8869-e9b2a984743f","title":"Joel Jang on X: \"Scaling 📈 the total # of tasks during instruction tuning has been known to unlock new abilities in LMs. However, we find that an LM trained on a single task outperforms an LM trained on 300+ tasks on unseen tasks 🤯 📝:https://t.co/Y54e41BVOw 1/8 https://t.co/i6bGbmQY0r\" / X","url":"https://twitter.com/jang_yoel/status/1623169024489328640","urlHash":2392904593},"3a27defc-a746-408c-ad14-778dc1028b3c":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/badged-favicon-32x32.png","id":"3a27defc-a746-408c-ad14-778dc1028b3c","title":"(5) GPTQLoRA: Efficient Finetuning of Quantized LLMs with GPTQ : LocalLLaMA","url":"https://www.reddit.com/r/LocalLLaMA/comments/13r7pzg/gptqlora_efficient_finetuning_of_quantized_llms/","urlHash":3763562825},"3a469613-bd89-48a6-b819-15ef1d5ecf8a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"3a469613-bd89-48a6-b819-15ef1d5ecf8a","title":"AK on X: \"Axiomatic Preference Modeling for Longform Question Answering paper page: https://t.co/uMhCVEZc6d The remarkable abilities of large language models (LLMs) like GPT-4 partially stem from post-training processes like Reinforcement Learning from Human Feedback (RLHF) involving… https://t.co/TrfgAx5hah\" / X","url":"https://twitter.com/_akhaliq/status/1732214906085068955","urlHash":98393868},"3aadad7e-290f-4fea-a56a-7026b16fefcc":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"3aadad7e-290f-4fea-a56a-7026b16fefcc","title":"LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing | PDF","url":"https://arxiv.org/pdf/2311.00571.pdf","urlHash":1316496830},"3ab50e68-619d-455d-b9e6-eacd86d59df4":{"favIconUrl":"fallback","id":"3ab50e68-619d-455d-b9e6-eacd86d59df4","title":"i2d2 - Google Search","url":"https://www.google.com/search?q=i2d2&oq=i2d2&aqs=chrome..69i57j35i39j0i512l3j0i30j0i15i30.853j0j1&sourceid=chrome&ie=UTF-8","urlHash":227337328},"3acf5bc1-e61b-427d-b723-161e3e519c54":{"favIconUrl":"fallback","id":"3acf5bc1-e61b-427d-b723-161e3e519c54","title":"我们今天所说的克苏鲁神话，还是洛夫克拉夫特笔下的那个神话吗？","url":"https://www.gcores.com/articles/104435","urlHash":4173022035},"3aec21c2-b4ed-4c49-b06e-db9e7a32ca9c":{"favIconUrl":"fallback","id":"3aec21c2-b4ed-4c49-b06e-db9e7a32ca9c","title":"randomized smoothing transformer - Google Search","url":"https://www.google.com/search?q=randomized+smoothing+transformer&newwindow=1&sxsrf=APq-WBu7Pw-v7fWSW4M4vrry6XcqjfJdkw%3A1643881562115&ei=WqT7YYC3Bq_DkPIP1bOz2A8&oq=randomized+smoothing+transformer&gs_lcp=ChNtb2JpbGUtZ3dzLXdpei1zZXJwEAMyBQghEKABMgUIIRCgAToHCCMQsAMQJzoCCAA6BAgjECc6BQgAEIAEOgYIABAWEB46BwghEAoQoAFKBAhBGAFQqgRYoS9gijFoAHAAeACAAasCiAG9CpIBBTAuNi4xmAEAoAEByAEBwAEB&sclient=mobile-gws-wiz-serp","urlHash":4039360535},"3af03237-e2db-45a4-8eb2-5986b9c02e99":{"favIconUrl":"https://miro.medium.com/v2/1*m-R_BkNf1Qjr1YbyOIJY2w.png","id":"3af03237-e2db-45a4-8eb2-5986b9c02e99","title":"GPT4- All Details Leaked. The details about the best LLM model… | by katerinaptrv | Medium","url":"https://medium.com/@daniellefranca96/gpt4-all-details-leaked-48fa20f9a4a","urlHash":465791303},"3afd7439-b34e-494c-a7f9-d657732e0b9d":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"3afd7439-b34e-494c-a7f9-d657732e0b9d","title":"twitter.com/_akhaliq/status/1684030297661403136","url":"https://twitter.com/_akhaliq/status/1684030297661403136","urlHash":3430726884},"3b010ae6-b4d4-4079-bfb8-b951dadbb500":{"favIconUrl":"fallback","id":"3b010ae6-b4d4-4079-bfb8-b951dadbb500","title":"Recognize Anything: A Strong Image Tagging Model","url":"https://arxiv.org/abs/2306.03514","urlHash":100058334},"3b085852-da56-4059-a8e6-bbcfd0f5dcdc":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"3b085852-da56-4059-a8e6-bbcfd0f5dcdc","title":"十一月上半月值得关注的大模型相关研究","url":"https://mp.weixin.qq.com/s?__biz=MzkxMTUxOTYwNg==&mid=2247484388&idx=1&sn=63b5bf5d2aba3b547cf8e112a9c99b0c&exportkey=n_ChQIAhIQIfKC%2F3QY0rqtJDNoDwdspxKWAgIE97dBBAEAAAAAAOxEBAWKHCIAAAAOpnltbLcz9gKNyK89dVj0hOD4d1mkqAPp04uC1zwjIo%2BW0xfQcdWBlXCuvwa1zOqdkED3Zz8haQcQfY1h27VNITX%2BZu%2Fihq%2BzDLouQjtlKWQPuC8bVqvuj0ciFltNt8AUhhMoCO%2B0gdxxyfEaq9WoYaBN8OVwRR5z%2BtrarvEYNuT3G9XXgRCOJ3Ou2dyTtSS89R9Zepn6OrQkWOSVuotON50Ffz5NMVEyWa8tHn%2Btr3obBB%2FDdmlT1e3WT%2BiwSHACN93ewgu7REasR8exl6dGASGdrHnPgB%2FfB7nVyDkqCltT79FFdRdP5T%2F4cX%2B%2BRgwHDJOieX9U3IMYK7jeatQA&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsa0IRqPWmoO2%2FWfG8IFE2h%2FYYnscG4fL3fOnYfM1qQfHA%3D%3D&wx_header=0","urlHash":4084241225},"3b107d3b-7733-4823-ba55-172c61b3d17a":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"3b107d3b-7733-4823-ba55-172c61b3d17a","title":"Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models | Abstract","url":"https://arxiv.org/abs/2311.00871?utm_source=substack&utm_medium=email","urlHash":3912365962},"3b49b89e-d262-4235-bf15-a08f663b37eb":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"3b49b89e-d262-4235-bf15-a08f663b37eb","title":"Fully Parameterized Quantile Function for Distributional Reinforcement Learning | PDF","url":"https://arxiv.org/pdf/1911.02140.pdf","urlHash":2086507977},"3b5b4ac3-e52b-45f6-8df0-7ebb224ccf0f":{"favIconUrl":"fallback","id":"3b5b4ac3-e52b-45f6-8df0-7ebb224ccf0f","title":"Mapping Language Models to Grounded Conceptual Spaces","url":"https://openreview.net/forum?id=gJcEM8sxHK","urlHash":1792361889},"3b5ef701-168d-4694-a205-eac6254194ad":{"favIconUrl":"fallback","id":"3b5ef701-168d-4694-a205-eac6254194ad","title":"《推理学导论9》评","url":"https://www.douban.com/note/839881322/?_i=9590426KLQjbnS","urlHash":3879265974},"3b84dc90-5824-4a83-adbe-d70f8c5e282e":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"3b84dc90-5824-4a83-adbe-d70f8c5e282e","title":"langgraph/examples/time-travel.ipynb at main · langchain-ai/langgraph","url":"https://github.com/langchain-ai/langgraph/blob/main/examples/time-travel.ipynb","urlHash":827918566},"3b91a462-1c25-45e8-bd71-d2a82ced6806":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"3b91a462-1c25-45e8-bd71-d2a82ced6806","title":"Guangxing Han on X: \"Thanks @_akhaliq for tweeting our work. We propose to unify a large variety of coarse-to-fine vision-language tasks using a multimodal large language model. We show promising results on both single-image comprehension benchmarks and multi-image benchmarks, e.g., co-segmentation.\" / X","url":"https://twitter.com/GuangxingHan/status/1737320478119694530","urlHash":3451750149},"3b9fba3e-de3b-46eb-b1b9-021e5aec56f5":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"3b9fba3e-de3b-46eb-b1b9-021e5aec56f5","title":"Aran Komatsuzaki on X: \"Enable Language Models to Implicitly Learn Self-Improvement From Data Reformulates the training objective of RLHF by maximizing the quality gap of the response conditioned on a reference response https://t.co/vkAnTeMtmF https://t.co/Z6zDpQyBeJ\" / X","url":"https://twitter.com/arankomatsuzaki/status/1709034803847209097","urlHash":336770599},"3b9ff0f9-75cb-411e-9f10-e044f60b9d3c":{"favIconUrl":"fallback","id":"3b9ff0f9-75cb-411e-9f10-e044f60b9d3c","title":"KoLA Carefully Benchmarking World Knowledge of Large Language Models - Arxiv-2306.09296","url":"https://arxiv.org/abs/2306.09296","urlHash":1539244914},"3bfe0923-381c-46c2-963f-61b379b1a8d3":{"favIconUrl":"fallback","id":"3bfe0923-381c-46c2-963f-61b379b1a8d3","title":"Fairness Without Demographics in Repeated Loss Minimization - PMLR-2018-hashimoto18a","url":"https://arxiv.org/pdf/1806.08010.pdf","urlHash":1465397286},"3bfe29cd-da3e-44f5-9c28-d12e2501458c":{"favIconUrl":"fallback","id":"3bfe29cd-da3e-44f5-9c28-d12e2501458c","title":"Flow-based Deep Generative Models","url":"https://lilianweng.github.io/posts/2018-10-13-flow-models/","urlHash":3175570770},"3c41d06b-3093-4f9c-9066-e6ad718c22fb":{"favIconUrl":"fallback","id":"3c41d06b-3093-4f9c-9066-e6ad718c22fb","title":"A Succinct Summary of Reinforcement Learning - Arxiv-2301.01379","url":"https://arxiv.org/abs/2301.01379","urlHash":1662340341},"3c849b72-b3fa-468a-b5c3-f460a419d293":{"favIconUrl":"fallback","id":"3c849b72-b3fa-468a-b5c3-f460a419d293","title":"NICE-SLAM Neural Implicit Scalable Encoding for SLAM - Arxiv-2112.12130","url":"https://arxiv.org/pdf/2112.12130.pdf","urlHash":764821072},"3c8a03e6-5705-4d56-97a1-a5f645cac505":{"favIconUrl":"fallback","id":"3c8a03e6-5705-4d56-97a1-a5f645cac505","title":"alexis-jacq/LOLA_DiCE: Pytorch implementation of LOLA (https://arxiv.org/abs/1709.04326) using DiCE (https://arxiv.org/abs/1802.05098)","url":"https://github.com/alexis-jacq/LOLA_DiCE","urlHash":457237703},"3c9e4032-1210-4a84-b744-6e1f0a1bab84":{"favIconUrl":"fallback","id":"3c9e4032-1210-4a84-b744-6e1f0a1bab84","title":"Studying Large Language Model Generalization with Influence Functions - Arxiv-2308.03296","url":"https://arxiv.org/abs/2308.03296?utm_source=substack&utm_medium=email","urlHash":4258145765},"3cbc104a-6633-49a8-8807-b282d86258f6":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"3cbc104a-6633-49a8-8807-b282d86258f6","title":"看见这张图没有，你就照着画：谷歌图像生成AI掌握多模态指令","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650903502&idx=2&sn=187b2a122aa1e8efdeee19af39c87f22&chksm=84e457b0b393dea6f14b1c9c11918c18b75d26d62ac0b1bd54b495250e76d6e849ee10a4d142&mpshare=1&scene=1&srcid=0123RXLR0mIubr7yyIjGiXAM&sharer_shareinfo=737407b8b49b9283f4225c0b9beb5902&sharer_shareinfo_first=737407b8b49b9283f4225c0b9beb5902&exportkey=n_ChQIAhIQafqDhKSlMUa3DA4HKGyE1RKWAgIE97dBBAEAAAAAAGqrIlNygkkAAAAOpnltbLcz9gKNyK89dVj05QHRMDRQqz0cZl6ZunhqbJPofVN%2FqXyKNhDGwU4Hc232pYQxtoIWtLajLLTx0DKXWKbmMcwInUt%2F9xMCCb1KWjkozgBIQT4aPfE%2BbQvPN830i2dR0MiYz8ZaIWM5Cger%2BLlVSNRozGEv62ivF8k5Nsw58%2Fx23vVmtoflbOUyYb3LOcMhlbdaAzU1YiKHPXIAm6tdici9x7HTTOriuCNQMRL2TzdsFHLr%2Bl6tGkiEOmmoZ1GGVoe3SLUXLgBR2b5p%2BD0TYKPwj9GmCyBR9KV5b3BI6zGjV6kfNlsnIPvikKb0jGYer9FdZR3lGnjr%2FMTS&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HP7I4WJn5LsCC1umDAeuAfQVgJa38W%2BO7PuQsLIWMC4xQ%3D%3D&wx_header=0#rd","urlHash":2907802632},"3cdd7d4b-77f9-43c7-b3ad-418f445275bc":{"favIconUrl":"https://www.oxen.ai/favicon.ico","id":"3cdd7d4b-77f9-43c7-b3ad-418f445275bc","title":"Papers | Oxen.ai","url":"https://www.oxen.ai/blog/road-to-sora-reading-list","urlHash":227967775},"3d00076e-464a-47e1-be27-55b2a7fa7101":{"favIconUrl":"fallback","id":"3d00076e-464a-47e1-be27-55b2a7fa7101","title":"twitter.com/omarsar0/status/1628575458735403009","url":"https://twitter.com/omarsar0/status/1628575458735403009","urlHash":1517202480},"3d1c8b84-cdce-4d3b-af2d-db2f0c9af295":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"3d1c8b84-cdce-4d3b-af2d-db2f0c9af295","title":"大模型无标注对齐RLAIF讲解","url":"https://mp.weixin.qq.com/s?__biz=MzIwNDY1NTU5Mg==&mid=2247486722&idx=1&sn=b971de2e9f9808c5174438a08cf09d0a&chksm=973d9385a04a1a93e95e35de558bad052b092b01ba7726be00c975a906022c088dc98d27a839&mpshare=1&scene=1&srcid=1001quL5EcjHn4QPF6TVAyL1&sharer_shareinfo=fd2368e902ab9225da65ab61c428b795&sharer_shareinfo_first=fd2368e902ab9225da65ab61c428b795&exportkey=n_ChQIAhIQz4SpEQPSkqsvzRCREBuN8BKWAgIE97dBBAEAAAAAAGXvAGXjKIoAAAAOpnltbLcz9gKNyK89dVj0LqmVzveKnKnKhuApXzRG7jCcrZ4OkKXxjv9pgKLnd45bo68ip4AWGrbvGdBStgPU6Y30QvOhgqZjNm71Xn70gzfR%2B%2Fq5dsMrM0AMeh%2BbJWH7%2FJkGT8NnYOs0nGoj2L0QBk5coY4uVUAQu6EIF4126PGZOLhoiI9N8SoMkL0FjFBVhN1tNH49ENMY5mDCvd87FUiJ0zOxs9FyM0BJS4FjA8GrhPU69kfqcXI1wobgajrSz9699tJC37yITeI4zo311lHTJB2O6hPLaic%2FwM%2BU26oHyg1e%2BqPgJhRdBp9Ap6wS1LIfF0XEIYDijXBB0eMc&acctmode=0&pass_ticket=G3cNQZHuNYeTYvulYmGjDp3Au8Av8JPYG4GkQrPRRidMmVDa7BuXceVBI1Jtp3Lx&wx_header=0#rd","urlHash":72862051},"3d571f65-2b12-4608-b3ff-14de54f9ce17":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"3d571f65-2b12-4608-b3ff-14de54f9ce17","title":"OSU-NLP-Group/TravelPlanner: Dataset and code for the paper \"TravelPlanner: A Benchmark for Real-World Planning with Language Agents\"","url":"https://github.com/OSU-NLP-Group/TravelPlanner","urlHash":1081444255},"3d867364-de7a-4cd7-8dfe-2e6096c0f142":{"favIconUrl":"fallback","id":"3d867364-de7a-4cd7-8dfe-2e6096c0f142","title":"流浪着的人啊，世界把它的一切呈在你面前","url":"https://www.gcores.com/radios/167475","urlHash":3081405748},"3d8d6276-0848-4879-96b5-87b69fd6d932":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"3d8d6276-0848-4879-96b5-87b69fd6d932","title":"Do Language Models Know When They're Hallucinating References? | Abstract","url":"https://arxiv.org/abs/2305.18248","urlHash":3271020594},"3d8eed81-9cb4-4803-8e9e-2ec6d6bb4f79":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"3d8eed81-9cb4-4803-8e9e-2ec6d6bb4f79","title":"Diffusion Model Alignment Using Direct Preference Optimization | Abstract","url":"https://arxiv.org/abs/2311.12908","urlHash":2158874260},"3d996b78-ef42-40e3-91ce-f43025093e0a":{"favIconUrl":"fallback","id":"3d996b78-ef42-40e3-91ce-f43025093e0a","title":"FLUTE Figurative Language Understanding through Textual Explanations - Arxiv-2205.12404","url":"https://arxiv.org/pdf/2205.12404.pdf","urlHash":778185692},"3da0c35f-3563-45dc-aad6-e2283943bb10":{"favIconUrl":"fallback","id":"3da0c35f-3563-45dc-aad6-e2283943bb10","title":"Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned","url":"https://arxiv.org/pdf/2209.07858.pdf","urlHash":2344176960},"3dcfdc16-661d-4196-8a4b-e5572fad8e97":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"3dcfdc16-661d-4196-8a4b-e5572fad8e97","title":"Seonghyeon Ye on X: \"Instruction Tuning &amp; RLHF all we need to follow instructions? 🙅‍♂️ In-Context Instruction Learning (ICIL) significantly improves the performance of both pretrained &amp; instruction-fine-tuned LLMs ✨without backpropagation✨. Just append a fixed prompt! 📜 : https://t.co/d2epURnih5 https://t.co/q4dyZSvlCe\" / X","url":"https://twitter.com/SeonghyeonYe/status/1630783945385328640","urlHash":1021621529},"3ddebffc-1a0d-4923-8454-5b3212ed2206":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"3ddebffc-1a0d-4923-8454-5b3212ed2206","title":"twitter.com/Francis_YAO_/status/1701946403038085172","url":"https://twitter.com/Francis_YAO_/status/1701946403038085172","urlHash":1468434133},"3df07850-5537-490f-ac89-aad182d9233b":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"3df07850-5537-490f-ac89-aad182d9233b","title":"Differentially Private Continual Learning | PDF","url":"https://arxiv.org/pdf/1902.06497.pdf","urlHash":3848035078},"3e0494ee-e263-4a4a-8d29-71cfe8c57615":{"favIconUrl":"fallback","id":"3e0494ee-e263-4a4a-8d29-71cfe8c57615","title":"专题：H.P.洛夫克拉夫特诞辰128周年祭：这些年我们追过的克苏鲁","url":"https://www.gcores.com/articles/101187","urlHash":2948839512},"3e3eaa1b-e0e1-4b0c-9b2c-a83011f94366":{"favIconUrl":"fallback","id":"3e3eaa1b-e0e1-4b0c-9b2c-a83011f94366","title":"bundleSDF - Google Search","url":"https://www.google.com/search?q=bundleSDF&rlz=1C1GCEA_enUS1059US1059&oq=bundleSDF&aqs=chrome..69i57.1414j0j7&sourceid=chrome&ie=UTF-8","urlHash":3594255809},"3e7602b5-f16b-4431-bbb8-aba10803b460":{"favIconUrl":"fallback","id":"3e7602b5-f16b-4431-bbb8-aba10803b460","title":"MAmmoTH Building Math Generalist Models through Hybrid Instruction Tuning - Arxiv-2309.05653","url":"https://arxiv.org/abs/2309.05653?utm_source=substack&utm_medium=email","urlHash":376922952},"3eb98e95-7869-4493-bb45-a1c916186f58":{"favIconUrl":"fallback","id":"3eb98e95-7869-4493-bb45-a1c916186f58","title":"ID-Pose","url":"https://xt4d.github.io/id-pose/","urlHash":2080495955},"3f0ab461-5310-469d-ba34-05205b987ed5":{"favIconUrl":"fallback","id":"3f0ab461-5310-469d-ba34-05205b987ed5","title":"用别的模型权重训练神经网络，改神经元不影响输出：英伟达神奇研究","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650887911&idx=2&sn=150dd2fd897dd86401ec02f527a3d71d&chksm=84e49299b3931b8fabaf3149ba8391d0e8ad5156e7ed15751eff2894c29e009319f2f584330f&mpshare=1&scene=1&srcid=1001eubR5L5MuJKgSqZh6AO9&sharer_shareinfo=78211de58f9fe3422e74f8d3713d713e&sharer_shareinfo_first=78211de58f9fe3422e74f8d3713d713e&exportkey=n_ChQIAhIQjxj0HCfXF4dwH90DjA7wlhKWAgIE97dBBAEAAAAAAO%2BlLppGikYAAAAOpnltbLcz9gKNyK89dVj0QE5yhsfTpYjCIohOI3fin9TswfsBFfsocsRnxsGU9FUGrRILEqUu8xTYsbzBwfJBvBQU9RVX5ZV8APv8ub8olT1%2FD5DoXnl1K7UIMU2BEVHXT1g45H35k5WIZqcBr7Vje1XKrs%2BUN5Wh073yKxLFlTihx6ovBw8PmMC97FyfIJfINUpFAfRv%2FVDHh8kOBGvRnYxKGBgizfBa%2BW%2BlQEMlSxTsSK%2FP8xdQwpt4sfP%2BHpkey43DMz7Chybft8CYJAqk1HtVKopvfGro8%2BSh3E%2Fn%2BzaEx19Qe2xiK5UB4lyt4K3b0dHYLM18dDOZqLHLvcvO&acctmode=0&pass_ticket=BjeUYuC2BwJE4thV5Gybqn7LBLuTYTUfez2j2YR3ugjITpoCie1CjLFxnGQQCG%2F2&wx_header=0#rd","urlHash":3300588124},"3f2f9adf-3c5a-4a71-ab3d-20373d62d2fb":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"3f2f9adf-3c5a-4a71-ab3d-20373d62d2fb","title":"Prompting Language Models for Linguistic Structure | Abstract","url":"https://arxiv.org/abs/2211.07830","urlHash":200544991},"3f3b6461-a71a-4a84-92b3-6ae95363f5d8":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"3f3b6461-a71a-4a84-92b3-6ae95363f5d8","title":"Effective Long-Context Scaling of Foundation Models | Abstract","url":"https://arxiv.org/abs/2309.16039?utm_source=substack&utm_medium=email","urlHash":1432337001},"3f7e1059-7e9a-409b-a4b2-80c32a6c97ac":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"3f7e1059-7e9a-409b-a4b2-80c32a6c97ac","title":"Shikra: Unleashing Multimodal LLM's Referential Dialogue Magic | PDF","url":"https://arxiv.org/pdf/2306.15195.pdf","urlHash":2437869304},"3f989401-44b4-4fb4-9e96-ac88a317619d":{"favIconUrl":"fallback","id":"3f989401-44b4-4fb4-9e96-ac88a317619d","title":"Reading Walter Benjamin’s Theses on the Concept of History : CriticalTheory","url":"https://www.reddit.com/r/CriticalTheory/comments/12nnzpr/reading_walter_benjamins_theses_on_the_concept_of/","urlHash":3873486230},"3fb6087a-3f76-4a9a-9ec7-69b62d15b05b":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"3fb6087a-3f76-4a9a-9ec7-69b62d15b05b","title":"Simple synthetic data reduces sycophancy in large language models | PDF","url":"https://arxiv.org/pdf/2308.03958.pdf","urlHash":3154183917},"3fbb1247-c64e-4bb3-9ee8-d8290017bd50":{"favIconUrl":"fallback","id":"3fbb1247-c64e-4bb3-9ee8-d8290017bd50","title":"Learning to Rank： pointwise 、 pairwise 、 listwise - 知乎","url":"https://zhuanlan.zhihu.com/p/111636490","urlHash":1139605017},"3fbf3026-2b7f-4642-a26d-08a2edf9ff1a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"3fbf3026-2b7f-4642-a26d-08a2edf9ff1a","title":"Cong Wei on X: \"🚀 Introduce UniIR, a unified instruction-guided multimodal retriever handles diverse tasks. - 1️⃣model for 8️⃣ retrieval tasks (SoTA w/ Instruction-tuning) - Generalizes to unseen retrieval tasks. - M-BEIR: multimodal retrieval benchmark w/ 10 datasets, 1.1M queries, 5.6M cands. https://t.co/Y8IZfmgE8U\" / X","url":"https://twitter.com/CongWei1230/status/1730307767469068476","urlHash":2891514},"3fce421b-afc0-4488-b8ce-7486db3a784d":{"favIconUrl":"fallback","id":"3fce421b-afc0-4488-b8ce-7486db3a784d","title":"格雷格·伊根：当代科幻不可逾越的高峰","url":"https://www.gcores.com/articles/162183","urlHash":3695446402},"3fecefa3-add7-495d-a840-6ba4a6bffc9b":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"3fecefa3-add7-495d-a840-6ba4a6bffc9b","title":"How Does Counterfactually Augmented Data Impact Models for Social Computing Constructs? | PDF","url":"https://arxiv.org/pdf/2109.07022.pdf","urlHash":7483352},"3ff48e84-c6e0-4969-b009-82502a6d723b":{"favIconUrl":"fallback","id":"3ff48e84-c6e0-4969-b009-82502a6d723b","title":"metapoison/meta.py at master · wronnyhuang/metapoison","url":"https://github.com/wronnyhuang/metapoison/blob/master/meta.py","urlHash":4077076435},"3ff9cd92-fe2a-4754-affe-569138e1567c":{"favIconUrl":"fallback","id":"3ff9cd92-fe2a-4754-affe-569138e1567c","title":"Unsupervised Discontinuous Constituency Parsing with Mildly Context-Sensitive Grammars - Arxiv-2212.09140","url":"https://arxiv.org/pdf/2212.09140.pdf","urlHash":1159868617},"401bfd76-2b35-4eb1-82b3-a902646e3c59":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"401bfd76-2b35-4eb1-82b3-a902646e3c59","title":"手把手教你，从零开始实现一个稀疏混合专家架构语言模型（MoE）","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650907458&idx=1&sn=14d6a69dda179cece342d0d798bacec7&chksm=84e4673cb393ee2a32c68d49934ee1474f63f0b3eeb3b8926f6437c278b4fc3ac79f085cc997&mpshare=1&scene=1&srcid=0211b4Iq3zu5ZFeLSfMATeh0&sharer_shareinfo=9627d90dba027d24969c6156f7052d90&sharer_shareinfo_first=9627d90dba027d24969c6156f7052d90&exportkey=n_ChQIAhIQZmVjPK%2ByZaGyRWLi6RtRyRKWAgIE97dBBAEAAAAAANA2CxTnnKoAAAAOpnltbLcz9gKNyK89dVj01zJ%2B4tYOcd4yOBtKJnOt8jQgqJ3nBHGX12cUCxRgAQQZQXGEF0Iiavhw4O%2FOWr%2B86b6xf8Z4nD84ZNvLOlVXsPtFHRDeVhL7xlrYcQorJRehC0YldXMbF0hF6KUi4ZG5HTkV4qETy7S%2Fbn3Wthlo%2B45kMY8qWkHo426hcrDrvPl7ujLsXp0HHvNoXDiKJbSHkkUTpYxwUxPtB644wepZY0AoS0Tivaf2ndicG2EgUyuSrP6tGBflikJqvMNw6hlROaliu6rhQGzZa0pBvWdRe1PqRyRzQ0%2Bz3Ll%2FZPp6myzXkQPNsHAkfBoVl75Qllzk&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HNxgIP8UN4585%2FWeOjGPa%2FB7zSjgEsmwiZaj%2FLpz8VHVw%3D%3D&wx_header=0#rd","urlHash":2643834526},"401e259d-943c-4997-9748-8ce0f173a68f":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"401e259d-943c-4997-9748-8ce0f173a68f","title":"IP-Adapter-FaceID - a Hugging Face Space by multimodalart","url":"https://huggingface.co/spaces/multimodalart/Ip-Adapter-FaceID","urlHash":4271680446},"40532e2c-885e-40af-b8f0-c1606bbb495b":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"40532e2c-885e-40af-b8f0-c1606bbb495b","title":"Beyond neural scaling laws: beating power law scaling via data pruning | PDF","url":"https://arxiv.org/pdf/2206.14486.pdf","urlHash":3383098495},"40992ab3-c8e0-4540-a647-fb61caa83791":{"favIconUrl":"fallback","id":"40992ab3-c8e0-4540-a647-fb61caa83791","title":"Deduplicating Training Data Makes Language Models Better","url":"https://arxiv.org/pdf/2107.06499.pdf","urlHash":1874903734},"40f76221-8a75-46f3-9911-8afd7b5f7b2d":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"40f76221-8a75-46f3-9911-8afd7b5f7b2d","title":"Seungone Kim on X: \"Excited to present 🔥Prometheus, a fully open-source evaluator LM that is on par with GPT-4 evaluation when the “appropriate” reference materials are appended! * Could generalize to customized score rubrics * Shows high correlation with both human evaluators &amp; GPT-4 evaluation\" / X","url":"https://twitter.com/seungonekim/status/1713587475229401493","urlHash":296688086},"4100e486-b0b6-4d8c-b870-b63052ab18dd":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"4100e486-b0b6-4d8c-b870-b63052ab18dd","title":"(1) Qian Huang on X: \"Can we build AI research agents to perform long-horizon tasks like ML engineering tasks e.g.Kaggle? Introducing our new work MLAgentBench: Benchmarking Large Language Models as AI Research Agents! https://t.co/m9uYcdjZKw\" / X","url":"https://twitter.com/qhwang3/status/1710352234343739795","urlHash":3640425286},"411f1306-7442-4622-bb6e-bc16c56a984d":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"411f1306-7442-4622-bb6e-bc16c56a984d","title":"Suhas Kotha on X: \"Why exactly does fine-tuning make language models worse at some tasks? Can this change how we use models like ChatGPT? In recent work with @AdtRaghunathan and @jacspringer, we find that “catastrophic forgetting” might not be as catastrophic as expected. https://t.co/N9FwXMah0e https://t.co/lhER3RQSbI\" / X","url":"https://twitter.com/kothasuhas/status/1704294056455458906","urlHash":3463425956},"413bf559-7810-458f-83cc-de383a1bb87b":{"favIconUrl":"fallback","id":"413bf559-7810-458f-83cc-de383a1bb87b","title":"BiGAN-QP：简单清晰的编码&生成模型 - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/6214","urlHash":2733869006},"4149a3fb-6470-4cf2-adc6-d9905cd072c5":{"favIconUrl":"fallback","id":"4149a3fb-6470-4cf2-adc6-d9905cd072c5","title":"How to Explain the Prediction of a Machine Learning Model?","url":"https://lilianweng.github.io/posts/2017-08-01-interpretation/","urlHash":624191677},"4155f415-3d62-48e3-818e-b268bcf6ada7":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"4155f415-3d62-48e3-818e-b268bcf6ada7","title":"When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories | PDF","url":"https://arxiv.org/pdf/2212.10511.pdf","urlHash":4005315430},"415d8578-8b2e-494b-87a6-dd571bb76ffc":{"favIconUrl":"fallback","id":"415d8578-8b2e-494b-87a6-dd571bb76ffc","title":"Logical Reasoning with Span-Level Predictions for Interpretable and Robust NLI Models - Arxiv-2205.11432","url":"https://arxiv.org/pdf/2205.11432.pdf","urlHash":2357759483},"415dc606-1639-4e3f-9f13-07f7ddead49a":{"favIconUrl":"fallback","id":"415dc606-1639-4e3f-9f13-07f7ddead49a","title":"Automatic Clipping Differentially Private Deep Learning Made Easier and Stronger - Arxiv-2206.07136","url":"https://arxiv.org/abs/2206.07136","urlHash":3975159804},"415e45b4-2d78-401a-9759-344c33425759":{"favIconUrl":"fallback","id":"415e45b4-2d78-401a-9759-344c33425759","title":"UnNatural Language Inference - Arxiv-2101.00010","url":"https://arxiv.org/pdf/2101.00010.pdf","urlHash":4268218322},"419a9846-1437-4a58-b63b-670e8ae629e9":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"419a9846-1437-4a58-b63b-670e8ae629e9","title":"Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models | PDF","url":"https://arxiv.org/pdf/2402.13064.pdf","urlHash":3724623399},"41aa4ef2-d525-4e5d-a4e6-4358b781537d":{"favIconUrl":"fallback","id":"41aa4ef2-d525-4e5d-a4e6-4358b781537d","title":"CReST A Class-Rebalancing Self-Training Framework for Imbalanced Semi-Supervised Learning - Arxiv-2102.09559","url":"https://arxiv.org/pdf/2102.09559.pdf","urlHash":1476379686},"41d7a6a4-5fce-497d-80be-a96cf3ccdb6d":{"favIconUrl":"fallback","id":"41d7a6a4-5fce-497d-80be-a96cf3ccdb6d","title":"DiffCSE Difference-based Contrastive Learning for Sentence Embeddings - Arxiv-2204.10298","url":"https://arxiv.org/abs/2204.10298","urlHash":3291444954},"41e78ed4-dc89-4f28-8f42-ab548de50bfe":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"41e78ed4-dc89-4f28-8f42-ab548de50bfe","title":"谷歌发布Prompt Expansion框架，让文生图更轻松！","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247571989&idx=2&sn=7c5ebf7cd30a18f567b8e44c78c09b69&chksm=970ef2c3a0797bd51373850ad4b376467df225f7995d5234f45aa707f56be1361c2e4b8ca65d&mpshare=1&scene=1&srcid=0115bHe7KfKIkDJfYzjTXEos&sharer_shareinfo=21148e515f2df1bf44c07e36e201106b&sharer_shareinfo_first=21148e515f2df1bf44c07e36e201106b&exportkey=n_ChQIAhIQjFHg%2F8kEzONzGKEg4catfBKWAgIE97dBBAEAAAAAAFyFEv8fjgMAAAAOpnltbLcz9gKNyK89dVj0EtBrk3D4nwe6zIpl9yjRHyKvepe6s7RCqy7fv4LbYd28r7l2ylZ9sO5he5JZCtALvS%2FnV35ZnaQBJAAlc5e1A6pNDQu7n%2FBBoUIVJpSi0d8I8lneuA1de3Ol7VoyQw3glZOeGFJcLbv5e2eCyqzT%2BD5oXelARJYgl6axhsVvACHgM2SjvxSndvHKVQNEqgHhCN4L7oerhEYIPrgLgjWKESAaxhfouISmpE%2FZJd%2BaBZYG2tiBdj5TUkC6386m%2FiOOhSoNe3FxlfPkfhcwWDlEqFwBbtZMWHiNJN2wYRYWViPJch60AUoxZ3O3YyrfDs5X&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsYbmAL6w4edY5dogFwFtMns%2BU%2B54NM9QPWaJcszYxKmFw%3D%3D&wx_header=0#rd","urlHash":3553445177},"41e8667d-f2b4-4155-9114-5b5155f21310":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"41e8667d-f2b4-4155-9114-5b5155f21310","title":"(2) Matthew Finlayson on X: \"Wanna know gpt-3.5-turbo's embed size? We find a way to extract info from LLM APIs and estimate gpt-3.5-turbo’s embed size to be 4096. With the same trick we also develop 25x faster logprob extraction, audits for LLM APIs, and more! 📄 https://t.co/NdYU8ZhuVH Here’s how 1/🧵 https://t.co/JOFmR0kmte\" / X","url":"https://twitter.com/mattf1n/status/1768668564624654381","urlHash":3608368638},"424a755e-7de4-4741-8e35-073cd6262445":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"424a755e-7de4-4741-8e35-073cd6262445","title":"smol-ai/developer: the first library to let you embed a developer agent in your own app!","url":"https://github.com/smol-ai/developer","urlHash":3249643651},"424b71b5-253c-4f92-8ba6-602aa0202374":{"favIconUrl":"fallback","id":"424b71b5-253c-4f92-8ba6-602aa0202374","title":"Algorithmic Recourse from Counterfactual Explanations to Interventions - Arxiv-2002.06278","url":"https://arxiv.org/pdf/2002.06278.pdf","urlHash":82896566},"4262572b-6b9f-4a9a-a838-3f746013dc0a":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"4262572b-6b9f-4a9a-a838-3f746013dc0a","title":"Quantifying Memorization Across Neural Language Models | PDF","url":"https://arxiv.org/pdf/2202.07646.pdf","urlHash":2661076286},"42a52177-b1b7-4cf4-8d40-6bf855f63f0d":{"favIconUrl":"fallback","id":"42a52177-b1b7-4cf4-8d40-6bf855f63f0d","title":"Differentially Private Decoding in Large Language Models - Arxiv-2205.13621","url":"https://arxiv.org/pdf/2205.13621.pdf","urlHash":1249368366},"42ba8e0b-74e9-4abc-a646-6d03d1c21943":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"42ba8e0b-74e9-4abc-a646-6d03d1c21943","title":"Git Re-Basin: Merging Models modulo Permutation Symmetries | Abstract","url":"https://arxiv.org/abs/2209.04836","urlHash":532020145},"42c6800f-a53e-48e2-a3f2-5b80958c4a54":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"42c6800f-a53e-48e2-a3f2-5b80958c4a54","title":"Reward Model Ensembles Help Mitigate Overoptimization | PDF","url":"https://arxiv.org/pdf/2310.02743.pdf","urlHash":4248131145},"42e8ea35-f8b8-4091-abb7-a8d9ccc33fa1":{"favIconUrl":"fallback","id":"42e8ea35-f8b8-4091-abb7-a8d9ccc33fa1","title":"Anatomize Deep Learning with Information Theory","url":"https://lilianweng.github.io/posts/2017-09-28-information-bottleneck/","urlHash":1050362755},"42fdc09b-6683-43f5-b0e9-e547a667f433":{"favIconUrl":"fallback","id":"42fdc09b-6683-43f5-b0e9-e547a667f433","title":"Reformer The Efficient Transformer - OR-ICLR-2020_rkgNKkHtvB","url":"https://arxiv.org/pdf/2001.04451.pdf","urlHash":372619764},"4301f355-c915-462b-b0ce-b83478805cc4":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"4301f355-c915-462b-b0ce-b83478805cc4","title":"AK on X: \"Nash Learning from Human Feedback paper page: https://t.co/PEcKvynF5A Reinforcement learning from human feedback (RLHF) has emerged as the main paradigm for aligning large language models (LLMs) with human preferences. Typically, RLHF involves the initial step of learning a… https://t.co/RODKdAzRnh\" / X","url":"https://twitter.com/_akhaliq/status/1731880108191809662","urlHash":977527784},"4307c4a8-68c5-4e24-97f2-70e9af48a369":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"4307c4a8-68c5-4e24-97f2-70e9af48a369","title":"Hungry Hungry Hippos: Towards Language Modeling with State Space Models | PDF","url":"https://arxiv.org/pdf/2212.14052.pdf","urlHash":1642054891},"4310d073-f240-49db-bd70-6f3f04e96faa":{"favIconUrl":"fallback","id":"4310d073-f240-49db-bd70-6f3f04e96faa","title":"Implicit Representations of Meaning in Neural Language Models - Arxiv-2106.00737","url":"https://arxiv.org/abs/2106.00737","urlHash":2030438206},"4327639d-032b-4f8c-aefd-68911f537f4e":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"4327639d-032b-4f8c-aefd-68911f537f4e","title":"xlang-ai/xlang-paper-reading: Paper collection on building and evaluating language model agents via executable language grounding","url":"https://github.com/xlang-ai/xlang-paper-reading/tree/main","urlHash":3540178906},"433dd18c-201b-48a3-bdd8-1cc3aade711f":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"433dd18c-201b-48a3-bdd8-1cc3aade711f","title":"Chinchilla之死：只要训练足够长时间，小模型也能超过大模型","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650892149&idx=1&sn=0c642ca64a8b0fbda8eb15c44b079298&chksm=84e4a30bb3932a1d3e7de9ff646fd41ee528807dd712ffa238074a9038b6e6f09d5f36f5d687&mpshare=1&scene=1&srcid=0115G8nvipl51amGoH6OONZu&sharer_shareinfo=f44d9133f00578daa2271b9cffc6d8f2&sharer_shareinfo_first=f44d9133f00578daa2271b9cffc6d8f2&exportkey=n_ChQIAhIQgcrQxHsRHStJAKYIpkh9oxKWAgIE97dBBAEAAAAAAGeNLygb7dIAAAAOpnltbLcz9gKNyK89dVj059Q%2BoORx6yTbXgsbcTDSwmK9lePVEPwdOjybfnlyWClFpDKGS3b%2FdV8V4yYTbkxCxjvbPzfWPZByJyWAgMGQffS2MkxIr%2F3PLiH1tyP18p91%2FGvgOR%2FEJRAO6xCs8bo3HI3IfrN1SRx6X9hfap1tJv1MgLc1w2GuBNz7nQNkITtc2SEcGcojuZolvUlY5of%2F7KCsHvt3KT4fMzSXyoxeHfZFEMubqbrjVPM1wZYN8f0m9cTdqW6STqikXCEeWY%2FUBcLZDkV9KuB2Xg5RHUZVCwGXZthIgPvt%2Fd8IeJfOoSP2pRuyq7s2WLQt6hmnY6Bs&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsauBq2wpWN4Fro9%2Bf88IbkWJzLk4LuA%2B93RZYzqUNLVSA%3D%3D&wx_header=0#rd","urlHash":220266290},"4353484d-8332-4bff-8576-bc2bb33de2e9":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"4353484d-8332-4bff-8576-bc2bb33de2e9","title":"Bodhisattwa Majumder on X: \"🆕🔍 It is important for LLMs interacting with humans to align models' behavior to their users. 👧🏽🧒🏽🦸🏽‍♀️🧝🏽‍♀️🧜🏽‍♀️ But how to best align an LLM with an individual (and not to a stereotyped group)? Paper: https://t.co/TOBAlu4EBl w @_eunjeong_hwang, Niket @allen_ai @ai2_aristo @ucsd_cse https://t.co/egdEolXXtt\" / X","url":"https://twitter.com/mbodhisattwa/status/1661313006507278336","urlHash":1497509167},"436805d8-e5d4-4f41-ab79-30404a3b6e68":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"436805d8-e5d4-4f41-ab79-30404a3b6e68","title":"xlang-ai/OpenAgents: OpenAgents: An Open Platform for Language Agents in the Wild","url":"https://github.com/xlang-ai/OpenAgents","urlHash":350638837},"436e5d32-927e-4b39-9012-0e8a1da9c4d2":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"436e5d32-927e-4b39-9012-0e8a1da9c4d2","title":"万字长文-大语言模型指令调优综述","url":"https://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&mid=2247486921&idx=1&sn=5898a7f0c56d4375768778951d498bcb&exportkey=n_ChQIAhIQ0ek%2BJX0gG5klYwFrMS%2F64xKWAgIE97dBBAEAAAAAAOAtCk7peiUAAAAOpnltbLcz9gKNyK89dVj0hBSDR5YLe8Re%2FQGvUQOgQXea%2FtCD7RRlsc1trw35jfU%2FQO0ZjD%2FkfsuNLo7KhhLzgr9oGROJDPSvz68UvEtCsqlFLkHcI3l%2FG0h7XuX0NmY6fM14R%2BTZbY6IodA%2BZEeRjv38S%2FXrY1OLqgWo1bmHOvw69eGZ9fXZBMIaekCEUeId8F4zcQZBPVQZexPq%2BtXdj%2F8l%2FxW4LGJISpBMhClL23QQv7CkMKOK59aOR%2Fdhix9Y0kN54gMwcFmWckJAZoouoxscbTgju4PO5IBtgoM7xKRbzQYNVoUdW%2FpulftgTXCuJcTXgpud1%2FmVSFd%2BUaUE&acctmode=0&pass_ticket=TB2tDKlv0fLhZ%2BziA2VIl2qNTnCNnua%2Bfx3qIw9boFfbCY20Hy%2B2n3fJjivkdrn8&wx_header=0","urlHash":1137467364},"4389e5bf-3a1d-42fb-9bcd-f35206013ef0":{"favIconUrl":"fallback","id":"4389e5bf-3a1d-42fb-9bcd-f35206013ef0","title":"Google新作Synthesizer：我们还不够了解自注意力 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/7430","urlHash":4258215472},"438ac4d4-6ad7-4678-8bae-ba01f0847692":{"favIconUrl":"fallback","id":"438ac4d4-6ad7-4678-8bae-ba01f0847692","title":"关于通关村正的一些碎碎念（装甲恶鬼村正 装甲悪鬼村正）文字","url":"https://www.douban.com/review/14377952/","urlHash":1832242434},"438f3955-c0a3-4204-93d9-757a1786cd1b":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"438f3955-c0a3-4204-93d9-757a1786cd1b","title":"The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning | Abstract","url":"https://arxiv.org/abs/2312.01552","urlHash":3450542692},"43c76fd5-f259-4e7a-a121-f04db644454d":{"favIconUrl":"fallback","id":"43c76fd5-f259-4e7a-a121-f04db644454d","title":"Learning to Search","url":"https://duvenaud.github.io/learning-to-search/","urlHash":3163159027},"43d07f6c-1096-42e7-830c-1fae0e6ceaae":{"favIconUrl":"fallback","id":"43d07f6c-1096-42e7-830c-1fae0e6ceaae","title":"圆角骑士魔理沙 - 知乎","url":"https://www.zhihu.com/people/marisa.moe","urlHash":3966340651},"442b66d5-a659-4f18-a45c-e85a44de181e":{"favIconUrl":"fallback","id":"442b66d5-a659-4f18-a45c-e85a44de181e","title":"Do Prompt-Based Models Really Understand the Meaning of their Prompts? - Arxiv-2109.01247","url":"https://arxiv.org/pdf/2109.01247.pdf","urlHash":353995841},"4431d348-5ecb-4e40-9933-c473d1e128de":{"favIconUrl":"fallback","id":"4431d348-5ecb-4e40-9933-c473d1e128de","title":"The Wisdom of Hindsight Makes Language Models Better Instruction Followers - Arxiv-2302.05206","url":"https://arxiv.org/abs/2302.05206?utm_source=substack&utm_medium=email","urlHash":3648566702},"446a816b-949c-40e7-ad98-ba2064b17039":{"favIconUrl":"fallback","id":"446a816b-949c-40e7-ad98-ba2064b17039","title":"Sequence-to-Sequence Learning with Latent Neural Grammars - NeurIPS-2021_dd17e652","url":"https://proceedings.neurips.cc/paper/2021/file/dd17e652cd2a08fdb8bf7f68e2ad3814-Paper.pdf","urlHash":2183845463},"4470ef50-a3f4-4da9-b7e0-4cfa5e4866ac":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"4470ef50-a3f4-4da9-b7e0-4cfa5e4866ac","title":"elvis on X: \"Advances in Multimodal LLMs In the last couple of weeks, we saw a spike in multimodal LLMs (MM-LLMs) research papers. Among these publications, there was a nice comprehensive survey summarizing 26 existing MM-LLMs. It also includes training recipes to enhance these models,… https://t.co/9C55iodBaK\" / X","url":"https://twitter.com/omarsar0/status/1751705689964089616?utm_source=substack&utm_medium=email","urlHash":1248371701},"44b00988-a7b6-4b49-9e28-f905219533ec":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"44b00988-a7b6-4b49-9e28-f905219533ec","title":"langchain/cookbook/learned_prompt_optimization.ipynb at master · langchain-ai/langchain","url":"https://github.com/langchain-ai/langchain/blob/master/cookbook/learned_prompt_optimization.ipynb","urlHash":777111615},"44bb7041-845a-4997-9efd-0216ab5f84be":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"44bb7041-845a-4997-9efd-0216ab5f84be","title":"Knowledge Neurons in Pretrained Transformers | PDF","url":"https://arxiv.org/pdf/2104.08696.pdf","urlHash":1440401783},"44bba762-99b6-450d-b192-447c6afa47fc":{"favIconUrl":"fallback","id":"44bba762-99b6-450d-b192-447c6afa47fc","title":"李航统计学习方法 - 知乎","url":"https://www.zhihu.com/column/c_1213397558586257408","urlHash":4026049616},"44bc36e7-636f-42a3-8157-f7e9752d08cb":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"44bc36e7-636f-42a3-8157-f7e9752d08cb","title":"今日arXiv最热NLP论文：Meta重磅，为训练数据打上烙印，以判断是否被大模型所用","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247576984&idx=2&sn=7b64a34409045b72b09510019e0b3ea7&chksm=970e854ea0790c586e5c0864f7d5aca699c7ee033644e907ff689e03559b7688750cb1e36fc2&mpshare=1&scene=1&srcid=0402TGhVv2lFwb2noTbPUWKh&sharer_shareinfo=86448771f7e16cecd43bc3c8fa47f20d&sharer_shareinfo_first=86448771f7e16cecd43bc3c8fa47f20d&exportkey=n_ChQIAhIQardTX42MTk%2BJSF4G4XUpQxKUAgIE97dBBAEAAAAAAK9UBeFK6vgAAAAOpnltbLcz9gKNyK89dVj0WddLbeY2KJvTIIPoflfsW1V1%2FybIxDgXNwWdGh%2FWu0DOdFzUCUXFfSaOluQGtGXkGdx%2BfhLxa42xPOJxPJYJS7koweeFWFp40yvoqOZmkqOTb3yKardlfMV4mdjOszRqF14A4gxdm7pVK7AEgiQqXlNBIQDp1wc8CWIFZ%2FACh0cfzhg%2BE0cEyKmxU1OsoP44leVh2Jwyy4lEXTTJUe26VdgXAW9b5%2FtaRzmYl5SELk9aUWBpF%2FnDMnaVGCWiJPzK9ImClwWT861uYpBwO0%2F0mskD2s39sUv7hkSLvL6L5vxHTqF4wZ5Rj2upL19ZLQ%3D%3D&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCOWwy3r814dCBB%2FXF%2FH8jxPeS70DR541pRsySfcElj50Q%3D%3D&wx_header=0#rd","urlHash":2345749106},"44bf9227-20e9-47d7-806a-9339bb884cf3":{"favIconUrl":"fallback","id":"44bf9227-20e9-47d7-806a-9339bb884cf3","title":"Stochastic Training is Not Necessary for Generalization - Arxiv-2109.14119","url":"https://arxiv.org/abs/2109.14119","urlHash":3987888832},"44e01b53-8cc4-4e79-842e-a901a6deea3a":{"favIconUrl":"fallback","id":"44e01b53-8cc4-4e79-842e-a901a6deea3a","title":"Designing GANs：又一个GAN生产车间 - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/7210","urlHash":896834999},"44f6e37f-dcf7-48e2-ad38-93c6542e7246":{"favIconUrl":"fallback","id":"44f6e37f-dcf7-48e2-ad38-93c6542e7246","title":"Training Language Models with Memory Augmentation - Arxiv-2205.12674","url":"https://arxiv.org/pdf/2205.12674.pdf","urlHash":188646138},"4540a588-3bb2-4d29-8b97-71f007a383e7":{"favIconUrl":"fallback","id":"4540a588-3bb2-4d29-8b97-71f007a383e7","title":"CPL Counterfactual Prompt Learning for Vision and Language Models - Arxiv-2210.10362","url":"https://arxiv.org/abs/2210.10362","urlHash":3153615793},"455f0f2a-083c-45aa-a7f7-7444154f9d22":{"favIconUrl":"fallback","id":"455f0f2a-083c-45aa-a7f7-7444154f9d22","title":"Can Large Language Models Explain Themselves? A Study of LLM-Generated Self-Explanations","url":"https://arxiv.org/abs/2310.11207?utm_source=substack&utm_medium=email","urlHash":2013424157},"456b9048-0e2e-4a61-bb5d-5a30fd466e10":{"favIconUrl":"fallback","id":"456b9048-0e2e-4a61-bb5d-5a30fd466e10","title":"CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text","url":"https://arxiv.org/pdf/1908.06177.pdf","urlHash":4131199200},"4597b73e-f1b4-45b5-b3de-7c3dfa62fd48":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"4597b73e-f1b4-45b5-b3de-7c3dfa62fd48","title":"A Closer Look at Deep Policy Gradients | PDF","url":"https://arxiv.org/pdf/1811.02553.pdf","urlHash":2973157565},"459a5bc5-71d1-479d-a8a0-8e53abb67656":{"favIconUrl":"https://lf-scm-cn.feishucdn.com/ccm/pc/web/resource/bear/src/common/assets/favicons/icon_file_doc_nor-32x32.8cb0fef16653221e74b9.png","id":"459a5bc5-71d1-479d-a8a0-8e53abb67656","title":"Q* - Feishu Docs","url":"https://lslfd0slxc.feishu.cn/wiki/Bf35wc5U3i80x9kmmNKcfhvenxh","urlHash":1868875534},"45bc5e8b-d988-4199-bcd7-62c0b381a1ae":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"45bc5e8b-d988-4199-bcd7-62c0b381a1ae","title":"Tricking LLMs into Disobedience: Formalizing, Analyzing, and Detecting Jailbreaks | Abstract","url":"https://arxiv.org/abs/2305.14965","urlHash":2129781194},"45c7b39d-d2d5-4d30-b6ec-8aeeeabe9783":{"favIconUrl":"fallback","id":"45c7b39d-d2d5-4d30-b6ec-8aeeeabe9783","title":"What Can Transformers Learn In-Context? A Case Study of Simple Function Classes - Arxiv-2208.01066","url":"https://arxiv.org/abs/2208.01066","urlHash":2189641074},"45e6796f-2e39-4395-b730-183db243d019":{"favIconUrl":"fallback","id":"45e6796f-2e39-4395-b730-183db243d019","title":"尼采山下的树 - Google Search","url":"https://www.google.com/search?q=%E5%B0%BC%E9%87%87%E5%B1%B1%E4%B8%8B%E7%9A%84%E6%A0%91&oq=%E5%B0%BC%E9%87%87%E5%B1%B1%E4%B8%8B%E7%9A%84%E6%A0%91&aqs=chrome..69i57j0i546l2.5274j0j1&sourceid=chrome&ie=UTF-8","urlHash":3759067146},"45eebf00-c95b-49da-97aa-8e9a025bd0ca":{"favIconUrl":"fallback","id":"45eebf00-c95b-49da-97aa-8e9a025bd0ca","title":"Yushi-Hu/tifa: TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering","url":"https://github.com/Yushi-Hu/tifa","urlHash":3412963124},"4603f258-5c0b-4fd0-912c-00f3a249b627":{"favIconUrl":"fallback","id":"4603f258-5c0b-4fd0-912c-00f3a249b627","title":"Video-LLaMA An Instruction-tuned Audio-Visual Language Model for Video Understanding - Arxiv-2306.02858","url":"https://arxiv.org/abs/2306.02858","urlHash":1027897428},"4613bb85-dd04-4047-ba6e-098ff0927ad6":{"favIconUrl":"https://www.youtube.com/s/desktop/54055272/img/favicon_32x32.png","id":"4613bb85-dd04-4047-ba6e-098ff0927ad6","title":"返校 Detention｜劇情簡介+彩蛋解析｜一個不僅止於恐怖解謎的遊戲 - YouTube","url":"https://www.youtube.com/watch?v=OakieFvHE8U","urlHash":2022320907},"461c8fd6-ca48-4383-b9a1-abc10e4e45e2":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"461c8fd6-ca48-4383-b9a1-abc10e4e45e2","title":"Recognize Detect Segment Anything - a Hugging Face Space by xinyu1205","url":"https://huggingface.co/spaces/xinyu1205/recognize-anything","urlHash":3660822363},"46268940-fbeb-45b1-a185-eacf17c268f0":{"favIconUrl":"https://openreview.net/favicon.ico","id":"46268940-fbeb-45b1-a185-eacf17c268f0","title":"Git Re-Basin: Merging Models modulo Permutation Symmetries | OpenReview","url":"https://openreview.net/forum?id=CQsmMYmlP5T","urlHash":75284259},"466348f3-7016-454d-9486-15c8272430fb":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"466348f3-7016-454d-9486-15c8272430fb","title":"梅杜莎,看鏡子 (豆瓣)","url":"https://book.douban.com/subject/27035205/","urlHash":2445484256},"4664c383-95ff-4155-a1d1-e73f77f6a9d9":{"favIconUrl":"fallback","id":"4664c383-95ff-4155-a1d1-e73f77f6a9d9","title":"If at First You Don't Succeed, Try, Try Again Faithful Diffusion-based Text-to-Image Generation by Selection - Arxiv-2305.13308","url":"https://arxiv.org/pdf/2305.13308.pdf","urlHash":1484163041},"466e39a9-a055-49e6-8fa1-56e2e3d1071f":{"favIconUrl":"fallback","id":"466e39a9-a055-49e6-8fa1-56e2e3d1071f","title":"ttengwang/Caption-Anything: Caption-Anything is a versatile tool combining image segmentation, visual captioning, and ChatGPT, generating tailored captions with diverse controls for user preferences.","url":"https://github.com/ttengwang/Caption-Anything","urlHash":1936567183},"46a39dd5-9986-4c52-b125-5c8c1d6234d3":{"favIconUrl":"https://www.google.com/favicon.ico","id":"46a39dd5-9986-4c52-b125-5c8c1d6234d3","title":"llm unlearning - Google Search","url":"https://www.google.com/search?q=llm+unlearning&oq=llm+unlearning&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBwgBEAAYgAQyCAgCEAAYFhgeMggIAxAAGBYYHjIICAQQABgWGB4yCAgFEAAYFhgeMgoIBhAAGIYDGIoFMgoIBxAAGIYDGIoFMgoICBAAGIYDGIoF0gEIMjY1MWowajGoAgCwAgA&sourceid=chrome&ie=UTF-8","urlHash":3220151993},"46b77938-fd40-432b-b8c8-303bad33994e":{"favIconUrl":"fallback","id":"46b77938-fd40-432b-b8c8-303bad33994e","title":"Certifying Some Distributional Robustness with Principled Adversarial Training - Arxiv-1710.10571","url":"https://arxiv.org/abs/1710.10571v5","urlHash":3949100456},"4709320f-4801-481d-b484-cc75ecc0c120":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"4709320f-4801-481d-b484-cc75ecc0c120","title":"OpenBMB/XAgent: An Autonomous LLM Agent for Complex Task Solving","url":"https://github.com/OpenBMB/XAgent","urlHash":1842107419},"4713649e-b41e-4af5-92f4-56456401c3b0":{"favIconUrl":"fallback","id":"4713649e-b41e-4af5-92f4-56456401c3b0","title":"When is BERT Multilingual? Isolating Crucial Ingredients for Cross-lingual Transfer - Arxiv-2110.14782","url":"https://arxiv.org/abs/2110.14782","urlHash":818932679},"474919d2-8916-4c63-8d88-875b17cd39a2":{"favIconUrl":"fallback","id":"474919d2-8916-4c63-8d88-875b17cd39a2","title":"hu2012matrix-calculus.pdf","url":"https://project.hupili.net/tutorial/hu2012-matrix-calculus/hu2012matrix-calculus.pdf","urlHash":4101902932},"4771461e-8a0c-405c-8b2e-43170e9de9b2":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"4771461e-8a0c-405c-8b2e-43170e9de9b2","title":"Weixin Official Accounts Platform","url":"https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzIwNDY1NTU5Mg==&action=getalbum&album_id=2201726564759846914&scene=173&from_msgid=2247486002&from_itemidx=1&count=3&nolastread=1#wechat_redirect","urlHash":1455271668},"479d63b4-5b80-4f35-b13c-d3c62043ca39":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"479d63b4-5b80-4f35-b13c-d3c62043ca39","title":"「think step by step」还不够，让模型「think more steps」更有用","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650905569&idx=2&sn=03269eb4f72c1dd974310dbe1570ff91&chksm=84e45f9fb393d6898d10cfa5781dc41382556945a4f1a72fdffca66e1dbb3ec3ce2a063a03b4&mpshare=1&scene=1&srcid=0125Jsn3KkzM3qbFRNAbaq0X&sharer_shareinfo=87eb697bace381151febb12858c13429&sharer_shareinfo_first=87eb697bace381151febb12858c13429&exportkey=n_ChQIAhIQdVlZ8%2BA4MCMlLlai21nKuRKWAgIE97dBBAEAAAAAAJyuAqMNj2AAAAAOpnltbLcz9gKNyK89dVj0JzMaDkeyhH9z4hrLpdtK%2F3boXu9W2RR5%2BMjY8rfQWpLPsScpyXUdakj7YmBIZXsuJn6JoIvT%2Bxvs7t7U53%2B1k7oLnTTBmD3oCtZufDXAvl3X9QMBEQ8GlW%2BVQAqM8tJ4pYliFGe3b8HQ3MOWrwNoUnWFD%2B%2B5J9D0yB0oHkAecLjOG3yenNK08N%2FiSRaiplvPRiXJTIS5LpKZHXOma0Sf2gsTm9Px8VUAScwHb42vVFu89%2Fg63JE6I61np8RpQVjALKX6nMKMcC4KKC5tGeiSVD%2FOn7F4vKq%2FzawHsgQcHcC0Mbh%2BwX0z8NJRlXFP6%2Fzb&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HMJqmijCX%2B1D%2BcJl%2BIdyAotYhkJkKi94e5xSyMZnYRztw%3D%3D&wx_header=0#rd","urlHash":2710926289},"47bd6d39-9063-4bea-b9ef-7a0560963164":{"favIconUrl":"fallback","id":"47bd6d39-9063-4bea-b9ef-7a0560963164","title":"scalable differential privacy with certified robustness in adversarial learning - Google Search","url":"https://www.google.com/search?q=scalable+differential+privacy+with+certified+robustness+in+adversarial+learning&oq=scalable+differen&aqs=chrome.0.35i39j69i57j0i512j0i15i22i30j0i22i30l2j69i61l2.4136j0j1&sourceid=chrome&ie=UTF-8","urlHash":3007711002},"47da4332-397b-4341-8ac8-f2597264e5b2":{"favIconUrl":"fallback","id":"47da4332-397b-4341-8ac8-f2597264e5b2","title":"Certified Adversarial Robustness via Randomized Smoothing","url":"https://arxiv.org/pdf/1902.02918.pdf)","urlHash":3407048069},"47de07f6-241a-42a5-afce-6ab25af58791":{"favIconUrl":"fallback","id":"47de07f6-241a-42a5-afce-6ab25af58791","title":"On the Principles of Parsimony and Self-Consistency for the Emergence of Intelligence - Arxiv-2207.04630","url":"https://arxiv.org/abs/2207.04630","urlHash":3870559675},"47e016fa-e694-436f-963e-18725142da79":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"47e016fa-e694-436f-963e-18725142da79","title":"AK on X: \"JudgeLM: Fine-tuned Large Language Models are Scalable Judges paper page: https://t.co/9GnGcLCZae Evaluating Large Language Models (LLMs) in open-ended scenarios is challenging because existing benchmarks and metrics can not measure them comprehensively. To address this… https://t.co/zzsFVJBhuo\" / X","url":"https://twitter.com/_akhaliq/status/1717718525958037799","urlHash":1809262810},"47f65177-b775-4439-b7e2-5c5521af8da8":{"favIconUrl":"fallback","id":"47f65177-b775-4439-b7e2-5c5521af8da8","title":"Cinofix/beta_poisoning: Official implementation of 'The Hammer and the Nut: Is Bilevel Optimization Really Needed to Poison Linear Classifiers?' [Submitted to IJCNN 2021]","url":"https://github.com/Cinofix/beta_poisoning","urlHash":509115257},"481a684e-0adc-4b13-8ee1-ea18b51ad4a1":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"481a684e-0adc-4b13-8ee1-ea18b51ad4a1","title":"What Algorithms can Transformers Learn? A Study in Length Generalization | Abstract","url":"https://arxiv.org/abs/2310.16028","urlHash":4219370750},"4827574e-2226-4455-a739-7d81df740ed5":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"4827574e-2226-4455-a739-7d81df740ed5","title":"Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey | Abstract","url":"https://arxiv.org/abs/2311.12351?utm_source=substack&utm_medium=email","urlHash":643662293},"483a66ab-211b-4ed8-ba38-d1629b6f654b":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"483a66ab-211b-4ed8-ba38-d1629b6f654b","title":"Discovering Language Model Behaviors with Model-Written Evaluations | PDF","url":"https://arxiv.org/pdf/2212.09251.pdf","urlHash":976396681},"48424c3e-9393-4f96-b8d7-f9f7f4ff9ecd":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"48424c3e-9393-4f96-b8d7-f9f7f4ff9ecd","title":"Segment Everything Everywhere All at Once | PDF","url":"https://arxiv.org/pdf/2304.06718.pdf","urlHash":1934560229},"487f38ce-1932-4123-86e9-4686a7dafcd6":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"487f38ce-1932-4123-86e9-4686a7dafcd6","title":"【渣译】我的神秘宫殿by泽村伊智","url":"https://www.douban.com/note/728081430/?_i=8490432KLQjbnS,2451377oZQdRGV","urlHash":1182154736},"48b48fa4-7a2d-4a04-b91e-9acceb49eb39":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"48b48fa4-7a2d-4a04-b91e-9acceb49eb39","title":"Tom Sherborne on X: \"🚨 new paper 🚨 Can we train for flat minima with less catastrophic forgetting? We propose Trust Region Aware Minimization for smoothness in parameter+representations. TL;DR representations matter as much as parameters! https://t.co/SNCaglqioE w/@nsaphra @pdasigi @haopeng_nlp https://t.co/mp5wNfu4BI\" / X","url":"https://twitter.com/tomsherborne/status/1711693081379053998","urlHash":1672797756},"48ed0928-3bbf-494e-9d7e-6e188b6e56bc":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/favicon-32x32.png","id":"48ed0928-3bbf-494e-9d7e-6e188b6e56bc","title":"Reddit - Dive into anything","url":"https://www.reddit.com/r/reinforcementlearning/comments/qgkxjz/hierarchical_reinforcement_learning/","urlHash":4126029223},"48f87b1e-7441-4a26-b275-c19c4f75bd1c":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"48f87b1e-7441-4a26-b275-c19c4f75bd1c","title":"Break the Sequential Dependency of LLM Inference Using Lookahead Decoding | PDF","url":"https://arxiv.org/pdf/2402.02057.pdf","urlHash":1081006076},"4911b657-196c-4eae-9d03-759769dd09a3":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"4911b657-196c-4eae-9d03-759769dd09a3","title":"UX-Decoder/Segment-Everything-Everywhere-All-At-Once: [NeurIPS 2023] Official implementation of the paper \"Segment Everything Everywhere All at Once\"","url":"https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once/tree/v1.0","urlHash":3502542477},"49190e4b-feec-4587-989a-8558ab51e314":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"49190e4b-feec-4587-989a-8558ab51e314","title":"仇恨文化入侵了圣诞节——圣诞节威胁论如何构建出神圣共同体的控制技术与等级制结构","url":"https://mp.weixin.qq.com/s?__biz=MzU3NjY5MzE1OQ==&mid=2247486763&idx=1&sn=2f1d0b75d43ea8d66356a5310e91a67a&chksm=fd0ebbe3ca7932f5e8d8a15a9ac5d5203f615892502e23dc45d53eb078cca531a46b2b35c221&mpshare=1&scene=1&srcid=0115MsYRtDKXN08j6SvBNESH&sharer_shareinfo=c25866e984540f3412760445ac8b8556&sharer_shareinfo_first=c25866e984540f3412760445ac8b8556&exportkey=n_ChQIAhIQh8fIgPzxkMHJG7Xr1s%2BNkBKWAgIE97dBBAEAAAAAAMJCKMUnQ%2B4AAAAOpnltbLcz9gKNyK89dVj07Wx51XRNf3PPp4EvibAWF4biRTtLhsRuiqdT5PXDRczrXNTqUMFvtNj3ETROdW18L8OOhJECtSvs7Pic5QiRyLsHHqmVLiGP%2B6WrnJtvK6KzO68tboANapF503hSDhD2uxdHRfxSMRotHmVFJdMUcVLmX3LooOqZwB7QARwDe9Sg%2FK3xSgnJfm%2FIkR6o4m%2F6StkzzeoHqhyLLnT5Zq%2Fv0ePipxgECgo9%2Fmp2cjhgIb1KogxmPLrikqt8k213uEeTvkmJDe4W9qyuscOf%2BhMnE1xK7QM%2F15qO%2F%2BN%2FMsXyB%2Fr33A%2BUraH4wOnqcPDyVHjj&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsaUOWpebsjAerpUIDA5yAMW3fdO0N8NAwqbmJiF4c8I%2FA%3D%3D&wx_header=0#rd","urlHash":3006566059},"493c98cd-11b3-47ae-8eef-4f8c4d50173a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"493c98cd-11b3-47ae-8eef-4f8c4d50173a","title":"AK on X: \"Language models are weak learners paper page: https://t.co/LWkMJiN8iK A central notion in practical and theoretical machine learning is that of a weak learner, classifiers that achieve better-than-random performance (on any given distribution over data), even by a small margin.… https://t.co/muPr2BcFVg\" / X","url":"https://twitter.com/_akhaliq/status/1673518661926264832","urlHash":377858971},"49592e41-5c84-4784-85fa-34f7ce25a46a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"49592e41-5c84-4784-85fa-34f7ce25a46a","title":"twitter.com/tatsu_hashimoto/status/1641849903172419585","url":"https://twitter.com/tatsu_hashimoto/status/1641849903172419585","urlHash":1179212253},"4975c18b-8f6c-42f8-bfb0-b22dc68e96a5":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"4975c18b-8f6c-42f8-bfb0-b22dc68e96a5","title":"OpenAI终于Open一回：DALL-E 3论文公布、上线ChatGPT，作者一半是华人","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650893822&idx=1&sn=530df826606e755d978fa8b1dab16b35&exportkey=n_ChQIAhIQ25v8gA6iWp9dL4Faz6HKlBKWAgIE97dBBAEAAAAAAJsbCrgHb%2BEAAAAOpnltbLcz9gKNyK89dVj0djsxIQ4NYhi%2FhTMPohqT0kf7gTZf3uEkbuEFoZ0%2Bh95%2FdNMFIGRqu7%2Fe%2B9KfGAq3kt6vCWBmodJTJsUAMja%2BE9uH4I92UaN9KKlhhxnh%2F%2BCHNxhu9f1S40o6LsTiKSZhfX%2FT62L9ZijwszUehKCDJDthuQxc7O10wHS8fseVTQ8uuy%2BhXeuSnM2qF0%2BubpJh6R0fYY%2FzNqaFeFcnxLWyrKVecp6NKif2WLvtfX1wIalNy2zypbRJ5aCx%2BAcgEmMZTiRmY336c0QPNcFVLGaTE%2FKV32oQ4c4wd5lyIe3DY6D6cE9OC0WvUTk%2F61lWRK6O&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsbl65QAwFLi7HMdn5NKXNBkxisahE%2BnqQVQVSObFdtDCQ%3D%3D&wx_header=0","urlHash":3186382836},"4993521f-ee01-43c1-a702-274c9ee4c92f":{"favIconUrl":"https://underline.io/favicon/favicon.ico","id":"4993521f-ee01-43c1-a702-274c9ee4c92f","title":"Underline | FLamE: Few-shot Learning from Natural Language Explanations","url":"https://underline.io/events/395/sessions/15249/lecture/76290-flame-few-shot-learning-from-natural-language-explanations","urlHash":3821349954},"49a756b6-abcb-40d0-8383-1c619ed64572":{"favIconUrl":"fallback","id":"49a756b6-abcb-40d0-8383-1c619ed64572","title":"Commonsense Reasoning for Question Answering with Explanations","url":"https://openreview.net/forum?id=rg-zrfteOZc","urlHash":2344584803},"49b595d5-282f-414b-ae80-21460eed3c9e":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"49b595d5-282f-414b-ae80-21460eed3c9e","title":"Parameter-Efficient Fine-Tuning Design Spaces | PDF","url":"https://arxiv.org/pdf/2301.01821.pdf","urlHash":1535086873},"49ec0e2c-1e42-4420-ad81-832768643346":{"favIconUrl":"fallback","id":"49ec0e2c-1e42-4420-ad81-832768643346","title":"wen22d.pdf","url":"https://proceedings.mlr.press/v162/wen22d/wen22d.pdf","urlHash":2574438978},"4a06fe37-7bf6-41fd-aa13-472dce7bf553":{"favIconUrl":"fallback","id":"4a06fe37-7bf6-41fd-aa13-472dce7bf553","title":"Paper Digest: Recent Papers on ChatGPT – Paper Digest","url":"https://www.paperdigest.org/2023/01/recent-papers-on-chatgpt/","urlHash":2635692656},"4a10c229-c59d-444e-8f41-f7ad9c31bf04":{"favIconUrl":"fallback","id":"4a10c229-c59d-444e-8f41-f7ad9c31bf04","title":"A Gentle Introduction to Graph Neural Networks","url":"https://distill.pub/2021/gnn-intro/","urlHash":2040841258},"4a8d6ea4-3f08-466d-9b2e-ddf0c6c81870":{"favIconUrl":"fallback","id":"4a8d6ea4-3f08-466d-9b2e-ddf0c6c81870","title":"Curriculum for Reinforcement Learning","url":"https://lilianweng.github.io/lil-log/2020/01/29/curriculum-for-reinforcement-learning.html","urlHash":474459332},"4abaa3f1-ca5d-4e10-8901-03448a8bf876":{"favIconUrl":"fallback","id":"4abaa3f1-ca5d-4e10-8901-03448a8bf876","title":"Towards Interpreting and Mitigating Shortcut Learning Behavior of NLU Models - Arxiv-2103.06922","url":"https://arxiv.org/abs/2103.06922","urlHash":934143860},"4abd8a52-027e-416f-8686-a55662cbca53":{"favIconUrl":"fallback","id":"4abd8a52-027e-416f-8686-a55662cbca53","title":"Unnatural Instructions Tuning Language Models with (Almost) No Human Labor - Arxiv-2212.09689","url":"https://arxiv.org/abs/2212.09689","urlHash":3586937685},"4ad9ee0d-4340-4c3f-9d9e-8b101895555d":{"favIconUrl":"fallback","id":"4ad9ee0d-4340-4c3f-9d9e-8b101895555d","title":"TART A plug-and-play Transformer module for task-agnostic reasoning - Arxiv-2306.07536","url":"https://arxiv.org/pdf/2306.07536.pdf","urlHash":868152533},"4b02ad2a-8425-4b0e-986a-ac597c9ae6f8":{"favIconUrl":"fallback","id":"4b02ad2a-8425-4b0e-986a-ac597c9ae6f8","title":"SayCan: Grounding Language in Robotic Affordances","url":"https://say-can.github.io/","urlHash":1955864888},"4b27ed0c-bbe5-4321-a509-dcc90d0aacc5":{"favIconUrl":"https://www.google.com/favicon.ico","id":"4b27ed0c-bbe5-4321-a509-dcc90d0aacc5","title":"Data2vec - Google Search","url":"https://www.google.com/search?q=Data2vec","urlHash":3190910386},"4bc7c8f8-009a-4df8-b3b5-e420e98647b7":{"favIconUrl":"fallback","id":"4bc7c8f8-009a-4df8-b3b5-e420e98647b7","title":"Certified Defenses for Data Poisoning Attacks","url":"https://arxiv.org/pdf/1706.03691.pdf","urlHash":3795567316},"4bd28d0d-3224-4fcf-ae16-4332f4d198bb":{"favIconUrl":"fallback","id":"4bd28d0d-3224-4fcf-ae16-4332f4d198bb","title":"group equivariant convolutional networks pytorch - Google Search","url":"https://www.google.com/search?q=group+equivariant+convolutional+networks+pytorch&newwindow=1&sxsrf=APwXEdc1EQT0ukBjJQmvqqrv3PAMONqOZw%3A1681231286822&ei=to01ZO3eMaWn5NoPh4K4kA4&oq=group+equivariant+convoultion+network+&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQARgCMgYIABAWEB4yBggAEBYQHjIGCAAQFhAeMgYIABAWEB4yBggAEBYQHjoKCAAQRxDWBBCwA0oECEEYAFDZBFjZBGD-EmgBcAF4AIABZYgBZZIBAzAuMZgBAKABAcgBCMABAQ&sclient=gws-wiz-serp","urlHash":2413854867},"4bd86ccc-86b6-47f3-971a-ffdfa03c6bcb":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"4bd86ccc-86b6-47f3-971a-ffdfa03c6bcb","title":"Yao Fu on X: \"What remains mysterious to me is why Chinchilla has completely different function forms than OpenAI, and why method 3 in chinchilla is also rather different from method 1 and 2. More mysteriously, if you take all the papers in the scaling law literature, guess what? They all… https://t.co/uNIRSRRa0r\" / X","url":"https://twitter.com/Francis_YAO_/status/1730022774473687084","urlHash":4087781226},"4c0414fe-7b7d-4b1f-b868-4286b4b56101":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"4c0414fe-7b7d-4b1f-b868-4286b4b56101","title":"ICLR2024：南洋理工发布!改几个参数就为大模型注入后门","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247579488&idx=3&sn=67375e26b6c95dd5ddaf3c286e04e416&chksm=970e9fb6a07916a0ef8616799bff155bdfbe5b00acc7a85c1a5c3661eaed29f0087cb775814a&mpshare=1&scene=1&srcid=0329epygKVHzYB5GREgxuE9c&sharer_shareinfo=1ead3925ba20dde683989bc5d7b7d5ce&sharer_shareinfo_first=1ead3925ba20dde683989bc5d7b7d5ce&exportkey=n_ChQIAhIQKp5R6R45ROf7kRGIo1dQmhKWAgIE97dBBAEAAAAAAGGXAi78BesAAAAOpnltbLcz9gKNyK89dVj0H3I%2F%2BwuAoSM2tfT%2FFIbOU7agl6G6qcc9%2FGX9rE08k2Uk77%2FRseIqLaNuA5Cu%2FaF%2BboibiIBgBCUrYAhoO8IZ7CB%2F5VR0iahu8R7dHHM4%2FN9i6EBqBIXYGNyJGoxcAbgei2%2BSf1AJhMh%2FIPqKzsoLn9XH5Ie2J%2BrdVKGFH2YxRzdh5qbwCLJF2XrKQrmhA2q9jprYFg6tYB7rgcFbSE0MJ8X5fOwRiK3tYe71hmYVzTbWzikY6WN4Re%2Fc%2Fbp36ZRZ6udqItrYcnLb4CB1OtY%2B6ek%2BEQZFOjh6I5hAHNSBCLVrGdbijjvk%2BlfQVAA%2BbgJu&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCPDmkLXwkFOG1iYnwHrEhcjeiHtwx6AWpYW1g0Da5gNeQ%3D%3D&wx_header=0#rd","urlHash":781522283},"4c097cd9-3f8d-43f3-8e09-6d46334e5f92":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"4c097cd9-3f8d-43f3-8e09-6d46334e5f92","title":"twitter.com/huybery/status/1660835495310499840","url":"https://twitter.com/huybery/status/1660835495310499840","urlHash":1598197923},"4c3b1d0e-b05f-4a40-98d1-46f7efcb7842":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"4c3b1d0e-b05f-4a40-98d1-46f7efcb7842","title":"A U-turn on Double Descent: Rethinking Parameter Counting in Statistical Learning | Abstract","url":"https://arxiv.org/abs/2310.18988","urlHash":223653181},"4c8fc1bd-ad99-40b0-a91d-746bf67079d0":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"4c8fc1bd-ad99-40b0-a91d-746bf67079d0","title":"灰かぶりの夕海 (豆瓣)","url":"https://book.douban.com/subject/35982719/","urlHash":3367468173},"4ca32fee-d25f-4d9e-ad44-5a171de0ffc5":{"favIconUrl":"fallback","id":"4ca32fee-d25f-4d9e-ad44-5a171de0ffc5","title":"Finding Dataset Shortcuts with Grammar Induction - Arxiv-2210.11560","url":"https://arxiv.org/abs/2210.11560","urlHash":1113650646},"4cb2b7c2-9053-41ac-a807-d031c3d974a2":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"4cb2b7c2-9053-41ac-a807-d031c3d974a2","title":"张俊林趣谈：GPT4是否已具备类人智慧，为何GPT通过Next Token Prediction可以产生智能","url":"https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247557377&idx=1&sn=ae5a6b626890588883a83036d9de3401&chksm=ebb6d9d5dcc150c3e863b185c23e17ee0e5f20357af72a6853ba5ad7728975e8f30f1b9b7c9a&mpshare=1&scene=1&srcid=0701LWkDIWdrwz2cOTa4WeKM&sharer_sharetime=1688170780193&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQOVDOhrbqApJ%2B2Nz%2FE%2BECkRKOAgIE97dBBAEAAAAAAOJjCHYPj%2BkAAAAOpnltbLcz9gKNyK89dVj0ljquQqIX0FVrNyiZn21u2MSpMdYPY1w%2BKThXoTH0wH3d1bAnZlhqryR6M%2B23qgMib%2B5smmFjUE6eMDzCCcb6Q%2FtimJDsdlQZLP%2FL00JzMC3AaHdKGJ4mVDJMUzLPrYCX4OFpbO62EQ4rK79rRTCApLi8ZpCre2WExvmv8WfZfm03QXPLFfqJbGe%2F388FtX%2F7EDkc1u3osMGQMYMHIjUKDB%2FmMX2BUtRVlL%2FylHBNRU4NAKpliMou%2F23ubcPBUnrQSleUEsv2FCu52kMvBnYG3qKk0B5vg7wBJxD6Ui1pQyGX%2BG17%2BiHc7A%3D%3D&acctmode=0&pass_ticket=D0xNyIm5hhfuHgBPiT5UjK%2B09WIEnBa3eCl9LYt5%2B%2FXSHlApc7tS62A11%2F0CjZrS&wx_header=0#rd","urlHash":2861065422},"4cb8f8a1-97a9-456b-a187-0792390b7e86":{"favIconUrl":"fallback","id":"4cb8f8a1-97a9-456b-a187-0792390b7e86","title":"Gen-2 - Google Search","url":"https://www.google.com/search?q=Gen-2","urlHash":3202393006},"4cd62234-64a1-4c65-8047-e032d854e552":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"4cd62234-64a1-4c65-8047-e032d854e552","title":"AK on X: \"GPT4Point: A Unified Framework for Point-Language Understanding and Generation paper page: https://t.co/H1uNLYKAnY Multimodal Large Language Models (MLLMs) have excelled in 2D image-text comprehension and image generation, but their understanding of the 3D world is notably… https://t.co/bgcdFE7Trw\" / X","url":"https://twitter.com/_akhaliq/status/1732221250318090255","urlHash":1335553438},"4ce04b23-581c-4a8c-add6-16df96dc6417":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"4ce04b23-581c-4a8c-add6-16df96dc6417","title":"Symbolic Chain-of-Thought Distillation: Small Models Can Also \"Think\" Step-by-Step | PDF","url":"https://arxiv.org/pdf/2306.14050.pdf","urlHash":1693889485},"4d0a4288-37e8-4e03-bf46-5aea9faafac0":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"4d0a4288-37e8-4e03-bf46-5aea9faafac0","title":"Quantize 🤗 Transformers models","url":"https://huggingface.co/docs/transformers/main/en/main_classes/quantization#exllama-kernels-for-faster-inference","urlHash":2089473306},"4d2d916c-fbbb-409e-9872-e0390b0e4054":{"favIconUrl":"https://ieeexplore.ieee.org/favicon.ico","id":"4d2d916c-fbbb-409e-9872-e0390b0e4054","title":"Towards Evaluating the Robustness of Neural Networks | IEEE Conference Publication | IEEE Xplore","url":"https://ieeexplore.ieee.org/abstract/document/7958570","urlHash":199829756},"4d65a79d-2a7b-4004-b09a-6c53ea78229b":{"favIconUrl":"https://zh.wikisource.org/static/favicon/wikisource.ico","id":"4d65a79d-2a7b-4004-b09a-6c53ea78229b","title":"死火 - 维基文库，自由的图书馆","url":"https://zh.wikisource.org/wiki/%E6%AD%BB%E7%81%AB","urlHash":619743848},"4d6e6ab6-eb3a-422b-9936-ee31a80fe54f":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"4d6e6ab6-eb3a-422b-9936-ee31a80fe54f","title":"AK on X: \"VILA: On Pre-training for Visual Language Models paper page: https://t.co/1QHJmbElUU Visual language models (VLMs) rapidly progressed with the recent success of large language models. There have been growing efforts on visual instruction tuning to extend the LLM with visual… https://t.co/got4MZRbPH\" / X","url":"https://twitter.com/_akhaliq/status/1734773179401269465","urlHash":3425021128},"4d8528ff-0e28-4e22-a675-9573b5b33837":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"4d8528ff-0e28-4e22-a675-9573b5b33837","title":"Richard Song on X: \"Thanks for the retweet, @_akhaliq!\" / X","url":"https://twitter.com/XingyouSong/status/1760885003469111390","urlHash":1091995491},"4d90f2cb-4ad6-49a4-b70f-98745696bfd9":{"favIconUrl":"fallback","id":"4d90f2cb-4ad6-49a4-b70f-98745696bfd9","title":"EmbodiedGPT Vision-Language Pre-Training via Embodied Chain of Thought - Arxiv-2305.15021","url":"https://arxiv.org/abs/2305.15021","urlHash":1415596750},"4da779d6-9cb5-4ead-9c38-1205b70ca69f":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"4da779d6-9cb5-4ead-9c38-1205b70ca69f","title":"ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate | PDF","url":"https://arxiv.org/pdf/2308.07201.pdf","urlHash":1175208920},"4dd3ec68-3edd-4562-8029-47ce3f51630c":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"4dd3ec68-3edd-4562-8029-47ce3f51630c","title":"twitter.com/aormazabalo/status/1725513067293724897","url":"https://twitter.com/aormazabalo/status/1725513067293724897","urlHash":2012518001},"4e0d1def-77d3-4c3e-8e09-ca3afe1d6787":{"favIconUrl":"https://hpc-ai.com/hubfs/logos/colossal-ai_emblem.svg","id":"4e0d1def-77d3-4c3e-8e09-ca3afe1d6787","title":"Replicate ChatGPT Training Quickly and Affordable with Open Source Colossal-AI","url":"https://hpc-ai.com/blog/colossal-ai-chatgpt","urlHash":1184302046},"4e164bb0-0018-483a-a9ae-bda984740e63":{"favIconUrl":"https://nicholas.carlini.com/favicon.ico","id":"4e164bb0-0018-483a-a9ae-bda984740e63","title":"Writing | Nicholas Carlini","url":"https://nicholas.carlini.com/writing","urlHash":1450933914},"4e36ea12-7294-416f-8634-bbdf28f0be9d":{"favIconUrl":"https://mon.tuilixy.net/image/favicon_32_new.png","id":"4e36ea12-7294-416f-8634-bbdf28f0be9d","title":"首届新星国际推理文学奖决选入围名单 - 推理小说 - 贝克街推理学院","url":"https://www.tuilixy.net/thread-156395-1-1.html","urlHash":985555476},"4e725864-c9ad-426a-abd2-e622a4528f29":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"4e725864-c9ad-426a-abd2-e622a4528f29","title":"twitter.com/vidhisha_b/status/1661129571239071745","url":"https://twitter.com/vidhisha_b/status/1661129571239071745","urlHash":3296263611},"4ea7741c-a037-4fe2-8e21-8e2c950d871a":{"favIconUrl":"fallback","id":"4ea7741c-a037-4fe2-8e21-8e2c950d871a","title":"SIGIR20|最佳论文：通往公平、公正的Learning to Rank！ - 知乎","url":"https://zhuanlan.zhihu.com/p/214242589","urlHash":4122302971},"4ee76121-d760-4e63-abed-2ca99283f087":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"4ee76121-d760-4e63-abed-2ca99283f087","title":"Large Language Models Struggle to Learn Long-Tail Knowledge | PDF","url":"https://arxiv.org/pdf/2211.08411.pdf","urlHash":172288317},"4f1fcabe-5133-499a-9396-2dd753e94e22":{"favIconUrl":"fallback","id":"4f1fcabe-5133-499a-9396-2dd753e94e22","title":"zbchern/awesome-machine-learning-reliability: A curated list of awesome resources regarding machine learning reliability.","url":"https://github.com/zbchern/awesome-machine-learning-reliability","urlHash":3533186748},"4f28036d-0355-403f-8744-34ad75ce2410":{"favIconUrl":"https://www.wildchatdataset.com/favicon.ico","id":"4f28036d-0355-403f-8744-34ad75ce2410","title":"WildChat Dataset","url":"https://www.wildchatdataset.com/","urlHash":76821880},"4f30ed13-60ca-4d2a-879b-f598f07250a6":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"4f30ed13-60ca-4d2a-879b-f598f07250a6","title":"A Simple Framework for Open-Vocabulary Segmentation and Detection | PDF","url":"https://arxiv.org/pdf/2303.08131.pdf","urlHash":2581385438},"4f4eef69-e650-4357-8dd1-4984e55fa195":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"4f4eef69-e650-4357-8dd1-4984e55fa195","title":"AK on X: \"LLaVA-Grounding: Grounded Visual Chat with Large Multimodal Models paper page: https://t.co/6BkGJ3IGrp With the recent significant advancements in large multi-modal models (LMMs), the importance of their grounding capability in visual chat is increasingly recognized. Despite… https://t.co/XaF2ZxGXgL\" / X","url":"https://twitter.com/_akhaliq/status/1732220055931256916","urlHash":1408493002},"4f5d0205-23c4-4b7f-9f57-6a871e5a93eb":{"favIconUrl":"fallback","id":"4f5d0205-23c4-4b7f-9f57-6a871e5a93eb","title":"解读模型压缩9：无需数据的神经网络压缩技术 (一) - 知乎","url":"https://zhuanlan.zhihu.com/p/385866470","urlHash":194378004},"4f92a692-ed19-4b3c-8b80-bda3da891b32":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"4f92a692-ed19-4b3c-8b80-bda3da891b32","title":"Extending the WILDS Benchmark for Unsupervised Adaptation | PDF","url":"https://arxiv.org/pdf/2112.05090.pdf","urlHash":1894583856},"4f9c6822-21be-47ad-bb7d-e0f97f812c7f":{"favIconUrl":"fallback","id":"4f9c6822-21be-47ad-bb7d-e0f97f812c7f","title":"Sequence Modeling with CTC","url":"https://distill.pub/2017/ctc/","urlHash":1478454322},"501d248b-c197-417a-8d63-5e29d5984dd0":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"501d248b-c197-417a-8d63-5e29d5984dd0","title":"Technical Report: Large Language Models can Strategically Deceive their Users when Put Under Pressure | Abstract","url":"https://arxiv.org/abs/2311.07590?utm_source=substack&utm_medium=email","urlHash":4054410169},"50221986-f10c-45a8-b56c-04011c05a5bb":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"50221986-f10c-45a8-b56c-04011c05a5bb","title":"显存瓶颈被打破！大模型训练的黑科技来了，带宽不再制约大模型训练","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247571631&idx=1&sn=3248e471d4e256004141476e4c9e08f9&chksm=970ef079a079796f031f8f7961fb6a54a70297b00728a958fb1718c7edabc74a715eb64577f5&mpshare=1&scene=1&srcid=0115FJsUrEhDcfYH7uvMCwiw&sharer_shareinfo=2f54f7eee2e5be4f622b080f40489378&sharer_shareinfo_first=2f54f7eee2e5be4f622b080f40489378&exportkey=n_ChQIAhIQ4kjyKaiG2Q7gCFgl4rmocRKWAgIE97dBBAEAAAAAAPmQDmWcn7kAAAAOpnltbLcz9gKNyK89dVj0BcGoa0S%2BqzFUagNQREFJMSpvWL56Tq%2B6ttLN7FIA4Xim4swe1hGXXj9uIt9OlAVoOr9air%2FKy0d9LhDnU3LqFz3BKoJS%2BqzVolzTr1CYyEcK%2BzxHEPZEedYNRoFnQxUDO8ntYZYfO6DLNE14z4P2JjAMKoFUQrT%2BxOXfIBFzTugujDvw8SAcrA3oL56y7rguiFGnOmCmSpb9Zww81ojxtu1QMViA%2FNelasHbGbwTB%2F7dmiDMQgJo9QaJaJKPyxUddjs2mUTB7KZQYSx5B54MiJL%2FzBDsIb8SG8LKXu6Fzzo8tAkp4C%2B1PJHNJ8zLR8T5&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsY%2B2CAEJ%2BIEK8x5Sj7wElaZ1UxOxyBvhL2Ae0dy0vfWOg%3D%3D&wx_header=0#rd","urlHash":2230974872},"502ac76a-6327-4305-a576-4d8b85b28deb":{"favIconUrl":"https://opendilab.github.io/DI-engine/_static/images/favicon.ico","id":"502ac76a-6327-4305-a576-4d8b85b28deb","title":"RND — DI-engine 0.1.0 documentation","url":"https://opendilab.github.io/DI-engine/12_policies/rnd.html","urlHash":1401303593},"5034787e-3e08-4122-a214-95265cf738a5":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"5034787e-3e08-4122-a214-95265cf738a5","title":"Scaling Laws for Associative Memories | PDF","url":"https://arxiv.org/pdf/2310.02984.pdf","urlHash":3423890752},"5058c115-283f-4a29-b38c-f3940638b121":{"favIconUrl":"data:image/vnd.microsoft.icon;base64,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","id":"5058c115-283f-4a29-b38c-f3940638b121","title":"【自翻】似鸟鸡《叙述性诡计短篇集》——背靠背的恋人（下） - 简书","url":"https://www.jianshu.com/p/7346a4291fb5","urlHash":4120848340},"508f4302-148c-4c60-8fb8-9ab44fb853ab":{"favIconUrl":"fallback","id":"508f4302-148c-4c60-8fb8-9ab44fb853ab","title":"Decoupling Knowledge from Memorization Retrieval-augmented Prompt Learning - Arxiv-2205.14704","url":"https://arxiv.org/pdf/2205.14704.pdf","urlHash":1693287420},"509344fc-e707-4ef6-94cd-38ecf11748fc":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"509344fc-e707-4ef6-94cd-38ecf11748fc","title":"羊驼再度进化，“长颈鹿版”LongLLaMA 来啦，上下文长度冲向 100K ，性能不减","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247555578&idx=1&sn=e79cee50490b564ba2ee27beaaa90f08&exportkey=n_ChQIAhIQnPytta%2F7kENN8hSTlNk%2FERKWAgIE97dBBAEAAAAAAFpoELYLtYwAAAAOpnltbLcz9gKNyK89dVj0ao%2F88uYEkDI7TCWOGRmxhOqDRtxx60kM5BzZDeJs37M%2Bfjy1mk%2BfEnrKLydaK0iV9j11yYZ6%2BQk%2FuQXICXQHml%2B%2F4b7EGxRYO7pGjQ6rOt%2BICYYoMZN%2FlUZUZzAVIqzsxvpn8A%2BwPM7fJVqxMzLdULHS%2Fmkj7Ee6swzmwgQGBdSEQuPJoeHU8I3mdb1XmGxHDUMYdnrQuKRCzsX15wFktRTeUVJ1X%2BL9er%2F8ZiCrr9kxwbBY0X0p2vEzmpN37PGdJgB84MVwaiUWQTF1j9wh0OU71OWevLyUKnu8Z2B9711gdjP0F7w%2BlNHANkdBsWll&acctmode=0&pass_ticket=qt%2FhX9sXeJcL5yLOQQIL6hfioZsi2Asfbb4qi0y6KQiSxrgQtSpcV%2FP2f11CRow1&wx_header=0","urlHash":2627108543},"50a9e263-7b46-4ca2-9521-7243cc37e892":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"50a9e263-7b46-4ca2-9521-7243cc37e892","title":"(1) Chujie Zheng on X: \"✨New Paper Alert✨ Adding safety prompts can safeguard LLMs against harmful inputs, but do you know how they intrinsically work? Check our latest paper: We study the working mechanisms of safety prompts from the perspective of model representations 📄https://t.co/nX7UMTyKus\" / X","url":"https://twitter.com/ChujieZheng/status/1754609348645691770","urlHash":57818893},"510bd8a3-c1f2-4195-83a2-2cbd7cbf581f":{"favIconUrl":"fallback","id":"510bd8a3-c1f2-4195-83a2-2cbd7cbf581f","title":"DISCO Distilling Phrasal Counterfactuals with Large Language Models - Arxiv-2212.10534","url":"https://arxiv.org/pdf/2212.10534.pdf","urlHash":3697594084},"513cf06e-d9ee-437f-bda6-f217e8cb2103":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"513cf06e-d9ee-437f-bda6-f217e8cb2103","title":"LLM评估综述论文问世，分三方面全面总结，还带资料库","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650885739&idx=5&sn=2bc8a123e86393f449e43ffb356be549&exportkey=n_ChQIAhIQinTXoDui%2FG25MCTDzDEcsBKWAgIE97dBBAEAAAAAADCHBSVxHysAAAAOpnltbLcz9gKNyK89dVj0pd2eShEBH9iBDtugOKKweiiw%2BG4709JMEqcfi6oi9NhPq8TRR%2FFOqO709O2fVIEYxIUaxnZHLISv7Wde10coDjGWKOrJPE1%2FCT8ZERgxZ8vwseHdwrYnesxLLWKhZHhzFSqDGWZetOsyHQoddJRWqPouLgjXzuuBYKNMO6q5niT94F18ImOKuguf2Ienl7ZGsEVq9lYV%2BVI9bV5cicFRYQ%2BqtN9C1gAqrJUqppjNOqpiuygOizLqROxCZcVIsNDJtSmuazj9Bj6WRfmAqyG1HcIhuA0m7DtuTag2RZjCxmNEfGDElHSWXyqqB0tqShX6&acctmode=0&pass_ticket=Hf%2FVkZehz12zHUbZIeVDkzsN9K7doQSuxy8djMrPCi3oZqo8RWpyj9a1pkOPdrEL&wx_header=0","urlHash":99184336},"5168ef7a-080d-409c-8436-bb4e8fd9d534":{"favIconUrl":"https://www.google.com/favicon.ico","id":"5168ef7a-080d-409c-8436-bb4e8fd9d534","title":"stable video diffusion - Google Search","url":"https://www.google.com/search?q=stable+video+diffusion&newwindow=1&sca_esv=585494945&sxsrf=AM9HkKkCwLk9e-QPnTxKv2vMCAznAMIumQ%3A1701050014047&ei=nvZjZfLAAtikptQPiJWHiAg&oq=Stable+vi&gs_lp=Egxnd3Mtd2l6LXNlcnAiCVN0YWJsZSB2aSoCCAAyBBAAGAMyCxAAGIAEGIoFGJECMgQQABgDMgQQABgDMgQQABgDMgQQABgDMgQQABgDMgQQABgDMgQQABgDMgQQABgDSKE8ULEGWL43cAV4AZABAJgBkgGgAb4KqgEDNC44uAEByAEA-AEBwgIKEAAYRxjWBBiwA8ICChAjGIAEGIoFGCfCAgoQABiABBiKBRhDwgINEAAYgAQYigUYsQMYQ8ICEBAAGIAEGIoFGLEDGIMBGEPCAgsQLhiABBiKBRiRAsICEBAuGIAEGIoFGLEDGIMBGEPCAhYQLhiABBiKBRixAxiDARjHARjRAxhDwgINEAAYgAQYsQMYgwEYCsICBxAAGIAEGArCAhoQLhiABBiKBRiRAhiXBRjcBBjeBBjgBNgBAcICERAAGIAEGIoFGLEDGIMBGJECwgIQEC4YgAQYxwEYrwEYjgUYCsICBRAAGIAEwgILEAAYgAQYsQMYgwHiAwQYACBBiAYBkAYIugYGCAEQARgU&sclient=gws-wiz-serp","urlHash":3942357775},"51719e25-ba53-44f6-bd97-4be480a8d8a7":{"favIconUrl":"fallback","id":"51719e25-ba53-44f6-bd97-4be480a8d8a7","title":"Explainable AI Course","url":"https://interpretable-ml-class.github.io/","urlHash":3566872392},"5177c51e-66d6-420e-b898-b5d32769c31e":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"5177c51e-66d6-420e-b898-b5d32769c31e","title":"PKU-Alignment/safe-rlhf: Safe RLHF: Constrained Value Alignment via Safe Reinforcement Learning from Human Feedback","url":"https://github.com/PKU-Alignment/safe-rlhf?tab=readme-ov-file","urlHash":2821311244},"51822f43-a1de-4f67-8c38-1201cc0ad995":{"favIconUrl":"fallback","id":"51822f43-a1de-4f67-8c38-1201cc0ad995","title":"Ludwig Wittgenstein (Stanford Encyclopedia of Philosophy)","url":"https://plato.stanford.edu/entries/wittgenstein/","urlHash":921601186},"5193d233-779f-486c-a59d-f28d2a0be897":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5193d233-779f-486c-a59d-f28d2a0be897","title":"AK on X: \"Rank-without-GPT: Building GPT-Independent Listwise Rerankers on Open-Source Large Language Models paper page: https://t.co/WYVl18cpr9 Listwise rerankers based on large language models (LLM) are the zero-shot state-of-the-art. However, current works in this direction all depend… https://t.co/0pie3W18tz\" / X","url":"https://twitter.com/_akhaliq/status/1732216033975357820","urlHash":4077265186},"51c3c8a8-ee74-4c4c-a2a4-f8d9e6893e3b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"51c3c8a8-ee74-4c4c-a2a4-f8d9e6893e3b","title":"twitter.com/QuanquanGu/status/1748330986251993486","url":"https://twitter.com/QuanquanGu/status/1748330986251993486","urlHash":2188050224},"51fb3506-7003-4701-8aa3-b364400954f6":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"51fb3506-7003-4701-8aa3-b364400954f6","title":"Jason Wei on X: \"It was an honor to give a guest lecture yesterday at Stanford’s CS330 class, \"Deep Multi-Task and Meta-Learning\"! I discussed a few very simple intuitions for how I personally think about large language models. Slides: https://t.co/NmusNTUVXb Here are the six intuitions: (1)… https://t.co/qjmy7FGWWv\" / X","url":"https://twitter.com/_jasonwei/status/1729585618311950445","urlHash":2771508529},"522d0090-2c63-41cf-a879-91d52aba9692":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"522d0090-2c63-41cf-a879-91d52aba9692","title":"Aran Komatsuzaki on X: \"LLM Agent Operating System Presents AIOS, an LLM agent operating system, which embeds large language model into operating systems repo: https://t.co/wb2VKLYnZl abs: https://t.co/voVGuC1Dfz https://t.co/4gWMMIbHLB\" / X","url":"https://twitter.com/arankomatsuzaki/status/1772460132745547976","urlHash":872704797},"523605c0-47e3-4134-a85b-325de9908e81":{"favIconUrl":"fallback","id":"523605c0-47e3-4134-a85b-325de9908e81","title":"hamiltorch: a PyTorch Python package for sampling","url":"https://adamcobb.github.io/journal/hamiltorch.html","urlHash":227694561},"526d010f-00f9-4d79-818b-ec4b8f0308ec":{"favIconUrl":"fallback","id":"526d010f-00f9-4d79-818b-ec4b8f0308ec","title":"Learning to rank基本算法小结 - 知乎","url":"https://zhuanlan.zhihu.com/p/26539920","urlHash":2742501780},"5273036d-3fe7-4b52-a33b-a6cedfb4e58b":{"favIconUrl":"fallback","id":"5273036d-3fe7-4b52-a33b-a6cedfb4e58b","title":"一句话修图时代来了！谷歌新模型碾压DALLE·2和Imagen","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247541344&idx=2&sn=8a3e3f02b82fe89cce8c940a5acf4dba&exportkey=n_ChQIAhIQTqvEYqSlT9A7LDjZytRiQxKWAgIE97dBBAEAAAAAAG1hJPwqrnkAAAAOpnltbLcz9gKNyK89dVj0fnW0%2Fwakqf0gKRNuG1hNvg4yIuFdmuiI95dNPOZ%2FJ9joCOvy5WAzG4mngwFrl8S%2BxKNixlVq95SB2aAibtsEYKtqbt11XM0QAXnIXUvna9gCtHVAFgGWkZ7Jpsd7LcJiGvui1Frxh%2FG0B%2Bg8I6Qx3gkkI2e27ixWJnw2RwCNvVh1I5TMl47ZKl1tePVDrzAltTzaiHc7eA7zmZWJSEdrwV%2Fcm2reIYqBjaYTs2kzTLRYm7guMwKIEJeBaITjkhNAeHCejVb5U4ivFLFvmsIPEaKnEEOz4St5ZB0AgdaheybZXgBYIVU1Hl0TDS1lmSVT&acctmode=0&pass_ticket=3HIlKyjzTAFL%2FxFljj2tEtyLfkTobYOBU23FblbSLUp8Vu1SdLzUzUslMYnl2lP3NKfoplIeqIBS54Iibm%2FChw%3D%3D&wx_header=0","urlHash":3517582506},"527f12e3-dff8-45d6-8c5f-16a6b32e2588":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"527f12e3-dff8-45d6-8c5f-16a6b32e2588","title":"日本历史上的东与西 (豆瓣)","url":"https://book.douban.com/subject/36085059/","urlHash":3097877769},"52932afd-1372-4431-8f3b-598e54b14607":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"52932afd-1372-4431-8f3b-598e54b14607","title":"elvis on X: \"Retrieval Augmented Thoughts Shows that iteratively revising a chain of thoughts with information retrieval can significantly improve LLM reasoning and generation in long-horizon generation tasks. The key idea is that each thought step is revised with relevant retrieved… https://t.co/yZm3QISsiT\" / X","url":"https://twitter.com/omarsar0/status/1767251740443746435?utm_source=substack&utm_medium=email","urlHash":3992168403},"5293bc84-9da1-4e13-b621-94383403f6c7":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"5293bc84-9da1-4e13-b621-94383403f6c7","title":"(1) Hao Liu on X: \"New paper w/ @matei_zaharia @pabbeel on transformers with large context size. We propose RingAttention, which allows training sequences that are device count times longer than those of prior state-of-the-arts, without attention approximations or incurring additional overhead. https://t.co/MWB8kF9nnk\" / X","url":"https://twitter.com/haoliuhl/status/1709630382457733596?t=KCjKoVk5yXVuqUuOEzCJvA","urlHash":969752047},"529cd507-7ea0-4f31-b548-1014aa067ef3":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"529cd507-7ea0-4f31-b548-1014aa067ef3","title":"ICLR2024 oral paper with code 集锦","url":"https://mp.weixin.qq.com/s?__biz=MzI5NzAzODcyNw==&mid=2454901195&idx=1&sn=8ecb247ead0fde8765a670d50d49115e&chksm=fb1d5723cc6ade35ac455f686c6e808762447ddc7ecbf5a6bdc0bf0ad7809165ef732046f9c2&mpshare=1&scene=1&srcid=0419e6YUIIZjgx19t1zSWfgn&sharer_shareinfo=8f9b5e24860dfb56221b899a1253d32c&sharer_shareinfo_first=8f9b5e24860dfb56221b899a1253d32c&exportkey=n_ChQIAhIQGPJSNsKI5LCzUqfbtkkypBKWAgIE97dBBAEAAAAAAPGOKIBWKl8AAAAOpnltbLcz9gKNyK89dVj0ol2MyodPn5N1wik4FNJ9SQSBKkbvgyZV245%2FUX5lrNdanSR4efaLz9a6TaHmVBcyORRqULNsPuPd8mv7Nbd%2FudrMxt5rPN1hUJGgmCaRufmpRnU4Xz3kLHIH005cY2iasO1Sgr%2B%2ByhZVfhOYPHnIwPOT62V6LTnjNiUEtR12Fvfg40ojeLDRUALI5rP0unuC0xo2NV1bdokE8IBpsPXSalPcX%2FmLdfyfRr%2Bg6FOu4CQWZv0sZj3uRuldKMkIPEprGBuomXbBIBmvaeGjUN5Awec8ueaxymh2PgUHXs9ob5c71bZGNCebF%2BCMbP%2BdNlMT&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCPUy%2FaLofimlrxkLD%2BUQDSfEDYgMU5hgWNHTL3KW5q9uQ%3D%3D&wx_header=0#rd","urlHash":2402288967},"52b6d19c-8a83-4fbb-adb8-782c50541f53":{"favIconUrl":"fallback","id":"52b6d19c-8a83-4fbb-adb8-782c50541f53","title":"李航统计学习方法（第四章） - 知乎","url":"https://zhuanlan.zhihu.com/p/110955275","urlHash":1588448928},"52bf9f48-c8fa-4afe-9ca6-4d99f018edf3":{"favIconUrl":"fallback","id":"52bf9f48-c8fa-4afe-9ca6-4d99f018edf3","title":"深入浅出Yolo系列之Yolov3&Yolov4&Yolov5&Yolox核心基础知识完整讲解 - 知乎","url":"https://zhuanlan.zhihu.com/p/143747206","urlHash":2729164300},"52c5734c-f027-4d7c-8e7f-5727796ed45a":{"favIconUrl":"fallback","id":"52c5734c-f027-4d7c-8e7f-5727796ed45a","title":"标签 生成模型 下的文章 - 科学空间|Scientific Spaces","url":"https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/5/","urlHash":2142184247},"52e99827-1034-4596-9572-2ec8e5219559":{"favIconUrl":"fallback","id":"52e99827-1034-4596-9572-2ec8e5219559","title":"Explanations from Large Language Models Make Small Reasoners Better - Arxiv-2210.06726","url":"https://arxiv.org/pdf/2210.06726.pdf","urlHash":3644883124},"52ed82be-bf7f-425b-8003-2c03f7f08406":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"52ed82be-bf7f-425b-8003-2c03f7f08406","title":"twitter.com/zdeborova/status/1755158457785704771?utm_source=substack&utm_medium=email","url":"https://twitter.com/zdeborova/status/1755158457785704771?utm_source=substack&utm_medium=email","urlHash":830183507},"52f1a41c-1d26-4dd7-8e3d-a2444936e9d0":{"favIconUrl":"fallback","id":"52f1a41c-1d26-4dd7-8e3d-a2444936e9d0","title":"ssd 检测 - 搜索结果 - 知乎","url":"https://www.zhihu.com/search?q=ssd%20%E6%A3%80%E6%B5%8B&type=content","urlHash":1578332293},"5318c336-fd06-4e6c-b14d-9155b37085bf":{"favIconUrl":"https://www.youtube.com/s/desktop/cc8e7b2e/img/favicon_32x32.png","id":"5318c336-fd06-4e6c-b14d-9155b37085bf","title":"(16) Neel Nanda: Mechanistic Interpretability & Mathematics - YouTube","url":"https://www.youtube.com/watch?v=bZvPLRZx-V8","urlHash":936279962},"5321fa53-3072-4b97-b289-88df536eb875":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"5321fa53-3072-4b97-b289-88df536eb875","title":"Augmenting Language Models with Long-Term Memory | PDF","url":"https://arxiv.org/pdf/2306.07174.pdf","urlHash":3691227986},"535744af-82c3-4ce6-95ab-a00bfa4d2111":{"favIconUrl":"fallback","id":"535744af-82c3-4ce6-95ab-a00bfa4d2111","title":"Meta-Learning: Learning to Learn Fast","url":"https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html","urlHash":4110486158},"53611b1b-0e1e-4595-a46f-63f2f44f7784":{"favIconUrl":"https://www.google.com/favicon.ico","id":"53611b1b-0e1e-4595-a46f-63f2f44f7784","title":"《ゴースト≠ノイズ》 - Google Search","url":"https://www.google.com/search?q=%0A%E3%80%8A%E3%82%B4%E3%83%BC%E3%82%B9%E3%83%88%E2%89%A0%E3%83%8E%E3%82%A4%E3%82%BA%E3%80%8B","urlHash":4214443622},"536804d9-ca98-4a9b-a8dc-4a69a296cb6a":{"favIconUrl":"fallback","id":"536804d9-ca98-4a9b-a8dc-4a69a296cb6a","title":"symbolic knowledge distillation - Google Search","url":"https://www.google.com/search?q=symbolic+knowledge+distillation&oq=symbolic+knowle&aqs=chrome.1.0i512l2j69i57j0i512l5j0i22i30j0i15i22i30.3129j1j1&sourceid=chrome&ie=UTF-8","urlHash":2832437193},"53786dad-ed56-4df8-bd24-51a0b3e3d268":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"53786dad-ed56-4df8-bd24-51a0b3e3d268","title":"LisaAnne/Hallucination","url":"https://github.com/LisaAnne/Hallucination","urlHash":3806303323},"53829bf7-8342-4d3b-a960-52c355b6c408":{"favIconUrl":"fallback","id":"53829bf7-8342-4d3b-a960-52c355b6c408","title":"中科院版「分割一切」模型来了，比Meta原版提速50倍","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247683472&idx=4&sn=3bc734583268c2182809c22c12a9f012&exportkey=n_ChQIAhIQiEMR85yyb%2FilPFFIturJbhKWAgIE97dBBAEAAAAAAH0zGOU85E4AAAAOpnltbLcz9gKNyK89dVj0L9g8LqPDEDBWoO1%2BXiYPJgZdVYaTi5o5yqEAkv3bskOfRG6T6cgaABPfN9edktP2jXHq1emGBybZJauwWeWHmBp4wCyteAOyPjLryY6gOggqvVVNik2sthmW7YINz2C5OArykDcr4bDShAr1kW0gY5MvxmBRW%2Fd%2FNqSAZlJuETOMyzGKwLs%2B%2FdjzTZoK25ifkAjpQfzu18MRum5emEflBG8gfI3O5nAKQDvr%2Bpav%2F0oxtO3XHPYDyVvyJLGvU987dZxR0gYkm8vgOEet%2Bzk2ao6yyoKZZjcOOF759BSoKHyFiGQfJ1P8z0NIdfg7QMXT&acctmode=0&pass_ticket=H4CRnR%2Fvfai5yQn5nrtl1iNVY7uD7EMH9DS8gNglPfCDG9xaSjdxg3Ju18iEQsQq&wx_header=0","urlHash":451930374},"5382bf11-7e29-47ec-9246-4414afdf00c0":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"5382bf11-7e29-47ec-9246-4414afdf00c0","title":"Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models | Abstract","url":"https://arxiv.org/abs/2312.06585?utm_source=substack&utm_medium=email","urlHash":4226177284},"5387a4cf-50e1-4be0-b77c-914852c31484":{"favIconUrl":"fallback","id":"5387a4cf-50e1-4be0-b77c-914852c31484","title":"Certified Defenses against Adversarial Examples - Arxiv-1801.09344","url":"https://arxiv.org/pdf/1801.09344.pdf","urlHash":552381216},"53885156-e93b-4320-9fab-6e935c8032f1":{"favIconUrl":"fallback","id":"53885156-e93b-4320-9fab-6e935c8032f1","title":"reference free summarization yejin - Google Search","url":"https://www.google.com/search?q=reference+free+summarization+yejin&newwindow=1&sxsrf=APwXEderrMicSDs_ruVWm4R5tFid1QTVRA%3A1683918396756&ei=PI5eZInkLfXY5NoPwPqpkA0&ved=0ahUKEwiJ8vnuvPD-AhV1LFkFHUB9CtIQ4dUDCBA&uact=5&oq=reference+free+summarization+yejin&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIHCCEQoAEQCjIHCCEQoAEQCjIHCCEQoAEQCjIHCCEQoAEQCjIHCCEQoAEQCjIFCCEQqwI6CAgAEKIEELADOgUIABCiBDoFCCEQoAFKBAhBGAFQzQFYwgZgiAhoAXAAeACAAXaIAdsEkgEDMy4zmAEAoAEByAEFwAEB&sclient=gws-wiz-serp","urlHash":3681527204},"5389629c-c3a3-4a9c-b4e7-8c0c91e03338":{"favIconUrl":"fallback","id":"5389629c-c3a3-4a9c-b4e7-8c0c91e03338","title":"(24 封私信 / 81 条消息) Learning To Rank的pair wise方法如何得到全局排序结果呢？ - 知乎","url":"https://www.zhihu.com/question/389068269","urlHash":4244659380},"5389f66c-8a79-4d82-943a-7687a5aa223a":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"5389f66c-8a79-4d82-943a-7687a5aa223a","title":"Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT | Abstract","url":"https://arxiv.org/abs/2304.11116","urlHash":715672501},"53fbad97-6785-46ca-ad8e-0b0c8bab408d":{"favIconUrl":"fallback","id":"53fbad97-6785-46ca-ad8e-0b0c8bab408d","title":"Machine Learning for Inverse Graphics – Scene Representation Group","url":"https://www.scenerepresentations.org/courses/inverse-graphics-23/","urlHash":3169500686},"54037c60-ca18-4cc8-8780-63020f612b86":{"favIconUrl":"fallback","id":"54037c60-ca18-4cc8-8780-63020f612b86","title":"Inner Monologue Embodied Reasoning through Planning with Language Models - OR-CoRL-2022_3R3Pz5i0tye","url":"https://openreview.net/pdf?id=3R3Pz5i0tye","urlHash":2999245877},"5418d067-31ff-4c2e-9043-3728b1ce2234":{"favIconUrl":"fallback","id":"5418d067-31ff-4c2e-9043-3728b1ce2234","title":"Primer: Searching for Efficient Transformers for Language Modeling","url":"https://arxiv.org/abs/2109.08668","urlHash":1960643081},"542f28fb-f8bb-44a1-b6b8-f11bd8c60568":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"542f28fb-f8bb-44a1-b6b8-f11bd8c60568","title":"Knowledge Prompting in Pre-trained Language Model for Natural Language Understanding | PDF","url":"https://arxiv.org/pdf/2210.08536.pdf","urlHash":2489555080},"543e8d42-7f5f-4505-97b4-78223d2d79d5":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"543e8d42-7f5f-4505-97b4-78223d2d79d5","title":"Guillermo Ortiz-Jiménez on X: \"Are you amazed by weight interpolation techniques to edit large pre-trained models? 🤔 Then you’re going to love our work 🚀: “Task Arithmetic in the Tangent Space”🏄 which explains why they work and gives a simple way to make them better! 🤓 📄: https://t.co/Npw0es3IAS 🧵1/9 https://t.co/LSi1nZMOUM\" / X","url":"https://twitter.com/gortizji/status/1664553552671391744","urlHash":1501123282},"547eaeb3-b704-4593-8c90-44e7ad31070e":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"547eaeb3-b704-4593-8c90-44e7ad31070e","title":"Robert Kirk on X: \"Excited to share work from my FAIR internship on understanding the effects of RLHF on LLM generalisation and diversity: https://t.co/R4r0hT6aVF While RLHF outperforms SFT in-distribution and OOD, this comes at the cost of a big drop in output diversity! Read more below🧵 https://t.co/lYZr0oVBir\" / X","url":"https://twitter.com/_robertkirk/status/1712083230965280784","urlHash":3090292620},"5487492a-c912-49a5-9752-f966a2656b81":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"5487492a-c912-49a5-9752-f966a2656b81","title":"Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise | Abstract","url":"https://arxiv.org/abs/2208.09392","urlHash":2004698766},"54935cc5-6917-4e50-95ad-08b834cf86b8":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"54935cc5-6917-4e50-95ad-08b834cf86b8","title":"何恺明谢赛宁解剖扩散模型，新作刚刚出炉","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247714782&idx=1&sn=ede6aa736b47aad96ad7995fb10e230f&chksm=e8df30acdfa8b9ba4816ca8fd5f1ad16ca9162a747e6aa7f16269cfb39298145a03c3206e347&mpshare=1&scene=1&srcid=0126sJIfEaMx1fU9oJVxbSus&sharer_shareinfo=0f7907ac6f68cde5c44f6ca792ad0126&sharer_shareinfo_first=0f7907ac6f68cde5c44f6ca792ad0126&exportkey=n_ChQIAhIQpATHLZeZOtX64k1vEvkGehKWAgIE97dBBAEAAAAAAHY1NAaP%2BwwAAAAOpnltbLcz9gKNyK89dVj015VxIhJxBzCt1HoCalVKbVLOhO%2BJ%2Bvk%2BCzeJALbkIz4EwzG8dQELRwdTREFuhvqRMLFdcevBfsuarAllykC8EX%2BTqJw28GOLjI3FIM1CSl0jY7wsWv8qRkSYGGg0Avkb18QhmwK1IZNalsmV4LhmLVjiYWFbXULUdrIwJp7vxit%2BXUOSDfloA1jsoM1TUxTKxRNuioG%2BlgcaIRMQBwkQuRFUWpnwM0aa8B%2Fu%2FP55nzWVlJRQG0SR%2B0YRyfyr%2BtCrEDLUB1wQl3OIkcTm4vcKgnend%2FH3SBoMruT0Q5%2F%2FL00%2BG4IV7dM%2FPbM6ows1WVfi&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HNgU2ozJaThzWT6sLn5KOpodGeZPxbccHAQievgjNxsiA%3D%3D&wx_header=0#rd","urlHash":2202406266},"5494f858-facc-4593-bafe-26a152e188e6":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"5494f858-facc-4593-bafe-26a152e188e6","title":"mit-han-lab/llm-awq: AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration","url":"https://github.com/mit-han-lab/llm-awq","urlHash":3401002799},"54b62ab3-2d8d-4a02-8aad-973178f20ebf":{"favIconUrl":"fallback","id":"54b62ab3-2d8d-4a02-8aad-973178f20ebf","title":"BERT Rediscovers the Classical NLP Pipeline - Arxiv-1905.05950","url":"https://arxiv.org/pdf/1905.05950.pdf","urlHash":1463765584},"54bb66bd-98c9-4cc3-9690-4be530475823":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"54bb66bd-98c9-4cc3-9690-4be530475823","title":"奇职怪业俱乐部 短评","url":"https://book.douban.com/subject/5348099/comments/","urlHash":4245884035},"54d486c7-a606-424b-a845-c84ab6325b4a":{"favIconUrl":"fallback","id":"54d486c7-a606-424b-a845-c84ab6325b4a","title":"Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations - Arxiv-2204.02937","url":"https://arxiv.org/pdf/2204.02937.pdf","urlHash":3882609061},"5502532f-a26b-4505-965f-7bb230913edc":{"favIconUrl":"fallback","id":"5502532f-a26b-4505-965f-7bb230913edc","title":"Retentive Network A Successor to Transformer for Large Language Models - Arxiv-2307.08621","url":"https://arxiv.org/abs/2307.08621?utm_source=substack&utm_medium=email","urlHash":4248833521},"55183cc9-dae6-4c91-a6a2-e76d480225c7":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"55183cc9-dae6-4c91-a6a2-e76d480225c7","title":"jlindsey15/ComputationInSuperposition: Analysis of the extent to which computation can be performed on features represented \"in superposition\" (cf. Anthropic's \"Toy Models of Superposition\" paper). Some code taken from https://github.com/anthropics/toy-models-of-superposition.","url":"https://github.com/jlindsey15/ComputationInSuperposition/tree/main","urlHash":1811772618},"55388d6e-8f75-4240-aac4-348f068b4bc5":{"favIconUrl":"fallback","id":"55388d6e-8f75-4240-aac4-348f068b4bc5","title":"Measuring Data - Arxiv-2212.05129","url":"https://arxiv.org/pdf/2212.05129.pdf","urlHash":2096066013},"553bac8d-14a9-44cd-8a3a-f36a11cd2074":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"553bac8d-14a9-44cd-8a3a-f36a11cd2074","title":"xinyu1205/recognize-anything: Open-source and strong foundation image recognition models.","url":"https://github.com/xinyu1205/recognize-anything","urlHash":1398719802},"557ee541-69e9-4c61-a12b-217db047615a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"557ee541-69e9-4c61-a12b-217db047615a","title":"Junxian He on X: \"💡 We release methods and datasets for extremely data-efficient alignment 🚀 6K SFT samples lead to 7.22 MT-Bench score, further DPO with 10K samples achieve 7.55 MT-Bench +90+% AlpacaEval Try our data to align models more efficiently: https://t.co/zgQQAscVPE\" / X","url":"https://twitter.com/junxian_he/status/1740319972147294226","urlHash":571493640},"558167d9-37c1-4ef4-8e37-d638c6f4163f":{"favIconUrl":"https://g.csdnimg.cn/static/logo/favicon32.ico","id":"558167d9-37c1-4ef4-8e37-d638c6f4163f","title":"强化学习极简入门：通俗理解MDP、DP MC TC和Q学习、策略梯度、PPO_强化学习极简入门:通俗理解mdp、dpmc-CSDN博客","url":"https://blog.csdn.net/v_JULY_v/article/details/128965854","urlHash":839648009},"558c35d3-8418-4491-b19c-3e28d6cae4e5":{"favIconUrl":"fallback","id":"558c35d3-8418-4491-b19c-3e28d6cae4e5","title":"HTLM Hyper-Text Pre-Training and Prompting of Language Models - Arxiv-2107.06955","url":"https://arxiv.org/abs/2107.06955","urlHash":2871553857},"55a76010-2962-4682-ba29-0c55844dd96c":{"favIconUrl":"https://www.youtube.com/s/desktop/7ea5dfab/img/favicon_32x32.png","id":"55a76010-2962-4682-ba29-0c55844dd96c","title":"A Walkthrough of Interpretability in the Wild Part 2/2: Deep Dive (w/ authors Kevin, Arthur & Alex) - YouTube","url":"https://www.youtube.com/watch?v=b9xfYBKIaX4","urlHash":2981220121},"55a8a24d-c529-4771-91de-bfb13a4f1232":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"55a8a24d-c529-4771-91de-bfb13a4f1232","title":"De-Diffusion Makes Text a Strong Cross-Modal Interface | PDF","url":"https://arxiv.org/pdf/2311.00618.pdf","urlHash":835202301},"55fe93b5-1b6d-496c-ab89-5d4804274abd":{"favIconUrl":"https://assets.squarespace.com/universal/default-favicon.ico","id":"55fe93b5-1b6d-496c-ab89-5d4804274abd","title":"An Extremely Opinionated Annotated List of My Favourite Mechanistic Interpretability Papers — Neel Nanda","url":"https://www.neelnanda.io/mechanistic-interpretability/favourite-papers","urlHash":2906691630},"562d36b0-6c2e-4b52-9b04-d6abcfb96397":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"562d36b0-6c2e-4b52-9b04-d6abcfb96397","title":"twitter.com/arankomatsuzaki/status/1668780180238921728","url":"https://twitter.com/arankomatsuzaki/status/1668780180238921728","urlHash":2454227817},"5646cdbe-e9df-4aff-83ad-b032d62cb707":{"favIconUrl":"https://tsmatz.files.wordpress.com/2017/11/cropped-sitelogo.jpg?w=32","id":"5646cdbe-e9df-4aff-83ad-b032d62cb707","title":"Implement Advanced Reasoning in Semantic Kernel – tsmatz","url":"https://tsmatz.wordpress.com/2023/06/08/semantic_kernel_reasoning_for_autonomous_agent/","urlHash":2306026193},"565586ac-8fb0-4b7c-b61d-40865fbb4ca6":{"favIconUrl":"fallback","id":"565586ac-8fb0-4b7c-b61d-40865fbb4ca6","title":"WGAN-div：一个默默无闻的WGAN填坑者 - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/6139","urlHash":3332389674},"5677aaa0-718f-47b5-90a0-b6334f44db47":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5677aaa0-718f-47b5-90a0-b6334f44db47","title":"twitter.com/arankomatsuzaki/status/1703572097954435571","url":"https://twitter.com/arankomatsuzaki/status/1703572097954435571","urlHash":187878778},"56bcc703-19e7-4f2d-9bdd-755ce14ff055":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"56bcc703-19e7-4f2d-9bdd-755ce14ff055","title":"System 2 Attention (is something you might need too) | Abstract","url":"https://arxiv.org/abs/2311.11829?utm_source=substack&utm_medium=email","urlHash":3628241798},"56bd054d-9d25-4d6d-bd33-55c1f394bd1b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"56bd054d-9d25-4d6d-bd33-55c1f394bd1b","title":"Aparna Dhinakaran on X: \"(1/7) The G in RAG Trips Up GPT-4 .... Or Does it? The retrieval stage of RAG gets an incredible amount of attention. The generation stage ... not so much 🤔 We set out to test how models handle the Generation stage of RAG .. and @AnthropicAI beat @OpenAI #GPT4 ‼️ Most Evals… https://t.co/NiYBrujzLh\" / X","url":"https://twitter.com/aparnadhinak/status/1757073620612923785","urlHash":3656737423},"56d4b3bc-8e0a-491d-b832-cd330556103b":{"favIconUrl":"https://www.google.com/favicon.ico","id":"56d4b3bc-8e0a-491d-b832-cd330556103b","title":"斩首T字之谜 - Google Search","url":"https://www.google.com/search?q=%E6%96%A9%E9%A6%96T%E5%AD%97%E4%B9%8B%E8%B0%9C","urlHash":4279525422},"5755dcf5-a0b2-4e18-9b9b-9a6ebda4de95":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"5755dcf5-a0b2-4e18-9b9b-9a6ebda4de95","title":"【民翻】白井智之 食之信条","url":"https://www.douban.com/note/790069051/?_i=8488771KLQjbnS,2451370oZQdRGV","urlHash":3681499198},"57567886-a7d5-4a80-a623-1b019571a019":{"favIconUrl":"https://ai.stanford.edu/blog/assets/img/favicon-32x32.png","id":"57567886-a7d5-4a80-a623-1b019571a019","title":"How does in-context learning work? A framework for understanding the differences from traditional supervised learning | SAIL Blog","url":"https://ai.stanford.edu/blog/understanding-incontext/","urlHash":334307844},"576071db-1923-4963-a148-7fe7d4847c54":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"576071db-1923-4963-a148-7fe7d4847c54","title":"(2) Sumit on X: \"Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity Dynamically selects the most suitable retrieval-augmented strategy based on the predicted complexity level of input query 📝https://t.co/NsxAkBEo3d 👨🏽‍💻https://t.co/y6cj5Jm6YY https://t.co/20LqssQtMq\" / X","url":"https://twitter.com/_reachsumit/status/1771014435269922979","urlHash":3585605991},"576ee8e3-3df7-419c-a221-256c3249bc50":{"favIconUrl":"fallback","id":"576ee8e3-3df7-419c-a221-256c3249bc50","title":"From GAN to WGAN","url":"https://lilianweng.github.io/posts/2017-08-20-gan/","urlHash":3742730847},"5785b6b3-7e46-4e72-a821-1737606f52e0":{"favIconUrl":"fallback","id":"5785b6b3-7e46-4e72-a821-1737606f52e0","title":"You Can Have Better Graph Neural Networks by Not Training Weights at All Finding Untrained GNNs Tickets - OR-logconference-2022_dF6aEW3_62O","url":"https://openreview.net/pdf?id=dF6aEW3_62O","urlHash":3372174628},"5790eb59-4da7-46ec-b80c-7138b717f447":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5790eb59-4da7-46ec-b80c-7138b717f447","title":"twitter.com/gaotianyu1350/status/1661186546907639808","url":"https://twitter.com/gaotianyu1350/status/1661186546907639808","urlHash":2678232941},"57e0c6b6-c0d4-4123-85c0-64dfa94d55c5":{"favIconUrl":"fallback","id":"57e0c6b6-c0d4-4123-85c0-64dfa94d55c5","title":"Stronger Data Poisoning Attacks Break Data Sanitization Defenses - Arxiv-1811.00741","url":"https://arxiv.org/pdf/1811.00741.pdf","urlHash":3931551229},"57e5a87a-46e1-4d24-b05a-3ac42d0dcdd6":{"favIconUrl":"fallback","id":"57e5a87a-46e1-4d24-b05a-3ac42d0dcdd6","title":"Reward Design with Language Models - Arxiv-2303.00001","url":"https://arxiv.org/abs/2303.00001","urlHash":2388982519},"57fd2939-98db-4141-8b47-34dac0fe237b":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"57fd2939-98db-4141-8b47-34dac0fe237b","title":"微调语言模型学到的知识是权重空间里的一块区域（建议阅读）","url":"https://mp.weixin.qq.com/s?__biz=MzkwMjUwNTg3OA==&mid=2247485188&idx=1&sn=e1344f0f4815a7773a633e18d4c8b9e7&chksm=c0a533fdf7d2baeb268d3e2508360d0d156c384e0b927c5afb019584589f9de64464d65561ca&mpshare=1&scene=1&srcid=0115sPimJ0KGmwTwi4H6Cu38&sharer_shareinfo=b5190915daaec5cf7be147d81abbdac5&sharer_shareinfo_first=b5190915daaec5cf7be147d81abbdac5&exportkey=n_ChQIAhIQtQuh8A%2Faw04y9N0fgKSHkRKWAgIE97dBBAEAAAAAAKP9MU288aoAAAAOpnltbLcz9gKNyK89dVj0KB0VVEXvYCchkeMmTzzGvGgO85mqY%2FQjpMX3z1mi%2FpuOGLpaMrLlpJx2jgFwQQ%2BHgsj3cmZfFleOUvDih5%2FswHoxno8fAGsmMuR47ma719EUY655ID8O78V02OD4PeeqMIDvfT9l%2FgVFn4mhbu%2BixzbkzwDL6wli5EANcAJMjv4SG1umrS3OAP4ogUhuEgl4mXAERMv0o%2FXPgNVR%2BJTxFiiOaM1nkDWty9hyZVpBBJ49976KE19H%2FFZR8UzC1GgHXtS%2BzXy2gOd3sHy6%2FXTRv%2BXCtB3sa9LrD4sQ7s7kw%2BoLC%2FjNpmcm4lTnaZlE0WS%2F&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsZhY8d91HJB8LjwPx4TNAQvIp6jy1AzoCAt29JRiDWMlA%3D%3D&wx_header=0#rd","urlHash":2869628783},"5825c935-8d14-44f4-81c6-066517c1e157":{"favIconUrl":"fallback","id":"5825c935-8d14-44f4-81c6-066517c1e157","title":"Large Language Model Alignment A Survey - Arxiv-2309.15025","url":"https://arxiv.org/abs/2309.15025?utm_source=substack&utm_medium=email","urlHash":3181003238},"58453007-1111-467b-b655-bacf9b2d2af3":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"58453007-1111-467b-b655-bacf9b2d2af3","title":"（民翻）《ギガくらりの殺人（巨型库拉莉杀人事件）》——相泽沙呼","url":"https://www.douban.com/note/833389446/?_i=2453448oZQdRGV","urlHash":2670257763},"584abf5e-46fb-4313-a128-1929a026bf41":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"584abf5e-46fb-4313-a128-1929a026bf41","title":"twitter.com/srchvrs/status/1659398804175568902","url":"https://twitter.com/srchvrs/status/1659398804175568902","urlHash":3418910001},"587b9ddf-3c3b-49fb-b955-31bca2670a44":{"favIconUrl":"fallback","id":"587b9ddf-3c3b-49fb-b955-31bca2670a44","title":"Transformer Memory as a Differentiable Search Index - Arxiv-2202.06991","url":"https://arxiv.org/abs/2202.06991","urlHash":3118589324},"589f33eb-6557-4ce0-9d2d-cda9573e5365":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"589f33eb-6557-4ce0-9d2d-cda9573e5365","title":"The Efficiency Spectrum of Large Language Models: An Algorithmic Survey | Abstract","url":"https://arxiv.org/abs/2312.00678?utm_source=substack&utm_medium=email","urlHash":2683670482},"58d6f3dd-f8c4-4dad-a9b3-ddbae049e48d":{"favIconUrl":"fallback","id":"58d6f3dd-f8c4-4dad-a9b3-ddbae049e48d","title":"InstructRetro Instruction Tuning post Retrieval-Augmented Pretraining - Arxiv-2310.07713","url":"https://arxiv.org/pdf/2310.07713.pdf","urlHash":933219248},"58f3f478-55d2-435f-a29e-ff425b2f9db7":{"favIconUrl":"fallback","id":"58f3f478-55d2-435f-a29e-ff425b2f9db7","title":"https://arxiv.org/pdf/2104.09667.pdf","url":"https://arxiv.org/pdf/2104.09667.pdf","urlHash":3403176931},"59191874-5601-413f-af10-79574e5de8e6":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"59191874-5601-413f-af10-79574e5de8e6","title":"Graph of Thoughts: Solving Elaborate Problems with Large Language Models | Abstract","url":"https://arxiv.org/abs/2308.09687","urlHash":3291042515},"5931bbec-f86e-4d94-a710-fa5ad505df1d":{"favIconUrl":"https://static.olelive.com/upload/site/20201117-1/08aee3974ca3d001ceab066233599789.png","id":"5931bbec-f86e-4d94-a710-fa5ad505df1d","title":"长安三万里_高清播放 - 欧乐影院－面向海外华人的在线视频媒体平台,海量高清视频在线观看","url":"https://www.olehdtv.com/index.php/vod/play/id/48957/sid/1/nid/1.html","urlHash":1292066092},"594eda2a-6128-4ea4-a057-615940cc2a18":{"favIconUrl":"fallback","id":"594eda2a-6128-4ea4-a057-615940cc2a18","title":"Meaning of stop-gradient · Issue #56 · facebookresearch/higher","url":"https://github.com/facebookresearch/higher/issues/56","urlHash":2423845396},"595af1ff-59a0-4f17-b621-ac5f42949490":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"595af1ff-59a0-4f17-b621-ac5f42949490","title":"贾佳亚韩松团队新作：两行代码让大模型上下文窗口倍增 | GitHub热榜","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247697654&idx=2&sn=7fd35249a89441f661d7f92ca1364220&chksm=e8df7384dfa8fa92b429aa0f2745e74d23150695af3317c96db7ac4c4d4a550545a6e2993da6&mpshare=1&scene=1&srcid=1001088MLSSvykBojZ1evjth&sharer_shareinfo=2942df4553ac53d1e72c5e0dbe81b50e&sharer_shareinfo_first=2942df4553ac53d1e72c5e0dbe81b50e&exportkey=n_ChQIAhIQ9kgWDug9v%2B9qj3Df7yHO4RKWAgIE97dBBAEAAAAAAL%2B9GvRJjRIAAAAOpnltbLcz9gKNyK89dVj0tVarv39Oo%2FUGeGkBHhXZ1%2BbJsvuq%2Fll2idzzUoJFdB0yVvVTBIM8yGI1ToCdLBtY25M94aTR7T1IK%2BXPnATUqufdXgqvVbwrS3czuCE%2FTskbP4XwCdMVoFr%2FAufU7PwRmTP%2BkfZDiYi3cwzEwr5fbc2EGxvUUt1JG%2BmDoJik4xe7xobWZallrbK2002QYqHYnKpd3QhNex6BxhmmuCvPKjIgzpq2TwfvmNliD%2B00N2jEDvRqfWXe1UgDH7Hs%2BTEpy3CcyGmCqHnrsLA%2B3XpXng%2BHSm3uELTjN1R2KeKM8DBnxhY4ZA2Zf0Vqya6n%2FZ7N&acctmode=0&pass_ticket=IA9g%2FqI7tZ0PzQQTnYIlvk6FMNN12avtU9Nmk6d%2F%2BvcikE6%2B424KHs9v%2B98wotw2&wx_header=0#rd","urlHash":475644563},"596cc7d2-62cd-428a-8e3d-0d632652eea7":{"favIconUrl":"fallback","id":"596cc7d2-62cd-428a-8e3d-0d632652eea7","title":"Structural Guidance for Transformer Language Models - Arxiv-2108.00104","url":"https://arxiv.org/pdf/2108.00104.pdf","urlHash":3649041333},"599603cf-09bd-4a84-9950-fc0b54205af0":{"favIconUrl":"fallback","id":"599603cf-09bd-4a84-9950-fc0b54205af0","title":"Luodian/RelateAnything: Relate Anything Model is capable of taking an image as input and utilizing SAM to identify the corresponding mask within the image.","url":"https://github.com/Luodian/RelateAnything","urlHash":1737528413},"59b67f0b-d572-4639-9935-d8b1058b9b32":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"59b67f0b-d572-4639-9935-d8b1058b9b32","title":"从JL引理看熵不变性Attention - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/9588","urlHash":3924707215},"59d28fb8-5c2c-4fe9-9634-65437bfcf412":{"favIconUrl":"fallback","id":"59d28fb8-5c2c-4fe9-9634-65437bfcf412","title":"flow/nice.py at master · bojone/flow","url":"https://github.com/bojone/flow/blob/master/nice.py","urlHash":3335560186},"59e8c3f8-f965-4525-b900-506d22b4a712":{"favIconUrl":"fallback","id":"59e8c3f8-f965-4525-b900-506d22b4a712","title":"Prompt-based Language Models：模版增强语言模型小结 - 知乎","url":"https://zhuanlan.zhihu.com/p/366771566","urlHash":534097265},"59fb7e24-043b-443d-b78b-4fe293b98cba":{"favIconUrl":"fallback","id":"59fb7e24-043b-443d-b78b-4fe293b98cba","title":"MIT Reading Group (Fall 2022): The Science of Deep Learning","url":"https://www.neuralnet.science/reading-group/","urlHash":2454256832},"5a1a7ef6-04f4-493c-b6a7-491f068af8ab":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5a1a7ef6-04f4-493c-b6a7-491f068af8ab","title":"AK on X: \"Microsoft presents SliceGPT Compress Large Language Models by Deleting Rows and Columns paper page: https://t.co/9Eungdu9Ca show that SliceGPT can remove up to 25% of the model parameters (including embeddings) for LLAMA2-70B, OPT 66B and Phi-2 models while maintaining 99%,… https://t.co/jenQcSYOwC\" / X","url":"https://twitter.com/_akhaliq/status/1751796334531592496?utm_source=substack&utm_medium=email","urlHash":3170767923},"5a2bcef5-a6e2-4e2c-8746-d9bda227698a":{"favIconUrl":"fallback","id":"5a2bcef5-a6e2-4e2c-8746-d9bda227698a","title":"Retrieval as Attention End-to-end Learning of Retrieval and Reading within a Single Transformer - Arxiv-2212.02027","url":"https://arxiv.org/pdf/2212.02027.pdf","urlHash":2604164848},"5a338bb7-fbee-4279-8a89-8dcf5573f3f0":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"5a338bb7-fbee-4279-8a89-8dcf5573f3f0","title":"(2) Tianle Cai on X: \"How much value does your fine-tuning add? Believe it or not, just 1 bit 🤏 Thrilled to unveil BitDelta, a super simple yet effective method for compressing fine-tuning deltas into a single bit while barely touching performance. This approach slashes storage and GPU memory demands… https://t.co/FC63vUuHUo\" / X","url":"https://twitter.com/tianle_cai/status/1758329111620292919","urlHash":2550055745},"5a33af87-8a82-4c27-b30f-c1f7f41b9861":{"favIconUrl":"fallback","id":"5a33af87-8a82-4c27-b30f-c1f7f41b9861","title":"Learning Disentangled Representations of Negation and Uncertainty - Arxiv-2204.00511","url":"https://arxiv.org/abs/2204.00511","urlHash":11967459},"5a3c66d7-2c92-4531-a8bf-3363181c46ce":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"5a3c66d7-2c92-4531-a8bf-3363181c46ce","title":"ChatGPT说谎竟然是故意的？哈佛大学提出ITI：模型真实性翻倍，计算开销基本为零","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652343568&idx=3&sn=5f525fc561501e769711c9b29a717d1a&chksm=f124f9e1c65370f7492b89094d5beb75a0ec45d73d098b806292f4404c440162ec9c8a84edfe&mpshare=1&scene=1&srcid=0701lefk6wANMyFPZX2yjJvF&sharer_sharetime=1688170859431&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQZNSMGG0cQowTCJnhw7TKshKWAgIE97dBBAEAAAAAAOmHAaXffJsAAAAOpnltbLcz9gKNyK89dVj050pB2sXe19SB9TlVKVfVB4SxEHBOfoJfF0U275g3s9WhHIOiQec6GVQvOBlNVKlRktI8HIofY6EsW8swiEebfHYCGvGzwd1VAWiSMdEXq32ItI5layU7SwOm%2Bm0emlKyFdSM5HrHXkVEpdGuzMleO4HCD481DWFdYQCwmVy%2Bi0mY5Q%2F8Vd7SroidRmPZ7Olug2LtDBIbrr9uriX6q0%2F%2BCFEZmpYvT0DozjPSFleqXoutb%2Fp%2BJetytru4da65DJefOBCGRENsHUI%2B6vf5VRbCPandPwOpkT5ybB4hnkJNjnAERC%2FJhVEoETI2ZbVhvQxS&acctmode=0&pass_ticket=StCG2Tng6bTu%2FWs61TPD637OHXRdbZycw4t%2FREs8hob3TmmSPWrToURbDw187EBF&wx_header=0#rd","urlHash":62755699},"5a44d850-0ced-4f52-a7c6-93d50a0b6fa5":{"favIconUrl":"fallback","id":"5a44d850-0ced-4f52-a7c6-93d50a0b6fa5","title":"allegro/allRank: allRank is a framework for training learning-to-rank neural models based on PyTorch.","url":"https://github.com/allegro/allRank","urlHash":3008586067},"5a6afcfa-49d6-4dee-997a-74d3ca9ac80e":{"favIconUrl":"fallback","id":"5a6afcfa-49d6-4dee-997a-74d3ca9ac80e","title":"Sha-Lab/kfo: Code release for \"When MAML Can Adapt Fast and How to Assist When It Cannot\", AISTATS 2021.","url":"https://github.com/Sha-Lab/kfo","urlHash":539352355},"5a901e87-7a53-46fb-823f-9881a0cca937":{"favIconUrl":"fallback","id":"5a901e87-7a53-46fb-823f-9881a0cca937","title":"William James - Wikiwand","url":"https://www.wikiwand.com/en/William_James","urlHash":3255984667},"5aa68719-8547-4910-8ea1-c79fa0b3c5a2":{"favIconUrl":"https://underline.io/favicon/favicon.ico","id":"5aa68719-8547-4910-8ea1-c79fa0b3c5a2","title":"Underline | SCOTT: Self-Consistent Chain-of-Thought Distillation","url":"https://underline.io/events/395/sessions/15222/lecture/76266-scott-self-consistent-chain-of-thought-distillation","urlHash":2934544421},"5ab6fb63-3ad3-480f-9fd0-6a564c59fd3a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5ab6fb63-3ad3-480f-9fd0-6a564c59fd3a","title":"twitter.com/sangmichaelxie/status/1623397365443960832","url":"https://twitter.com/sangmichaelxie/status/1623397365443960832","urlHash":3739686256},"5ab97902-45cd-4402-a9bb-e94fd69339fe":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"5ab97902-45cd-4402-a9bb-e94fd69339fe","title":"Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting | PDF","url":"https://arxiv.org/pdf/2310.11324.pdf","urlHash":3128933993},"5ac30751-1514-458a-a027-906dd91485aa":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"5ac30751-1514-458a-a027-906dd91485aa","title":"Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models | Abstract","url":"https://arxiv.org/abs/2310.04406?ref=blog.langchain.dev","urlHash":177757069},"5b35623d-e002-4597-92e0-ca78b4894c65":{"favIconUrl":"fallback","id":"5b35623d-e002-4597-92e0-ca78b4894c65","title":"r - What is the difference between McNemar's test and the chi-squared test, and how do you know when to use each? - Cross Validated","url":"https://stats.stackexchange.com/questions/76875/what-is-the-difference-between-mcnemars-test-and-the-chi-squared-test-and-how","urlHash":2651843942},"5b3ba212-13f8-4680-bdc1-de75a1c35303":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5b3ba212-13f8-4680-bdc1-de75a1c35303","title":"Xinyun Chen on X: \"Our new work (https://t.co/j2CJG3k1rM) shows that currently LLM self-correction w/o external feedback (e.g., oracle verification, code execution) often degrades the performance on reasoning tasks. The main issue is the LLM itself does not properly judge its reasoning correctness.\" / X","url":"https://twitter.com/xinyun_chen_/status/1709975281199632390","urlHash":1149472566},"5b43d514-2f89-4df2-8118-25aaf642d5e4":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5b43d514-2f89-4df2-8118-25aaf642d5e4","title":"Noam Brown on X: \"Nice new paper from @huggingface investigating LLM scaling laws once data is the bottleneck (which will eventually be the case for large models). They show little degradation for training with up to 4 epochs https://t.co/yEt5sTrvjd\" / X","url":"https://twitter.com/polynoamial/status/1662152330760814625","urlHash":2667649759},"5b6d529e-3ed2-433d-a16b-51b435b4da0e":{"favIconUrl":"fallback","id":"5b6d529e-3ed2-433d-a16b-51b435b4da0e","title":"Visualizing Neural Networks with the Grand Tour","url":"https://distill.pub/2020/grand-tour/","urlHash":3321642187},"5b956494-5b6b-4678-883a-8000960a0d0d":{"favIconUrl":"https://ssl.gstatic.com/atari/images/public/favicon.ico","id":"5b956494-5b6b-4678-883a-8000960a0d0d","title":"home","url":"https://sites.google.com/view/pku-beavertails","urlHash":1193092053},"5bd81609-8e9f-4991-9463-50297bdfe5ea":{"favIconUrl":"fallback","id":"5bd81609-8e9f-4991-9463-50297bdfe5ea","title":"Learning-From-Data-A-Short-Course/Solutions to Chapter 2 Training versus Testing.ipynb at master · niuers/Learning-From-Data-A-Short-Course","url":"https://github.com/niuers/Learning-From-Data-A-Short-Course/blob/master/Solutions%20to%20Chapter%202%20Training%20versus%20Testing.ipynb","urlHash":599941883},"5be0542d-df21-46ab-911a-d9899661c002":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"5be0542d-df21-46ab-911a-d9899661c002","title":"担心prompt泄露隐私？这个框架让LLaMA-7B完成安全推理","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650885739&idx=3&sn=67330e11131298cd2300f79f36729969&exportkey=n_ChQIAhIQsvo%2F9KxiGibNGuQSA72unxKWAgIE97dBBAEAAAAAAGQrNf8tckcAAAAOpnltbLcz9gKNyK89dVj0fsqOgQA1cHbtXt180xT0xUGZJHj%2BLeVuMbAdUOUTTMUgtWPQGeVmIlNEQxfuzJzUgZGNdEeNsPHiDo%2FewaeMi23zoKCTcKiUbBj6YBt6bjxdWuTq20LNWxYco4ekjeEXfQhqc%2BNve%2BZ6JaZ5GL21mVERvGeoh46lzRpDlG78024vzXAZdGF1yOlF5gY463U8ZnsgeMTEemswUEsfNIZXkLzbt5D2yF9kB1auV1dNNKwKOWd8d0NvVSpbFk7T%2BRBQasRkHFXTpuJL5FFSSC36PaC1gMhU2XRUmql5um0E%2FAZAc7zAjmrMTW1IUAT4hyzt&acctmode=0&pass_ticket=Ky7yzVRNJwiVPUi%2BiHMYsWuJRafZo2Ms6C%2BCRjT7vsl3wgoZL32%2BB9HgtCoq%2B0TI&wx_header=0","urlHash":3448568809},"5c48f1c8-01cd-47a2-add8-b6e0f8a74ec3":{"favIconUrl":"fallback","id":"5c48f1c8-01cd-47a2-add8-b6e0f8a74ec3","title":"Taming Transformers for High-Resolution Image Synthesis","url":"https://compvis.github.io/taming-transformers/","urlHash":1937335474},"5c563fb9-3aba-4dd2-8c18-dea2ccc6bb14":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"5c563fb9-3aba-4dd2-8c18-dea2ccc6bb14","title":"Transformer后继有模！MSRA提出全新大模型基础架构：推理速度8倍提升，内存占用减少70%","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247686895&idx=2&sn=9a2763953d209a29e5d0b03e8b75a912&exportkey=n_ChQIAhIQTF3QsBpnE%2BLxCpoSAjAjMhKWAgIE97dBBAEAAAAAAJPmAGFW1y8AAAAOpnltbLcz9gKNyK89dVj052Di%2FYsOFork%2BLi0N%2BruWQAW0rLMBoDe%2FNUJULLChlTjzvfm1mEE9wCvLEZdCZAiKjlv7Hqbsbfa1%2B0apbTXp623NiGMku7%2FpqBbs32qqVZBNKgodqe0Yf7OPmuzeZhZNQ2wbncAOCaCCXUKKhZZZDbu4fpcFByWLROMdGaFM87YXUEIVZxnKUqGCSTRxGUTxpt5U5oepQC6vhF96Nq5tcvkOuRmIXj0%2BOwZTUux08IbQMG3UvfLgmXJyegklUu1TJPvHhitWbJVVARlLHMCA8rDGFJlxrfTwGpAqfpTb33UDIjWeFwT%2BdKP3XtmkUn7&acctmode=0&pass_ticket=SUqwcOCNIdDASnaAl57mL3fTEoUSquM%2BKAwkLHKf5%2FLbQz83fMpC45if8zfS5BB9&wx_header=0","urlHash":3882755725},"5c5d6a3d-daa9-46fa-a7ce-51173fae2a0e":{"favIconUrl":"https://kexue.fm/usr/themes/geekg/favicon.ico","id":"5c5d6a3d-daa9-46fa-a7ce-51173fae2a0e","title":"Transformer升级之路：3、从Performer到线性Attention - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/8338","urlHash":498073134},"5c8d7b47-837e-40a9-b8a0-380068ae9b97":{"favIconUrl":"fallback","id":"5c8d7b47-837e-40a9-b8a0-380068ae9b97","title":"The Lottery Ticket Hypothesis for Pre-trained BERT Networks","url":"https://arxiv.org/abs/2007.12223","urlHash":2927743176},"5ca6a1db-b63d-4b40-af23-7549dfc748fb":{"favIconUrl":"fallback","id":"5ca6a1db-b63d-4b40-af23-7549dfc748fb","title":"Equivariant Contrastive Learning - Arxiv-2111.00899","url":"https://arxiv.org/pdf/2111.00899.pdf","urlHash":955501139},"5cbc547b-acea-4959-8776-2eb61e8ac86c":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"5cbc547b-acea-4959-8776-2eb61e8ac86c","title":"logsumexp运算的几个不等式 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/9070","urlHash":1930181255},"5cc1a4f4-daed-4d7f-9304-d56c79e34550":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5cc1a4f4-daed-4d7f-9304-d56c79e34550","title":"John Nay on X: \"Smaller LLMs Can Imitate Reasoning of Larger LLMs -13-billion param model learns from rich GPT-4 signals (explanations, step-by-step, complex instructions) guided by teaching of ChatGPT -Beats SoTA instruction-tuned LLM (Vicuna-13B) by 100% in reasoning https://t.co/hbQSbNXzp9 https://t.co/j8rWUdFdmE\" / X","url":"https://twitter.com/johnjnay/status/1665906453587034112","urlHash":621301332},"5cc85d80-ef13-4fe4-9e88-c041e84f1990":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5cc85d80-ef13-4fe4-9e88-c041e84f1990","title":"Aran Komatsuzaki on X: \"SlimPajama-DC: Understanding Data Combinations for LLM Training Aims to understand the impacts of various data combinations on the training of LLMs using SlimPajama https://t.co/S2BVtmlef6 https://t.co/widkSxx95Z\" / X","url":"https://twitter.com/arankomatsuzaki/status/1704293580863353338","urlHash":1213969046},"5cdc9ec6-095d-4b3b-9eee-efafcd3e6bbd":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"5cdc9ec6-095d-4b3b-9eee-efafcd3e6bbd","title":"Evaluate What You Can't Evaluate: Unassessable Quality for Generated Response | PDF","url":"https://arxiv.org/pdf/2305.14658.pdf","urlHash":3144724762},"5d035f0f-fc95-4dfd-a442-25d19b257345":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"5d035f0f-fc95-4dfd-a442-25d19b257345","title":"多模态大模型学杂了能力反下降？新研究：MoE+通用专家解决冲突","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247711325&idx=3&sn=bf7c466d9c56036fc486887eaec3de4a&chksm=e8df0d2fdfa88439be61c302347e0de5b70f2d7bc01e59d154a23cf97ebf78fc5dae2b4b294c&mpshare=1&scene=1&srcid=0120SdEJUQyDEdSPYeVbyXiN&sharer_shareinfo=72f24b7d451bc3df96ba0930b4b7e45d&sharer_shareinfo_first=72f24b7d451bc3df96ba0930b4b7e45d&exportkey=n_ChQIAhIQ4Zh6KErGBKSP4RW%2F6YmlABKWAgIE97dBBAEAAAAAAPKKOSUPAOkAAAAOpnltbLcz9gKNyK89dVj0AtBDD23PwMCRZ28JERjKFSsnb1TKppY9yu57%2BSBHiobwk4h39nlqWuZvRlubqAyLktqowHSitVCaWRQqOwD4SlCEDIKvmH457fYuxiLLMXpenfgpFyXtZUEdQXkj0G%2B1kB933NhBSduFvwP4mcmvBPaPeRE7d%2FY0IkHcX%2BohZM%2BeMIQlXn%2Br%2BQ1ZvO%2FqZwGOVhZ6%2FRKUljI7v3RRs%2BJtXIxG7wFgWHiSTCAhnIt2VW8sc4BxnzT%2FsEPowbG6zmKxwiqUROFKwOPd3Y4b%2FBZw1XdWcblnWHFEC2RFQCdUMdJ2aLbzeFEuBlVRkfRoLzzo&acctmode=0&pass_ticket=Lh6fMKyRptprTXRrV6vPSrjdLsXHlUx5QEYzUr9kC2X7FY91Vud5EdloXENJi0LXpQWtT34l%2FYxrKbo6qBO6Bg%3D%3D&wx_header=0#rd","urlHash":2506267489},"5d0c459e-e347-4f1f-9693-fc13af9acc8f":{"favIconUrl":"https://cdn.semanticscholar.org/b5fbde4a4847434e/img/darkmode/favicon-32x32.png","id":"5d0c459e-e347-4f1f-9693-fc13af9acc8f","title":"[PDF] Towards Automated Circuit Discovery for Mechanistic Interpretability | Semantic Scholar","url":"https://www.semanticscholar.org/paper/Towards-Automated-Circuit-Discovery-for-Mechanistic-Conmy-Mavor-Parker/b8d75686dd806cf6ef40122278c6dcacb7edb463","urlHash":2738515914},"5d2433e8-5ec9-4b16-b4c2-321762631eb4":{"favIconUrl":"fallback","id":"5d2433e8-5ec9-4b16-b4c2-321762631eb4","title":"叔本华在《作为意志和表象的世界》一书中经常谈到的充足理由律是什么? - 知乎","url":"https://www.zhihu.com/question/269926545","urlHash":4129003383},"5d603eec-8a9b-4f49-b41a-1462224d48ed":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"5d603eec-8a9b-4f49-b41a-1462224d48ed","title":"Can Language Models Encode Perceptual Structure Without Grounding? A Case Study in Color | Abstract","url":"https://arxiv.org/abs/2109.06129","urlHash":3292475575},"5d6e485c-936c-4ba4-b06b-fb08566f07d6":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5d6e485c-936c-4ba4-b06b-fb08566f07d6","title":"elvis on X: \"Fact-checking with LLMs Great paper studying the fact-checking capabilities of LLMs like GPT-4. This is an important research topic especially if you are enriching LLMs with new information, such as is the case with RAG. \"Results show the enhanced prowess of LLMs when equipped… https://t.co/OaiTokesXs\" / X","url":"https://twitter.com/omarsar0/status/1717550929145119212?s=20&utm_source=substack&utm_medium=email","urlHash":392271409},"5d7bca29-53ac-4644-bd3b-64aeb76c5c53":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"5d7bca29-53ac-4644-bd3b-64aeb76c5c53","title":"Reinforced Self-Training (ReST) for Language Modeling | Abstract","url":"https://arxiv.org/abs/2308.08998","urlHash":76861193},"5d7e0cbe-437e-439b-a121-cef07af2db6c":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"5d7e0cbe-437e-439b-a121-cef07af2db6c","title":"MedicalGPT/README_EN.md at main · shibing624/MedicalGPT","url":"https://github.com/shibing624/MedicalGPT/blob/main/README_EN.md","urlHash":1322482791},"5df8686d-6530-4693-8a39-d0ea258139fc":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"5df8686d-6530-4693-8a39-d0ea258139fc","title":"むかしむかしあるところに、死体があってもめでたしめでたし。 (豆瓣)","url":"https://book.douban.com/subject/36442333/","urlHash":2033115707},"5dff1f71-a5ea-49dc-b6ec-bb355a425a87":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5dff1f71-a5ea-49dc-b6ec-bb355a425a87","title":"twitter.com/wellecks/status/1693402747616559207","url":"https://twitter.com/wellecks/status/1693402747616559207","urlHash":3177677158},"5e4bbef8-d7cf-4cf6-aa97-0f5d43895582":{"favIconUrl":"fallback","id":"5e4bbef8-d7cf-4cf6-aa97-0f5d43895582","title":"DakshIdnani/pytorch-nice: Implementation of non-linear independent components estimation (NICE) in pytorch","url":"https://github.com/DakshIdnani/pytorch-nice","urlHash":570980450},"5e4c1a47-b242-41d7-a5cd-80512bf0d81f":{"favIconUrl":"https://www.google.com/favicon.ico","id":"5e4c1a47-b242-41d7-a5cd-80512bf0d81f","title":"On Multi-Domain Long-Tailed Recognition, Imbalanced Domain Generalization and Beyond - Google Search","url":"https://www.google.com/search?q=On+Multi-Domain+Long-Tailed+Recognition%2C+Imbalanced+Domain+Generalization+and+Beyond&sourceid=chrome&ie=UTF-8","urlHash":3907144262},"5e7ab637-fafc-4e39-8ca0-4b9dec366458":{"favIconUrl":"fallback","id":"5e7ab637-fafc-4e39-8ca0-4b9dec366458","title":"LM-Infinite：无需参数更新即可实现大语言模型长度泛化","url":"https://mp.weixin.qq.com/s?__biz=MzkwMjUwNTg3OA==&mid=2247484712&idx=1&sn=b815d9ad59e6ec9d541ecd5df9873064&exportkey=n_ChQIAhIQq%2FLIC%2F5RSpa58N4bxuqPChKWAgIE97dBBAEAAAAAAFt%2FM3EG1hYAAAAOpnltbLcz9gKNyK89dVj0uygywH%2BMQJSIAPrn9uXogdOxWWHusvo0payHR480YAGCurq2043RrBY962bYytd0%2FUryhgM3uxXoYQhCYCBqOX1X1uMMRWk4%2FzT5KwVLQVtRQbcz%2FCKi2UtVlXgEBpqYT%2BvOJqMYMiA%2BWvlcxCIotbtDExL2AcsywP3AXWNuKF3mvZ7r85bqjrT58fJh9eEGlCbWUbMGBxXaKWc8qVLEJmi0encFHSOUW0FlZjaACFE2wqW4O2oibpmSHiN3gfXCgFFJhQidexpJafe0j%2FrcHu%2FGyXhAvMq13zgn3OonMIFsCZ2MA6cBmRn6ovXNTMHm&acctmode=0&pass_ticket=pN8jHievGzaB%2F0W93pNudIihxxNMgFatoXR0MkinJxTA1k0ROlmAJWqJK7X%2FqTMf&wx_header=0","urlHash":3820838416},"5e7def65-6c1d-429a-a9bb-1118c92dc5fc":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"5e7def65-6c1d-429a-a9bb-1118c92dc5fc","title":"注意力和Softmax的两点有趣发现：鲁棒性和信息量 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/9593","urlHash":3740380516},"5ea8f130-84bb-4e52-9d4f-8a9ca1296d5c":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5ea8f130-84bb-4e52-9d4f-8a9ca1296d5c","title":"AK on X: \"Instruction-tuned Language Models are Better Knowledge Learners In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data. The standard… https://t.co/GnTPsIuXIb\" / X","url":"https://twitter.com/_akhaliq/status/1760165533448568856","urlHash":2550245008},"5eb25819-230f-4dad-ab19-a2e49a72a336":{"favIconUrl":"fallback","id":"5eb25819-230f-4dad-ab19-a2e49a72a336","title":"The Internal State of an LLM Knows When its Lying - Arxiv-2304.13734","url":"https://arxiv.org/pdf/2304.13734.pdf","urlHash":389129759},"5ec7e00a-9a45-4771-a7f7-cdb5c9ab61d8":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/badged-favicon-32x32.png","id":"5ec7e00a-9a45-4771-a7f7-cdb5c9ab61d8","title":"(5) New quantization method AWQ outperforms GPTQ in 4-bit and 3-bit with 1.45x speedup and works with multimodal LLMs : LocalLLaMA","url":"https://www.reddit.com/r/LocalLLaMA/comments/13yehfn/new_quantization_method_awq_outperforms_gptq_in/?sort=new","urlHash":3474022547},"5ed7c339-82c3-472f-afaf-7e91877082c4":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"5ed7c339-82c3-472f-afaf-7e91877082c4","title":"Beyond Prompting: Making Pre-trained Language Models Better Zero-shot Learners by Clustering Representations | Abstract","url":"https://arxiv.org/abs/2210.16637","urlHash":107572894},"5edb0760-63b1-492d-bb27-10cfbed5d6d2":{"favIconUrl":"fallback","id":"5edb0760-63b1-492d-bb27-10cfbed5d6d2","title":"gradient descent - Variance of reparameterization trick and score function - Cross Validated","url":"https://stats.stackexchange.com/questions/390437/variance-of-reparameterization-trick-and-score-function","urlHash":601720795},"5ef7921c-d314-4b82-89ca-881630956c92":{"favIconUrl":"fallback","id":"5ef7921c-d314-4b82-89ca-881630956c92","title":"标签 flow 下的文章 - 科学空间|Scientific Spaces","url":"https://kexue.fm/tag/flow/","urlHash":3120885217},"5f0ca100-842c-491f-b844-0eb1cb7023a7":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"5f0ca100-842c-491f-b844-0eb1cb7023a7","title":"The Generative AI Paradox: \"What It Can Create, It May Not Understand\" | Abstract","url":"https://arxiv.org/abs/2311.00059","urlHash":1232397942},"5f2a5a31-f1bb-4d8f-a40a-9ef68cba2d8c":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"5f2a5a31-f1bb-4d8f-a40a-9ef68cba2d8c","title":"GPT-5只会更笨！斯坦福莱斯研究警告，AI训AI超过5次，模型反噬，性能大减","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652355390&idx=4&sn=9b71b381fefb2562cf4675c99fdfd9db&exportkey=n_ChQIAhIQsbmsJkdP0dC2vYgf%2BFD5pBKWAgIE97dBBAEAAAAAAHLLEQKQe5QAAAAOpnltbLcz9gKNyK89dVj0VrwF4b%2FjOJfXdE0TzJOJffryITAzorH0B2SAjEKhDgEHWzc1zJzKiTAG3zdWa2cjtzK9exYfBz9V9OYVzKLuyJoT%2B3yAsyOXGXR6QINV9Ym3tP%2Fu7fdGI0HcNvnMbfnZJPMIURVH8kNL9iaym5GntRA0OpUVAEINd3sRn89pP3lLmpKPUtfeXlSMfqzPf3bGf7OaCQYmTL5eGRGG7C5GYaOGn7l0S9FNWKmdg9hq%2FvhinbjDIeWwcajDUHo3m0BhmDjSHCjWU36O1sji84ZyXN8WRw2KaUqTai%2F9xT%2FxG1LUOZFl2C%2FxVyjfqKvr%2BGQL&acctmode=0&pass_ticket=ajJdhwhlUXZpMVOYz6AOR454tJbBfye%2FpLFx%2F3%2FEgdNb9cvHQs40%2FGnTC7Iwi1XK&wx_header=0","urlHash":3528562143},"5fb0d103-019e-4abe-96f0-9dde163802f2":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"5fb0d103-019e-4abe-96f0-9dde163802f2","title":"Tanishq Mathew Abraham, Ph.D. on X: \"Tree Prompting: Efficient Task Adaptation without Fine-Tuning abs: https://t.co/D0k1GtAf3R code: https://t.co/TeDtEqho0l Building a decision tree of prompts and LM responses to solve a task. The approach is competitive with finetuning and allows inspection of decisionmaking. https://t.co/Vf5COJwHhz\" / X","url":"https://twitter.com/iScienceLuvr/status/1716693122317758903","urlHash":4149233340},"5fe20ddf-ea8d-4add-9cb8-67d6518a6103":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"5fe20ddf-ea8d-4add-9cb8-67d6518a6103","title":"无需额外训练提升模型30%性能！DeepMind科学家点赞MIT博士生实习成果","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247711344&idx=3&sn=a738896503bc92519c51f8fadbdd8412&chksm=e8df0d02dfa884144dfce92048c638054e80eed2c360ac772e72eca71c69e67a37bbeee5a73a&mpshare=1&scene=1&srcid=0115bMvCvpKmZiRFKom5jJKY&sharer_shareinfo=750549ea13dbc27e11c3ca539153ede0&sharer_shareinfo_first=750549ea13dbc27e11c3ca539153ede0&exportkey=n_ChQIAhIQIcH%2FcXU7aYhidEotG7%2Bs5RKWAgIE97dBBAEAAAAAADVvExF1aq8AAAAOpnltbLcz9gKNyK89dVj0FGWu0pNtjV9FR0llZ1kbRoO6x0Umo7A11wpXVC3SKDkP2YDlpZ%2BxZ7FfrZA%2B6Vcy1zC1jRTxDXi7klt2Hwu6c8p8%2Fx9LLdt5%2B65wbKi7pFuApUR6Ga1UAMxMaCSWYgv24%2FL6zG8GKe%2FkJ2y6hZolzBv9WCD1No67y0uFG6lnBzDh8m8Xyc6m93nRfUAWwKUHF9CyhHF%2BfasN6O6j6mHLW0%2BNmPIFWDZqkioiyA2%2FSrNTFZaYk32TlUneCGXiCTWPCKrOkx0xo2pJXmI2VbfiD0Yey%2B%2BhxHBvyp6W2rM516lrWYlDoNp%2BEQVZdm6VRE5d&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsYBxNvBPBeQpx7HmoCKspviULavGeDaFDh1%2ByMF1BDJWw%3D%3D&wx_header=0#rd","urlHash":580989073},"6014b209-5628-4828-99ee-eeca9fc145ea":{"favIconUrl":"fallback","id":"6014b209-5628-4828-99ee-eeca9fc145ea","title":"What exactly is Walter Benjamin arguing in \"Theses on the Philosophy of History\"? : CriticalTheory","url":"https://www.reddit.com/r/CriticalTheory/comments/5wew96/what_exactly_is_walter_benjamin_arguing_in_theses/","urlHash":450076733},"60302835-3cac-4a2c-b0b3-365bc5d7d0f7":{"favIconUrl":"fallback","id":"60302835-3cac-4a2c-b0b3-365bc5d7d0f7","title":"Better Aligning Text-to-Image Models with Human Preference - Arxiv-2303.14420","url":"https://arxiv.org/pdf/2303.14420.pdf","urlHash":3671734000},"603992ed-f231-4c90-895d-e13c7680e71d":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"603992ed-f231-4c90-895d-e13c7680e71d","title":"tokens危机到来怎么办？新国立最新研究：为什么当前的大语言模型的训练都是1次epoch？多epochs是否会降低大模型性能？","url":"https://mp.weixin.qq.com/s?__biz=Mzg2MTIzNDcyNQ==&mid=2247484398&idx=1&sn=b4816ecc61407cac945707ccb762d54e&chksm=ce1b70a4f96cf9b2c1deb43d12a526d30469dc2763a918599c871724a3366e5b8b0c0d4a3894&mpshare=1&scene=1&srcid=07015AMndSCMYsEdY4p0aXOB&sharer_sharetime=1688170880251&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQX20bWXFZYVPFOzgMRd0AJRKWAgIE97dBBAEAAAAAAIx9JIj02k0AAAAOpnltbLcz9gKNyK89dVj05hmJ3egTr0pmuMMSfzvV6GEMPEqCZTqz%2BcwTHL6RfdxA1gyFJZ2s3ENjl%2B4GQNJmDeLT2Me99AS1NKx7%2FJ9ubfNEkgCzu3PmYjbISVdYETiPEYxjaXtF00Q2f9XV9j%2FFhbI14a5Ph7qcaI1nsotTyS4X5LcpiB9r0VYScej02YD4OS0vd2fTCZALEWZonIZCCgAx7TFKVg34bkGT1v4Bc%2BDXffoBb1npwNAWwT1TjCEMiMmuucx3I4gGxQjGIvGnS%2FDJaBZTsbKou%2FblJMQkkebFOLv%2FNgyU%2F2iILSyA78n1FAnf34TJyIGVjltreiD8&acctmode=0&pass_ticket=ItvnpQfe%2B2toeIy9yZ0PDX8ngQbT7kc%2FvgP%2FnuAIq9stILYQl7yjJpR%2Fo8nADEc9&wx_header=0#rd","urlHash":1720380888},"606d7549-101b-482c-b99f-d9f2e02a242c":{"favIconUrl":"fallback","id":"606d7549-101b-482c-b99f-d9f2e02a242c","title":"【轻吐槽】回应先知，关于《胰脏》中的校园阶级那些事 - 知乎","url":"https://zhuanlan.zhihu.com/p/56166459","urlHash":192233419},"606f0641-a265-4024-b396-ab7668924d85":{"favIconUrl":"fallback","id":"606f0641-a265-4024-b396-ab7668924d85","title":"Learning Discrete Latent Structure","url":"https://duvenaud.github.io/learn-discrete/","urlHash":2468314127},"60ff676b-a449-420c-a8f7-1845316cd25d":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"60ff676b-a449-420c-a8f7-1845316cd25d","title":"好きです、死んでください (豆瓣)","url":"https://book.douban.com/subject/36472369/","urlHash":1641840965},"61047030-38a4-49c5-9a78-5733b2f62f08":{"favIconUrl":"fallback","id":"61047030-38a4-49c5-9a78-5733b2f62f08","title":"A Survey on Segment Anything Model (SAM): Vision Foundation Model Meets Prompt Engineering","url":"https://arxiv.org/pdf/2306.06211.pdf","urlHash":3245763406},"6110e5b8-b42e-467b-b19d-66092f1207c0":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6110e5b8-b42e-467b-b19d-66092f1207c0","title":"Keiran Paster on X: \"Super cool - seems like labeling documents as &lt;good&gt; or &lt;bad&gt; at the beginning of the sequence during pretraining outperforms throwing out the bad data. Lots of parallels to supervised RL / decision transformer as well.\" / X","url":"https://twitter.com/keirp1/status/1627484879758794753","urlHash":992417805},"611d261f-9554-447a-ab8a-70fe3b5b82f3":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"611d261f-9554-447a-ab8a-70fe3b5b82f3","title":"sshh12/multi_token: Embed arbitrary modalities (images, audio, documents, etc) into large language models.","url":"https://github.com/sshh12/multi_token","urlHash":1067615226},"612c2f24-780d-47bb-ade5-a3d6b2ce6a9b":{"favIconUrl":"fallback","id":"612c2f24-780d-47bb-ade5-a3d6b2ce6a9b","title":"​​What learning algorithm is in-context learning? Investigations with linear models - OR-ICLR-2023_0g0X4H8yN4I","url":"https://openreview.net/pdf?id=0g0X4H8yN4I","urlHash":1196762365},"614c6e85-cf75-4d84-bb51-560566e5b4c1":{"favIconUrl":"fallback","id":"614c6e85-cf75-4d84-bb51-560566e5b4c1","title":"Fast Sampling of Diffusion Models with Exponential Integrator - Arxiv-2204.13902","url":"https://arxiv.org/pdf/2204.13902.pdf","urlHash":3302713791},"61689ba5-a02e-4a00-8882-f8672f237af5":{"favIconUrl":"https://www.google.com/favicon.ico","id":"61689ba5-a02e-4a00-8882-f8672f237af5","title":"Learning from Natural Language Feedback - Google Search","url":"https://www.google.com/search?q=Learning%20from%20Natural%20Language%20Feedback","urlHash":1169340215},"618650d2-6a00-4833-b560-d22003f60f64":{"favIconUrl":"fallback","id":"618650d2-6a00-4833-b560-d22003f60f64","title":"Impact of Pretraining Term Frequencies on Few-Shot Reasoning - Arxiv-2202.07206","url":"https://arxiv.org/abs/2202.07206","urlHash":2076814543},"61941647-0da2-4405-9395-9b5515845742":{"favIconUrl":"fallback","id":"61941647-0da2-4405-9395-9b5515845742","title":"Model evaluation for extreme risks - Arxiv-2305.15324","url":"https://arxiv.org/abs/2305.15324","urlHash":4013564524},"61cd6300-5ee8-4362-83c4-bc247a70dce3":{"favIconUrl":"fallback","id":"61cd6300-5ee8-4362-83c4-bc247a70dce3","title":"Private Fine-tuning of Large Language Models with Zeroth-order Optimization | PDF","url":"https://arxiv.org/pdf/2401.04343.pdf","urlHash":1760887187},"61e993ee-42b8-4912-86ab-4eadc7d32c87":{"favIconUrl":"fallback","id":"61e993ee-42b8-4912-86ab-4eadc7d32c87","title":"圆圆要学习 - 知乎","url":"https://www.zhihu.com/people/kong-gu-91/posts","urlHash":2736874201},"61f4d9b4-c9ba-445d-bf7b-ee250887949d":{"favIconUrl":"fallback","id":"61f4d9b4-c9ba-445d-bf7b-ee250887949d","title":"SODA Million-scale Dialogue Distillation with Social Commonsense Contextualization - Arxiv-2212.10465","url":"https://arxiv.org/abs/2212.10465","urlHash":4227944963},"61fbe29f-e11b-4a8b-95ad-f12e61347cc1":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"61fbe29f-e11b-4a8b-95ad-f12e61347cc1","title":"Aran Komatsuzaki on X: \"Google presents: Do Large Language Models Latently Perform Multi-Hop Reasoning? Finds strong evidence of latent multi-hop reasoning for the prompts of certain relation types, with the reasoning pathway used in more than 80% of the prompts https://t.co/7o4ppQz4CW https://t.co/BmtQrT40Kc\" / X","url":"https://twitter.com/arankomatsuzaki/status/1762341010208600095","urlHash":2360979095},"6206efbb-d3c5-45f8-b671-f4186f5c7438":{"favIconUrl":"fallback","id":"6206efbb-d3c5-45f8-b671-f4186f5c7438","title":"你可能不需要BERT-flow：一个线性变换媲美BERT-flow - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/8069","urlHash":1336123425},"6214b748-d592-48aa-af1a-7f4c83f9bc06":{"favIconUrl":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA99JREFUeNrsG4t1ozDMzQSM4A2ODUonKBucN2hugtIJ6E1AboLcBiQTkJsANiAb9OCd/OpzMWBJBl5TvaeXPiiyJetry0J8wW3D3QpjRh3GjneXDq+fSQA9s2mH9x3KDhN4foJfCb8N/Jrv+2fnDn8vLRQOplWHVYdvHZYdZsBcZP1vBmh/n8DzEmhUQDPaOuP9pFuY+JwJHwHnCLQE2tnWBGEyXozY9xCUgHMhhjE2I4heVWtgIkZ83wL6Qgxj1obfWBxymPwe+b00BCCRNPbwfb60yleAkkBHGT5AEehIYz7eJrFDMF9CvH4wwhcGHiHMneFvLDQwlwvMLQq58trRcYBWfYn0A0OgHWQUSu25mE+BnoYKnnEJoeIWAifzOv7vLWd2ZKRfWAIme3tOiUaQ3UnLkb0xj1FxRIeEGKaGIHOs9nEgLaaA9i0JRYo1Ic67wJW86KSKE/ZAM8KuVMk8ITVhmxUxJ3Cl2xlm9Vtkeju1+mpCQNxaEGNCY8bs9X2YqwNoQeGjBWut/ma0QAWy/TqAsHx9wSya3I5IRxOfTC+leG+kA/4vSeEcGBtNUN6byhu3+keEZCQJUNh8MAO7HL6H8pQLnsW/Hd4T4lv93TPjfM7A46iEEqbB5EDOvwYNW6tGNZzT/o+CZ6sqZ6wUtR/wf7mi/VL8iNciT6rHih48Y55b4nKCHJCCzb4y0nwFmin3ZEMIoLfZF8F7nncFmvnWBaBj7CGAYA/WGJsUwHdYqVDwAmNsUgAx4CGgAA7GOOxADYOFWOaIKifuVYzmOpREqA21Mo7aPsgiY1PhOMAmxtR+AUbYH3Id2wc0SAFIQTsn9IUGWR8k9jx3vtXSiAacFxTAGakBk9UudkNECd6jLe+6HrshshvIuC6IlLMRy7er+JpcKma24SlE4cFZSZJDGVVrsNvitQhQrDhW0jfiOLfFd47C42eHT56D/BK0To+58Ahj+cAT8HT1UWlfLZCCd/uKawzU0Rh2EyIX/Icqth3niG8ybNroezwe6khdCNxRN+l4XGdOLVLlOOt2hTRJlr1ETIuMAltVTMz70mJrkdGAaZLSmnBEqmAE32JCMmuTlCnRgsBENtOUpHhvvsYIL0ibnBkaC6QvKcR7738GKp0AKnim7xgUSNv1bpS8QwhBt8r+EP47v/oyRK/S34yJ9nT+AN0Tkm4OdB9E4BsmXM3SnMlRFUrtp6IDpV2eKzdYvF3etm3KhQksbOLChGkSmcBdmcEwvqkrMy5BzL00NZeu3qPYJOOuCc+5NjcWKXQxFvTa3NoXJ4d8in7fiAUuTt781dkvuHX4K8AA2Usy7yNKLy0AAAAASUVORK5CYII=","id":"6214b748-d592-48aa-af1a-7f4c83f9bc06","title":"Deconvolution and Checkerboard Artifacts","url":"https://distill.pub/2016/deconv-checkerboard/","urlHash":2543565737},"6224992f-cb9c-4a93-8149-8869a50ab9eb":{"favIconUrl":"fallback","id":"6224992f-cb9c-4a93-8149-8869a50ab9eb","title":"Internet-augmented language models through few-shot prompting for open-domain question answering - Arxiv-2203.05115","url":"https://arxiv.org/pdf/2203.05115.pdf","urlHash":1853201430},"622e1cf3-0bac-4bc2-a804-cbb663fb0aa8":{"favIconUrl":"fallback","id":"622e1cf3-0bac-4bc2-a804-cbb663fb0aa8","title":"Reconstructing Training Data from Model Gradient, Provably - Arxiv-2212.03714","url":"https://arxiv.org/abs/2212.03714","urlHash":2267645311},"6239fc54-e4a8-4134-948c-aedf2b95a48f":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"6239fc54-e4a8-4134-948c-aedf2b95a48f","title":"The role of Bayesian ML in AI safety - an overview — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/RJZ7bwoDB6BWgt6St/the-role-of-bayesian-ml-in-ai-safety-an-overview","urlHash":429667417},"62bde13a-f10d-411d-ad38-a95272b280b3":{"favIconUrl":"fallback","id":"62bde13a-f10d-411d-ad38-a95272b280b3","title":"DiCE The Infinitely Differentiable Monte-Carlo Estimator - Arxiv-1802.05098","url":"https://arxiv.org/pdf/1802.05098.pdf","urlHash":1093405145},"6352837a-297d-43a5-8276-1d941d79ef25":{"favIconUrl":"https://www.sto.cx/favicon.ico","id":"6352837a-297d-43a5-8276-1d941d79ef25","title":"水天一色《校园惨剧》_全文在線閱讀_思兔","url":"https://www.sto.cx/book-27321-1.html","urlHash":3812159488},"638b32b8-e2d4-4a69-a7d5-669b63c247c5":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"638b32b8-e2d4-4a69-a7d5-669b63c247c5","title":"Jason Wei on X: \"Glad to see this work on alignment; an interesting takeaway for me here is that instruction tuning on data that the model doesn't know can be really, really bad. Basically when you finetune on data the model doesn't know, in addition to teaching it that particular training…\" / X","url":"https://twitter.com/_jasonwei/status/1689376492029964288","urlHash":1880377912},"638b91fe-8fef-4382-87a2-0daf1ef9b64d":{"favIconUrl":"fallback","id":"638b91fe-8fef-4382-87a2-0daf1ef9b64d","title":"Contrastive Out-of-Distribution Detection for Pretrained Transformers - Arxiv-2104.08812","url":"https://arxiv.org/pdf/2104.08812.pdf","urlHash":4218431083},"639e52b0-c822-47bf-8a68-6f2e8319d74b":{"favIconUrl":"fallback","id":"639e52b0-c822-47bf-8a68-6f2e8319d74b","title":"COS 597G: Understanding Large Language Models","url":"https://www.cs.princeton.edu/courses/archive/fall22/cos597G/","urlHash":760005215},"63b1b010-05a6-4b6a-9d07-fc9aea3e4027":{"favIconUrl":"fallback","id":"63b1b010-05a6-4b6a-9d07-fc9aea3e4027","title":"neurips19_memorization","url":"https://ai.stanford.edu/~cbfinn/_files/neurips19_memorization.pdf","urlHash":2198643961},"63b57e9f-e80b-4757-a149-bce68f0daaac":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"63b57e9f-e80b-4757-a149-bce68f0daaac","title":"Shuaijie She on X: \"🔥Introducing MAPO: a novel Multilingual-Alignment-as-Preference Optimization framework 🤩No need to annotate reasoning processes! 😍Improve your LLMs in a generalizable manner! 👑BEST performance on all three Multilingual reasoning benchmarks! https://t.co/rZsE4l5esw\" / X","url":"https://twitter.com/kevinprossj/status/1762524055658508437","urlHash":1597593370},"63c90f5a-c4a1-47d1-989b-e9f634ece105":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"63c90f5a-c4a1-47d1-989b-e9f634ece105","title":"(2) Hanze Dong on X: \"🚀 Iterative DPO is efficient theoretically and empirically! 🚀 We've got extensive empirical support for GSHF now! 📊 Joint work with Wei @weixiong_1, Chenlu @ye_chenlu, Ziqi @wzq016, Han @han_zhong1, Heng @elgreco_winter, Nan @nanjiang_cs , Tong https://t.co/ylFbCKfrFQ\" / X","url":"https://twitter.com/hendrydong/status/1758300085665108072","urlHash":2504245290},"63e2e076-0fdc-4b79-b59c-36dc7b51a9b4":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"63e2e076-0fdc-4b79-b59c-36dc7b51a9b4","title":"What In-Context Learning \"Learns\" In-Context: Disentangling Task Recognition and Task Learning | Abstract","url":"https://arxiv.org/abs/2305.09731","urlHash":285651999},"6400b961-2cee-4c05-bddc-e86274ead516":{"favIconUrl":"fallback","id":"6400b961-2cee-4c05-bddc-e86274ead516","title":"AlexTMallen/adaptive-retrieval","url":"https://github.com/AlexTMallen/adaptive-retrieval","urlHash":3028500414},"643355aa-0bf1-4afe-8c4e-bcc7a32e1577":{"favIconUrl":"fallback","id":"643355aa-0bf1-4afe-8c4e-bcc7a32e1577","title":"Broken Neural Scaling Laws - Arxiv-2210.14891","url":"https://arxiv.org/pdf/2210.14891.pdf","urlHash":831312186},"64b21e7e-10c6-4d57-b5cf-4bc01c297256":{"favIconUrl":"fallback","id":"64b21e7e-10c6-4d57-b5cf-4bc01c297256","title":"(3) I want to get into Cioran, I enjoyed Kafka's aphorisms the most of any philosophical texts I've read, where shoudl I start? : cioran","url":"https://www.reddit.com/r/cioran/comments/sx0kc1/i_want_to_get_into_cioran_i_enjoyed_kafkas/","urlHash":3053479686},"64b41008-2927-4ac9-b1c5-39ec826838c0":{"favIconUrl":"fallback","id":"64b41008-2927-4ac9-b1c5-39ec826838c0","title":"https://arxiv.org/pdf/2202.05749.pdf","url":"https://arxiv.org/pdf/2202.05749.pdf","urlHash":799497744},"65183e68-b4ad-42e5-8f76-a5e5a5fe8845":{"favIconUrl":"fallback","id":"65183e68-b4ad-42e5-8f76-a5e5a5fe8845","title":"hbaniecki/adversarial-explainable-ai: 💡 Adversarial attacks on explanations and how to defend them","url":"https://github.com/hbaniecki/adversarial-explainable-ai#attacks-on-explainability-and-fairness","urlHash":1421670295},"6521c917-d4f1-4c78-a531-7534d3aa833f":{"favIconUrl":"fallback","id":"6521c917-d4f1-4c78-a531-7534d3aa833f","title":"Influence Functions in Deep Learning Are Fragile","url":"https://arxiv.org/pdf/2006.14651.pdf","urlHash":2802032695},"6537466b-5df1-4c4d-bd29-7c076a50b74b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6537466b-5df1-4c4d-bd29-7c076a50b74b","title":"Yujie Alice Lu on X: \"🚀Excited to release VISUAL EMBEDDED INSTRUCTION (#VIM), a new paradigm to probe the visual instruction following capability of Multimodal Large Language Models. 📜 paper: https://t.co/72v13XB5dC 🔗 website: https://t.co/z7SwMiCken 🛠️ code: https://t.co/DR8Wc1QzKy The current… https://t.co/qcNYmJZ9zx\" / X","url":"https://twitter.com/yujielu_10/status/1730689946607030558","urlHash":630569311},"654f0785-88e6-4e03-b519-bada535d8bf3":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"654f0785-88e6-4e03-b519-bada535d8bf3","title":"A Survey of Large Language Models | PDF","url":"https://arxiv.org/pdf/2303.18223.pdf","urlHash":4232555633},"6561b13a-d58b-4adc-b165-534f11374e40":{"favIconUrl":"https://www.google.com/favicon.ico","id":"6561b13a-d58b-4adc-b165-534f11374e40","title":"Certified Robustness to Word Substitution Attack with Differential Privacy - Google Search","url":"https://www.google.com/search?q=Certified+Robustness+to+Word+Substitution+Attack+with+Differential+Privacy&sourceid=chrome&ie=UTF-8","urlHash":1689712057},"657b55b4-7397-4f53-b53f-a772a244afce":{"favIconUrl":"fallback","id":"657b55b4-7397-4f53-b53f-a772a244afce","title":"Large Language Models Can Be Strong Differentially Private Learners - Arxiv-2110.05679","url":"https://arxiv.org/pdf/2110.05679.pdf","urlHash":1095501704},"6583b783-8cb7-4a13-a405-137ba74b5c72":{"favIconUrl":"fallback","id":"6583b783-8cb7-4a13-a405-137ba74b5c72","title":"Multimodal Chain-of-Thought Reasoning in Language Models - Arxiv-2302.00923","url":"https://arxiv.org/pdf/2302.00923.pdf","urlHash":2732899936},"65854bed-1a04-4e4d-9abf-7fa305c38012":{"favIconUrl":"fallback","id":"65854bed-1a04-4e4d-9abf-7fa305c38012","title":"Reverse engineering the NTK: towards first-principles architecture design – The Berkeley Artificial Intelligence Research Blog","url":"https://bair.berkeley.edu/blog/2022/08/29/reverse-engineering/","urlHash":1853277637},"65bbdb98-a25b-4263-9d41-a2b2d3dba9d2":{"favIconUrl":"fallback","id":"65bbdb98-a25b-4263-9d41-a2b2d3dba9d2","title":"Detailed SSD object detection algorithm - actorsfit","url":"https://blog.actorsfit.com/a?ID=00001-38d70c78-3466-4c1b-bbff-26805f5a4ea4","urlHash":1706428491},"66281e14-f0f2-4632-9c64-a6761d852726":{"favIconUrl":"fallback","id":"66281e14-f0f2-4632-9c64-a6761d852726","title":"data-poisoning-release/generate_or_process_bounds.py at master · kohpangwei/data-poisoning-release","url":"https://github.com/kohpangwei/data-poisoning-release/blob/master/generate_or_process_bounds.py","urlHash":875508595},"663abb32-dd9d-4389-a5c7-e5ab2be9454f":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"663abb32-dd9d-4389-a5c7-e5ab2be9454f","title":"Tim Dettmers on X: \"@srush_nlp @4evaBehindSOTA Regular transformers are notoriously difficult to sparsify, this is even true for the FFN layers in MoE transformers. But MoE layers are very different. You can also quantize them to 1 bit without any problem, but sparsification gives you better memory benefits than 1-bit quant.…\" / X","url":"https://twitter.com/Tim_Dettmers/status/1733676239292866682","urlHash":677800854},"6642b31a-1640-43e1-bf23-135aab2413d7":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6642b31a-1640-43e1-bf23-135aab2413d7","title":"Sara Hooker on X: \"Were you curious to find out @GoogleDeepMind Gemma is using REINFORCE instead of PPO? We have been working on this paper for months --that takes apart PPO and motivates REINFORCE Style Optimization as far simpler and more effective. 🔥✨ https://t.co/HIIDhBtT7x https://t.co/2LHwqi9chX\" / X","url":"https://twitter.com/sarahookr/status/1761042445997945070?utm_source=substack&utm_medium=email","urlHash":127901191},"667cdc10-b206-430c-92e0-1617484ead70":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"667cdc10-b206-430c-92e0-1617484ead70","title":"Reincarnating Reinforcement Learning: Reusing Prior Computation to Accelerate Progress | PDF","url":"https://arxiv.org/pdf/2206.01626.pdf","urlHash":1397440684},"66980613-1a71-44ce-a8df-a4183759d253":{"favIconUrl":"fallback","id":"66980613-1a71-44ce-a8df-a4183759d253","title":"Gilbert Ryle (Stanford Encyclopedia of Philosophy)","url":"https://plato.stanford.edu/entries/ryle/","urlHash":445865413},"669d132f-7d36-43a2-aec5-2df58a00f3b9":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"669d132f-7d36-43a2-aec5-2df58a00f3b9","title":"(1) X 上的 Wenda Xu：“Can we not criticize LLM but pinpoint errors it makes and automatically guide it with fine-grained actionable feedback? Can we formulate iterative refinement into a local search problem, simulated annealing? My cool summer intern work @Google @_danieldeutsch @markuseful @ucsbNLP https://t.co/JH9WlNAxPm” / X","url":"https://twitter.com/WendaXu2/status/1725026201410957346","urlHash":3736846307},"66be895f-7909-482b-a812-5d8a2aeec187":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"66be895f-7909-482b-a812-5d8a2aeec187","title":"PandaGPT: One Model To Instruction-Follow Them All | PDF","url":"https://arxiv.org/pdf/2305.16355.pdf","urlHash":2976495785},"66c807ae-efc8-446d-bc53-1e89e22a7b22":{"favIconUrl":"https://snip.mathpix.com/favicon.ico","id":"66c807ae-efc8-446d-bc53-1e89e22a7b22","title":"Viewing 2211.00789.pdf - Snip Web","url":"https://snip.mathpix.com/jxu1/pdfs/4612f9f6-5b44-47a2-b44c-e65c7c31a828/view","urlHash":729554924},"66dff8e0-edde-4bf3-943e-c7fb30c9a82d":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"66dff8e0-edde-4bf3-943e-c7fb30c9a82d","title":"Learning to Generate Better Than Your LLM | PDF","url":"https://arxiv.org/pdf/2306.11816.pdf","urlHash":1209431248},"66e456e0-2321-4049-8f96-ae731036ffc8":{"favIconUrl":"https://assets-global.website-files.com/64f6f2c0e3f4c5a91c1e823a/654693d569494912cfc0c0d4_favicon.svg","id":"66e456e0-2321-4049-8f96-ae731036ffc8","title":"Paving the way to efficient architectures: StripedHyena-7B, open source models offering a glimpse into a world beyond Transformers","url":"https://www.together.ai/blog/stripedhyena-7b","urlHash":3645095884},"66f1d10b-43ec-466e-858d-91091a942aa1":{"favIconUrl":"https://www.google.com/favicon.ico","id":"66f1d10b-43ec-466e-858d-91091a942aa1","title":"二律背反诅咒 - Google Search","url":"https://www.google.com/search?q=%E4%BA%8C%E5%BE%8B%E8%83%8C%E5%8F%8D%E8%AF%85%E5%92%92","urlHash":1979662680},"670cc0b4-90fa-4626-b4f9-1a19a61b5cae":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"670cc0b4-90fa-4626-b4f9-1a19a61b5cae","title":"为什么拉康说：“栖居于日语中的人无需接受精神分析”","url":"https://mp.weixin.qq.com/s?__biz=MzkwMzQzODI2Ng==&mid=2247483954&idx=1&sn=55c192f9f7423b053c78e5205413f685&chksm=c09708e7f7e081f19f8335120157034a9c73036599607707c3a3d043b86da4831114b8286e58&mpshare=1&scene=1&srcid=041932Exf5Kld8tUph0whxGe&sharer_shareinfo=49eb9b64c94298ab61df5d2496d1e5eb&sharer_shareinfo_first=49eb9b64c94298ab61df5d2496d1e5eb&exportkey=n_ChQIAhIQ6OzNdeak5zAI4MIOojEmLBKWAgIE97dBBAEAAAAAAO9%2BMlcFHygAAAAOpnltbLcz9gKNyK89dVj0EAOtc5fuFkZeakyigE2empDbAyyq7ZWWf7vznY5cgh%2BTZIhCqVutlUxoOXuXai6fObEMrfz%2BVXDWFY%2F7fyto%2FXVf4hVCQXQgV0hxDrHXINYLBG7JkS765vnwYWjLyz2d7QRD7QUADYAvgeIV1qYBcf8Hezr2X1ymniroTx8Kf8kdJUEDrArgQ5nnLkB3MfMALeoYtpuYpN3k9z7cJy0FDiC7308K25ujQJjMgsoIuXBs8hNXjRHRAo75H6ETT9LZ%2B8SZDNP6ymskSwRV4mzO7708V%2BjMhpq81iNRfdL%2BNNDEMDfDRK695gxI6mK6LeGi&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCMJypYReZtP4Kk76ZohOWDSsK2osCrh%2BKpMQBGsecklvA%3D%3D&wx_header=0#rd","urlHash":3536766782},"671b1026-8e1a-420a-acdc-8d64427771cf":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"671b1026-8e1a-420a-acdc-8d64427771cf","title":"Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4 | PDF","url":"https://arxiv.org/pdf/2312.16171v2.pdf","urlHash":2833582037},"67319a2d-4d66-4bc7-b1c1-001cc20a2986":{"favIconUrl":"fallback","id":"67319a2d-4d66-4bc7-b1c1-001cc20a2986","title":"Understanding Zero-Shot Adversarial Robustness for Large-Scale Models - Arxiv-2212.07016","url":"https://arxiv.org/pdf/2212.07016.pdf","urlHash":1475674128},"673c4c2c-3ff8-461f-87b1-723e511300ee":{"favIconUrl":"https://blog.langchain.dev/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png","id":"673c4c2c-3ff8-461f-87b1-723e511300ee","title":"Supercharging If-Statements With Prompt Classification Using Ollama and LangChain","url":"https://blog.langchain.dev/supercharging-if-statements-with-prompt-classification-using-ollama-and-langchain/","urlHash":4006271894},"676c0e26-1a97-4207-a1e1-09e4b7ce1fac":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"676c0e26-1a97-4207-a1e1-09e4b7ce1fac","title":"mp.weixin.qq.com/mp/appmsgalbum?__biz=MzIwNDY1NTU5Mg==&action=getalbum&album_id=2298214853309857797&scene=173&from_msgid=2247486002&from_itemidx=1&count=3&nolastread=1#wechat_redirect","url":"https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzIwNDY1NTU5Mg==&action=getalbum&album_id=2298214853309857797&scene=173&from_msgid=2247486002&from_itemidx=1&count=3&nolastread=1#wechat_redirect","urlHash":1734485683},"67781963-4adf-487b-a778-29c640da49f6":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"67781963-4adf-487b-a778-29c640da49f6","title":"elvis on X: \"Can LLMs Reason and Plan? There is a lot of debate about whether LLMs can reason and plan. These are important capabilities for unlocking complex applications with LLMs such as in the domains of robotics and autonomous agents. This position paper discusses the topic of… https://t.co/hIeGLi2VKO\" / X","url":"https://twitter.com/omarsar0/status/1766123621326475285?utm_source=substack&utm_medium=email","urlHash":3702647307},"67959314-e6d0-4f9d-a8d5-6b4c1663cf0b":{"favIconUrl":"fallback","id":"67959314-e6d0-4f9d-a8d5-6b4c1663cf0b","title":"Data Shapley Equitable Valuation of Data for Machine Learning - Arxiv-1904.02868","url":"https://arxiv.org/pdf/1904.02868.pdf","urlHash":761103301},"67a1c3d7-262f-43f2-a778-378a642c7497":{"favIconUrl":"fallback","id":"67a1c3d7-262f-43f2-a778-378a642c7497","title":"GPT 的野望 - 知乎","url":"https://zhuanlan.zhihu.com/p/348402227","urlHash":4176079292},"67c544b0-3b41-4858-a74a-e895942a7a56":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"67c544b0-3b41-4858-a74a-e895942a7a56","title":"为节约而生：从标准Attention到稀疏Attention - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/6853","urlHash":22745006},"67cd0cc3-1718-4fda-9a3d-11a01a96bf97":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"67cd0cc3-1718-4fda-9a3d-11a01a96bf97","title":"langchain/cookbook/meta_prompt.ipynb at master · langchain-ai/langchain","url":"https://github.com/langchain-ai/langchain/blob/master/cookbook/meta_prompt.ipynb","urlHash":4061010347},"67e3599f-8718-4917-9890-88b16e5f9b08":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"67e3599f-8718-4917-9890-88b16e5f9b08","title":"Injecting structural hints: Using language models to study inductive biases in language learning | PDF","url":"https://arxiv.org/pdf/2304.13060.pdf","urlHash":2044580993},"68023304-fb02-4b74-98f3-bbecd9bb6932":{"favIconUrl":"https://www.mdpi.com/favicon.ico","id":"68023304-fb02-4b74-98f3-bbecd9bb6932","title":"MAKE | Free Full-Text | Hierarchical Reinforcement Learning: A Survey and Open Research Challenges","url":"https://www.mdpi.com/2504-4990/4/1/9","urlHash":2314050607},"68134338-ab1e-4e05-b17d-62cc8119dc70":{"favIconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","id":"68134338-ab1e-4e05-b17d-62cc8119dc70","title":"Towards Monosemanticity: Decomposing Language Models With Dictionary Learning — LessWrong","url":"https://www.lesswrong.com/posts/TDqvQFks6TWutJEKu/towards-monosemanticity-decomposing-language-models-with","urlHash":2645471298},"68264fa1-d328-4980-b68c-60ec3788386a":{"favIconUrl":"fallback","id":"68264fa1-d328-4980-b68c-60ec3788386a","title":"有哪些令你印象深刻的魔改transformer？ - 知乎","url":"https://www.zhihu.com/question/349958732/answer/945349902","urlHash":3806223139},"682872ea-a9cd-414d-b636-84a11fb7207e":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"682872ea-a9cd-414d-b636-84a11fb7207e","title":"The Perils & Promises of Fact-checking with Large Language Models | Abstract","url":"https://arxiv.org/abs/2310.13549?utm_source=substack&utm_medium=email","urlHash":2555789288},"68316ed6-4f5b-4b8a-bc31-b77714673032":{"favIconUrl":"fallback","id":"68316ed6-4f5b-4b8a-bc31-b77714673032","title":"BERTology","url":"https://huggingface.co/docs/transformers/main/en/bertology","urlHash":844909175},"687d8736-888d-4cbc-bf60-8dbfcb2a7583":{"favIconUrl":"fallback","id":"687d8736-888d-4cbc-bf60-8dbfcb2a7583","title":"Dataset Distillation A Comprehensive Review - Arxiv-2301.07014","url":"https://arxiv.org/abs/2301.07014","urlHash":1489227100},"6880bd19-a67d-4c5d-8c59-faeae499f36a":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"6880bd19-a67d-4c5d-8c59-faeae499f36a","title":"统一图像和文字生成的MiniGPT-5来了：Token变Voken，模型不仅能续写，还会自动配图了","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650892501&idx=1&sn=711cf3de5c18bc243f6c38e248540289&chksm=84e4acabb39325bd823d74abc00c0bbce11d2e42efbf7fa2ed6c57388d9bc50dc379df72a6d9&mpshare=1&scene=1&srcid=0115AGnhizkD40cGn6dTq0Oo&sharer_shareinfo=e8ba85c68023a70cccc3bfea5b5ca2b1&sharer_shareinfo_first=e8ba85c68023a70cccc3bfea5b5ca2b1&exportkey=n_ChQIAhIQoAW%2FeW30rFI1sML1rsgZ3BKWAgIE97dBBAEAAAAAACaFJqc3kpkAAAAOpnltbLcz9gKNyK89dVj0LSoIyZ4UqHzBUGPgPaBcvThnbu3009YcGXW67cV%2BScNwwX8bA9vywZFSAMiqasMa1tWUa4kM3J2kTq1Cgcgj0z2xPJrT6LfbzSLyuXr1xSNE5dcQB%2Fi9fLChg5BPsutSIqnbkdZpkZFldjkqQrwdj1GW%2FOKgjZthoREcV2cFfFznDSstZGNvGtw%2F4oH74ee664KHKZ7hoBo8yiWWkvjvlkYDeaYJ9nCp5EA0u6RLHbZX%2FDhg50H9KPXtIoNKTopw0p7vhQXeTc7azEHO%2BrWcViUWGEOoo34zp%2FSq8hykLLB649WilJV6WFwRUfBvVA3l&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsbNx20dr%2BNKtY%2BHtkgnXBdn65MRjXQqgMrp%2BaCzDvIkXw%3D%3D&wx_header=0#rd","urlHash":2034798801},"68981960-f1d7-4a91-8a45-b131b7a257c2":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"68981960-f1d7-4a91-8a45-b131b7a257c2","title":"OpenAI官宣开源Transformer Debugger！不用写代码，人人可以破解LLM黑箱","url":"https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247561454&idx=1&sn=4e80202c97bd7db5c3524985c0cfa0be&chksm=ebb6c83adcc1412cf39dd198f605c2e66906c06c5219541a4a35d378864e54a97b106ff85150&mpshare=1&scene=1&srcid=03274gsK21xkyMMRyWUOD7Pn&sharer_shareinfo=e5adf9aa091104101b19176f3cb25ca9&sharer_shareinfo_first=e5adf9aa091104101b19176f3cb25ca9&exportkey=n_ChQIAhIQml52gnKe6qzAsvIVy2U%2FYxKWAgIE97dBBAEAAAAAAAWKISc1ZRUAAAAOpnltbLcz9gKNyK89dVj0ZvGvS140NC71p2MaQW%2BuAnWhpXlhD49EeR5u0jkKoZQVwfdewiKhd%2Bzey1YhQqfy0tUeyHS4MTV8EqSW0EHsFhCLJnpJhJq9E%2B2xtVKGL7vfyli%2FWn4V3GOCgPTm2eGyDcTvxYRE3LgQMltsU9ShhFZbHT51IbVmZjZVcA%2BjNw01aZ8tXQ3T8QCiPOZi65b%2FcR2H0pdRbY71Oci%2Ft0pkP3W9%2F6uff1kF%2Fis1Aa21qZA01H5PBnUpdXliDUTlWKv0htJ35mBk1Weec3Oj9axnghsrMAVF1zvsOGWPedfHGKBSyblV8BZg7supqJ1uN1zs&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCMeTqITwyqpYwZBj4PZ5mojcByk22pbclud%2FNMcEtIRRA%3D%3D&wx_header=0#rd","urlHash":87621810},"68a211fd-8c58-4240-8762-555f07df00ad":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"68a211fd-8c58-4240-8762-555f07df00ad","title":"AlignScore: Evaluating Factual Consistency with a Unified Alignment Function | PDF","url":"https://arxiv.org/pdf/2305.16739.pdf","urlHash":1051749557},"68a9a7be-2655-414e-b30d-2b7ff276425a":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"68a9a7be-2655-414e-b30d-2b7ff276425a","title":"大模型推理速度飙升3.6倍，「美杜莎」论文来了，贾扬清：最优雅加速推理方案之一","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650905383&idx=2&sn=8d210130093e60fdbcafc1e884bf8232&chksm=84e45f59b393d64f4c752725381c254db65d5ec3fe66b31d49a70325d2be566c6dadb7fb4cd1&mpshare=1&scene=1&srcid=0125c7fJUgZIlWI3hXbcTAbA&sharer_shareinfo=261bd1c54bd8abefd739e8e40edab6ad&sharer_shareinfo_first=261bd1c54bd8abefd739e8e40edab6ad&exportkey=n_ChQIAhIQVlrsmCbWSJ8i4t1JbiPR5BKWAgIE97dBBAEAAAAAAHY%2BLYUbK1MAAAAOpnltbLcz9gKNyK89dVj0eySqBpV8Qb6HKcCbm%2BMcGiY2%2FX%2F9M79ja5WPkscENfsn6ccusfz0EYUMI2Id5vB2sF1D5vzQBBrpHtvwD7qWbxk2hwP7XlG4WhR4AQHKeEGdV9r0ezQMygjGjZLML5j7IBBVIH5MmP9gVUTgEuoK5g9SiQrCJijyZyW1qciocThM9dDkBm79ClwPG6A2pcN9PlO3Ineg6Cvpkyg54RL7gzd9MxKXBUvZ1FZXJeXMypm%2BC2JlNQOgOJLm2tNlYluzOsnulQRAcoQ4tb4g%2FWScSkXXaWGg19XsfGgIesD%2BF02sj0BhTfyWKJWqG7JQYr8R&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HMG2dn%2BR%2FfFkZqwb%2BQCMJyMN1bvxfvr4BvNGicljjTW7Q%3D%3D&wx_header=0#rd","urlHash":3570090455},"68bad277-bf49-4dd4-aca6-a85062f21f76":{"favIconUrl":"fallback","id":"68bad277-bf49-4dd4-aca6-a85062f21f76","title":"Evaluating Explanations How much do explanations from the teacher aid students? - Arxiv-2012.00893","url":"https://arxiv.org/pdf/2012.00893.pdf","urlHash":4274358078},"68cc8b2f-5f07-4823-89e2-3372b193b423":{"favIconUrl":"fallback","id":"68cc8b2f-5f07-4823-89e2-3372b193b423","title":"细水长flow之RealNVP与Glow：流模型的传承与升华 - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/5807","urlHash":710731352},"68daca0f-ad50-4ee5-8ad3-154cf03351bf":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"68daca0f-ad50-4ee5-8ad3-154cf03351bf","title":"Mark Tenenholtz on X: \"AutoAct is a method to train agents to solve multi-step tasks with little data. It outperforms methods that use synthetic data from GPT-4 with as small as 13B models. Summary of how it works: 1. Start with a small dataset of tasks, simply questions mapped to outcomes 2. Use… https://t.co/lzLd0Trv9q\" / X","url":"https://twitter.com/marktenenholtz/status/1748050083046736203","urlHash":3263857218},"68f3600a-239d-4ef3-b17c-2e9b470647d9":{"favIconUrl":"fallback","id":"68f3600a-239d-4ef3-b17c-2e9b470647d9","title":"www.cs.toronto.edu/~rgrosse/teaching.html","url":"http://www.cs.toronto.edu/~rgrosse/teaching.html","urlHash":3888626755},"696315cf-c975-43c4-b6d5-2ad3dd7c3054":{"favIconUrl":"fallback","id":"696315cf-c975-43c4-b6d5-2ad3dd7c3054","title":"Welcome to the UvA Deep Learning Tutorials! — UvA DL Notebooks v1.2 documentation","url":"https://uvadlc-notebooks.readthedocs.io/en/latest/index.html","urlHash":3784638194},"6983b034-22f3-4200-bef1-ccbee2b6a524":{"favIconUrl":"https://blog.langchain.dev/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png","id":"6983b034-22f3-4200-bef1-ccbee2b6a524","title":"LangGraph: Multi-Agent Workflows","url":"https://blog.langchain.dev/langgraph-multi-agent-workflows/","urlHash":3789460997},"699423e2-8053-4584-bb87-73de0013b8a8":{"favIconUrl":"fallback","id":"699423e2-8053-4584-bb87-73de0013b8a8","title":"Are All Spurious Features in Natural Language Alike? An Analysis through a Causal Lens - Arxiv-2210.14011","url":"https://arxiv.org/abs/2210.14011","urlHash":2488476394},"69d85cc5-2eac-487c-891a-3ce78f6648f7":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"69d85cc5-2eac-487c-891a-3ce78f6648f7","title":"语言模型输出端共享Embedding的重新探索 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/9698","urlHash":2323571588},"69e68e65-c8fe-497c-8ecb-85cefb39aff7":{"favIconUrl":"fallback","id":"69e68e65-c8fe-497c-8ecb-85cefb39aff7","title":"DiffCSE Difference-based Contrastive Learning for Sentence Embeddings - Arxiv-2204.10298","url":"https://arxiv.org/pdf/2204.10298.pdf","urlHash":3097315436},"69fec033-de23-4315-bc5d-a78db0da58b6":{"favIconUrl":"fallback","id":"69fec033-de23-4315-bc5d-a78db0da58b6","title":"《呼吸》各篇短评（呼吸）书评","url":"https://book.douban.com/review/12163001/","urlHash":3154311496},"6a28bf08-429f-41c0-bcc3-7ebb520e0d95":{"favIconUrl":"https://cdn.semanticscholar.org/3cf37988806f7507/img/darkmode/favicon-32x32.png","id":"6a28bf08-429f-41c0-bcc3-7ebb520e0d95","title":"[PDF] LoRA Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B | Semantic Scholar","url":"https://www.semanticscholar.org/paper/LoRA-Fine-tuning-Efficiently-Undoes-Safety-Training-Lermen-Rogers-Smith/d1b5151231a790c7a60f620e21860593dae9a1c5","urlHash":1770041773},"6a2d4756-1c6b-42e8-bc6e-5fb75e8e220a":{"favIconUrl":"fallback","id":"6a2d4756-1c6b-42e8-bc6e-5fb75e8e220a","title":"A Survey of Data Augmentation Approaches for NLP - Arxiv-2105.03075","url":"https://arxiv.org/pdf/2105.03075.pdf","urlHash":2350645151},"6a597d87-23ea-4d9a-a290-9b4bd91044eb":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"6a597d87-23ea-4d9a-a290-9b4bd91044eb","title":"Birth of a Transformer: A Memory Viewpoint | PDF","url":"https://arxiv.org/pdf/2306.00802.pdf","urlHash":1665012052},"6a8d9b9b-63dc-47a8-9022-d7bf19196e8d":{"favIconUrl":"fallback","id":"6a8d9b9b-63dc-47a8-9022-d7bf19196e8d","title":"Composer Creative and Controllable Image Synthesis with Composable Conditions - Arxiv-2302.09778","url":"https://arxiv.org/abs/2302.09778?utm_source=substack&utm_medium=email","urlHash":708301481},"6a93ec3d-5360-443a-a01f-8cf71976e902":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"6a93ec3d-5360-443a-a01f-8cf71976e902","title":"A Study on the Calibration of In-context Learning | PDF","url":"https://arxiv.org/pdf/2312.04021.pdf","urlHash":3045385154},"6a97ef75-f3aa-4b8e-bc16-4dab84a17aef":{"favIconUrl":"https://static.xx.fbcdn.net/rsrc.php/v3/y4/r/WUJbsVI4ruF.png","id":"6a97ef75-f3aa-4b8e-bc16-4dab84a17aef","title":"Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations | Research - AI at Meta","url":"https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/?utm_source=substack&utm_medium=email","urlHash":2464067283},"6aa03dd3-f50f-43b8-a9b1-69836e96e50e":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6aa03dd3-f50f-43b8-a9b1-69836e96e50e","title":"twitter.com/omarsar0/status/1621328054143385601","url":"https://twitter.com/omarsar0/status/1621328054143385601","urlHash":359480007},"6ad88eb1-8a76-4adf-8332-37c122fe46fd":{"favIconUrl":"fallback","id":"6ad88eb1-8a76-4adf-8332-37c122fe46fd","title":"Dirichlet Distribution, Dirichlet Process and Dirichlet Process Mixture","url":"https://www.cs.cmu.edu/~epxing/Class/10701-08s/recitation/dirichlet.pdf","urlHash":2426790625},"6ad8aa25-e0e3-4a5c-8eee-f86798bede7a":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"6ad8aa25-e0e3-4a5c-8eee-f86798bede7a","title":"Solving the Mechanistic Interpretability challenges: EIS VII Challenge 2 — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/k43v47eQjaj6fY7LE/solving-the-mechanistic-interpretability-challenges-eis-vii-1","urlHash":1749589148},"6aedf61e-be24-47fe-bba7-b539ae5d3448":{"favIconUrl":"fallback","id":"6aedf61e-be24-47fe-bba7-b539ae5d3448","title":"Unifying Flow, Stereo and Depth Estimation - Arxiv-2211.05783","url":"https://arxiv.org/abs/2211.05783","urlHash":1391783945},"6b0044a5-ed0c-4874-90d6-cf3a928bc36c":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6b0044a5-ed0c-4874-90d6-cf3a928bc36c","title":"Tanishq Mathew Abraham, Ph.D. on X: \"OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web abs: https://t.co/YuwsDcBIq3 A novel dataset of desktop and website applications consisting of over 9.8K natural language tasks, UI screens, and corresponding code snippets… https://t.co/fb8AGP1qlF\" / X","url":"https://twitter.com/iScienceLuvr/status/1762685270527267052","urlHash":3746822126},"6b02b6da-593a-4782-9cfd-be26f471beac":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"6b02b6da-593a-4782-9cfd-be26f471beac","title":"Generative Pretraining in Multimodality | Abstract","url":"https://arxiv.org/abs/2307.05222","urlHash":2965090793},"6b314714-7cf7-4c1f-8ec3-3febaaa0e32a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6b314714-7cf7-4c1f-8ec3-3febaaa0e32a","title":"Jerry Liu on X: \"The @OpenAI retrieval API seems to be doing basic top-k RAG on limited context if there's context overflows. Asking for a summary of the Uber 10-K (~150k-200k tokens), returns oddly specific stuff around acquisitions and legal proceedings 👇 https://t.co/s7GBm6y1PS\" / X","url":"https://twitter.com/jerryjliu0/status/1721987237771133219","urlHash":47784846},"6b332384-f732-4c72-a6c9-80d08b2d5a6a":{"favIconUrl":"fallback","id":"6b332384-f732-4c72-a6c9-80d08b2d5a6a","title":"Reasoning Through Memorization Nearest Neighbor Knowledge Graph Embeddings - Arxiv-2201.05575","url":"https://arxiv.org/abs/2201.05575","urlHash":3449000920},"6b5ed9d7-2c57-440f-bea0-dc5313dd3193":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6b5ed9d7-2c57-440f-bea0-dc5313dd3193","title":"Wei Ping on X: \"🔥Introducing IntructRetro 48B, which largely outperforms the instruction tuned GPT🔥 Surprisingly, we find that one can ablate the encoder from the Retro architecture and directly use it as a GPT decoder, while still obtaining comparable results on zero-shot QA tasks!\" / X","url":"https://twitter.com/_weiping/status/1712614917604577778","urlHash":3734154957},"6b5f1826-aa9a-47ee-8001-c95850b008a6":{"favIconUrl":"fallback","id":"6b5f1826-aa9a-47ee-8001-c95850b008a6","title":"Kosmos-G Generating Images in Context with Multimodal Large Language Models - Arxiv-2310.02992","url":"https://arxiv.org/abs/2310.02992?utm_source=substack&utm_medium=email","urlHash":5796372},"6b627272-4f1f-4822-9297-8cc4a469c85a":{"favIconUrl":"fallback","id":"6b627272-4f1f-4822-9297-8cc4a469c85a","title":"Guang000/Awesome-Dataset-Distillation: Awesome Dataset Distillation Papers","url":"https://github.com/Guang000/Awesome-Dataset-Distillation","urlHash":4078451489},"6b69670a-0281-45bd-87fa-70efc1dcde9b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6b69670a-0281-45bd-87fa-70efc1dcde9b","title":"Jason Weston on X: \"🚨 Introducing Branch-Train-miX (BTX) 🚨 BTX improves a generalist LLM on multiple fronts: - Train expert LLMs in parallel for new skills in domains such as math, code &amp; world knowledge - Join (mix) them together &amp; finetune as a Mixture-of-Experts https://t.co/7I2sCBnsNB 🧵(1/4) https://t.co/GL4YDrkBwv\" / X","url":"https://twitter.com/jaseweston/status/1767727740952682667?utm_source=substack&utm_medium=email","urlHash":3296865063},"6b75f4ab-34bf-4f7d-a0e6-18079e8e685b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6b75f4ab-34bf-4f7d-a0e6-18079e8e685b","title":"twitter.com/jd92wang/status/1652640799056875520","url":"https://twitter.com/jd92wang/status/1652640799056875520","urlHash":3183012169},"6b776c15-a1be-4d3d-b095-b94d633727d4":{"favIconUrl":"fallback","id":"6b776c15-a1be-4d3d-b095-b94d633727d4","title":"An Overview of Deep Learning for Curious People","url":"https://lilianweng.github.io/posts/2017-06-21-overview/","urlHash":3610103744},"6b8ace50-8169-4fe2-aa69-d9ebe2f91355":{"favIconUrl":"fallback","id":"6b8ace50-8169-4fe2-aa69-d9ebe2f91355","title":"SGD on Neural Networks Learns Functions of Increasing Complexity - Arxiv-1905.11604","url":"https://arxiv.org/pdf/1905.11604.pdf","urlHash":1607614349},"6ba3e731-692a-4325-a21d-d7e46f72c0dd":{"favIconUrl":"fallback","id":"6ba3e731-692a-4325-a21d-d7e46f72c0dd","title":"A General Language Assistant as a Laboratory for Alignment","url":"https://arxiv.org/pdf/2112.00861.pdf","urlHash":1669477032},"6babff64-cbdc-445e-b0fc-f7724d0b146d":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6babff64-cbdc-445e-b0fc-f7724d0b146d","title":"Quanquan Gu on X: \"I've noticed an increasing number of signs indicating a strong correlation between RL and LLMs, suggesting they might eventually converge.\" / X","url":"https://twitter.com/QuanquanGu/status/1731344290230702300","urlHash":70552973},"6bc08b3e-c829-4be0-9a0a-f8f76f57a3a0":{"favIconUrl":"fallback","id":"6bc08b3e-c829-4be0-9a0a-f8f76f57a3a0","title":"Unsupervised Semantic Segmentation by Distilling Feature Correspondences - Arxiv-2203.08414","url":"https://arxiv.org/abs/2203.08414","urlHash":1693148194},"6bd6c6a2-b945-4ded-a878-cca33d528087":{"favIconUrl":"fallback","id":"6bd6c6a2-b945-4ded-a878-cca33d528087","title":"Scaling Transformer to 1M tokens and beyond with RMT - Arxiv-2304.11062","url":"https://arxiv.org/abs/2304.11062?utm_source=substack&utm_medium=email","urlHash":1336907184},"6c3de9e3-ac6f-41d7-8be8-d0f7d52c0977":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"6c3de9e3-ac6f-41d7-8be8-d0f7d52c0977","title":"Learning by Distilling Context | PDF","url":"https://arxiv.org/pdf/2209.15189.pdf","urlHash":2102233860},"6c66fb8d-5263-45bc-8442-b196654af675":{"favIconUrl":"fallback","id":"6c66fb8d-5263-45bc-8442-b196654af675","title":"卡尔维诺的《分成两半的子爵》好在哪里？ - 知乎","url":"https://www.zhihu.com/question/66794537","urlHash":605504746},"6c6c59a4-62b0-42b3-9fe0-7a15acd4135c":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6c6c59a4-62b0-42b3-9fe0-7a15acd4135c","title":"elvis on X: \"Get Insights From Your Data with Data LLM This is a neat blog post discussing an LLM-powered solution to find actionable insights using your data. Here is a quick summary: Why LLMs? - LLMs power key features like understanding user query intent, fetching knowledge, generating… https://t.co/Nuo8XhxdES\" / X","url":"https://twitter.com/omarsar0/status/1695113644416147877","urlHash":85089080},"6c6cf695-49f2-4b11-8f81-78cfc56a4c00":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"6c6cf695-49f2-4b11-8f81-78cfc56a4c00","title":"LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding | PDF","url":"https://arxiv.org/pdf/2308.14508.pdf","urlHash":4266085658},"6c8bda29-80b8-424e-b81f-2be064bab38a":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"6c8bda29-80b8-424e-b81f-2be064bab38a","title":"RvS: What is Essential for Offline RL via Supervised Learning? | Abstract","url":"https://arxiv.org/abs/2112.10751","urlHash":1500255075},"6c9bdaed-a5d4-4650-a8e6-3a0834445d3c":{"favIconUrl":"fallback","id":"6c9bdaed-a5d4-4650-a8e6-3a0834445d3c","title":"Language Model Augmented Relevance Score - Arxiv-2108.08485","url":"https://arxiv.org/pdf/2108.08485.pdf","urlHash":1519368269},"6c9cb724-d419-410e-ad1f-c2d92072c812":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6c9cb724-d419-410e-ad1f-c2d92072c812","title":"Aran Komatsuzaki on X: \"RLCD: Reinforcement Learning from Contrast Distillation for Language Model Alignment - Proposes a method for aligning LMs to follow natural language principles without using human feedback - Outperforms RLAIF and context distillation baselines. https://t.co/TFY2kPrRal https://t.co/fJKw3LAfdc\" / X","url":"https://twitter.com/arankomatsuzaki/status/1683650121186021378","urlHash":2887055090},"6ca619c4-cc83-47db-9a98-98267f75b41b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6ca619c4-cc83-47db-9a98-98267f75b41b","title":"Costa Huang on X: \"Thanks to @masud99r, @cleanrl_lib has a new algorithm called Robust Policy Optimization — 5 lines of code change to PPO to get better performance in 57 out of 61 continuous action envs 🚀 (e.g., dm_control) 📜docs: https://t.co/TyZQkmn7b3 💾code: https://t.co/4rdCjkcIwo 👇 https://t.co/sFpBN6hGeO\" / X","url":"https://twitter.com/vwxyzjn/status/1617561414276898822","urlHash":2442731580},"6ca676a0-86d0-40a5-9351-ae7507218c18":{"favIconUrl":"fallback","id":"6ca676a0-86d0-40a5-9351-ae7507218c18","title":"下一个GAN？OpenAI提出可逆生成模型Glow","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650745032&idx=1&sn=a889433dd4c4d9f62bfab347909d9d28&chksm=871aecb6b06d65a02625abdf4b21a2116251e311a49508db587b76ae8f76d7a9e03d4a6ab80a&scene=27#wechat_redirect","urlHash":726670522},"6cae0277-cf5e-4cb9-8a0f-7a51d8856214":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6cae0277-cf5e-4cb9-8a0f-7a51d8856214","title":"Kianté Brantley on X: \"New paper! Learning to Generate Better Than Your LLM (https://t.co/D3n7PIpYHK) RLHF has become a powerful paradigm for fine-tuning LLM, but we only use general-purpose RL algorithms. We introduce new algorithmic paradigm that takes advantage of additional feedback for learning.\" / X","url":"https://twitter.com/xkianteb/status/1674892973878681602","urlHash":657380278},"6ccb5da5-8f5b-4478-b1cf-808f9f3f99bc":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"6ccb5da5-8f5b-4478-b1cf-808f9f3f99bc","title":"大模型为啥这么慢，原来是想多了：新方向是和人一样的思维算法","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650890037&idx=3&sn=9284d03df731ea4b3defc334081c5ad1&chksm=84e49b4bb393125df2bd2f4098b4461fd915c7d465bee1939a0cc70523be9c55c7d2e12d79b9&mpshare=1&scene=1&srcid=1001CfA0Nl7kiBoHfEgrV5dG&sharer_shareinfo=72cb0c267568eac5d1b4e21272da070f&sharer_shareinfo_first=72cb0c267568eac5d1b4e21272da070f&exportkey=n_ChQIAhIQvN%2B6s7vVVem4w0n16pq6dxKWAgIE97dBBAEAAAAAANKtAwAou44AAAAOpnltbLcz9gKNyK89dVj0k7lNtt4du1irFJAhFw68B5WlpmCOswal0gEi1jxasgI5xKcjLWVm4Xtof%2FrIjt3xiTwARIWRlBYF47dib0ojSwiLft89IqB6f5BGksvxIfV4X4WDHNdq0T6rBbc6n7jam0tJ30x1FYFaDYvD7pIECozp1DH%2FfZbpvPOfpeNyaMBqHu8p3oDjQw22ADOhCT0orFemBX0u%2FLFd05uoqvdBAYOCMiQUXBVhC8XqEFYG8sM10BJZZ4waAgvU1SOdcuS2MB2oAATCLCaBhv7KBJakBVe8kDWfWb4lk1wzmQeWlXyBAB5%2FVNae1dQZAG0ZigNt&acctmode=0&pass_ticket=e0JF3r33bJl67iQhpvByopZH7ntkPbLd%2Fy%2B5Nzq0lmdkMJU1tG3Gjb%2BburtmgU6E&wx_header=0#rd","urlHash":417582620},"6cfbdc2f-380e-4a8d-bd7c-578012d6c72a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6cfbdc2f-380e-4a8d-bd7c-578012d6c72a","title":"twitter.com/arankomatsuzaki/status/1684209212291784707","url":"https://twitter.com/arankomatsuzaki/status/1684209212291784707","urlHash":2840140572},"6d0a4767-5b8e-4deb-bdbf-6c58bfeba10a":{"favIconUrl":"fallback","id":"6d0a4767-5b8e-4deb-bdbf-6c58bfeba10a","title":"如何解读芥川龙之介的《地狱变》一文？ - 知乎","url":"https://www.zhihu.com/question/22198714","urlHash":3431546451},"6d15b2a7-2b97-4ded-a082-06ce42082f74":{"favIconUrl":"fallback","id":"6d15b2a7-2b97-4ded-a082-06ce42082f74","title":"Hands-on Bayesian Neural Networks -- a Tutorial for Deep Learning Users - Arxiv-2007.06823","url":"https://arxiv.org/abs/2007.06823","urlHash":4101505683},"6d1740a0-ebdc-44aa-a2e8-ec4820e1e7d4":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"6d1740a0-ebdc-44aa-a2e8-ec4820e1e7d4","title":"(2) Da Yin on X: \"Human will succeed after failure. Why not LLM agents?🤔️ Check out 🤖ETO, an LLM agent learning method continually exploring envs to learn from failures and optimize agent decisions. ❤️Great thanks for awesome Yifan, @xiangyue96, @jefffhj, Prof. Sujian Li, and @billyuchenlin !\" / X","url":"https://twitter.com/Wade_Yin9712/status/1765589522275062024","urlHash":4269695132},"6d32735e-2dea-4df5-8c20-5c156de31143":{"favIconUrl":"https://ruishu.io/assets/img/prof_pic.png","id":"6d32735e-2dea-4df5-8c20-5c156de31143","title":"An Homage to REINFORCE | Rui Shu","url":"https://ruishu.io/2024/03/09/reinforce/","urlHash":133875575},"6d570b7b-1209-479d-8d0c-6d9611057c5c":{"favIconUrl":"fallback","id":"6d570b7b-1209-479d-8d0c-6d9611057c5c","title":"dvlab-research/LBGAT: Learnable Boundary Guided Adversarial Training (ICCV2021)","url":"https://github.com/dvlab-research/LBGAT","urlHash":807722385},"6d76aee7-c49c-4289-a2fe-4375ef6a15f1":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"6d76aee7-c49c-4289-a2fe-4375ef6a15f1","title":"香港大学发布思维扩散DoT，让思维在时间上扩散，提效保质！","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247576559&idx=3&sn=ef5bb56039011d77fe3d03f800758e2e&chksm=970e8339a0790a2f4227c4162f4aac5d8c59d4206f562e0bdb4d9687fd47a12024ca59b50573&mpshare=1&scene=1&srcid=0303Gb7qwZTPGuyXXbaQ7hlt&sharer_shareinfo=58c278c806853232a5de9eef7d146e7b&sharer_shareinfo_first=58c278c806853232a5de9eef7d146e7b&exportkey=n_ChQIAhIQXO%2BeXqC%2BZ7l5g82opPOyzxKWAgIE97dBBAEAAAAAAHOZBZwHOPYAAAAOpnltbLcz9gKNyK89dVj0NAtDvlmm212qc9GzrI%2FIVDIGz8fr4yS7VWXDAVwaZbZWRSD0p1Cckw62thAngNtHhiJznqHPbrmxwl3yh3T7RZMcONkxb6U1osfX0d%2FVea%2FOZct7GptyG8Ra51sI7YiIGgcoBzct%2BzPT4m4usmPTBkqPMw1P1uP7kKAtc%2FXzt%2F%2FZmlqvef%2BEsPi5dWzgp%2FdCsiGnNPFxtVI0GbGG4U4QqrC9JlESGAgRPtClZ83A%2B4XQYgr9Q0mABB6WrQMh4dZ%2BmncuHuLreOm61y09eph25wLsAYMtiKdQn%2FLGyeLAYNTcKraLHbT85kgcecb%2FKS%2FY&acctmode=0&pass_ticket=2PIOTp07NumM73b6%2BDXCh%2BnkNx8%2F1ykJABKPHCCPJcOlCtq1GL4VTRLgrpL4ALho5Q%2B7v4QUCT1N%2B50zAcqd%2Bg%3D%3D&wx_header=0#rd","urlHash":3124045233},"6dcd2051-3342-4d99-a4c0-c59bf95731e9":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"6dcd2051-3342-4d99-a4c0-c59bf95731e9","title":"Effective Long-Context Scaling of Foundation Models | PDF","url":"https://arxiv.org/pdf/2309.16039.pdf","urlHash":4045949250},"6de53084-bbf4-4b4a-a416-74ed469c905b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"6de53084-bbf4-4b4a-a416-74ed469c905b","title":"Sean Welleck on X: \"I was honored to give a talk at UW Mathematics on \"Language models and formal mathematics\", covering: - Neural theorem proving tutorial: https://t.co/zv67aqz3OG - LLMstep: https://t.co/2cYFj6u2Sj - Llemma: https://t.co/n0OXQcNURL Slides are here! https://t.co/9gCmLSQCRH https://t.co/TUHJ0Y32s4\" / X","url":"https://twitter.com/wellecks/status/1733900514335867379","urlHash":2444401157},"6e1fcad9-5a42-4539-9336-6116101eb707":{"favIconUrl":"fallback","id":"6e1fcad9-5a42-4539-9336-6116101eb707","title":"Multi-Concept Customization of Text-to-Image Diffusion - Arxiv-2212.04488","url":"https://arxiv.org/pdf/2212.04488.pdf","urlHash":3043456552},"6e2d094f-20de-4a69-9f6f-fa85935ce7ea":{"favIconUrl":"fallback","id":"6e2d094f-20de-4a69-9f6f-fa85935ce7ea","title":"自监督对比学习（Contrastive Learning）综述+代码 - 知乎","url":"https://zhuanlan.zhihu.com/p/334732028","urlHash":1462917081},"6e3e438c-94cb-4863-894e-436cafc1b225":{"favIconUrl":"https://www.99csw.com/favicon.ico","id":"6e3e438c-94cb-4863-894e-436cafc1b225","title":"把自己推理成凶手的名侦探·Stupid Detective_亮亮_在线阅读_九九藏书网","url":"https://www.99csw.com/book/8174/index.htm","urlHash":2562253799},"6e480d3e-cec1-4a37-ab19-3ed010d339d9":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"6e480d3e-cec1-4a37-ab19-3ed010d339d9","title":"Did You Read the Instructions? Rethinking the Effectiveness of Task Definitions in Instruction Learning | PDF","url":"https://arxiv.org/pdf/2306.01150.pdf","urlHash":3121664878},"6e6c0e64-e987-4f9c-b8eb-0ee822fc446c":{"favIconUrl":"fallback","id":"6e6c0e64-e987-4f9c-b8eb-0ee822fc446c","title":"YOLOv5 Documentation","url":"https://docs.ultralytics.com/","urlHash":3382018376},"6e9e5065-a29c-4ae7-88dd-be547578b3e7":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"6e9e5065-a29c-4ae7-88dd-be547578b3e7","title":"Test-Time Adaptation via Conjugate Pseudo-labels | PDF","url":"https://arxiv.org/pdf/2207.09640.pdf","urlHash":337386967},"6eb0872f-c77b-4b46-9372-e90f12eaface":{"favIconUrl":"fallback","id":"6eb0872f-c77b-4b46-9372-e90f12eaface","title":"仅花费60美元就能破坏0.01%数据集，AI模型性能显著降低","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650869505&idx=4&sn=cd93eb4c3187ee0e363d1ddb311a1580&exportkey=n_ChQIAhIQpfAoub28AZDpvGPieAe5eRKWAgIE97dBBAEAAAAAAOsDDgsW%2BzoAAAAOpnltbLcz9gKNyK89dVj0%2BNzjo%2Fr5GjOU%2FmTeHQTC1cuysI4Ayx3fahhDRU7tFNw303H33%2FSqu8KvgE91j3iAAm9H3r1DjzJlmtTxujA0zVneQv3gV2OklPWou5gV6Ao2NOLPlU0TCUvMswNC9SwW5fvldFBDBEsMN6HeCyB%2FbNu41wn%2FCUV%2B8mK9SSbffwmIL3YXowetIVpUQcJFA5Sce%2FM5UQWEH2fAznA7gWwsczL4Q3KgqVk9O7SAaZrGauGm65jMqAQvEwGmsGpVQKl0hwW9WIV92PFZKOwZEiIRFY0zxRGhR%2BO8PKV17SmVcoE7iuRpazlucpRA4D%2B7%2Bq6F&acctmode=0&pass_ticket=DUWJdFUi1JDJOm6OXRe2ZUPZKRPw403wXxhVQ6QEDdu9B7AVKM9XasxAa2JtBdupt4tylOpaV9ISpQ0xDSoL1Q%3D%3D&wx_header=0","urlHash":919588136},"6ed1f909-d15f-4387-85bf-8846c3b02445":{"favIconUrl":"fallback","id":"6ed1f909-d15f-4387-85bf-8846c3b02445","title":"Plagiarism by ICCV 2021 paper “Learnable Boundary Guided Adversarial Training”?","url":"https://medium.com/@fahad.sarfraz/plagiarism-by-iccv-2021-paper-learnable-boundary-guided-adversarial-training-404d2ff5ed4e","urlHash":3433271951},"6f0563ab-48ab-40c2-8a8c-5d75a20d66ce":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"6f0563ab-48ab-40c2-8a8c-5d75a20d66ce","title":"What Matters In On-Policy Reinforcement Learning? A Large-Scale Empirical Study | PDF","url":"https://arxiv.org/pdf/2006.05990.pdf","urlHash":1662956202},"6f2d104a-4fc9-4351-be60-bb52a9b0b6e1":{"favIconUrl":"fallback","id":"6f2d104a-4fc9-4351-be60-bb52a9b0b6e1","title":"IGA An Intent-Guided Authoring Assistant - Arxiv-2104.07000","url":"https://arxiv.org/abs/2104.07000","urlHash":1737136473},"6f2e2377-4f40-41ad-8aa2-9e7411518aff":{"favIconUrl":"fallback","id":"6f2e2377-4f40-41ad-8aa2-9e7411518aff","title":"PCL Proxy-Based Contrastive Learning for Domain Generalization - CVPR-2022_31606908","url":"https://openaccess.thecvf.com/content/CVPR2022/papers/Yao_PCL_Proxy-Based_Contrastive_Learning_for_Domain_Generalization_CVPR_2022_paper.pdf","urlHash":2466768652},"6f36f836-9366-4237-ae53-065ce30cd7d8":{"favIconUrl":"fallback","id":"6f36f836-9366-4237-ae53-065ce30cd7d8","title":"A Fine-Grained Analysis on Distribution Shift - Arxiv-2110.11328","url":"https://arxiv.org/pdf/2110.11328.pdf","urlHash":1033394670},"6f3fdb37-6f7b-457a-b4d5-802b62bcc235":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"6f3fdb37-6f7b-457a-b4d5-802b62bcc235","title":"Reinforcement Learning from Human Feedback (RLHF) - a simplified explanation","url":"https://gist.github.com/JoaoLages/c6f2dfd13d2484aa8bb0b2d567fbf093","urlHash":2547289423},"6f75b18f-ae24-4a9e-8042-46b9b0a1e20e":{"favIconUrl":"fallback","id":"6f75b18f-ae24-4a9e-8042-46b9b0a1e20e","title":"Reddit - Dive into anything","url":"https://www.reddit.com/r/CriticalTheory/comments/27t4o2/walter_benjamins_historical_materialism/","urlHash":1723073047},"6f7e6898-cf14-4402-8bbf-0be6ed6b7ede":{"favIconUrl":"fallback","id":"6f7e6898-cf14-4402-8bbf-0be6ed6b7ede","title":"Optimizing Prompts for Text-to-Image Generation - Arxiv-2212.09611","url":"https://arxiv.org/pdf/2212.09611.pdf","urlHash":1605489194},"6fa404f6-a498-4ab7-91e5-fa527a506dff":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"6fa404f6-a498-4ab7-91e5-fa527a506dff","title":"FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation | Abstract","url":"https://arxiv.org/abs/2305.14251","urlHash":3407812757},"6fee6f47-d5a1-464a-a899-3e0db4668a6e":{"favIconUrl":"fallback","id":"6fee6f47-d5a1-464a-a899-3e0db4668a6e","title":"ER-TEST Evaluating Explanation Regularization Methods for NLP Models - Arxiv-2205.12542","url":"https://arxiv.org/pdf/2205.12542.pdf","urlHash":122371047},"6ff02d65-8d49-4648-9553-9c8940adbfdb":{"favIconUrl":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA99JREFUeNrsG4t1ozDMzQSM4A2ODUonKBucN2hugtIJ6E1AboLcBiQTkJsANiAb9OCd/OpzMWBJBl5TvaeXPiiyJetry0J8wW3D3QpjRh3GjneXDq+fSQA9s2mH9x3KDhN4foJfCb8N/Jrv+2fnDn8vLRQOplWHVYdvHZYdZsBcZP1vBmh/n8DzEmhUQDPaOuP9pFuY+JwJHwHnCLQE2tnWBGEyXozY9xCUgHMhhjE2I4heVWtgIkZ83wL6Qgxj1obfWBxymPwe+b00BCCRNPbwfb60yleAkkBHGT5AEehIYz7eJrFDMF9CvH4wwhcGHiHMneFvLDQwlwvMLQq58trRcYBWfYn0A0OgHWQUSu25mE+BnoYKnnEJoeIWAifzOv7vLWd2ZKRfWAIme3tOiUaQ3UnLkb0xj1FxRIeEGKaGIHOs9nEgLaaA9i0JRYo1Ic67wJW86KSKE/ZAM8KuVMk8ITVhmxUxJ3Cl2xlm9Vtkeju1+mpCQNxaEGNCY8bs9X2YqwNoQeGjBWut/ma0QAWy/TqAsHx9wSya3I5IRxOfTC+leG+kA/4vSeEcGBtNUN6byhu3+keEZCQJUNh8MAO7HL6H8pQLnsW/Hd4T4lv93TPjfM7A46iEEqbB5EDOvwYNW6tGNZzT/o+CZ6sqZ6wUtR/wf7mi/VL8iNciT6rHih48Y55b4nKCHJCCzb4y0nwFmin3ZEMIoLfZF8F7nncFmvnWBaBj7CGAYA/WGJsUwHdYqVDwAmNsUgAx4CGgAA7GOOxADYOFWOaIKifuVYzmOpREqA21Mo7aPsgiY1PhOMAmxtR+AUbYH3Id2wc0SAFIQTsn9IUGWR8k9jx3vtXSiAacFxTAGakBk9UudkNECd6jLe+6HrshshvIuC6IlLMRy7er+JpcKma24SlE4cFZSZJDGVVrsNvitQhQrDhW0jfiOLfFd47C42eHT56D/BK0To+58Ahj+cAT8HT1UWlfLZCCd/uKawzU0Rh2EyIX/Icqth3niG8ybNroezwe6khdCNxRN+l4XGdOLVLlOOt2hTRJlr1ETIuMAltVTMz70mJrkdGAaZLSmnBEqmAE32JCMmuTlCnRgsBENtOUpHhvvsYIL0ibnBkaC6QvKcR7738GKp0AKnim7xgUSNv1bpS8QwhBt8r+EP47v/oyRK/S34yJ9nT+AN0Tkm4OdB9E4BsmXM3SnMlRFUrtp6IDpV2eKzdYvF3etm3KhQksbOLChGkSmcBdmcEwvqkrMy5BzL00NZeu3qPYJOOuCc+5NjcWKXQxFvTa3NoXJ4d8in7fiAUuTt781dkvuHX4K8AA2Usy7yNKLy0AAAAASUVORK5CYII=","id":"6ff02d65-8d49-4648-9553-9c8940adbfdb","title":"Experiments in Handwriting with a Neural Network","url":"https://distill.pub/2016/handwriting/","urlHash":2755513387},"701958a1-3dac-493f-991d-4ea701013f69":{"favIconUrl":"fallback","id":"701958a1-3dac-493f-991d-4ea701013f69","title":"Archive - Deep (Learning) Focus","url":"https://cameronrwolfe.substack.com/archive?sort=new","urlHash":2159402685},"706632eb-6e92-4fae-9c78-3082fd58ce82":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"706632eb-6e92-4fae-9c78-3082fd58ce82","title":"Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples | PDF","url":"https://arxiv.org/pdf/2302.04578.pdf","urlHash":3729238711},"7092251d-84e0-47e7-b78d-8b40c996b2ca":{"favIconUrl":"https://www.google.com/favicon.ico","id":"7092251d-84e0-47e7-b78d-8b40c996b2ca","title":"送葬列车 - Google Search","url":"https://www.google.com/search?q=%E9%80%81%E8%91%AC%E5%88%97%E8%BD%A6","urlHash":4056762495},"709ded56-8dd0-4f9a-ae2c-bb74aae5589f":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"709ded56-8dd0-4f9a-ae2c-bb74aae5589f","title":"Jiao Wenxiang on X: \"Good to see this! We also have similar observations in our practice. 🧐 - LLMs exhibit severe positional bias, compromising their fairness as evaluators - Two simple yet effective strategies to calibrate the positional bias of LLMs https://t.co/O9BCygq0cv https://t.co/08p5p4AsjT\" / X","url":"https://twitter.com/WenxiangJiao/status/1663358770557374465","urlHash":357975046},"70c915cf-3251-4fd4-b1c3-d467061b4440":{"favIconUrl":"https://www.google.com/favicon.ico","id":"70c915cf-3251-4fd4-b1c3-d467061b4440","title":"早坂吝『しおかぜ市一家殺害事件 あるいは迷宮牢の殺人』 - Google Search","url":"https://www.google.com/search?q=%E6%97%A9%E5%9D%82%E5%90%9D%E3%80%8E%E3%81%97%E3%81%8A%E3%81%8B%E3%81%9C%E5%B8%82%E4%B8%80%E5%AE%B6%E6%AE%BA%E5%AE%B3%E4%BA%8B%E4%BB%B6+%E3%81%82%E3%82%8B%E3%81%84%E3%81%AF%E8%BF%B7%E5%AE%AE%E7%89%A2%E3%81%AE%E6%AE%BA%E4%BA%BA%E3%80%8F&sourceid=chrome&ie=UTF-8","urlHash":2194547739},"7126e701-0fe1-4898-825e-7670ec13561a":{"favIconUrl":"fallback","id":"7126e701-0fe1-4898-825e-7670ec13561a","title":"nvidia-superni-talk","url":"https://danielkhashabi.com/files/2022_super_natural_instructions/nvidia-superni-talk.pdf","urlHash":3408379894},"7127064a-a759-4213-9094-aaa87c1ddcbc":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"7127064a-a759-4213-9094-aaa87c1ddcbc","title":"Origin Tracing and Detecting of LLMs | PDF","url":"https://arxiv.org/pdf/2304.14072.pdf","urlHash":2874640002},"7132a6c2-b9ea-4033-9b13-69a002c9029f":{"favIconUrl":"fallback","id":"7132a6c2-b9ea-4033-9b13-69a002c9029f","title":"Finding and Fixing Undesirable Behaviors in Pretrained Language Models - ProQuest","url":"https://www.proquest.com/openview/17b48d375b45931f6739a01f9086d6b0/1?pq-origsite=gscholar&cbl=18750&diss=y","urlHash":3572724303},"714da372-dc29-417d-a35f-ae62841b55d8":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"714da372-dc29-417d-a35f-ae62841b55d8","title":"S-LoRA: Serving Thousands of Concurrent LoRA Adapters | Abstract","url":"https://arxiv.org/abs/2311.03285v2?utm_source=substack&utm_medium=email","urlHash":1621909433},"71ce53ff-0c45-46bd-9f3e-a8d652484464":{"favIconUrl":"fallback","id":"71ce53ff-0c45-46bd-9f3e-a8d652484464","title":"metapoison/main.py at master · wronnyhuang/metapoison","url":"https://github.com/wronnyhuang/metapoison/blob/master/main.py","urlHash":3277279508},"71eeee39-a0f8-482f-a2cb-69052fa7f785":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"71eeee39-a0f8-482f-a2cb-69052fa7f785","title":"(2) AK on X: \"Microsoft presents The Era of 1-bit LLMs All Large Language Models are in 1.58 Bits Recent research, such as BitNet, is paving the way for a new era of 1-bit Large Language Models (LLMs). In this work, we introduce a 1-bit LLM variant, namely BitNet b1.58, in which every single… https://t.co/2PlQ8ePLDR\" / X","url":"https://twitter.com/_akhaliq/status/1762729757454618720?utm_source=substack&utm_medium=email","urlHash":1050646338},"71f061ae-8540-4f8d-8fd6-3c26d0f069c1":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"71f061ae-8540-4f8d-8fd6-3c26d0f069c1","title":"Instruction Tuning for Large Language Models: A Survey | Abstract","url":"https://arxiv.org/abs/2308.10792?utm_source=substack&utm_medium=email","urlHash":1027920023},"72167a42-e08f-4c43-993e-3e845313a6d5":{"favIconUrl":"fallback","id":"72167a42-e08f-4c43-993e-3e845313a6d5","title":"作为意欲和表象的世界（第2卷） (豆瓣)","url":"https://book.douban.com/subject/35703665/","urlHash":1921454394},"72601d89-abc8-4732-b03c-c63cc67d4b95":{"favIconUrl":"fallback","id":"72601d89-abc8-4732-b03c-c63cc67d4b95","title":"6.S898 Deep Learning, Fall 2022","url":"https://phillipi.github.io/6.s898/#schedule","urlHash":1178890263},"7284c80c-c99e-45e0-bc80-91d47ecaa84b":{"favIconUrl":"fallback","id":"7284c80c-c99e-45e0-bc80-91d47ecaa84b","title":"Understanding Contrastive Learning Requires Incorporating Inductive Biases - PMLR-2022-saunshi22a","url":"https://proceedings.mlr.press/v162/saunshi22a/saunshi22a.pdf","urlHash":1525173266},"728ba7ad-74c3-45dc-a6e7-542c9d7c5c8f":{"favIconUrl":"fallback","id":"728ba7ad-74c3-45dc-a6e7-542c9d7c5c8f","title":"generalized inner loop meta-learning - Google Search","url":"https://www.google.com/search?q=generalized+inner+loop+meta-learning&oq=generalized+inner+loop+&aqs=chrome.0.0i512j69i57.2930j0j1&sourceid=chrome&ie=UTF-8","urlHash":2409011704},"72aaf879-26b7-4c82-a2e7-1b311b167d45":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"72aaf879-26b7-4c82-a2e7-1b311b167d45","title":"Aran Komatsuzaki on X: \"Scaling Laws of Synthetic Images for Model Training ... for Now Studies the scaling laws of synthetic images generated by SotA text-to-image models, for the training of supervised models repo: https://t.co/gDcU1bQ3cw abs: https://t.co/YG34WQY36x https://t.co/eGg0cpcC6T\" / X","url":"https://twitter.com/arankomatsuzaki/status/1732946264839324024","urlHash":3730388926},"72acbc26-0334-488b-84c8-c23c62706194":{"favIconUrl":"fallback","id":"72acbc26-0334-488b-84c8-c23c62706194","title":"分类 数学研究 下的文章 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/category/Mathematics/2/","urlHash":2141672512},"72b83e96-9218-402b-b3bb-fbf80bb2ac95":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/badged-favicon-32x32.png","id":"72b83e96-9218-402b-b3bb-fbf80bb2ac95","title":"(7) Incredible results with Long Agent Tree Search with open source models : LocalLLaMA","url":"https://www.reddit.com/r/LocalLLaMA/comments/1903auj/incredible_results_with_long_agent_tree_search/","urlHash":3631901574},"72bf3ab3-fa2d-46aa-8be2-a2558db7216e":{"favIconUrl":"fallback","id":"72bf3ab3-fa2d-46aa-8be2-a2558db7216e","title":"Scaling Transformer to 1M tokens and beyond with RMT - Arxiv-2304.11062","url":"https://arxiv.org/pdf/2304.11062.pdf","urlHash":1743782834},"72c9c8af-3b32-451e-90c2-271e13a3b073":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"72c9c8af-3b32-451e-90c2-271e13a3b073","title":"Logits of API-Protected LLMs Leak Proprietary Information | PDF","url":"https://arxiv.org/pdf/2403.09539.pdf","urlHash":1930563854},"72cb856f-9139-4e21-aab8-22466ddcf8e2":{"favIconUrl":"https://blog.langchain.dev/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png","id":"72cb856f-9139-4e21-aab8-22466ddcf8e2","title":"Human-in-the-loop with OpenGPTs and LangGraph","url":"https://blog.langchain.dev/human-in-the-loop-with-opengpts-and-langgraph/","urlHash":4167934597},"72e52a3e-0557-45c3-8443-c00cea1c937e":{"favIconUrl":"fallback","id":"72e52a3e-0557-45c3-8443-c00cea1c937e","title":"GDL - Regular Group Convolutions — UvA DL Notebooks v1.2 documentation","url":"https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/Geometric_deep_learning/tutorial1_regular_group_convolutions.html","urlHash":1359718619},"72ea5fbc-a28b-4e39-ac45-c7d7b57bc748":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"72ea5fbc-a28b-4e39-ac45-c7d7b57bc748","title":"twitter.com/arankomatsuzaki/status/1724611226540421294","url":"https://twitter.com/arankomatsuzaki/status/1724611226540421294","urlHash":2155756239},"72ead16f-f75c-4008-8383-3a7a5f1cdec3":{"favIconUrl":"fallback","id":"72ead16f-f75c-4008-8383-3a7a5f1cdec3","title":"2022出圈的ML研究：爆火的Stable Diffusion、通才智能体Gato，LeCun转推","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650864503&idx=1&sn=ce2ee0ef67b5dbb3a5d317876fe6c4ee&chksm=84e53f09b392b61fd147a882c62182fc763c5a3b277088034bee6f7fe7f688f326cee51d05d5&mpshare=1&scene=1&srcid=0116IbftODk0hCiCpDtSZbCW&sharer_sharetime=1673842915752&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQNxXIXhvBYUSYqYAIcEMMGRKWAgIE97dBBAEAAAAAAHfeIrYeodAAAAAOpnltbLcz9gKNyK89dVj0FRXdhxZDWMBJ7xf76hktqTo5Mpc2kfAJ%2B4BXC3zFWKTYtba9X8ERBv4D89j7ztJFvs14NSAntweIt3IDMeXb00l%2BqXFVh6tCIGXFpuPKTL2hFB29bPs4HY8peLBZMxf%2BkZ7Jl%2BsUgcRJbwRTA7W7FhNPdEvwoQXXxzuZ4yF21bhyBjGCl9hkA96JzgMIO5zPyDC8b0LlxLePuuVeRQ%2FODNnJ2z%2FuN%2FM3lRjGsUWFSAQaOp1Gd31DH7Mn%2BEB8JBpZb%2BwQmQ7jSQeVYTw6R2YAjgTDtCNhikrHGW0cy%2Fe7DovtC391XqM9Prj46rfuYkSA&acctmode=0&pass_ticket=3HIlKyjzTAFL%2FxFljj2tEtyLfkTobYOBU23FblbSLUryiXQKeukyC1UTESVF%2FQzmPV58UkgRAhOEPkiHbp%2ByKg%3D%3D&wx_header=0#rd","urlHash":750041789},"73220080-5390-434b-9865-64b7a6bdf782":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"73220080-5390-434b-9865-64b7a6bdf782","title":"Larger language models do in-context learning differently | Abstract","url":"https://arxiv.org/abs/2303.03846","urlHash":3476548560},"7364a866-dd2d-41cc-a2f7-ef4f68bb5194":{"favIconUrl":"https://ssl.gstatic.com/colaboratory-static/common/36baee5adf8280432ec6933ecf0d0196/img/favicon.ico","id":"7364a866-dd2d-41cc-a2f7-ef4f68bb5194","title":"TransformerPuzzlers.ipynb - Colaboratory","url":"https://colab.research.google.com/github/srush/Transformer-Puzzles/blob/main/TransformerPuzzlers.ipynb#scrollTo=e69995ed","urlHash":1507953424},"73977942-0a40-49e3-a068-8f538087fe3f":{"favIconUrl":"fallback","id":"73977942-0a40-49e3-a068-8f538087fe3f","title":"图灵奖大佬+谷歌团队，为通用人工智能背书！CV 任务也能用 LM 建模！","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247519625&idx=1&sn=2ad9d58f8626c18ec7ef5bcd0e75d11e&exportkey=n_ChQIAhIQkHIV%2Fyg6LrO5CI%2BXFvTYAhKWAgIE97dBBAEAAAAAAKRAM8n0uJYAAAAOpnltbLcz9gKNyK89dVj0XCv066TM0ehUIpIgLZlOpj4G59QZckJT5wQaXur8Zz2s0vn6JdCfQlPt0JLudXA%2BZcLJLR4ufgsxqzqScI380nfPYbhWyk9Np6j0VxKrd0VcX%2BS%2FTVw8DupJEI5fRN7m1rPZPNo1S6epLNNaJr1U0mLafkcIxNdbKq7ZEHASwtQSG3uNJJF4IPzuGeWRQ%2BGAfmp1bDwPBj1rMTKhTdOwjdbmN8pUdiOtqC5RQAU%2FUvTmZPQZlouGdwYBV%2BAWv%2BCpXG9QfTm6i5HLKUwoJiKu%2BK4c3XIfPJgyLHXhtJ%2Bb6HdcX3BscdwcbKbJ4N0Ojzu3&acctmode=0&pass_ticket=dk1%2BYeI9KcxVieaewIrrrbKjqtemDbE%2BLsWThaEB6q3bdWILo60AnKxtn2MfZTE3&wx_header=0","urlHash":994394728},"73be16cb-7439-4979-8247-c906cecfd346":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"73be16cb-7439-4979-8247-c906cecfd346","title":"Agent Instructs Large Language Models to be General Zero-Shot Reasoners | PDF","url":"https://arxiv.org/pdf/2310.03710.pdf","urlHash":3006955494},"740c5cea-352b-4825-bea2-42c4035c068c":{"favIconUrl":"https://www.jmlr.org/favicon.ico","id":"740c5cea-352b-4825-bea2-42c4035c068c","title":"20-1316.pdf","url":"https://www.jmlr.org/papers/volume22/20-1316/20-1316.pdf","urlHash":3121968611},"7434fd61-c787-4c32-aee6-a13beca0b81f":{"favIconUrl":"fallback","id":"7434fd61-c787-4c32-aee6-a13beca0b81f","title":"Masked Language Modeling and the Distributional Hypothesis Order Word Matters Pre-training for Little - Arxiv-2104.06644","url":"https://arxiv.org/abs/2104.06644","urlHash":1665555854},"747d43ab-9026-494d-9cf5-a699ad51cae0":{"favIconUrl":"fallback","id":"747d43ab-9026-494d-9cf5-a699ad51cae0","title":"Leveraging Language to Learn Program Abstractions and Search Heuristics - PMLR-2021-wong21a","url":"http://proceedings.mlr.press/v139/wong21a.html","urlHash":4072935473},"748d0a1b-e506-4bb1-8127-46bbdc889a9e":{"favIconUrl":"fallback","id":"748d0a1b-e506-4bb1-8127-46bbdc889a9e","title":"paper_27.pdf","url":"https://neurips2022-enlsp.github.io/papers/paper_27.pdf","urlHash":3793287817},"74b2bf47-1782-4e59-88c8-088799e53dbd":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"74b2bf47-1782-4e59-88c8-088799e53dbd","title":"A Mechanistic Interpretability Analysis of Grokking — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/N6WM6hs7RQMKDhYjB/a-mechanistic-interpretability-analysis-of-grokking","urlHash":3160719904},"74b933c3-d6b1-4f8a-ae1a-7e5fc8626ca2":{"favIconUrl":"fallback","id":"74b933c3-d6b1-4f8a-ae1a-7e5fc8626ca2","title":"Atlas Few-shot Learning with Retrieval Augmented Language Models - Arxiv-2208.03299","url":"https://arxiv.org/pdf/2208.03299.pdf","urlHash":2737493368},"74c8199a-6edc-4e6d-ac29-dca94760a8bb":{"favIconUrl":"fallback","id":"74c8199a-6edc-4e6d-ac29-dca94760a8bb","title":"谷歌AGI机器人大招！54人天团憋7个月，强泛化强推理，DeepMind和谷歌大脑合并后新成果","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247688591&idx=1&sn=7fc12cf45c0f35ead15eb9f926d7dd4c&exportkey=n_ChQIAhIQCgvOO9WKEaQjh2zFvm6xExKWAgIE97dBBAEAAAAAAFBqKnF5Vl0AAAAOpnltbLcz9gKNyK89dVj0QnkZJEr%2FxlH5PdeLflejsUpMDovRmaXknYUWIEVGaYAEEZ58rcv2AGxXfD2qH9cZqFTA965WuLoiysNe%2B7%2B62GOqckMjzjasY4m6SaiDFtfYFoiX4j5U2dWsqCkQ9Xl0Nck87MUb%2BXV2U7GsPksDcjPCH4qCEb%2FcVaCqMfEBjWKpsueiv4JA2t5uLwbOctFMc7se7D6FGdKVN0hAtzBE4bIxVutANecRMePH2X07VMeYmKvBfAZocNVUhHQLQhC4MVeDw%2FBD5IwLLG2sWnOXhlquhKtRiNdM60WwMXebwyXf5pDBev315x2DIpVwbUUZ&acctmode=0&pass_ticket=ZFeGpAHbYKey04HMHv2edP0aCmfnVO%2FlqTWwSdpGrkZhWOVtBpNJNPFxTChFZnDW&wx_header=0","urlHash":210141357},"75042416-e5f5-4763-bfb1-8cbbe6e28b2e":{"favIconUrl":"fallback","id":"75042416-e5f5-4763-bfb1-8cbbe6e28b2e","title":"Knowledge Distillation（知识蒸馏）Review--20篇paper回顾 - 知乎","url":"https://zhuanlan.zhihu.com/p/160206075","urlHash":3515495516},"754a712a-ff3f-4753-be5b-ec258b062989":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"754a712a-ff3f-4753-be5b-ec258b062989","title":"Tree of Thoughts: Deliberate Problem Solving with Large Language Models | Abstract","url":"https://arxiv.org/abs/2305.10601","urlHash":2918893266},"754dda69-7d98-46dc-a959-6f8305a14e5f":{"favIconUrl":"https://ssl.gstatic.com/docs/documents/images/kix-favicon-2023q4.ico","id":"754dda69-7d98-46dc-a959-6f8305a14e5f","title":"Keeping up with AGI","url":"https://docs.google.com/document/d/e/2PACX-1vQD8IlBotGdBxp3BnXkSjk8bNZlPV_0EH9ZA6wHd5dNf-BLSiwXUinvgv8ZoBEnNyTCF-chWO30NRw0/pub#h.5avjijk7fbrh","urlHash":767631735},"75884ddd-93f9-451a-9f9d-0faf6db96ede":{"favIconUrl":"fallback","id":"75884ddd-93f9-451a-9f9d-0faf6db96ede","title":"CS/Stat 184 Intro to RL","url":"https://shamulent.github.io/CS_Stat184_Fall23.html","urlHash":3375447049},"75beaf72-2385-4d3e-a6bd-e851cdf50be1":{"favIconUrl":"fallback","id":"75beaf72-2385-4d3e-a6bd-e851cdf50be1","title":"2. Monty Hall Problem — pgmpy 0.1.19 documentation","url":"https://pgmpy.org/examples/Monty%20Hall%20Problem.html","urlHash":1963749726},"75d150c2-8848-4be5-86c0-37aec828003e":{"favIconUrl":"fallback","id":"75d150c2-8848-4be5-86c0-37aec828003e","title":"Can Explanations Be Useful for Calibrating Black Box Models?","url":"https://arxiv.org/abs/2110.07586","urlHash":4187042887},"75e1d38c-63f1-415e-9bd2-1c0e3eb93bc6":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"75e1d38c-63f1-415e-9bd2-1c0e3eb93bc6","title":"What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization? | Abstract","url":"https://arxiv.org/abs/2204.05832","urlHash":2728092255},"75fc50cf-db4d-4442-9d3c-e9e57c94b9bc":{"favIconUrl":"fallback","id":"75fc50cf-db4d-4442-9d3c-e9e57c94b9bc","title":"TIFA Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering - Arxiv-2303.11897","url":"https://arxiv.org/pdf/2303.11897.pdf","urlHash":2621503905},"760dcd17-97e7-4f90-b030-058765967e75":{"favIconUrl":"fallback","id":"760dcd17-97e7-4f90-b030-058765967e75","title":"Augmented Language Models a Survey - Arxiv-2302.07842","url":"https://arxiv.org/pdf/2302.07842.pdf","urlHash":3363387048},"760e4695-4164-4c92-bc36-d3e5979b0f67":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"760e4695-4164-4c92-bc36-d3e5979b0f67","title":"wang-research-lab/agentinstruct: Code repo for \"Agent Instructs Large Language Models to be General Zero-Shot Reasoners\"","url":"https://github.com/wang-research-lab/agentinstruct","urlHash":556282831},"761be789-80b0-4feb-9dae-1ae34bf3b868":{"favIconUrl":"fallback","id":"761be789-80b0-4feb-9dae-1ae34bf3b868","title":"commonsense knowledge mining from pretrained models - Google Search","url":"https://www.google.com/search?q=commonsense+knowledge+mining+from+pretrained+models&oq=commonsense+knowledge+mining&aqs=chrome.0.0i512j69i57.4632j0j1&sourceid=chrome&ie=UTF-8","urlHash":884539298},"76296eae-00ed-413b-bef0-089e60305a27":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"76296eae-00ed-413b-bef0-089e60305a27","title":"DocLLM: A layout-aware generative language model for multimodal document understanding | Abstract","url":"https://arxiv.org/abs/2401.00908?utm_source=substack&utm_medium=email","urlHash":715732367},"76349b5e-c433-4a13-b0b7-55626569f8dd":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"76349b5e-c433-4a13-b0b7-55626569f8dd","title":"embedchain/embedchain: The Open Source RAG framework","url":"https://github.com/embedchain/embedchain","urlHash":2054345189},"764206bd-ace3-49ec-8eeb-089a8214f270":{"favIconUrl":"https://www.playthepast.org/wp-content/uploads/2019/08/cropped-joystick_400x400-32x32.jpg","id":"764206bd-ace3-49ec-8eeb-089a8214f270","title":"Feeling History in Blasphemous: Affective Piety and Our Lady of the Charred Visage","url":"https://www.playthepast.org/?p=7695","urlHash":93682064},"7643c88c-7772-41b1-808e-8979a4e20816":{"favIconUrl":"fallback","id":"7643c88c-7772-41b1-808e-8979a4e20816","title":"Pruning Neural Networks at Initialization: Why are We Missing the Mark?","url":"https://arxiv.org/abs/2009.08576","urlHash":956346666},"766ef7e5-7401-478c-9fd5-048b473b26b2":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"766ef7e5-7401-478c-9fd5-048b473b26b2","title":"Sparse Low-rank Adaptation of Pre-trained Language Models | PDF","url":"https://arxiv.org/pdf/2311.11696.pdf","urlHash":2475645397},"76974c89-b044-4b43-9097-af2ca622e428":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"76974c89-b044-4b43-9097-af2ca622e428","title":"Mixture-of-Experts Meets Instruction Tuning:A Winning Combination for Large Language Models | Abstract","url":"https://arxiv.org/abs/2305.14705","urlHash":4235990767},"76bd8b84-d971-49c7-a748-4078c754132a":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"76bd8b84-d971-49c7-a748-4078c754132a","title":"casper-hansen/AutoAWQ: AutoAWQ implements the AWQ algorithm for 4-bit quantization with a 2x speedup during inference.","url":"https://github.com/casper-hansen/AutoAWQ","urlHash":1571920788},"76f68b83-bb10-4831-9e87-eb09b4f31c26":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"76f68b83-bb10-4831-9e87-eb09b4f31c26","title":"Toy Models and Tegum Products — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/3cR2YH9dpr7SmKvCb/toy-models-and-tegum-products","urlHash":2059937492},"76f725d6-7092-4851-883d-c184c7e579fa":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"76f725d6-7092-4851-883d-c184c7e579fa","title":"Zhenwen Liang on X: \"📢Check out our recent work in mathematical reasoning! Our Multi-View Fine-Tuning (MinT🌿) method achieves the SOTA performance of 7B models without LLM teachers, by harnessing different datasets, solution styles, and even noisy data in training. Link: https://t.co/gZbVwG2IS0 https://t.co/OY66Z3om76\" / X","url":"https://twitter.com/LiangZhenwen/status/1687677815146127360","urlHash":2201722110},"775724c0-b4ec-4660-b180-4f54eae437f1":{"favIconUrl":"fallback","id":"775724c0-b4ec-4660-b180-4f54eae437f1","title":"Make Up Your Mind! Adversarial Generation of Inconsistent Natural Language Explanations - Arxiv-1910.03065","url":"https://arxiv.org/abs/1910.03065","urlHash":3129374137},"775c63fd-3bd2-4066-86c3-79a68f42572c":{"favIconUrl":"https://du11hjcvx0uqb.cloudfront.net/dist/images/favicon-e10d657a73.ico","id":"775c63fd-3bd2-4066-86c3-79a68f42572c","title":"15.C08 Causal Inference","url":"https://canvas.mit.edu/courses/25916","urlHash":1589965971},"7767f239-889b-4c9e-885f-916f8d76eeeb":{"favIconUrl":"fallback","id":"7767f239-889b-4c9e-885f-916f8d76eeeb","title":"A Winning Hand Compressing Deep Networks Can Improve Out-Of-Distribution Robustness - Arxiv-2106.09129","url":"https://arxiv.org/abs/2106.09129","urlHash":2906006170},"777e132b-cf01-496f-9190-677587aee5b5":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"777e132b-cf01-496f-9190-677587aee5b5","title":"ICLR 2023 最高分论文被锤抄袭？？","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247536935&idx=1&sn=3593e2b71af9d7142b03978a67052f30&exportkey=n_ChQIAhIQA3oIolGi7kKNEC4aELHqBRKWAgIE97dBBAEAAAAAAEGlA1xy%2FPkAAAAOpnltbLcz9gKNyK89dVj03sw89IITQ%2BLgHRDDPgTW%2BonXNlWcBRzZjU9AdffLwr1Fh46%2Fcv4NNi3Y82ZbnEjNUIyHhqykrQxf1%2BLtvuxb%2FdP9TP%2FE2x0P8RObdvvi4sFMjeDMBxZxBUJVde9q%2Bz6OJl7xBNeVORUqfYC2sQM4U1gBGvtItsN06N2%2BmE%2BHag0AFNj%2ByvbzCHbnVpfbEfds3lrcryisusuztsJjhHl2sgRgvUBU0vgU8p%2B7UWS9dq9gadVb4eVF3d94mTeNglg2s8GJyvpY77XpO%2FN3kzXtBBMnIroqXeUliEnv2ThyXdm4cX%2FDJvNtHeW5hiAey0PP&acctmode=0&pass_ticket=zUvJ6Bt8HsTNAPBA6U4qajGZ5sn0Pt6WEGVtKUG1A6M6WdYO36NrmwEtOS6I%2Fz3o&wx_header=0","urlHash":2407621925},"77864362-9a36-4618-8b31-5b58d7004eba":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"77864362-9a36-4618-8b31-5b58d7004eba","title":"Learning Neural Network Subspaces | Abstract","url":"https://arxiv.org/abs/2102.10472","urlHash":1358646918},"77877adc-eb02-457a-aa59-9abf259c813d":{"favIconUrl":"fallback","id":"77877adc-eb02-457a-aa59-9abf259c813d","title":"swapnil-sop.pdf","url":"https://swapnilgandhi.com/sop/swapnil-sop.pdf","urlHash":289229359},"7793b247-f0ac-4cd5-9fcb-670ef3280929":{"favIconUrl":"fallback","id":"7793b247-f0ac-4cd5-9fcb-670ef3280929","title":"INSCIT Information-Seeking Conversations with Mixed-Initiative Interactions - Arxiv-2207.00746","url":"https://arxiv.org/pdf/2207.00746.pdf","urlHash":3070234627},"77a62518-a093-45ae-8cde-d5249ec253ae":{"favIconUrl":"fallback","id":"77a62518-a093-45ae-8cde-d5249ec253ae","title":"feedback transformer - Google Search","url":"https://www.google.com/search?q=feedback+transformer&oq=feedback+transformer&aqs=chrome..69i57j0i512l6j69i65.2237j0j1&sourceid=chrome&ie=UTF-8","urlHash":651963139},"77cfbe7e-77d1-41ac-92e0-000ec7879ff5":{"favIconUrl":"https://www.google.com/favicon.ico","id":"77cfbe7e-77d1-41ac-92e0-000ec7879ff5","title":"mechanistic interpretability chris olah hiring - Google Search","url":"https://www.google.com/search?q=mechanistic+interpretability+chris+olah+hiring&oq=mechanistic+interpretability+chris+olah+hiring&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigAdIBCDg3OThqMGoxqAIAsAIA&sourceid=chrome&ie=UTF-8","urlHash":3347192356},"77dd7d08-92c8-41e6-ac23-3c04aa26d070":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"77dd7d08-92c8-41e6-ac23-3c04aa26d070","title":"LLM巫师，代码预训练是魔杖！UIUC华人团队揭秘代码数据三大好处","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652438222&idx=3&sn=1e230a180b44c7d1ab172cdb78d32abd&chksm=f12b8a3fc65c0329af04bc0b19711a67733dc947e1a455f4e18c7ec6ec666d21caac6c350a58&mpshare=1&scene=1&srcid=0128ae67klGn9zzIiZaPWGsi&sharer_shareinfo=af70dade2f65f2606842783321dc73e8&sharer_shareinfo_first=af70dade2f65f2606842783321dc73e8&exportkey=n_ChQIAhIQzIKDMQO4T0oN0%2BGCVV3H7hKWAgIE97dBBAEAAAAAAENUAswdaq4AAAAOpnltbLcz9gKNyK89dVj07ha8gyp1s3V4ophYY%2FrresUvbxrcf5mRIbwKSIPS4DVKnNwbU5F7eRFPFqiHt72OCMrhHs%2FtMhM%2B30m73mBeJu9R6jm1BkMeYzGKub0%2FcYjYUjmUy8bhiSoa37VMDcWvBzcfaIzJLhZyXpok29LYgialN1pz16EsMarGpsMHTpIslkB7286WKX63Ho85mkhayxqV1Cj2%2F%2BtjVkYEgJHp6fknscwZnfJv2A1V4S94P9vFuSXv%2FjwQFfu4VlGKzm3ZLN9XhfIKDHqXwiSxUlWCxPIUol4wpQLqU4%2BP1gmrQ6ulL7aDIA62nKlcOXRCDxAc&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HOiGE%2BNCOGba%2FRQU0ju2raK6F4X%2BpXk6c73MPlTvPLGRg%3D%3D&wx_header=0#rd","urlHash":3053423330},"77ec9296-d4a5-423f-8575-119c76bb64cb":{"favIconUrl":"fallback","id":"77ec9296-d4a5-423f-8575-119c76bb64cb","title":"Learning to Recombine and Resample Data For Compositional Generalization","url":"https://openreview.net/forum?id=PS3IMnScugk","urlHash":412000900},"77f9fe5e-c129-4e10-84a4-30eeebae1c21":{"favIconUrl":"https://scholar.google.com/favicon.ico","id":"77f9fe5e-c129-4e10-84a4-30eeebae1c21","title":"‪Enric Boix-Adserà‬ - ‪Google Scholar‬","url":"https://scholar.google.com/citations?hl=en&user=KOZSrE8AAAAJ&view_op=list_works&sortby=pubdate","urlHash":1067050765},"78829ae5-ef72-4b28-8a1e-cbfb49f28169":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"78829ae5-ef72-4b28-8a1e-cbfb49f28169","title":"しおかぜ市一家殺害事件あるいは迷宮牢の殺人 (豆瓣)","url":"https://book.douban.com/subject/36392357/","urlHash":2858473772},"7891dbb0-c522-40fe-ae49-6c3a6acc38dd":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7891dbb0-c522-40fe-ae49-6c3a6acc38dd","title":"elvis on X: \"LMs Can Teach Themselves to Think Before Speaking This paper presents a generalization of STaR, called Quiet-STaR, to enable language models (LMs) to learn to reason in more general and scalable ways. Quiet-STaR enables LMs to generate rationales at each token to explain… https://t.co/DrGfztxmXw\" / X","url":"https://twitter.com/omarsar0/status/1768681638009975088?utm_source=substack&utm_medium=email","urlHash":3799147737},"78a6241c-a226-414c-a551-e24c5ccc1c9a":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"78a6241c-a226-414c-a551-e24c5ccc1c9a","title":"ちぎれた鎖と光の切れ端 (豆瓣)","url":"https://book.douban.com/subject/36497633/","urlHash":2916616792},"78d24066-f389-4a14-947a-97df4c485f68":{"favIconUrl":"fallback","id":"78d24066-f389-4a14-947a-97df4c485f68","title":"不要think step by step！谷歌最新自然语言推理算法LAMBADA：「反向链推理」才是答案","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652281804&idx=5&sn=d8314b372447232920af9406f22fec6d&exportkey=n_ChQIAhIQTSZ7LNbEkDg7CPjDj89fWhKWAgIE97dBBAEAAAAAAKHkFBKiBT8AAAAOpnltbLcz9gKNyK89dVj0rwXOVow%2BTokElchimHSFig7afNUP0rOBOhWYkBEYbxRh%2BhQozb2jxSZOycl30vyr4ILjxP22vdwg1Pq7VQuHELPj1Xvh5Rn7KbfEJa%2F%2FzdD2cNA4NRpCPQDeCPhTqtX%2B9xeVgoumuyc9L80OOqua2Bl2zkpqC06GSw4%2BL1%2BiiOD%2BwglaPvvVdTslsJUKiSGejFVOhxt%2FDMzEK8dcXBJjc333yzZqKsAsGsfVBLpsErBgGaBA13RgSfmqRl8QHgwO0GrypbUYW8YjIQDkniDVrt0Ci24qW8rNpkWA2%2BsgTTaEUcXUZhsfLbzZTYqrghoX&acctmode=0&pass_ticket=3HIlKyjzTAFL%2FxFljj2tEtyLfkTobYOBU23FblbSLUoOBbNUDxmZkfPNQYuQsky1hOlaOIRRZKNtxEF1pnL3Hw%3D%3D&wx_header=0","urlHash":2406565550},"78d878a7-f96a-4301-b089-f9335cf5e939":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"78d878a7-f96a-4301-b089-f9335cf5e939","title":"twitter.com/arankomatsuzaki/status/1716276658221769020","url":"https://twitter.com/arankomatsuzaki/status/1716276658221769020","urlHash":287744096},"790d924c-f402-4053-a1d3-bdc6d0cff4fc":{"favIconUrl":"fallback","id":"790d924c-f402-4053-a1d3-bdc6d0cff4fc","title":"L2正则没有想象那么好？可能是“权重尺度偏移”惹的祸 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/7681","urlHash":3792931445},"793488b2-04e8-4000-a640-f8aa934a53d2":{"favIconUrl":"https://www.youtube.com/s/desktop/18e58bd6/img/favicon_32x32.png","id":"793488b2-04e8-4000-a640-f8aa934a53d2","title":"(7) Prompt Engineering Overview - YouTube","url":"https://www.youtube.com/watch?v=dOxUroR57xs","urlHash":3070074995},"7941b9cb-a2e4-40bf-a5a1-d0baffedf603":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"7941b9cb-a2e4-40bf-a5a1-d0baffedf603","title":"A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models | Abstract","url":"https://arxiv.org/abs/2401.01313?utm_source=substack&utm_medium=email","urlHash":3164023649},"7950d96b-07c3-431c-80b0-5009df210c38":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7950d96b-07c3-431c-80b0-5009df210c38","title":"twitter.com/arankomatsuzaki/status/1772810043064258715","url":"https://twitter.com/arankomatsuzaki/status/1772810043064258715","urlHash":2543315481},"796ce604-99e6-428e-b884-9b3e36ba28a1":{"favIconUrl":"http://www.guishangtuili.com/favicon.ico","id":"796ce604-99e6-428e-b884-9b3e36ba28a1","title":"【第五届诡殇推理谜题大赛】第一题《兰亭序-十字街记》作者：暗月 御手洗奎因 - 推理赛事 - 诡殇推理论坛 - Powered by Discuz!","url":"http://www.guishangtuili.com/forum.php?mod=viewthread&tid=9031","urlHash":302516837},"796fff37-2385-4272-a7fb-147f1ed6a0fd":{"favIconUrl":"https://images.squarespace-cdn.com/content/v1/6502259e5d663b5ef39d98ba/a33980fd-66d8-4c31-8a29-6be6643e2979/favicon.ico?format=100w","id":"796fff37-2385-4272-a7fb-147f1ed6a0fd","title":"Mechanistic Interpretability — ML Alignment & Theory Scholars","url":"https://www.matsprogram.org/interpretability","urlHash":1040029748},"798adc65-aac0-421d-8894-80bbddc42f5c":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"798adc65-aac0-421d-8894-80bbddc42f5c","title":"国内团队提出全新RLTF框架，刷新SOTA！大模型生成代码质量更高bug更少","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652358133&idx=5&sn=f66fe4f12294a10a79f531e6323ced7d&exportkey=n_ChQIAhIQw1uE6vhJi3kvme02FuMD5hKWAgIE97dBBAEAAAAAAJq1KCtqQygAAAAOpnltbLcz9gKNyK89dVj077v95iTf2crqcB08jaRP2IfYOr4o7Wl1gJvuvJctOeyZUR7yjywFHP7Pdt7z%2BMnabrHKXsjld6pGJoX6ZWcznO8yvYcAQpOjSDJsj1iVAP8rJOTzL8CX14QbI7W963bvITpsrzPir9vz0%2FqwUsa4HJ8gfKfmemaF23wDggMqJ%2BM4tr4YF1k8Uc8b2MgJhWDcNP25J4YJSnAnSGM%2BGn7%2FRX8tVLzybMPAVLtsVwxuiDd%2FpYwe%2BCJJlZVSqx9gcYdq4uczMnPPRnGG7shS3tESf5e2hKE3PuJO9UUTYYjcddIU7JEExji06fNdbdEwVqQy&acctmode=0&pass_ticket=4djXIJ12hMcaBfJwjYwYJ2NpJk9OlfBxsckPvnAOiPqkywVDEBJCLk1N8yvqaBS2&wx_header=0","urlHash":3054035313},"79a31136-4c7c-4dbd-aeea-22d386470aa3":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"79a31136-4c7c-4dbd-aeea-22d386470aa3","title":"Mass-Editing Memory in a Transformer | PDF","url":"https://arxiv.org/pdf/2210.07229.pdf","urlHash":1089574331},"79b6cbf1-be23-4f10-990a-01ab6579168f":{"favIconUrl":"https://aclanthology.org/aclicon.ico","id":"79b6cbf1-be23-4f10-990a-01ab6579168f","title":"Fact-Checking Complex Claims with Program-Guided Reasoning - ACL Anthology","url":"https://aclanthology.org/2023.acl-long.386/","urlHash":4074319413},"7a104634-cdee-4e14-b2db-a83c5aa08703":{"favIconUrl":"fallback","id":"7a104634-cdee-4e14-b2db-a83c5aa08703","title":"facebookresearch/ImageBind: ImageBind One Embedding Space to Bind Them All","url":"https://github.com/facebookresearch/ImageBind","urlHash":1156572775},"7a1804b6-fc99-4d0b-a48c-c8b45873c024":{"favIconUrl":"fallback","id":"7a1804b6-fc99-4d0b-a48c-c8b45873c024","title":"Fine-tuned Language Models are Continual Learners - Arxiv-2205.12393","url":"https://arxiv.org/abs/2205.12393","urlHash":3322612530},"7a1e4f27-163a-429b-9b90-550c9ad37276":{"favIconUrl":"fallback","id":"7a1e4f27-163a-429b-9b90-550c9ad37276","title":"https://arxiv.org/abs/1708.03999","url":"https://arxiv.org/abs/1708.03999","urlHash":289931015},"7a3945e0-dfb8-490e-a6a7-441de611e653":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7a3945e0-dfb8-490e-a6a7-441de611e653","title":"Longyue Wang on X: \"🚀 A game-changer benchmark: LLM-Uncertainty-Bench 🌟 📚 We introduce \"Benchmarking LLMs via Uncertainty Quantification\", which challenges the status quo in LLM evaluation. 💡 Uncertainty matters too: we propose a novel uncertainty-aware metric, which tests 8 LLMs across 5… https://t.co/ZuO0cGDRKz\" / X","url":"https://twitter.com/wangly0229/status/1750165389881864634","urlHash":736662432},"7a3b3ee3-1f99-46c5-bd28-26a273addabf":{"favIconUrl":"fallback","id":"7a3b3ee3-1f99-46c5-bd28-26a273addabf","title":"InfoDiffusion: Representation Learning Using Information Maximizing Diffusion Models","url":"https://arxiv.org/abs/2306.08757","urlHash":2616368416},"7a624ae6-b5fb-4016-9b61-4b2252b6da32":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"7a624ae6-b5fb-4016-9b61-4b2252b6da32","title":"Knowledge Neurons in Pretrained Transformers — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/LdoKzGom7gPLqEZyQ/knowledge-neurons-in-pretrained-transformers","urlHash":4101952635},"7a68d1a3-71da-44bd-b047-62b79d861ce9":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7a68d1a3-71da-44bd-b047-62b79d861ce9","title":"Gradio on X: \"📢Hot Research alert: Blending Is All You Need From the paper: \"Integrating just 3 models of moderate size (6B/13B) can rival or even surpass the performance metrics of a substantially larger model like ChatGPT (175B+)\" 🤯🤯 We can't wait to play with the demo on Spaces!\" / X","url":"https://twitter.com/Gradio/status/1744643184045830452","urlHash":1875236294},"7a7dcb31-fbde-405b-be2f-2144c202f4b1":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7a7dcb31-fbde-405b-be2f-2144c202f4b1","title":"Maksym Andriushchenko 🇺🇦 on X: \"We all know that AGI is coming, BUT adversarial examples are *still* not solved and scale is not all you need! Simple random search using logprobs of GPT-4 reveals that it has quite limited robustness. Short paper: https://t.co/mD1dQOBnZk Code: https://t.co/0NJxLQXleH 🧵1/n https://t.co/azXnEdWij2\" / X","url":"https://twitter.com/maksym_andr/status/1737844601891983563","urlHash":541494370},"7aa0d4a0-4d8a-4cca-b935-ae4817b17f0b":{"favIconUrl":"fallback","id":"7aa0d4a0-4d8a-4cca-b935-ae4817b17f0b","title":"Pytorch Geometric Tutorial","url":"https://antoniolonga.github.io/Pytorch_geometric_tutorials/","urlHash":1023983897},"7aa97348-b3c1-4612-8337-76f0bd73adab":{"favIconUrl":"fallback","id":"7aa97348-b3c1-4612-8337-76f0bd73adab","title":"COPNER: Contrastive Learning with Prompt Guiding for Few-shot Named Entity Recognition","url":"https://aclanthology.org/2022.coling-1.222.pdf","urlHash":1321436853},"7aaac7d5-0064-4056-bb0a-d752c6153e11":{"favIconUrl":"fallback","id":"7aaac7d5-0064-4056-bb0a-d752c6153e11","title":"The Annotated S4","url":"https://srush.github.io/annotated-s4/#part-3-s4-in-practice","urlHash":3398318926},"7acd1ffb-5acc-4bbc-abd7-1b6e9456701f":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"7acd1ffb-5acc-4bbc-abd7-1b6e9456701f","title":"让视觉语言模型搞空间推理，谷歌又整新活了","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650907781&idx=4&sn=0ae531f6b8a4669362a264b2250efb00&chksm=84e460fbb393e9ed71ca6913cb39a1e606772a882adab45ee57f214c16ae22921ac9cd579776&mpshare=1&scene=1&srcid=0220vkSi51iVKEmsiwfpEIH9&sharer_shareinfo=44f3d9b672683a811f539a91e4b0a47a&sharer_shareinfo_first=44f3d9b672683a811f539a91e4b0a47a&exportkey=n_ChQIAhIQGv5wp5ZXfFwj%2FLCdxN2LuhKWAgIE97dBBAEAAAAAADWnM%2Bm2YAsAAAAOpnltbLcz9gKNyK89dVj0hJ%2BzNVvjxc8gmkgazdFz6XMVm%2B7UHMUWUNulbFLwy%2Bgz0ar%2Ft9gmROdBkWxjv7Um6yJjTkYug8f1Rn60qBsBaoKV%2BgfrqOzXoPcqLHraI77Wg4xyLh4auINoIk75JfmT8ZiNRFNjviUaHKOkPiatkgH6pzGyKl0r%2B%2B6vCW075SGUUSqh2Q3mIIZIQLS2dHYr%2B36VQR%2F1pkFxA52eE6m4wWn7JWbI%2Frjod1gfpXbEkQCoMBbT1%2FqVvMFQxnn9WcmqXPnuMT5nPYHtAhFZK14k2o79tU%2BZrekjm%2B7zS9%2B2eT8Po%2F%2Bo6sMhmyBtgE4DUMNV&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HPjG%2Fhc00DMnLYDWcwmzjHRLnQTfrvcAaElWZ3Ryei%2FXA%3D%3D&wx_header=0#rd","urlHash":3447497814},"7aeb133b-87f8-4e35-8a74-49cc90bbb2f6":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"7aeb133b-87f8-4e35-8a74-49cc90bbb2f6","title":"小红书开源「InstantID」效果炸裂，被Yann LeCun点赞，迅速蹿上Github热榜","url":"https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247560601&idx=1&sn=4a6d4751facc8dbbc652e8736db46d0d&chksm=ebb6d54ddcc15c5b34ae67a4ae771f26097ed5fe6c71e6d3cd1d8d8ffbfb519443aa1a2a67c2&mpshare=1&scene=1&srcid=0202kLTdbUq93vVHB0jNxK62&sharer_shareinfo=1727fcf0c55c652c4a0b05e6078d3ef9&sharer_shareinfo_first=1727fcf0c55c652c4a0b05e6078d3ef9&exportkey=n_ChQIAhIQs7yCsEhNJNgo5KER45OP5RKWAgIE97dBBAEAAAAAAFS6N89SBfcAAAAOpnltbLcz9gKNyK89dVj0wD3mYqkS87mbQjlWqz3UX2RY2aIvCcowPAL3eOpqofsaOjNPFp38KGP71EoiXkm7d5XOP9OtZ2v2m39yx6nry%2BWIKBq55ixIZXYIwB11IyMO8bg9enVObXd%2BGtnOv1v0l8FxGtRhUPS540ROxXUIf17oOHB5wDW9AUdD69opcr5Gk0dm%2FJU7yJNcYGZV0KbkxNdPnYfCdTzcm0LsKbeATRXFaOMku2cTsYiIop3iAcMVR6WdO2UDabZ6cZt2fa2S%2B%2FaGdlNGImPNztOLzcFeBmAmKk1BKp9uAqgrW%2FcxfAO%2BUqO%2B85MA5uxJMRXLik%2Fc&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HO5%2BfEqYo5yhrxz9qD%2FS3KRWzeMj1C2KX5FHPte%2BP%2BoBw%3D%3D&wx_header=0#rd","urlHash":3654003227},"7aee15e4-1e90-4ab7-8a85-f03db5c18dac":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"7aee15e4-1e90-4ab7-8a85-f03db5c18dac","title":"Evaluating the Ripple Effects of Knowledge Editing in Language Models | PDF","url":"https://arxiv.org/pdf/2307.12976.pdf","urlHash":2314673168},"7b1154ce-81ea-49f9-9b74-cebe38b0e61c":{"favIconUrl":"fallback","id":"7b1154ce-81ea-49f9-9b74-cebe38b0e61c","title":"Beyond Synthetic Noise Deep Learning on Controlled Noisy Labels - Arxiv-1911.09781","url":"https://arxiv.org/pdf/1911.09781.pdf","urlHash":1735938574},"7b1485cc-dc71-4d99-9114-c363490806dc":{"favIconUrl":"https://gligen.github.io/static/images/icon.png","id":"7b1485cc-dc71-4d99-9114-c363490806dc","title":"GLIGEN:Open-Set Grounded Text-to-Image Generation.","url":"https://gligen.github.io/","urlHash":560018357},"7b3fe2a8-fc68-4c55-8613-a0ae3993b435":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7b3fe2a8-fc68-4c55-8613-a0ae3993b435","title":"John Nay on X: \"LLM Overconfidence &amp; Uncertainty -Q&amp;A accuracy suffers when LLMs are prompted to use language like \"I’m 100% certain\" -GPT-3 has poor calibration in *certainty* expressions -But expressions of *UNcertainty* might lead to better model calibration Paper: https://t.co/9CfFi0kCis https://t.co/EjMvv73hHj\" / X","url":"https://twitter.com/johnjnay/status/1630408070240010243","urlHash":304380395},"7b630346-9982-4b78-bf7e-5d19dd047586":{"favIconUrl":"fallback","id":"7b630346-9982-4b78-bf7e-5d19dd047586","title":"QA-GNN Reasoning with Language Models and Knowledge Graphs for Question Answering - Arxiv-2104.06378","url":"https://arxiv.org/pdf/2104.06378.pdf","urlHash":4074862764},"7b77534d-de24-40d1-90d9-f2c27c24e30f":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7b77534d-de24-40d1-90d9-f2c27c24e30f","title":"twitter.com/xl_nlp/status/1691172503304187904","url":"https://twitter.com/xl_nlp/status/1691172503304187904","urlHash":228808067},"7b966a82-20fd-4196-9aa0-d68b3baa86d6":{"favIconUrl":"https://www.99csw.com/favicon.ico","id":"7b966a82-20fd-4196-9aa0-d68b3baa86d6","title":"恋爱曲线_小酒井不木_在线阅读_九九藏书网","url":"https://www.99csw.com/book/7743/index.htm","urlHash":3135824301},"7ba8323a-9d30-45ea-9c36-f50d2a087fb4":{"favIconUrl":"fallback","id":"7ba8323a-9d30-45ea-9c36-f50d2a087fb4","title":"Can Rationalization Improve Robustness? - Arxiv-2204.11790","url":"https://arxiv.org/pdf/2204.11790.pdf","urlHash":2602225618},"7bad0de7-cc50-4b60-ac85-7821efbe135c":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"7bad0de7-cc50-4b60-ac85-7821efbe135c","title":"BloombergGPT: A Large Language Model for Finance | PDF","url":"https://arxiv.org/pdf/2303.17564.pdf","urlHash":1012837424},"7bbfc71d-9ebd-4279-bace-e0424736519c":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"7bbfc71d-9ebd-4279-bace-e0424736519c","title":"elvis on X: \"Context-faithful Prompting for Large Language Models Presents a neat prompting technique that aims to improve LLMs' faithfulness using strategies such as opinion-based prompts and counterfactual demonstrations. https://t.co/ztp8bxVt6v https://t.co/NC0mnfVzm2\" / X","url":"https://twitter.com/omarsar0/status/1637992441042149376","urlHash":4238209761},"7bc32c1c-4d93-447d-9e75-77df012738c1":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7bc32c1c-4d93-447d-9e75-77df012738c1","title":"John Nay on X: \"Code for Eliciting Truthful Answers From LLMs: https://t.co/l8jQ0OSRSM\" / X","url":"https://twitter.com/johnjnay/status/1667484215435309057","urlHash":1990993782},"7bdafd06-268f-4690-ada4-36ee5efd63ee":{"favIconUrl":"fallback","id":"7bdafd06-268f-4690-ada4-36ee5efd63ee","title":"CSC2515 Winter 2021- University of Toronto Computer Science","url":"https://subercui.github.io/csc2515/Lectures.html","urlHash":363376650},"7bdb3376-a2a4-4dee-8fca-b26019202b05":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"7bdb3376-a2a4-4dee-8fca-b26019202b05","title":"Understanding Retrieval Augmentation for Long-Form Question Answering | Abstract","url":"https://arxiv.org/abs/2310.12150?utm_source=substack&utm_medium=email","urlHash":3676832492},"7bebc7b3-798d-405a-88fe-a93eef88deb8":{"favIconUrl":"fallback","id":"7bebc7b3-798d-405a-88fe-a93eef88deb8","title":"Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution - Arxiv-2202.10054","url":"https://arxiv.org/abs/2202.10054","urlHash":3360729935},"7c89265e-aefc-4a91-9668-57f7cf4c7474":{"favIconUrl":"fallback","id":"7c89265e-aefc-4a91-9668-57f7cf4c7474","title":"梦之囚徒 看漫画 - Google Search","url":"https://www.google.com/search?q=%E6%A2%A6%E4%B9%8B%E5%9B%9A%E5%BE%92+%E7%9C%8B%E6%BC%AB%E7%94%BB&newwindow=1&sxsrf=AB5stBheAcx3CsYpNIT3tNPCXq_4AhbTyQ%3A1688400408335&ei=GPKiZJT2E6ypptQP1rKD6AI&ved=0ahUKEwiU4s7U9fL_AhWslIkEHVbZAC0Q4dUDCBA&uact=5&oq=%E6%A2%A6%E4%B9%8B%E5%9B%9A%E5%BE%92+%E7%9C%8B%E6%BC%AB%E7%94%BB&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIICAAQiQUQogQyBQgAEKIEOgsIABCJBRCiBBCwAzoICAAQogQQsANKBAhBGAFQxQpYzg5gzA9oAXAAeACAAYcBiAHpAZIBAzEuMZgBAKABAcABAcgBAw&sclient=gws-wiz-serp#ip=1","urlHash":4147785697},"7cbb8934-89f4-4e73-9ade-de9dcf533896":{"favIconUrl":"fallback","id":"7cbb8934-89f4-4e73-9ade-de9dcf533896","title":"Pre-Trained Language Models for Interactive Decision-Making - Arxiv-2202.01771","url":"https://arxiv.org/abs/2202.01771","urlHash":1819860585},"7cbe09af-74b5-4766-9e88-1dcd2c3d395b":{"favIconUrl":"fallback","id":"7cbe09af-74b5-4766-9e88-1dcd2c3d395b","title":"A Theory on Adam Instability in Large-Scale Machine Learning","url":"https://arxiv.org/abs/2304.09871","urlHash":223936920},"7cd2f34b-9b04-481c-8f81-420b14b4ee9e":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7cd2f34b-9b04-481c-8f81-420b14b4ee9e","title":"twitter.com/XueFz/status/1724609662170144974","url":"https://twitter.com/XueFz/status/1724609662170144974","urlHash":2716088855},"7ce8cf88-b5a7-40f9-ad4d-3176e0368d06":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"7ce8cf88-b5a7-40f9-ad4d-3176e0368d06","title":"HuggingFaceH4 (Hugging Face H4)","url":"https://huggingface.co/HuggingFaceH4","urlHash":2559857448},"7d002c0e-99eb-43b8-b7e5-ce9a53af88f7":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7d002c0e-99eb-43b8-b7e5-ce9a53af88f7","title":"Sasha Rush on X: \"Dumb question: I'm simultaneously concerned that LLM generations are 1) undetectable and 2) break training of future models. Is that contradictory? Is there a theory of the case where outputs are statistically indistinguishable and yet still poisonous?\" / X","url":"https://twitter.com/srush_nlp/status/1669716955480064002","urlHash":3544577942},"7d188662-4729-472c-b369-67a1201b9fff":{"favIconUrl":"fallback","id":"7d188662-4729-472c-b369-67a1201b9fff","title":"3W字长文带你轻松入门视觉transformer - 知乎","url":"https://zhuanlan.zhihu.com/p/308301901","urlHash":1734541115},"7d328e80-3d14-4acc-b31b-c6b632d8a0b6":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"7d328e80-3d14-4acc-b31b-c6b632d8a0b6","title":"Attributed Question Answering: Evaluation and Modeling for Attributed Large Language Models | PDF","url":"https://arxiv.org/pdf/2212.08037.pdf","urlHash":2168644513},"7d444f3b-4978-4567-be08-27091e696f05":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"7d444f3b-4978-4567-be08-27091e696f05","title":"Attention is Not Only a Weight: Analyzing Transformers with Vector Norms | PDF","url":"https://arxiv.org/pdf/2004.10102.pdf","urlHash":2098891173},"7d820f7a-5252-46dc-b1c8-62696f57d706":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"7d820f7a-5252-46dc-b1c8-62696f57d706","title":"アミュレット・ホテル (豆瓣)","url":"https://book.douban.com/subject/36462250/","urlHash":2209609506},"7d9660fe-f1bb-4789-8ee0-1a35ad566941":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"7d9660fe-f1bb-4789-8ee0-1a35ad566941","title":"AgentScope: A Flexible yet Robust Multi-Agent Platform | PDF","url":"https://arxiv.org/pdf/2402.14034.pdf","urlHash":1524598866},"7d9818c6-abcc-4c30-b5fa-9b5e85f9201c":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"7d9818c6-abcc-4c30-b5fa-9b5e85f9201c","title":"东京往事 (豆瓣)","url":"https://book.douban.com/subject/36331229/","urlHash":845600553},"7d9c9ce1-ad6b-4523-8381-10652e318a91":{"favIconUrl":"fallback","id":"7d9c9ce1-ad6b-4523-8381-10652e318a91","title":"Conservative Prediction via Transductive Confidence Minimization - OR-ICLR-2023_pQ-dJqyf9GI","url":"https://openreview.net/pdf?id=pQ-dJqyf9GI","urlHash":3913726153},"7dbcd202-e6ea-4ffe-a290-a413ffbd99e3":{"favIconUrl":"fallback","id":"7dbcd202-e6ea-4ffe-a290-a413ffbd99e3","title":"Lorraine333/smoothed_box_embedding: smoothed box embedding code","url":"https://github.com/Lorraine333/smoothed_box_embedding","urlHash":1807190379},"7dd4cce8-0543-4a48-9cec-7b8e26d5868b":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"7dd4cce8-0543-4a48-9cec-7b8e26d5868b","title":"补齐Transformer规划短板，田渊栋团队的Searchformer火了","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650908456&idx=2&sn=535043d52c8265d079c5e5ca24d3cbcc&chksm=84e46356b393ea40199c140d71e89147f5f3b6b0b3156f1ef137343608c13900980f5f21c08e&mpshare=1&scene=1&srcid=0225jdPHuig4xJK4tGSMgwtK&sharer_shareinfo=bf3999727b0eba6409dcd8ba8e260099&sharer_shareinfo_first=bf3999727b0eba6409dcd8ba8e260099&exportkey=n_ChQIAhIQs19Kg%2FvOgKkSQFln%2Fz0k%2BhKWAgIE97dBBAEAAAAAAPyhFNa1MVwAAAAOpnltbLcz9gKNyK89dVj0gq%2BucOzLGw7EMr%2Bvg23RbhLSFHKJyFHqCVjhkV4KZ%2Fh4pCQzP3eBzY98M5IiLE4hIZDi%2FyGztABejGIBYrUzuIod7cEYs3%2BR43I5%2FRclFRCg8nG0S%2B%2Fx0Ku%2BrRj8A3MCUlc1UZsPZZc1oqMn8hpLyMhAEmh5pqqhQHdVGwj%2BLshJJXw439%2BCj7dgV3QlAdFTCt700cUuQLi3xWB%2FPITI4eHLsWVupY3tRQ3AELRCMjs%2BCeu3JKQR9EDriKpRXDU%2F%2BdMVkwtWOqYmgOcbim%2BehRQrb9gVRRKxHWppxUFzMTcnlJsycxmD1BWYcbRtMnCY&acctmode=0&pass_ticket=2PIOTp07NumM73b6%2BDXCh%2BnkNx8%2F1ykJABKPHCCPJcP5c4nZZa5hHvQzScfHf%2BfYvoDDjfNMfhXupCRzVxAcWQ%3D%3D&wx_header=0#rd","urlHash":2311865409},"7dd674eb-bca9-4103-b037-4a6c5a2ace67":{"favIconUrl":"fallback","id":"7dd674eb-bca9-4103-b037-4a6c5a2ace67","title":"Diversify and Disambiguate Learning From Underspecified Data - Arxiv-2202.03418","url":"https://arxiv.org/pdf/2202.03418.pdf","urlHash":1906988706},"7deb143e-a402-4a0a-8575-53be9fe05be7":{"favIconUrl":"fallback","id":"7deb143e-a402-4a0a-8575-53be9fe05be7","title":"近代自然语言处理技术发展的“第四范式” - 知乎","url":"https://zhuanlan.zhihu.com/p/395115779","urlHash":4082967506},"7e02dc29-07f4-4132-805f-fa570c91a4c6":{"favIconUrl":"fallback","id":"7e02dc29-07f4-4132-805f-fa570c91a4c6","title":"级联抑制：提升GAN表现的一种简单有效的方法 - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/7105","urlHash":1402317323},"7e22bdcc-337a-4324-93c9-20520f814202":{"favIconUrl":"https://www.google.com/favicon.ico","id":"7e22bdcc-337a-4324-93c9-20520f814202","title":"小包子和Jumbo - Google Search","url":"https://www.google.com/search?q=%E5%B0%8F%E5%8C%85%E5%AD%90%E5%92%8CJumbo","urlHash":3715455329},"7e29a184-4eb4-4df1-bb1d-2503e04bd2d1":{"favIconUrl":"fallback","id":"7e29a184-4eb4-4df1-bb1d-2503e04bd2d1","title":"TaskNorm Rethinking Batch Normalization for Meta-Learning - Arxiv-2003.03284","url":"https://arxiv.org/abs/2003.03284","urlHash":1665713515},"7e3014d2-344d-4b77-853a-a27c77cd394c":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"7e3014d2-344d-4b77-853a-a27c77cd394c","title":"(2) Jeremy Howard on X: \"Reranking is a critical step for effective retrieval in RAG, but it's something many people skip over or so poorly. https://t.co/gAatlfwlnE's @bclavie has released a new project to greatly simplify this important technique. Thanks Ben!\" / X","url":"https://twitter.com/jeremyphoward/status/1768344061805760943","urlHash":87592410},"7e331663-584e-48fd-b5b9-ca48e815d905":{"favIconUrl":"fallback","id":"7e331663-584e-48fd-b5b9-ca48e815d905","title":"THUYimingLi/BackdoorBox: The open-sourced Python toolbox for backdoor attacks and defenses.","url":"https://github.com/THUYimingLi/BackdoorBox","urlHash":4174291392},"7e605b00-1e8c-4165-b69a-df742df6020d":{"favIconUrl":"fallback","id":"7e605b00-1e8c-4165-b69a-df742df6020d","title":"Visual Anagrams","url":"https://dangeng.github.io/visual_anagrams/","urlHash":1071765452},"7e7ea512-b868-4b60-8777-d245a841c870":{"favIconUrl":"https://unity.com/themes/contrib/unity_base/images/favicons/favicon.ico","id":"7e7ea512-b868-4b60-8777-d245a841c870","title":"Unity - Manual: Working in Unity","url":"https://docs.unity3d.com/Manual/UnityOverview.html","urlHash":3860946322},"7e94a762-be4d-4ac3-bad9-9d7a788d3e0a":{"favIconUrl":"fallback","id":"7e94a762-be4d-4ac3-bad9-9d7a788d3e0a","title":"未来千年文学备忘录（诺顿讲稿） - 卡尔维诺中文站","url":"http://www.ruanyifeng.com/calvino/nonfiction/cat-76/","urlHash":555285816},"7ea2371a-e161-44c2-85c3-c411980849c9":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"7ea2371a-e161-44c2-85c3-c411980849c9","title":"thunlp/UltraChat: Large-scale, Informative, and Diverse Multi-round Chat Data (and Models)","url":"https://github.com/thunlp/UltraChat","urlHash":2349716275},"7ea6ea1f-3010-4f43-962e-cab01ef70108":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"7ea6ea1f-3010-4f43-962e-cab01ef70108","title":"3D-LLM: Injecting the 3D World into Large Language Models | PDF","url":"https://arxiv.org/pdf/2307.12981.pdf","urlHash":2277645271},"7ec1d990-240b-4c72-b20c-4e13988744a3":{"favIconUrl":"fallback","id":"7ec1d990-240b-4c72-b20c-4e13988744a3","title":"Learning to Rank读书笔记--排序评价指标 - 知乎","url":"https://zhuanlan.zhihu.com/p/64952093","urlHash":3531073903},"7eda712f-54b3-4116-8808-b3f8aca1c8c2":{"favIconUrl":"https://wikiwandv2-19431.kxcdn.com/icons/favicon.ico","id":"7eda712f-54b3-4116-8808-b3f8aca1c8c2","title":"Prolegomena to Any Future Metaphysics - Wikiwand","url":"https://www.wikiwand.com/en/Prolegomena_to_Any_Future_Metaphysics","urlHash":3175989496},"7f0a60ac-cf4a-493d-9dc3-cb73f50e3d20":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7f0a60ac-cf4a-493d-9dc3-cb73f50e3d20","title":"Graham Neubig on X: \"Check out FacTool - a new method using tools to fact check generated text! It can use search, calculators, code execution, etc. to better catch hallucinations in content generated by LLMs such as ChatGPT. We also release a dataset for benchmarking such fact checking systems.\" / X","url":"https://twitter.com/gneubig/status/1684658613921669120","urlHash":1547321604},"7f166644-a2e0-449f-8160-eb176fb8babb":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"7f166644-a2e0-449f-8160-eb176fb8babb","title":"Yihe Deng on X: \"Large Vision Language Models are prone to object hallucinations – how to cost-efficiently address this issue? 🚀 Introducing MARINE: a training-free, API-free framework to tackle object hallucinations. Joint work with an amazing team @linxizhao4 @WeitongZhang and @QuanquanGu!… https://t.co/DeIjFo7tcf\" / X","url":"https://twitter.com/Yihe__Deng/status/1757909873491345563","urlHash":1243230473},"7f24d63b-1fb8-47f6-b502-b30bf629f428":{"favIconUrl":"fallback","id":"7f24d63b-1fb8-47f6-b502-b30bf629f428","title":"Doraemonzzz/ML-Foundation-and-ML-Techniques: 台大机器学习课程作业详解","url":"https://github.com/Doraemonzzz/ML-Foundation-and-ML-Techniques","urlHash":2290186218},"7f66a341-66a8-4453-ba5c-9c623d77830e":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7f66a341-66a8-4453-ba5c-9c623d77830e","title":"Wenhu Chen on X: \"Thrilled to announce our recent work of Instruct-Imagen. We bring instruction tuning to image generation to combine diverse image generation tasks into a general format to see its generalization. Instruct-Imagen shows strong generalization to handle unseen compositional tasks. https://t.co/P6kLjz5Jia\" / X","url":"https://twitter.com/WenhuChen/status/1743108263552373169","urlHash":980738416},"7f6e2be7-f6e2-40d7-a921-09a6cf9591c4":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"7f6e2be7-f6e2-40d7-a921-09a6cf9591c4","title":"What Context Features Can Transformer Language Models Use? | Abstract","url":"https://arxiv.org/abs/2106.08367","urlHash":2993317593},"7f794915-34b9-41b6-a521-34f380c68c69":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7f794915-34b9-41b6-a521-34f380c68c69","title":"elvis on X: \"Step-by-Step Comparisons Make LLMs Better Reasoners Proposes RankPrompt, a prompting method to enable LLMs to self-rank their responses without additional resources. This self-ranking approach ranks candidates through a systematic, step-by-step comparative evaluation. This… https://t.co/rrVl5CTpXS\" / X","url":"https://twitter.com/omarsar0/status/1770492690129359135?utm_source=substack&utm_medium=email","urlHash":3553689107},"7f7ff597-8b4d-432d-adbf-b0e787e98da0":{"favIconUrl":"fallback","id":"7f7ff597-8b4d-432d-adbf-b0e787e98da0","title":"Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond","url":"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00511/113490","urlHash":461540011},"7fb20421-c533-4c17-af84-d4dc97461671":{"favIconUrl":"fallback","id":"7fb20421-c533-4c17-af84-d4dc97461671","title":"从Wasserstein距离、对偶理论到WGAN - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/6280/comment-page-1#mjx-eqn-eq%3Astrong-dual","urlHash":527931483},"7fc05b39-992a-477c-bcc9-5df437b4bfa6":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"7fc05b39-992a-477c-bcc9-5df437b4bfa6","title":"Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks | Abstract","url":"https://arxiv.org/abs/2402.04248","urlHash":1600956753},"7fc1c557-8f26-4522-957d-0f3e351716f7":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7fc1c557-8f26-4522-957d-0f3e351716f7","title":"AK on X: \"Vision-Flan Scaling Human-Labeled Tasks in Visual Instruction Tuning Despite vision-language models' (VLMs) remarkable capabilities as versatile visual assistants, two substantial challenges persist within the existing VLM frameworks: (1) lacking task diversity in pretraining… https://t.co/bNvapPl9RG\" / X","url":"https://twitter.com/_akhaliq/status/1759798160011018397","urlHash":3592811079},"7fc89588-a742-42c1-aa2f-d0cb5777efc3":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"7fc89588-a742-42c1-aa2f-d0cb5777efc3","title":"FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation | Abstract","url":"https://arxiv.org/abs/2310.03214?utm_source=substack&utm_medium=email","urlHash":2927051187},"7fc9c64b-b17f-4643-a62e-83d93cc474e7":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"7fc9c64b-b17f-4643-a62e-83d93cc474e7","title":"Daniel Vila Suero on X: \"🏆 YALL - Yet Another LLM Leaderboard by the awesome @maximelabonne using the @NousResearch benchmark Pretty crazy to see the top three models originated by our latest @argilla_io dataset, including a merge of a merge+dpo 🤯 created by Maxime https://t.co/6FsxFv8FTe\" / X","url":"https://twitter.com/dvilasuero/status/1746964994434953534","urlHash":880011716},"7ff4d38e-797c-4c86-9a8d-184f9514879e":{"favIconUrl":"fallback","id":"7ff4d38e-797c-4c86-9a8d-184f9514879e","title":"apm120-notes.pdf","url":"https://www.dropbox.com/s/keiaw6tib1afj38/apm120-notes.pdf?e=1&dl=0","urlHash":1919558641},"7ffee9bd-ab43-4251-9ad4-7e4bd2b7ed53":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"7ffee9bd-ab43-4251-9ad4-7e4bd2b7ed53","title":"srush/LLM-Training-Puzzles: What would you do with 1000 H100s...","url":"https://github.com/srush/LLM-Training-Puzzles","urlHash":3801046956},"801ea190-6351-4fad-9811-19b9e9423010":{"favIconUrl":"fallback","id":"801ea190-6351-4fad-9811-19b9e9423010","title":"使用 Beancount 记录证券投资","url":"https://wzyboy.im/post/1317.html","urlHash":3044991376},"802c089b-4290-4594-a076-4319ca4d2472":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"802c089b-4290-4594-a076-4319ca4d2472","title":"twitter.com/Muennighoff/status/1661895337248686081","url":"https://twitter.com/Muennighoff/status/1661895337248686081","urlHash":3317241707},"803f4cc1-1313-40b5-8d85-78488648dd9d":{"favIconUrl":"fallback","id":"803f4cc1-1313-40b5-8d85-78488648dd9d","title":"Transformers and Associative Memories","url":"https://alberto.bietti.me/files/mit_lecture_transformer.pdf","urlHash":2750407937},"805a6464-2256-4708-86bc-6c9f650d0795":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"805a6464-2256-4708-86bc-6c9f650d0795","title":"dair-ai/Prompt-Engineering-Guide: 🐙 Guides, papers, lecture, notebooks and resources for prompt engineering","url":"https://github.com/dair-ai/Prompt-Engineering-Guide","urlHash":1102206205},"80ac90f8-67da-42f8-b7d3-d34c0c2b6ab1":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"80ac90f8-67da-42f8-b7d3-d34c0c2b6ab1","title":"Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering | PDF","url":"https://arxiv.org/pdf/2212.10375.pdf","urlHash":1614044337},"80b2301f-d596-4188-b5b7-ec31c38d2975":{"favIconUrl":"fallback","id":"80b2301f-d596-4188-b5b7-ec31c38d2975","title":"benedekrozemberczki/pytorch_geometric_temporal: PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models (CIKM 2021)","url":"https://github.com/benedekrozemberczki/pytorch_geometric_temporal","urlHash":108508348},"80c8a0dc-963b-4276-93b5-342361793b2a":{"favIconUrl":"fallback","id":"80c8a0dc-963b-4276-93b5-342361793b2a","title":"The ICLR Blog Track ·","url":"https://iclr-blog-track.github.io/blog/","urlHash":904999034},"80cb20ef-b15a-4c7c-856b-195968a40403":{"favIconUrl":"fallback","id":"80cb20ef-b15a-4c7c-856b-195968a40403","title":"(1) Vijeta Deshpande on Twitter: \"We simplify the language and pre-train more than 70 language models in the range of 1-100M parameters. We evaluate the NLU capabilities with GLUE datasets. Our simplified language pre-training data is available at: https://t.co/7cuBo1i5hM\" / Twitter","url":"https://twitter.com/VijetaDeshpande/status/1668619183108808706","urlHash":1028777354},"80cf50fa-cac2-4819-bcf9-3aa835c87d49":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"80cf50fa-cac2-4819-bcf9-3aa835c87d49","title":"北大元培校友论文获ICML时间检验奖，Hinton弟子一作，生成式AI成今年热门获奖理由","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247688503&idx=3&sn=d1fa14b86f8e33f5f071123a8d78963a&exportkey=n_ChQIAhIQYzEwtmOMgst%2BPrTU6XjaHRKWAgIE97dBBAEAAAAAAJK7DIdYE%2BMAAAAOpnltbLcz9gKNyK89dVj0bwPYi1SbxerL5kV5df%2By9sShvv0QsrpjRXsCCzpr6e8CWI%2BMVgR9z5DpL%2Bqt04TeDG%2B%2B8zAWKMEaSkbkyA2odVIIiFb5TeoFNJCaRUYDDjLT%2Fv6m1uEpBhpmbJInh0vb%2BzYi2Hyeg%2F%2FMsw3lbosXVy1AMfPrxJTQ2AJWbGMDXZeSPuY9FjOeKyOrfLpizMmYhdDttrtGFHggkae%2BV0yrVPwQQwVQt8wPFHzlJLPfG4uBHZ%2FnezdsEtcLCpl9zNrZvyFu19%2F1xPx8ik%2BLwd6kkA%2FGmQ%2FVlzWy1IZZApNHntQtl1eZOspqgSkVuIXbQGaX&acctmode=0&pass_ticket=gM7jjNHSHn%2FFl2KBNYGxIYmGiyDJDXcMNwYamme80O9brlbafQKY2x4x973J%2BVc9&wx_header=0","urlHash":1948348894},"80e1fabd-3249-40f1-9c08-1862d270ed7b":{"favIconUrl":"fallback","id":"80e1fabd-3249-40f1-9c08-1862d270ed7b","title":"从DCGAN到SELF-MOD：GAN的模型架构发展一览 - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/6549","urlHash":2950325871},"8103ce22-2392-4e89-b96c-d8948c7ce7d4":{"favIconUrl":"fallback","id":"8103ce22-2392-4e89-b96c-d8948c7ce7d4","title":"[2007.08432] Data Poisoning Attacks Against Federated Learning Systems","url":"https://arxiv.org/abs/2007.08432","urlHash":4027887184},"8109e103-8ad4-4270-ada9-bdacc25262de":{"favIconUrl":"fallback","id":"8109e103-8ad4-4270-ada9-bdacc25262de","title":"Insights into Pre-training via Simpler Synthetic Tasks - Arxiv-2206.10139","url":"https://arxiv.org/abs/2206.10139","urlHash":3442425392},"81569853-9574-4c26-8319-aac0519e2a38":{"favIconUrl":"fallback","id":"81569853-9574-4c26-8319-aac0519e2a38","title":"consistency models yang song - Google Search","url":"https://www.google.com/search?q=consistency+models+yang+song&newwindow=1&sxsrf=APwXEde3scirTUq-M3zOTN-HXG3716va2A%3A1683930247564&ei=h7xeZJOFIsCe5NoPyP-1sAc&ved=0ahUKEwjT5O2B6fD-AhVAD1kFHch_DXYQ4dUDCBA&uact=5&oq=consistency+models+yang+song&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIFCAAQgAQyCggAEIAEEAoQywEyCAgAEIoFEIYDMggIABCKBRCGAzoKCAAQRxDWBBCwAzoHCCMQigUQJzoHCAAQigUQQzoICAAQgAQQsQM6CwguEIAEELEDEIMBOgQIIxAnOggIABCKBRCRAjoFCC4QgAQ6EQguEIAEELEDEIMBEMcBENEDOgsILhCvARDHARCABDoOCC4QgAQQsQMQxwEQ0QM6CAgAEIAEEMkDOg0IABCABBAUEIcCELEDOgsIABCABBCxAxDJAzoICAAQgAQQkgM6CAgAEIoFEJIDOgoIABCABBAUEIcCOgsIABCKBRCxAxCRAjoICAAQgAQQywFKBAhBGABQtgZY_iZg9SdoA3ABeACAAY0BiAH4E5IBBDIzLjWYAQCgAQHIAQjAAQE&sclient=gws-wiz-serp","urlHash":496498351},"8183e7d5-1a5b-47d4-b786-917cf7c1ac62":{"favIconUrl":"fallback","id":"8183e7d5-1a5b-47d4-b786-917cf7c1ac62","title":"Benign Overfitting in Linear Regression - Arxiv-1906.11300","url":"https://arxiv.org/pdf/1906.11300.pdf","urlHash":18813529},"819c5074-e39d-40d9-ac53-51265e7b4a4d":{"favIconUrl":"https://transformer-circuits.pub/favicon.ico","id":"819c5074-e39d-40d9-ac53-51265e7b4a4d","title":"Softmax Linear Units","url":"https://transformer-circuits.pub/2022/solu/index.html#section-6-3-4","urlHash":250042597},"81c87449-5085-4b3f-a4e0-b4702c3b8233":{"favIconUrl":"fallback","id":"81c87449-5085-4b3f-a4e0-b4702c3b8233","title":"Understanding SSD MultiBox — Real-Time Object Detection In Deep Learning","url":"https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab","urlHash":3869884355},"81d0544c-79ec-494d-8338-cf059ce7eda8":{"favIconUrl":"fallback","id":"81d0544c-79ec-494d-8338-cf059ce7eda8","title":"LLM+P Empowering Large Language Models with Optimal Planning Proficiency - Arxiv-2304.11477","url":"https://arxiv.org/pdf/2304.11477.pdf","urlHash":641440552},"81ecd826-e5f1-4dca-a985-f43729144cfc":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"81ecd826-e5f1-4dca-a985-f43729144cfc","title":"We're Afraid Language Models Aren't Modeling Ambiguity | PDF","url":"https://arxiv.org/pdf/2304.14399.pdf?trk=public_post_comment-text","urlHash":1347393569},"8224a4a3-e001-4d05-8153-eb6cb94952e5":{"favIconUrl":"https://wikiwandv2-19431.kxcdn.com/icons/favicon.ico","id":"8224a4a3-e001-4d05-8153-eb6cb94952e5","title":"Noumenon - Wikiwand","url":"https://www.wikiwand.com/en/Noumenon","urlHash":1750793990},"822aceb8-5c19-4454-8e9a-6152e5a6a296":{"favIconUrl":"fallback","id":"822aceb8-5c19-4454-8e9a-6152e5a6a296","title":"《过去之书》、《未来之书》简评","url":"https://www.douban.com/note/839749776/?_i=2431422KLQjbnS,2433879KLQjbnS","urlHash":1070034349},"82674030-107c-4a60-93f0-ae14ddb5640c":{"favIconUrl":"fallback","id":"82674030-107c-4a60-93f0-ae14ddb5640c","title":"COMPSCI 229BR: Topics in the Foundations of Machine Learning - Perusall","url":"https://app.perusall.com/courses/compsci-229br-topics-in-the-foundations-of-machine-learning/_/dashboard/assignments/aBxHqWK3cBuw3qp8g","urlHash":1249772743},"827d300a-6185-494e-a4da-00ec6a26f779":{"favIconUrl":"https://www.google.com/favicon.ico","id":"827d300a-6185-494e-a4da-00ec6a26f779","title":"dragon+ retriever - Google Search","url":"https://www.google.com/search?q=dragon%2B+retriever&oq=dragon%2B+retriever&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyCAgBEAAYFhgeMgoIAhAAGAoYFhgeMggIAxAAGBYYHjIICAQQABgWGB4yCAgFEAAYFhge0gEIMjUzNGowajGoAgCwAgA&sourceid=chrome&ie=UTF-8","urlHash":4289180893},"828cab97-402d-4df4-8b05-307cc7749109":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"828cab97-402d-4df4-8b05-307cc7749109","title":"Prompt Consistency for Zero-Shot Task Generalization | PDF","url":"https://arxiv.org/pdf/2205.00049.pdf","urlHash":2097638423},"82da2322-af79-4667-b564-258d09d12358":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"82da2322-af79-4667-b564-258d09d12358","title":"Jinhao Jiang on X: \"🧐Can LLMs perform autonomous complex reasoning (e.g., multi-hop, constraint, judgment, and numerical operation) over KG (e.g., Wikidata or Freebase)? Yes! KG-Agent can! And it only requires a 7B LLM and 10K tuning samples. (1/5) https://t.co/3ykwp1pnhZ\" / X","url":"https://twitter.com/Boru80914053/status/1760311739214868499","urlHash":1835633113},"83106cb0-16b1-49ee-876c-4cf53f4ff832":{"favIconUrl":"fallback","id":"83106cb0-16b1-49ee-876c-4cf53f4ff832","title":"walter benjamin theses on philosophy of history reddit - Google Search","url":"https://www.google.com/search?q=walter+benjamin+theses+on+philosophy+of+history+reddit&newwindow=1&rlz=1C1GCEA_enUS1059US1059&sxsrf=APwXEdfauyVl3-x-u9nfi1b33U2CBa2oxA%3A1688137244790&ei=HO6eZPDuL56h5NoP3IGDcA&ved=0ahUKEwjw7Lqmoev_AhWeEFkFHdzAAA4Q4dUDCBA&uact=5&oq=walter+benjamin+theses+on+philosophy+of+history+reddit&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIFCCEQoAE6CggAEEcQ1gQQsAM6BggAEBYQHjoICAAQigUQhgM6BQghEKsCSgQIQRgAUO0FWKQOYNgOaAFwAXgAgAFpiAH1A5IBAzUuMZgBAKABAcABAcgBCA&sclient=gws-wiz-serp","urlHash":3064194918},"831ab2f3-59da-4947-a371-2b80cb4f4063":{"favIconUrl":"fallback","id":"831ab2f3-59da-4947-a371-2b80cb4f4063","title":"Timothyxxx/RetrivalLMPapers: Paper collections of retrieval-based(augmented) language model.","url":"https://github.com/Timothyxxx/RetrivalLMPapers","urlHash":135395193},"832d845d-f35b-41cc-8b3c-a063fcd40dfd":{"favIconUrl":"https://g.csdnimg.cn/static/logo/favicon32.ico","id":"832d845d-f35b-41cc-8b3c-a063fcd40dfd","title":"ChatGPT技术原理解析：从RL之PPO算法、RLHF到GPT4、instructGPT-CSDN博客","url":"https://blog.csdn.net/v_JULY_v/article/details/128579457","urlHash":1010421498},"8342b36f-b509-4f43-b96f-6f5227d2d5fa":{"favIconUrl":"fallback","id":"8342b36f-b509-4f43-b96f-6f5227d2d5fa","title":"GanjinZero/RRHF: RRHF & Wombat","url":"https://github.com/GanjinZero/RRHF","urlHash":3836861678},"8360a0f5-0eec-4c7d-872d-9446378190cf":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"8360a0f5-0eec-4c7d-872d-9446378190cf","title":"Aran Komatsuzaki on X: \"Shepherd: A Critic for Language Model Generation Presents a LM specifically tuned to critique model responses and suggest refinements, which closely ties with ChatGPT. repo: https://t.co/e7kLd6U9pN abs: https://t.co/GL9M17ZUrS https://t.co/euOyaWwWwh\" / X","url":"https://twitter.com/arankomatsuzaki/status/1689457397293891584","urlHash":1801425513},"83c9e30f-7b9d-4c63-a41b-96416bb4d410":{"favIconUrl":"fallback","id":"83c9e30f-7b9d-4c63-a41b-96416bb4d410","title":"How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval | PDF","url":"https://arxiv.org/pdf/2302.07452.pdf","urlHash":3258810023},"83e18788-9241-4d65-adb1-7a6c7a518d29":{"favIconUrl":"https://www.youtube.com/s/desktop/54055272/img/favicon_32x32.png","id":"83e18788-9241-4d65-adb1-7a6c7a518d29","title":"返校游戏 - YouTube","url":"https://www.youtube.com/results?search_query=%E8%BF%94%E6%A0%A1%E6%B8%B8%E6%88%8F","urlHash":2539021684},"83e4840c-8962-4d93-bd24-de454842447c":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"83e4840c-8962-4d93-bd24-de454842447c","title":"StackLLaMA: A hands-on guide to train LLaMA with RLHF","url":"https://huggingface.co/blog/stackllama","urlHash":1258597252},"83f04485-a292-48c0-b5ea-db76e1e102d5":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"83f04485-a292-48c0-b5ea-db76e1e102d5","title":"Colin Raffel on X: \"How can we recycle specialized PEFT modules to create a generalist MoE-style model? We introduce PHATGOOSE, which learns a post-hoc routing scheme and significantly improves zero-shot generalization. 📜 https://t.co/s3S3EKZaPx 📝 https://t.co/rFphLDD9CR 💾 https://t.co/qnEcph3pxN https://t.co/doW1v4C0EQ\" / X","url":"https://twitter.com/colinraffel/status/1755770081475219823","urlHash":1022197471},"83f807f0-68c3-4486-9a15-b668665b803a":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"83f807f0-68c3-4486-9a15-b668665b803a","title":"Pretraining Language Models with Human Preferences | PDF","url":"https://arxiv.org/pdf/2302.08582.pdf","urlHash":1818041932},"840288b4-8530-46b4-bf8b-2d2fd3658cc4":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"840288b4-8530-46b4-bf8b-2d2fd3658cc4","title":"lucidrains/pause-transformer: Yet another random morning idea to be quickly tried and architecture shared if it works; to allow the transformer to pause for any amount of time on any token","url":"https://github.com/lucidrains/pause-transformer","urlHash":1040737152},"84116e49-39e9-4720-9483-00c4cce0ba65":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"84116e49-39e9-4720-9483-00c4cce0ba65","title":"Pan Lu on X: \"🚀Meet Chameleon! An innovative plug-and-play framework enhancing #GPT4 and #ChatGPT like #AutoGPT for compositional reasoning, blending off-the-shelf tools with tailored LLM models 🔧✨🧠. New SOTA on #ScienceQA and TabMWP! 📈 🔗https://t.co/IBCvtHfz7Q 📜https://t.co/b0fETXZHfq https://t.co/hidc9zIlJ8\" / X","url":"https://twitter.com/lupantech/status/1648879085115052033","urlHash":3862692167},"847a1b99-dc80-4cc6-9640-519a8e40befb":{"favIconUrl":"fallback","id":"847a1b99-dc80-4cc6-9640-519a8e40befb","title":"Putting Words in BERT's Mouth: Navigating Contextualized Vector Spaces with Pseudowords","url":"https://svivek.com/research/publications/karidi2021putting.pdf","urlHash":2149494902},"8481953a-9abe-464b-b997-625c9781adc9":{"favIconUrl":"fallback","id":"8481953a-9abe-464b-b997-625c9781adc9","title":"Measuring Progress on Scalable Oversight for Large Language Models - Arxiv-2211.03540","url":"https://arxiv.org/pdf/2211.03540.pdf","urlHash":3313373254},"84a9f355-f5a9-4dcc-9281-75d01f0b5f1a":{"favIconUrl":"fallback","id":"84a9f355-f5a9-4dcc-9281-75d01f0b5f1a","title":"Exacerbating Algorithmic Bias through Fairness Attacks - Arxiv-2012.08723","url":"https://arxiv.org/pdf/2012.08723.pdf","urlHash":1820909024},"84aaa27d-b91d-49ac-9418-b6751111dac4":{"favIconUrl":"fallback","id":"84aaa27d-b91d-49ac-9418-b6751111dac4","title":"differential privacy fairness - Google Search","url":"https://www.google.com/search?q=differential+privacy+fairness&newwindow=1&sxsrf=AJOqlzWuZGngWQiV7PJB0o3v6ePaCSBNZw%3A1679123878679&ei=pmUVZM6IKYWr5NoPsNGKgAQ&ved=0ahUKEwjO88ny9-T9AhWFFVkFHbCoAkAQ4dUDCBA&uact=5&oq=differential+privacy+fairness&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIFCAAQgAQyBggAEBYQHjIFCAAQhgMyBQgAEIYDOgoIABBHENYEELADOgcIABCwAxBDOg0IABDkAhDWBBCwAxgBOgwILhDIAxCwAxBDGAI6CggAEIAEEBQQhwI6BAgAEEM6BQguEIAESgQIQRgAUMUBWIIJYIwKaAFwAXgAgAFYiAHQBZIBATmYAQCgAQHIARHAAQHaAQYIARABGAnaAQYIAhABGAg&sclient=gws-wiz-serp","urlHash":3871153642},"84b011a7-1f4e-411c-9631-22ab8c8a1f34":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"84b011a7-1f4e-411c-9631-22ab8c8a1f34","title":"Towards Understanding Grokking: An Effective Theory of Representation Learning | Abstract","url":"https://arxiv.org/abs/2205.10343","urlHash":2165862814},"84c85910-d832-4a7e-ac42-4c63ef85e032":{"favIconUrl":"fallback","id":"84c85910-d832-4a7e-ac42-4c63ef85e032","title":"Noise Contrastive Estimation 前世今生——从 NCE 到 InfoNCE - 知乎","url":"https://zhuanlan.zhihu.com/p/334772391","urlHash":3038336842},"84d2509b-4005-4e12-a552-88f65676b1f1":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"84d2509b-4005-4e12-a552-88f65676b1f1","title":"AI视觉字谜爆火！梦露转180°秒变爱因斯坦，英伟达高级AI科学家：近期最酷的扩散模型","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247707563&idx=1&sn=228cecc31ffbd8c42936e1b883734d67&exportkey=n_ChQIAhIQmtxZL2SX2xh8VB7QsMU9CBKWAgIE97dBBAEAAAAAAJ%2BJAt4g7SQAAAAOpnltbLcz9gKNyK89dVj0qp0yv4gO%2F3%2B1NofQlxqXF0FMxdJ%2Bq70f9Sg7%2BIdw91H21pJIqk0bD7MPjkTVMk1DOm1fZihxXjqTsAPBJpLbc%2BdKQ7NZWcPD8%2F63NZBLOnbL7nU4n71hsHyLN6Wl%2FgKRftHIb9D6ZyfYQ2mMSa5M653n9kt5SHNuVBS3vGmwVN8jGYS9L3JpeEH7x6rJY3x8Rknhr9yDEDxk6gRelKjIS51DM%2BW0tDDNrUhcOqHiMtX4G9bS3hJu15gGLWRdcgn8qvvHPSqH90Yr3MDFyixP2ADA5uXfbYmsJZwzPmVA6SGptAVfD5JNfFRPI5xqjFPl&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsa2%2FkWdu8jmgDF4jIxhQCkqlA%2F6GR2Rcg%2FDbo3aRYElsA%3D%3D&wx_header=0","urlHash":2624885040},"84ff3661-6678-41c3-83ad-a36705076c6c":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"84ff3661-6678-41c3-83ad-a36705076c6c","title":"Large Language Models on Graphs: A Comprehensive Survey | Abstract","url":"https://arxiv.org/abs/2312.02783?utm_source=substack&utm_medium=email","urlHash":3104118055},"8517ab5d-d0e2-41a1-a7db-1c806eace623":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"8517ab5d-d0e2-41a1-a7db-1c806eace623","title":"Defining capability and alignment in gradient descent — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/Xg2YycEfCnLYrCcjy/defining-capability-and-alignment-in-gradient-descent","urlHash":249264801},"8518bbda-362c-4264-8ce5-2bf0ced6412a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"8518bbda-362c-4264-8ce5-2bf0ced6412a","title":"twitter.com/arankomatsuzaki/status/1661909042007031809","url":"https://twitter.com/arankomatsuzaki/status/1661909042007031809","urlHash":1983034306},"8552eeed-11e7-4de1-adf3-2a959df19a23":{"favIconUrl":"fallback","id":"8552eeed-11e7-4de1-adf3-2a959df19a23","title":"A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation","url":"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Perazzi_A_Benchmark_Dataset_CVPR_2016_paper.pdf","urlHash":1288465512},"8571f7b6-70d5-479e-81ae-4460f62e6328":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"8571f7b6-70d5-479e-81ae-4460f62e6328","title":"Transformer王者归来！无需修改任何模块，时序预测全面领先","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652393209&idx=4&sn=bf5e315109d96682b65c0ebd3dd121de&exportkey=n_ChQIAhIQk2aIJLC%2Bu8zs9P4RbBzttRKWAgIE97dBBAEAAAAAAFUwKbyYu%2BsAAAAOpnltbLcz9gKNyK89dVj0h8ns%2Fdf1AJTWSOAJtlc2eoCKMkpXjMmWJqGN70NOvFSROUlNxzu%2FgCSVBP3AP6E33ueZi%2FnNYl5CInkzIJxcZO27lcFAqM8pGN3u35PutatMsmwO9AIin0vw6qnppzWs8ZeJu2l8fDNBdl9rIGpbNz9xsYdxRidT596iY6%2BdCPtXrrFRc8C%2Bh1AQyypRX%2FaDL5DNgc%2BulWfUCPb9FOBhaPEjtz617jW2%2FADnnJxwJisurSDhUtOYO6y6jkZo7vzPjqwQq2yT%2FHaY9MO3TSwAv4SvNyfq0Y%2Fp2haA2LRet%2FhpQrNzVuoag%2F5CXJPxjksm&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsZ5YwFIYi1es4Y7mWon6k4ml%2Fl0eSNiZy1%2F6SMNiidD4w%3D%3D&wx_header=0","urlHash":3801951402},"85c5aa66-5dc0-4946-a9f3-30b06e98203a":{"favIconUrl":"fallback","id":"85c5aa66-5dc0-4946-a9f3-30b06e98203a","title":"Understanding Black-box Predictions via Influence Functions - Arxiv-1703.04730","url":"https://arxiv.org/abs/1703.04730","urlHash":542341094},"85c64763-56fb-4f98-a17c-04d830b69a50":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"85c64763-56fb-4f98-a17c-04d830b69a50","title":"Don't Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments | PDF","url":"https://arxiv.org/pdf/2212.09736.pdf","urlHash":1775307344},"85cb13bd-ee81-4bf5-8eb7-354c2208162c":{"favIconUrl":"https://ssl.gstatic.com/docs/presentations/images/favicon-2023q4.ico","id":"85cb13bd-ee81-4bf5-8eb7-354c2208162c","title":"Language Language Models (in 2023) - Google 幻灯片","url":"https://docs.google.com/presentation/d/1636wKStYdT_yRPbJNrf8MLKpQghuWGDmyHinHhAKeXY/edit#slide=id.g27b7c310230_0_269","urlHash":3865998002},"85f9866a-36da-462b-823c-140f8a57c8f1":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"85f9866a-36da-462b-823c-140f8a57c8f1","title":"开局一段扯，数据全靠编？真被一篇“神论文”气到了 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/8783","urlHash":2309388400},"86006621-1254-440e-92bc-547d04723afb":{"favIconUrl":"fallback","id":"86006621-1254-440e-92bc-547d04723afb","title":"Virtual Attention heads [rough early thoughts] - YouTube","url":"https://www.youtube.com/watch?v=CPmLjqmeNJo&list=PLoyGOS2WIonajhAVqKUgEMNmeq3nEeM51&index=13","urlHash":3983277549},"860d9144-7a8d-4fe2-9dd6-c50f0afaea6c":{"favIconUrl":"fallback","id":"860d9144-7a8d-4fe2-9dd6-c50f0afaea6c","title":"Understanding Deep Learning on Controlled Noisy Labels – Google AI Blog","url":"https://ai.googleblog.com/2020/08/understanding-deep-learning-on.html","urlHash":484287209},"86208296-f9b2-438c-856e-effa1a0326a9":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"86208296-f9b2-438c-856e-effa1a0326a9","title":"Instruction Mining: When Data Mining Meets Large Language Model Finetuning | PDF","url":"https://arxiv.org/pdf/2307.06290.pdf","urlHash":4027058420},"8623ca4a-d3cb-401d-a3ed-8a47ce4dcbc0":{"favIconUrl":"data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22> </text></svg>","id":"8623ca4a-d3cb-401d-a3ed-8a47ce4dcbc0","title":"Recognize Anything: A Strong Image Tagging Model","url":"https://recognize-anything.github.io/","urlHash":2655771837},"866b3b15-71ac-49ba-a621-f44ea03913cb":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"866b3b15-71ac-49ba-a621-f44ea03913cb","title":"Xin Eric Wang on X: \"What are next steps beyond current LLMs? While most powerful LLMs like GPT-4(v) excel in vision-and-language comprehension, they remain restricted to solely text-based output. We are excited to introduce our new work, MiniGPT-5, which demonstrates the potentials and… https://t.co/7rjzP8PKXN\" / X","url":"https://twitter.com/xwang_lk/status/1714115577630109723","urlHash":3571265460},"866cff29-6cd4-42dc-acc9-26950ee9b20c":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"866cff29-6cd4-42dc-acc9-26950ee9b20c","title":"arxiv.org","url":"https://arxiv.org/pdf/2307.10476.pdf","urlHash":629640202},"867b55f1-497e-4b7a-800f-c2c740abcf43":{"favIconUrl":"fallback","id":"867b55f1-497e-4b7a-800f-c2c740abcf43","title":"Decepticons Corrupted Transformers Breach Privacy in Federated Learning for Language Models - Arxiv-2201.12675","url":"https://arxiv.org/abs/2201.12675","urlHash":3935543527},"8685d659-8f96-4a61-a3e9-1d6cacf33012":{"favIconUrl":"fallback","id":"8685d659-8f96-4a61-a3e9-1d6cacf33012","title":"细水长flow之NICE：流模型的基本概念与实现 - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/5776/comment-page-3#comments","urlHash":717104482},"86a0434e-4d98-490a-a1c8-7ae4d86b50f4":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"86a0434e-4d98-490a-a1c8-7ae4d86b50f4","title":"Composing Parameter-Efficient Modules with Arithmetic Operations | PDF","url":"https://arxiv.org/pdf/2306.14870.pdf","urlHash":1254678531},"86a6a24d-6d72-47b0-b7b6-6861da356db9":{"favIconUrl":"fallback","id":"86a6a24d-6d72-47b0-b7b6-6861da356db9","title":"这本书算是散文吗？肯定不是小说","url":"https://book.douban.com/subject/10555509/discussion/637203803/","urlHash":2185021617},"86d733e0-772f-4bc7-ab0d-637c6b045aee":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"86d733e0-772f-4bc7-ab0d-637c6b045aee","title":"200 Concrete Open Problems in Mechanistic Interpretability: Introduction — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/LbrPTJ4fmABEdEnLf/200-concrete-open-problems-in-mechanistic-interpretability","urlHash":2001022950},"870551bc-707d-44b8-a1e8-64a3c319f6e1":{"favIconUrl":"fallback","id":"870551bc-707d-44b8-a1e8-64a3c319f6e1","title":"Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens | Abstract","url":"https://arxiv.org/abs/2401.17377","urlHash":2875163400},"87162daf-7a37-4125-a493-a8cb84f7566d":{"favIconUrl":"fallback","id":"87162daf-7a37-4125-a493-a8cb84f7566d","title":"ICLR2023","url":"https://mp.weixin.qq.com/s?__biz=Mzg3ODU3Njc4Ng==&mid=2247484643&idx=1&sn=a730394720c70e6f0b3a59d7937a2bd6&chksm=cf10d11ef86758080519064621cc3e50bccf29e792ca48cc43df5dd16a24b730f5745713e692&mpshare=1&scene=1&srcid=10015muUsP83InmTW5UOTQxM&sharer_shareinfo=9704d3c6987252ee0f7b74cbebf02d3c&sharer_shareinfo_first=9704d3c6987252ee0f7b74cbebf02d3c&exportkey=n_ChQIAhIQOdCkDGVLnm56MyJIOb2xIhKNAgIE97dBBAEAAAAAANz4DGiJ%2FJcAAAAOpnltbLcz9gKNyK89dVj0FBiAnNdkWobo1I5RCcmBkVbFbVQo4d9MRNPv2toqZ1%2FHSyg0%2B0LmnecKyz5qVyKhPMAnmwOx98p1UTLUjOybojjWrsDJc0dFpfZQQg3DGNxIDFsMug0gL6GFYoMd9a%2FbwHgNY1NCuOf0V%2B%2FvPTi1bpf4PrlQxmbNWRUGmdfv3H7ars58TZKBnAgTyDjITstyqeIzhpUcdFAgEbG%2FyLEUCHXOtmjd7AyNwEJsE%2Bg5kPxR%2BGnyulGX442Nwx58goMNjlmF3B3hmjANEWWXuBcs%2B%2FtLMGrD79vuvx5f3s7wlEWE0Vr9%2Fqn1&acctmode=0&pass_ticket=T5KLz%2FfQkq5FLLgq9O0suMaRAzAMi9%2FkP6bmbYEe6JORYXThUf%2FyQZQnD%2BBVwG%2Fh&wx_header=0#rd","urlHash":2432098932},"87177ef2-8de8-4099-a567-bff83bd2e62f":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"87177ef2-8de8-4099-a567-bff83bd2e62f","title":"Sam Bowman on X: \"I gave a talk! You can watch it! Covering: Scalable oversight, AI-AI debate, hard QA datasets, and getting truthful answers out of AI systems in domains we don't know much about. https://t.co/yRsD9GOEja\" / X","url":"https://twitter.com/sleepinyourhat/status/1737965471323066446","urlHash":780411338},"871f398d-78f4-45c7-b006-848aff0cb988":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"871f398d-78f4-45c7-b006-848aff0cb988","title":"全球最强「开源版Gemini」诞生！全能多模态模型Emu2登热榜，多项任务刷新SOTA","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652423845&idx=1&sn=37c2e0c00d9f16379bb86e789eae1121&chksm=f12bb254c65c3b42000bab97ed8b32b4b709e7881ca3b99a09c63f79870449dfb782ddeef8d9&mpshare=1&scene=1&srcid=01153ROJk79iAtdj1CaWMEL1&sharer_shareinfo=04f5b43457150c13d1cb7ee62608aea9&sharer_shareinfo_first=04f5b43457150c13d1cb7ee62608aea9&exportkey=n_ChQIAhIQMeMG0E%2Fxf%2BdsHLTJzlfmUhKWAgIE97dBBAEAAAAAAFqBMy54Tq8AAAAOpnltbLcz9gKNyK89dVj0OtFypD2cgYcIvsecLtysPo1Wd21UIh%2Fu%2FPMB9KUlKr1zmQDesnph%2F3woPe7rP86Eg5DGJxpsqPZJrC8MfA%2BP9ZzPS%2FVRMq0e0vIjGwyFQX%2FkEZie9xX4k7hfVdCcEzsadkVKlfRQ9%2Bn9rGXtlXHeIzMEs7fmzKm2p2FUK6BfaBlGJws3Dq00LVgfJTP01e1sI4kJs6G5DZddtErAWLUuP2a38Nd6pXBgwdgZJ%2FqltpbxRTACKybhIAeRaNf9EofUaX%2FN5tQnLoqfdDJJF719u0np%2BKapEGtuQIqJ5WA2lsVMiK%2BrP%2BqUqd%2FwbOc7Neyo&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsa7%2F6a24VUmnF2ktRSI23succ6Kivosq1rdmsvyDmlSSQ%3D%3D&wx_header=0#rd","urlHash":77084981},"8749b66f-b5fb-481b-8f99-009c8a3ea6b5":{"favIconUrl":"fallback","id":"8749b66f-b5fb-481b-8f99-009c8a3ea6b5","title":"查拉图斯特拉如是说 - Google Search","url":"https://www.google.com/search?q=%E6%9F%A5%E6%8B%89%E5%9B%BE%E6%96%AF%E7%89%B9%E6%8B%89%E5%A6%82%E6%98%AF%E8%AF%B4&oq=%E6%9F%A5%E6%8B%89%E5%9B%BE%E6%96%AF%E7%89%B9%E6%8B%89%E5%A6%82%E6%98%AF%E8%AF%B4&aqs=chrome..69i57.1404j0j1&sourceid=chrome&ie=UTF-8","urlHash":1343450059},"8750a9de-7651-4445-8860-edc5a71b5318":{"favIconUrl":"fallback","id":"8750a9de-7651-4445-8860-edc5a71b5318","title":"Robust Curriculum Learning: from clean label detection to noisy label self-correction","url":"https://openreview.net/forum?id=lmTWnm3coJJ","urlHash":1361436249},"87b809f4-bd30-472f-8709-11f58b71378d":{"favIconUrl":"https://www.google.com/favicon.ico","id":"87b809f4-bd30-472f-8709-11f58b71378d","title":"小林泰三《junk》 - Google Search","url":"https://www.google.com/search?q=%E5%B0%8F%E6%9E%97%E6%B3%B0%E4%B8%89%E3%80%8Ajunk%E3%80%8B","urlHash":2921477969},"87c3f06a-1562-42eb-9c05-6b56797dc859":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"87c3f06a-1562-42eb-9c05-6b56797dc859","title":"Transformers Agents by sgugger · Pull Request #23214 · huggingface/transformers","url":"https://github.com/huggingface/transformers/pull/23214","urlHash":4168319506},"87ca0348-9540-4e3c-b96d-63682734ec6f":{"favIconUrl":"fallback","id":"87ca0348-9540-4e3c-b96d-63682734ec6f","title":"A Learning Theoretic Perspective on Local Explainability - Arxiv-2011.01205","url":"https://arxiv.org/abs/2011.01205","urlHash":3523024659},"87d72195-dbe0-4759-a6c5-48e31e6564ac":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"87d72195-dbe0-4759-a6c5-48e31e6564ac","title":"LORD: Low Rank Decomposition Of Monolingual Code LLMs For One-Shot Compression | PDF","url":"https://arxiv.org/pdf/2309.14021.pdf","urlHash":409977114},"87de8db5-6cf0-49e5-ace3-664c05a21f66":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"87de8db5-6cf0-49e5-ace3-664c05a21f66","title":"RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture | Abstract","url":"https://arxiv.org/abs/2401.08406?utm_source=substack&utm_medium=email","urlHash":1401479837},"881aff31-3943-4752-b071-b4aa105e7959":{"favIconUrl":"fallback","id":"881aff31-3943-4752-b071-b4aa105e7959","title":"https://arxiv.org/pdf/2206.12654.pdf","url":"https://arxiv.org/pdf/2206.12654.pdf","urlHash":4039786692},"882da82a-07da-4863-9e30-f9ce14fa2394":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"882da82a-07da-4863-9e30-f9ce14fa2394","title":"A Survey on Large Language Model based Autonomous Agents | PDF","url":"https://arxiv.org/pdf/2308.11432.pdf","urlHash":619732820},"8834c57b-2ceb-4d4c-b7c5-6ae86f15f67d":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"8834c57b-2ceb-4d4c-b7c5-6ae86f15f67d","title":"Papers We Want to Read - a HuggingFaceH4 Collection","url":"https://huggingface.co/collections/HuggingFaceH4/papers-we-want-to-read-6570981910d0841de2d06744","urlHash":2567428276},"884803d5-4855-4d65-989f-8066e29fa483":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"884803d5-4855-4d65-989f-8066e29fa483","title":"M$^3$IT: A Large-Scale Dataset towards Multi-Modal Multilingual Instruction Tuning | PDF","url":"https://arxiv.org/pdf/2306.04387.pdf","urlHash":2542586697},"8854e20c-092b-4cfc-a2af-8330f5feca29":{"favIconUrl":"fallback","id":"8854e20c-092b-4cfc-a2af-8330f5feca29","title":"Timothyxxx/Chain-of-ThoughtsPapers: A trend starts from \"Chain of Thought Prompting Elicits Reasoning in Large Language Models\".","url":"https://github.com/Timothyxxx/Chain-of-ThoughtsPapers","urlHash":3193905576},"8881b76a-8c2d-49e6-9eaf-1c1a7bd3d124":{"favIconUrl":"fallback","id":"8881b76a-8c2d-49e6-9eaf-1c1a7bd3d124","title":"细水长flow之NICE：流模型的基本概念与实现 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/5776/comment-page-1#comments","urlHash":2949543944},"8887850c-e5ef-43dc-a913-c313192f7aa4":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"8887850c-e5ef-43dc-a913-c313192f7aa4","title":"Locating and Editing Factual Associations in GPT | PDF","url":"https://arxiv.org/pdf/2202.05262.pdf","urlHash":269255024},"888e87d2-1fbe-4f88-bb06-0050d44fe908":{"favIconUrl":"fallback","id":"888e87d2-1fbe-4f88-bb06-0050d44fe908","title":"Datasets","url":"https://wilds.stanford.edu/datasets/","urlHash":2521892554},"888ff935-bd19-401d-a5f6-3fb04a4e6bd6":{"favIconUrl":"https://transformer-circuits.pub/favicon.ico","id":"888ff935-bd19-401d-a5f6-3fb04a4e6bd6","title":"Privileged Bases in the Transformer Residual Stream","url":"https://transformer-circuits.pub/2023/privileged-basis/index.html","urlHash":2022060524},"88a0d9ad-6880-4b89-9a9b-01121de7588d":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"88a0d9ad-6880-4b89-9a9b-01121de7588d","title":"击败整个羊驼家族，Meta AI自对齐新方法只需极少人工标注数据","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247692038&idx=3&sn=bcf139672cb317c1c9eaf911f0ba143a&chksm=e8df5874dfa8d1623d06bc393c57f38241a2a3c7eef32c497617bfa9d9e9eff1e69d92900cf4&mpshare=1&scene=1&srcid=1001WtB2d6rdqzpBOc670X6w&sharer_shareinfo=4080c3519d9aaa643a03c0de9cc8889d&sharer_shareinfo_first=4080c3519d9aaa643a03c0de9cc8889d&exportkey=n_ChQIAhIQDFDCAJkft3hxPgR74LLnhxKWAgIE97dBBAEAAAAAAOiMIlY1Th0AAAAOpnltbLcz9gKNyK89dVj0Oun6eMR2ux4mMU3rH6E0i80Wlj9wmPgeVdqVtGVoMNLEs7Fxui1xrar8ivis1dFCspIBvZzcMSFYo7Nm630sSc0KmeJthTig7YFf81SN2tr40OxgDyeGGgS%2BRigvbcZUkXaoXtJtc2Pc1ekE%2FQ4QTqdkRM8HKvDOoCP8PPJTZQ5%2FAja3hEd2l0A78UvafbH%2FivaRlMHmtkW9y0dX3ta1KVSYPvmAaOJdwM8rFFP4usFQVW4t6NAbcSeRlzq5oh%2BshJdkJYpFwJXn22mfM3%2Fb1eYxI8RiJuFBPXdRKB5dCXH%2F1DTzGKTNojHqoYnFvDZ9&acctmode=0&pass_ticket=SPfjtJOtkuziUTQA4nnpBmKdoVj5eE2jTcakZApVJgoX54yDtDnwVYRk97TK3f3u&wx_header=0#rd","urlHash":4262491275},"88afd632-31bc-4fb6-a9d4-f514be1b532c":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"88afd632-31bc-4fb6-a9d4-f514be1b532c","title":"7 种 LLM 融合扩展总结：LLaMA-Pro、SOLAR、MoE 等","url":"https://mp.weixin.qq.com/s?__biz=Mzk0ODU3MjcxNA==&mid=2247485690&idx=1&sn=8eaade8ad751a90d957d2cde34d5e45b&chksm=c364cfbff41346a97d51c765d2a3a901239b29cc530fc3dce5d98afa02b62776950d63ccce0a&mpshare=1&scene=1&srcid=0120FbRsWtWeLPW9Sm3LhF7Q&sharer_shareinfo=6d3ddd17537b3a851f2ebf76a83c0fbf&sharer_shareinfo_first=6d3ddd17537b3a851f2ebf76a83c0fbf&exportkey=n_ChQIAhIQPXqL8ZirjzH4ogESmG8ltBKWAgIE97dBBAEAAAAAAI5fOdm36IQAAAAOpnltbLcz9gKNyK89dVj0s98X%2BALCND1p1g%2BrPWDRn07LMakON62yzJh5DfUNvB0P3i7tpVKodfKkafdfr5FiwkopRGg42xSZXlKw4fmhzkIOlfQn1h%2ByxsP5u1Spu87Csoo4yyk%2FSoU%2FXnqmYx%2FaD83ggwNdPRACWhx0YHBdZnS5nWd9fwQATLfbyibTDOfuKjy3KE4Qc%2FoF%2FEtC4DYQZHCbfUGbq11tKKYm2Uu5kJNYyC2PA5u3BQaECUY%2Fb25VE3SlSwdnxvAQRHZ%2FbYkA93lklux5tUXXVFwe3tTj7%2B%2Fms8gATD3B%2BHLVzOqYSEUu0p%2FkzuBcUoxoea8iHreO&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HPLy6y4Ap7NNtHdTKq%2FCzoE1CGkIa634xbzG9aN50r%2BDQ%3D%3D&wx_header=0#rd","urlHash":1601166438},"88c74955-685e-4433-8f4a-c1443720f186":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"88c74955-685e-4433-8f4a-c1443720f186","title":"Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm | Abstract","url":"https://arxiv.org/abs/2102.07350","urlHash":3445353175},"88ead5e8-89a0-47d1-adfa-b32e3771ce9d":{"favIconUrl":"fallback","id":"88ead5e8-89a0-47d1-adfa-b32e3771ce9d","title":"neelnanda-io/TransformerLens","url":"https://github.com/neelnanda-io/TransformerLens","urlHash":1794860087},"88ef246c-755d-4872-8d25-b45b9278019d":{"favIconUrl":"fallback","id":"88ef246c-755d-4872-8d25-b45b9278019d","title":"Data Distillation A Survey - Arxiv-2301.04272","url":"https://arxiv.org/pdf/2301.04272.pdf","urlHash":2149610779},"8919a406-e2e2-42e9-9d03-5c6d86c46201":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"8919a406-e2e2-42e9-9d03-5c6d86c46201","title":"twitter.com/lupantech/status/1631725387880480768","url":"https://twitter.com/lupantech/status/1631725387880480768","urlHash":535641501},"891ebd40-2956-4e18-8256-8649d8704fe2":{"favIconUrl":"fallback","id":"891ebd40-2956-4e18-8256-8649d8704fe2","title":"ChatDB Augmenting LLMs with Databases as Their Symbolic Memory - Arxiv-2306.03901","url":"https://arxiv.org/abs/2306.03901?utm_source=substack&utm_medium=email","urlHash":341708480},"891f98cf-f610-4aca-b866-f6089b5878d8":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"891f98cf-f610-4aca-b866-f6089b5878d8","title":"梯度视角下的LoRA：简介、分析、猜测及推广 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/9590","urlHash":356531614},"89235314-a600-4aa5-bdd9-5395463113c1":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"89235314-a600-4aa5-bdd9-5395463113c1","title":"flacuna: 释放vicuna的问题解决能力","url":"https://mp.weixin.qq.com/s?__biz=MzI3NTQ5MjA4OQ==&mid=2247487530&idx=5&sn=86123ae3376bed719d8133de33eb4c99&chksm=eb02adbcdc7524aa2307187e993b8edfa58fa41dc30486f237bd357fc1bbc422f366f660f53c&mpshare=1&scene=1&srcid=1001YHs4dV3wSMeiHu0ftg9Y&sharer_shareinfo=fdc9fd5accf54fcd920671cc138e8590&sharer_shareinfo_first=fdc9fd5accf54fcd920671cc138e8590&exportkey=n_ChQIAhIQDakurKrXPfA6I%2FO%2BcUOnyhKWAgIE97dBBAEAAAAAAFRHEqZNUEwAAAAOpnltbLcz9gKNyK89dVj0QQdOVqa831DqyBnRU1Hyc9tBu4ThlnQYLbwHMzJXykZbQgc5a%2FnTDagYfKCpQw%2BumohbA%2FdQm12k7RGOh3CQ3SlsXppkS77Wk%2F8qLHIj9vVepHPAx3bl1bY%2BjX6dUNkwqRj4k4VqgRKxnzM1aLli%2BEmmg3FTraJyuqqJoxW5faWqLMsOMUgfQzBwYkvD5ywJMon2d3JVHRoFTv%2FjN672JzeBKCN4NhVV5vb%2FlOhc0bm%2FxQuKQtxyvG3dMP03bvq5twGtrI%2FojnooGydvldwQD1VFXiGci3zFrUj6gEPupx5HTy0ygmsiSX9F0P0B5DOf&acctmode=0&pass_ticket=bTmiinnM9pJvvETkOLE9BxRBBZquz89aGTGEHO9%2BdVla0YprwIgWep45F0MHhT%2BD&wx_header=0#rd","urlHash":1390508640},"89694dc3-61df-46b5-ac87-fe0a02640433":{"favIconUrl":"fallback","id":"89694dc3-61df-46b5-ac87-fe0a02640433","title":"On the reproducibility of 'Exacerbating Algorithmic Bias through Fairness Attacks' - OR-ML_Reproducibility_Challenge-2022_H4lzChGmhCK","url":"https://openreview.net/forum?id=H4lzChGmhCK","urlHash":3657496828},"896c58a2-6cf6-4632-beee-1276a513c622":{"favIconUrl":"https://www.anthropic.com/favicon.ico","id":"896c58a2-6cf6-4632-beee-1276a513c622","title":"Many-shot jailbreaking \\ Anthropic","url":"https://www.anthropic.com/research/many-shot-jailbreaking","urlHash":2225794099},"899fd39f-f1c5-4ea6-be99-108b6a86cb83":{"favIconUrl":"fallback","id":"899fd39f-f1c5-4ea6-be99-108b6a86cb83","title":"Extending Contrastive Learning to the Supervised Setting – Google AI Blog","url":"https://ai.googleblog.com/2021/06/extending-contrastive-learning-to.html","urlHash":1621839090},"89b2520d-6cc9-4870-ae63-2e04f2986bb8":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"89b2520d-6cc9-4870-ae63-2e04f2986bb8","title":"Hierarchical Reinforcement Learning By Discovering Intrinsic Options | Abstract","url":"https://arxiv.org/abs/2101.06521","urlHash":3659909925},"89f146d5-8b60-4422-9e62-d2a2c632dc9d":{"favIconUrl":"fallback","id":"89f146d5-8b60-4422-9e62-d2a2c632dc9d","title":"Surface Form Competition: Why the Highest Probability Answer Isn’t Always Right","url":"https://aclanthology.org/2021.emnlp-main.564.pdf","urlHash":1300274723},"8a7ed0bd-fbd1-43b6-abca-445670fdd8bb":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"8a7ed0bd-fbd1-43b6-abca-445670fdd8bb","title":"A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation | Abstract","url":"https://arxiv.org/abs/2307.03987","urlHash":2370923450},"8a9cf8be-5449-4698-acff-f68085e06844":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"8a9cf8be-5449-4698-acff-f68085e06844","title":"大模型如何修复badcase","url":"https://mp.weixin.qq.com/s?__biz=MzIwNDY1NTU5Mg==&mid=2247487266&idx=1&sn=0a12ecb0ae397a19dd39239ab65b2818&chksm=973d91a5a04a18b38e002964ade33ff0a419bc2c752d536e5fd1338dc88ba43a7aaeb9834067&mpshare=1&scene=1&srcid=0115Dmh17NlxJXRcuH7qYjBk&sharer_shareinfo=184d2cc916a7c4608a5a0e0d66f027cf&sharer_shareinfo_first=184d2cc916a7c4608a5a0e0d66f027cf&exportkey=n_ChQIAhIQILbNESfrFgFaDL%2BSM%2F1I4BKWAgIE97dBBAEAAAAAALnXErECeM0AAAAOpnltbLcz9gKNyK89dVj07qXOcgZHv11hmZDNWI9fDNuiE1ciDF4u25cZhozokYJlrmF9lsPR%2FkIN8dcfYQyShu0AjIW8R%2BMxpFIXXD%2BOT6zcwnF0VwsHt0hpY7iIxaq30zyStfW3L23hh%2BNw0vYj4lltnaFpLls0wCu7MY7aBTmvt5h1aJrRhBW%2BXaOtGlhyNO3zXdDKy562bm1fPEwbXdrrckMwckXlMB3r%2FPN73h0jVEtvY9YtJ%2FkFQMkQbnBod%2BIT%2B2noDxI%2FPKgLUFuVpEXrJP3voR9i0r3xY%2BVkSzKz4kr4IzJAeurILugQ78k8j5mT%2BwiYZ2mhJyF9pVGN&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsY%2FiK1mqoadGvLQnJHPpGAexncPzyFrg5Ee6p2gcUOiwg%3D%3D&wx_header=0#rd","urlHash":3000558435},"8aa817d4-a608-46e9-a6c9-367f46a4a3e3":{"favIconUrl":"fallback","id":"8aa817d4-a608-46e9-a6c9-367f46a4a3e3","title":"robust curriculum learning - Google Search","url":"https://www.google.com/search?q=robust+curriculum+learning&oq=robust+curriculum+learning&aqs=chrome..69i57j0i390l4.3696j1j1&sourceid=chrome&ie=UTF-8","urlHash":990218400},"8ac6816f-69c3-40b0-9bd5-86939ed4251d":{"favIconUrl":"fallback","id":"8ac6816f-69c3-40b0-9bd5-86939ed4251d","title":"Relational Memory Augmented Language Models - Arxiv-2201.09680","url":"https://arxiv.org/pdf/2201.09680.pdf","urlHash":3954091308},"8ad2340b-82f5-4053-b79e-b5713e5fb3f8":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"8ad2340b-82f5-4053-b79e-b5713e5fb3f8","title":"Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models | PDF","url":"https://arxiv.org/pdf/2205.10770.pdf","urlHash":3877082967},"8aff9be9-9628-4626-b9c9-80ceade3e90e":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"8aff9be9-9628-4626-b9c9-80ceade3e90e","title":"AK on X: \"Linear Transformers are Versatile In-Context Learners Recent research has demonstrated that transformers, particularly linear attention models, implicitly execute gradient-descent-like algorithms on data provided in-context during their forward inference step. However, their… https://t.co/SrM7tw2GuD\" / X","url":"https://twitter.com/_akhaliq/status/1760887089044799782","urlHash":2739018073},"8b070059-38e4-48f5-ab08-758913f67407":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"8b070059-38e4-48f5-ab08-758913f67407","title":"Shangbin Feng on X: \"Looking for a summarization factuality metric? Are existing ones hard-to-use, require re-training, or not compatible with HuggingFace? Introducing FactKB, an easy-to-use, shenanigan-free, and state-of-the-art summarization factuality metric! https://t.co/UOaNGC29lN\" / X","url":"https://twitter.com/shangbinfeng/status/1659333099052990468","urlHash":3509880209},"8b6a86ec-94a3-4557-b71c-37588e37ea14":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"8b6a86ec-94a3-4557-b71c-37588e37ea14","title":"2行代码，「三体」一次读完！港中文贾佳亚团队联手MIT发布超长文本扩展技术，打破LLM遗忘魔咒","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652387809&idx=2&sn=a69e41abf4ca407ee11e18aef0906616&exportkey=n_ChQIAhIQ17K3rviayEhDZw3o8GdXBBKWAgIE97dBBAEAAAAAAOmOMqy5o%2FgAAAAOpnltbLcz9gKNyK89dVj0splipaOqdfGU5a8G2gFPLu8ac6gHefDLHuq%2FgAX74QYFH72LwN%2BINkZAzGYUz9oO5trPtGtET4%2FwgSJ3BLG4Im405xgpLBN2dV2kLw2MvP1PagEt8Y%2BiOXbVFM2TxKA%2Bnvz0x%2BZ%2B%2FPf%2B1q5DsovxS2M427ECXwYDb443nOnX39G%2FVuwfLajenA24iZ1sEFf2Sc7Tf8o3v%2BqFGsP03evbkxyUmLQRsgZtf%2F2Zv%2BRZyikfHU4HEK83gYQ%2B5Rrrvewo7L20az3p9sCb4hR%2Be3wdyNZX8w6VtJVXZEuJ2aQ1EY7r%2F9Dz4LiwDJzBFC4gJ6th&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsa926DGe9s7MelX35X26GkQIEs6PwiL6uGJx4PPvg8fUA%3D%3D&wx_header=0","urlHash":360386468},"8b80c09f-6202-4df1-a5fe-74a099c4304c":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"8b80c09f-6202-4df1-a5fe-74a099c4304c","title":"GENOME: GenerativE Neuro-symbOlic visual reasoning by growing and reusing ModulEs | PDF","url":"https://arxiv.org/pdf/2311.04901.pdf","urlHash":1432278580},"8ba7d579-20e6-436f-b9fb-f9f6e440a62a":{"favIconUrl":"fallback","id":"8ba7d579-20e6-436f-b9fb-f9f6e440a62a","title":"Visualizing the Impact of Feature Attribution Baselines","url":"https://distill.pub/2020/attribution-baselines/","urlHash":4223456277},"8bae1fa2-0d5b-4724-8000-f1469576255b":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"8bae1fa2-0d5b-4724-8000-f1469576255b","title":"Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning | Abstract","url":"https://arxiv.org/abs/2310.06694","urlHash":1976911436},"8bc42cc0-77cf-440f-bd9d-ce13918b9f7d":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"8bc42cc0-77cf-440f-bd9d-ce13918b9f7d","title":"让人惊叹的Johnson-Lindenstrauss引理：理论篇 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/8679","urlHash":3359562525},"8c40b998-0b59-4af1-bb19-ad236b2c7549":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"8c40b998-0b59-4af1-bb19-ad236b2c7549","title":"twitter.com/arankomatsuzaki/status/1668257596313092097","url":"https://twitter.com/arankomatsuzaki/status/1668257596313092097","urlHash":3508698061},"8c88ae29-357d-4fd9-b109-5365d7783ca1":{"favIconUrl":"fallback","id":"8c88ae29-357d-4fd9-b109-5365d7783ca1","title":"Communicating with Interactive Articles","url":"https://distill.pub/2020/communicating-with-interactive-articles/","urlHash":3426741724},"8c97e1b0-2e64-4996-960e-5a3654ed2bc4":{"favIconUrl":"fallback","id":"8c97e1b0-2e64-4996-960e-5a3654ed2bc4","title":"Liewschild - 知乎","url":"https://www.zhihu.com/people/ai-yu-16-30/posts","urlHash":2136879577},"8cc7cda5-8306-4373-8173-9d1a4b7c5811":{"favIconUrl":"fallback","id":"8cc7cda5-8306-4373-8173-9d1a4b7c5811","title":"12种模态，一个学习框架，Meta-Transformer实现骨干网络大一统","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650884954&idx=3&sn=ac1f2c70a3b2eb42de9149ab96831f44&exportkey=n_ChQIAhIQGwVpWulXUpj53TvqcMhEdBKWAgIE97dBBAEAAAAAAD%2BEIm6YOZgAAAAOpnltbLcz9gKNyK89dVj09VqvQlTPM8c5f84%2B5oI4dbez3mwERUCkqDrTzb4yEY%2BFfJFi3QGpnMQ%2FvHgkPmY6XYcsMKFj34rqIc8J4Sc8RYmVf2ykRsMqtlMfk9IYpVsCroWYN1vvaor7G%2FNGI1zTPxiFm%2BqBWXwd6wvzimlzlHL9T3iYioS1TWTgMbKrPuQ6LT1SZQagO0gyP9tYqRUlf5qn7%2FoAjDHNBveC9UZQfkDBWD1q6MeAYiBt%2F22HMkhrZvCFefpMnJ6sJe68XFb28m%2BBI38rKaR7sVUX0gnH42cSjRa2Gr5NXcRkozcfZocOLPQWolN6LG%2BNUp%2BZ4bO0&acctmode=0&pass_ticket=f3uExRar79D6xVq1X9Nw5WsXkVrFtFX8Lt2hcuAzWYfxG2pqaHuntCP%2BQtd9bdQZ&wx_header=0","urlHash":659754713},"8cd0277d-77b8-405b-82b2-aaa1b161877a":{"favIconUrl":"fallback","id":"8cd0277d-77b8-405b-82b2-aaa1b161877a","title":"openai/automated-interpretability","url":"https://github.com/openai/automated-interpretability","urlHash":3323245281},"8cdaac4c-d8bc-4484-97fb-9ae20baf0715":{"favIconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","id":"8cdaac4c-d8bc-4484-97fb-9ae20baf0715","title":"We Found An Neuron in GPT-2 — LessWrong","url":"https://www.lesswrong.com/posts/cgqh99SHsCv3jJYDS/we-found-an-neuron-in-gpt-2","urlHash":3421757832},"8d090620-953b-48a9-9bb8-3fe6bd0f3af8":{"favIconUrl":"fallback","id":"8d090620-953b-48a9-9bb8-3fe6bd0f3af8","title":"Re-Examining Calibration: The Case of Question Answering","url":"https://arxiv.org/abs/2205.12507","urlHash":1840134346},"8d0934bc-e652-4207-b7c5-0e67d5d7fa0e":{"favIconUrl":"fallback","id":"8d0934bc-e652-4207-b7c5-0e67d5d7fa0e","title":"Prompting Language Models for Linguistic Structure - Arxiv-2211.07830","url":"https://arxiv.org/pdf/2211.07830.pdf","urlHash":2310823949},"8d0e03c6-2d88-40d2-ac19-9f5f61ec24bd":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"8d0e03c6-2d88-40d2-ac19-9f5f61ec24bd","title":"ICLR2024 | 分享 8篇Spotlight论文，涉及多模态大模型、大模型优化、RLHF等热门话题！","url":"https://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&mid=2247497364&idx=1&sn=fa19f0a73152df22cac225c5b0c52fc7&chksm=fac06148cdb7e85e66461ef39de2324ba2c3f6350d31b06c08e409f354fe776ba7de0d69645b&mpshare=1&scene=1&srcid=0120BkBHLbfV9ZCFbppGb3n3&sharer_shareinfo=a96da8301c2a672e41a1228500a82b55&sharer_shareinfo_first=a96da8301c2a672e41a1228500a82b55&exportkey=n_ChQIAhIQSO1%2BVK7IzTun8AawOG2KwxKWAgIE97dBBAEAAAAAAFK%2BGS%2BGLfcAAAAOpnltbLcz9gKNyK89dVj0X2B1m2%2F5s1NJWWx%2BOwbd03kbRCpeWVl7TffM%2Bq9wTpoCrcho9khbAdL4IFxopY4%2Bdb87YWpqLB6Do3TxAmqb299z40A503pt5UIMg31W9o2z65iy3sCJzAt1AhcbZX39pB16c6XSFZ9enT9ntxDPhZSTo0NM6e8caKgKjxtKsaNMRijdSabVR3Q3%2BISqQgz3Gz3l26QfiUANTVCJkjg7dhgJH5VvN9f%2BPr9QaOcqVppoaahma2ynwE0bVqd8Z%2BoQzRmySR4gC2gQMD9pEjoJ63UNFcTj%2B%2FM7Brh9B0%2FBC4Y%2BWk2pWJvMAGoCngju7Mq%2F&acctmode=0&pass_ticket=Lh6fMKyRptprTXRrV6vPSrjdLsXHlUx5QEYzUr9kC2WSQNc4PNparzLBKKU5WRWNa502%2FaL9Xs2lZOJ0clqjvg%3D%3D&wx_header=0#rd","urlHash":1766496233},"8d10893b-e29d-4823-823d-664c1c7d4e23":{"favIconUrl":"fallback","id":"8d10893b-e29d-4823-823d-664c1c7d4e23","title":"dangkhoasdc/awesome-ai-residency: List of AI Residency Programs","url":"https://github.com/dangkhoasdc/awesome-ai-residency","urlHash":400304094},"8d1d91e2-3d2b-4fbb-bbc8-c83fb51797dd":{"favIconUrl":"https://ssl.gstatic.com/colaboratory-static/common/42523219716261df613294cff764e142/img/favicon.ico","id":"8d1d91e2-3d2b-4fbb-bbc8-c83fb51797dd","title":"How_A_Transformer_Takes_Max.ipynb - Colaboratory","url":"https://colab.research.google.com/drive/1N4iPEyBVuctveCA0Zre92SpfgH6nmHXY?usp=sharing","urlHash":3916539226},"8d5a4666-6814-4d8c-a5a7-8e93b9b4321e":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"8d5a4666-6814-4d8c-a5a7-8e93b9b4321e","title":"Atila on X: \"My takeaways from Apple's “LLM in a flash\" (1/n)\" / X","url":"https://twitter.com/atiorh/status/1737912777153609918","urlHash":1864720656},"8d8b53fa-4255-4e3c-8b58-07b9a1eb03fa":{"favIconUrl":"fallback","id":"8d8b53fa-4255-4e3c-8b58-07b9a1eb03fa","title":"Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback","url":"https://arxiv.org/abs/2307.15217","urlHash":1863805844},"8d96602b-78b7-4fba-ac28-c306e4650966":{"favIconUrl":"fallback","id":"8d96602b-78b7-4fba-ac28-c306e4650966","title":"https://arxiv.org/pdf/1708.06733.pdf","url":"https://arxiv.org/pdf/1708.06733.pdf","urlHash":829603759},"8d98cf06-aa97-4d74-849b-5375fdd328cd":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"8d98cf06-aa97-4d74-849b-5375fdd328cd","title":"Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations | PDF","url":"https://arxiv.org/pdf/2205.11822.pdf","urlHash":1084949974},"8dc4a2eb-f74a-423c-9c3c-da4e2fae7260":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"8dc4a2eb-f74a-423c-9c3c-da4e2fae7260","title":"Polysemanticity and Capacity in Neural Networks — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/kWp4R9SYgKJFHAufB/polysemanticity-and-capacity-in-neural-networks","urlHash":409192444},"8e018858-0430-4ef1-ba2d-153e600277ce":{"favIconUrl":"fallback","id":"8e018858-0430-4ef1-ba2d-153e600277ce","title":"Hako","url":"https://mercurixito.github.io/","urlHash":2165480263},"8e1f98cf-25db-4684-a417-42c6499a11c0":{"favIconUrl":"fallback","id":"8e1f98cf-25db-4684-a417-42c6499a11c0","title":"bookdraft2017nov5.pdf","url":"http://incompleteideas.net/book/bookdraft2017nov5.pdf","urlHash":1232092347},"8e5ad8e1-3716-40a5-b6f3-dd9843ea6fc0":{"favIconUrl":"fallback","id":"8e5ad8e1-3716-40a5-b6f3-dd9843ea6fc0","title":"RAFT Reward rAnked FineTuning for Generative Foundation Model Alignment - Arxiv-2304.06767","url":"https://arxiv.org/pdf/2304.06767.pdf","urlHash":3576745475},"8e5df407-af53-446b-9a68-4b04e9e68932":{"favIconUrl":"fallback","id":"8e5df407-af53-446b-9a68-4b04e9e68932","title":"Pyro Documentation — Pyro documentation","url":"https://docs.pyro.ai/en/stable/","urlHash":646742027},"8e9f8770-f8d7-4989-92bc-8170545d9d40":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"8e9f8770-f8d7-4989-92bc-8170545d9d40","title":"【民翻】支离破碎的蔷薇（城户喜由 短篇/本格/设定系）","url":"https://www.douban.com/note/783198695/?_i=6378567EY3cWDs,1224226oZQdRGV","urlHash":3810260600},"8ea4b73e-2e3c-4e34-bd80-09216ef6f2dc":{"favIconUrl":"fallback","id":"8ea4b73e-2e3c-4e34-bd80-09216ef6f2dc","title":"附卡夫卡日记","url":"https://www.douban.com/group/topic/3489955/?_i=4235368KLQjbnS","urlHash":1918994942},"8ee7053d-01ff-4b2b-add5-332288e87893":{"favIconUrl":"fallback","id":"8ee7053d-01ff-4b2b-add5-332288e87893","title":"palm_saycan.pdf","url":"https://say-can.github.io/assets/palm_saycan.pdf","urlHash":1942521323},"8ef5aad2-683c-4182-b64d-4e0017cd8f57":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"8ef5aad2-683c-4182-b64d-4e0017cd8f57","title":"AutoAgents - a Hugging Face Space by LinkSoul","url":"https://huggingface.co/spaces/LinkSoul/AutoAgents","urlHash":1067449169},"8ef91d4b-9089-49f3-8c66-dec917b5ca72":{"favIconUrl":"fallback","id":"8ef91d4b-9089-49f3-8c66-dec917b5ca72","title":"WGAN新方案：通过梯度归一化来实现L约束 - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/8757","urlHash":2221423418},"8f02a3a6-5333-4efc-b484-68775b6e2acf":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"8f02a3a6-5333-4efc-b484-68775b6e2acf","title":"大模型幻觉问题调研","url":"https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&mid=2247494247&idx=2&sn=a1614fa0f58c153330bb7f3c11652ad3&exportkey=n_ChQIAhIQa9K5HBT845thAe4hmzY9uBKWAgIE97dBBAEAAAAAAO%2BnDPkZcAoAAAAOpnltbLcz9gKNyK89dVj0kPgwrr66WLb3S2l6vMOQ%2FXvMnRoivdZUyb59X9KuvaBOtteqm2lFLxzXCcAS2P8jlKOIkPZ%2FIJ1GkT0D%2Bt7k2RNSHMU2Ygi6uyDk2h6uAvRwkspv5PMVOlvqhmZPvSzJ21QaS9Dxnt4I5695nJugmQBipA1jmf3ck9DWeZYerQu5IBYVIldC%2Bb8sz%2BOFj8vfa6UxzibBpfudf3ReI1RIZerjXJe55uhe017%2BGKowYmkVEa55uU15M4o1k0sLP567RSGAnTSHljoyf%2BI3vDF2vExDcPcpGsmzMCmQQPSrrIsJCddvadqmDd4N6v9fi9UM&acctmode=0&pass_ticket=52UGXs0PtWfkV3C1BnsnFQ6uALmCFJYBGOYtSe2VXb9BoCJgpnev%2Bjx%2B%2FnRp6Jzu&wx_header=0","urlHash":1272443426},"8f1960e6-655e-4da3-9ffd-820d1e27eab7":{"favIconUrl":"https://python.langchain.com/img/brand/favicon.png","id":"8f1960e6-655e-4da3-9ffd-820d1e27eab7","title":"🦜🕸️LangGraph | 🦜️🔗 LangChain","url":"https://python.langchain.com/docs/langgraph/#define-the-graph","urlHash":4092026371},"8f19bb8c-7df4-4ded-afdf-7653ccb55eec":{"favIconUrl":"https://baikebcs.bdimg.com/cms/static/baike-icon.svg","id":"8f19bb8c-7df4-4ded-afdf-7653ccb55eec","title":"死火（鲁迅创作的一首散文诗）_百度百科","url":"https://baike.baidu.com/item/%E6%AD%BB%E7%81%AB/3334798","urlHash":2983924894},"8f1a52f3-f6e7-423b-9969-fbe204e68c91":{"favIconUrl":"https://www.google.com/favicon.ico","id":"8f1a52f3-f6e7-423b-9969-fbe204e68c91","title":"LEARNING TO RECOMBINE AND RESAMPLE DATA FOR COMPOSITIONAL GENERALIZATION - Google Search","url":"https://www.google.com/search?q=LEARNING+TO+RECOMBINE+AND+RESAMPLE+DATA+FOR+COMPOSITIONAL+GENERALIZATION&sourceid=chrome&ie=UTF-8","urlHash":2075850409},"8f1cabc4-9191-4106-8d2c-11597119552d":{"favIconUrl":"https://assets.squarespace.com/universal/default-favicon.ico","id":"8f1cabc4-9191-4106-8d2c-11597119552d","title":"Mechanistic Interpretability Quickstart Guide — Neel Nanda","url":"https://www.neelnanda.io/mechanistic-interpretability/quickstart","urlHash":3642090135},"8f215cda-d79d-4650-a191-15caabe4e38c":{"favIconUrl":"fallback","id":"8f215cda-d79d-4650-a191-15caabe4e38c","title":"Memorizing Transformers","url":"https://arxiv.org/abs/2203.08913","urlHash":3948574403},"8f317653-3cc7-40d4-81d1-86c8e165cc65":{"favIconUrl":"fallback","id":"8f317653-3cc7-40d4-81d1-86c8e165cc65","title":"Measure and Improve Robustness in NLP Models A Survey - Arxiv-2112.08313","url":"https://arxiv.org/abs/2112.08313","urlHash":3684231860},"8f35bf76-b91d-46dc-9a73-a2a1a7083b8a":{"favIconUrl":"fallback","id":"8f35bf76-b91d-46dc-9a73-a2a1a7083b8a","title":"Knowledge Unlearning for Mitigating Privacy Risks in Language Models - OR-ICLR-2023_zAxuIJLb38","url":"https://openreview.net/pdf?id=zAxuIJLb38","urlHash":1402907909},"8f486662-1817-462d-9fb6-b3c4d336353b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"8f486662-1817-462d-9fb6-b3c4d336353b","title":"Adyasha Maharana on X: \"How to select important+diverse training data under a fixed data budget? 📢\"D2 Pruning\" --&gt; represent datasets as sparse undirected graph &amp; perform forward+reverse message passing to select both difficult &amp; diverse samples. https://t.co/7OPxsGUsbb @prateeky2806 @mohitban47 🧵 https://t.co/bPuU5NdmFk\" / X","url":"https://twitter.com/adyasha10/status/1712876384425529660","urlHash":1735176179},"8f5fd4a5-b64e-4cf2-9914-23a31f282bfc":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"8f5fd4a5-b64e-4cf2-9914-23a31f282bfc","title":"twitter.com/tallinzen/status/1727041368135180681","url":"https://twitter.com/tallinzen/status/1727041368135180681","urlHash":241952680},"8f858812-b550-42ae-b88d-a439787797b6":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"8f858812-b550-42ae-b88d-a439787797b6","title":"(2) elvis on X: \"PlanGPT: LLM for Urban and Spatial Planning Cool paper showing how you could leverage LLMs and combine multiple approaches like retrieval augmentation, fine-tuning, tool usage, and more. The proposed framework is applied to urban and spatial planning but I think there is a lot… https://t.co/iLfwlkO1Jt\" / X","url":"https://twitter.com/omarsar0/status/1763424166890377691?utm_source=substack&utm_medium=email","urlHash":3875081831},"8fc9d576-7311-4a5d-b409-7817f872a799":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"8fc9d576-7311-4a5d-b409-7817f872a799","title":"吉娃娃or松饼难题被解决！IDEA研究院新模型打通文本视觉Prompt，连黑客帝国的子弹都能数清楚","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247723398&idx=4&sn=ed585a6fe622fb866fb8890934fd23ea&chksm=e8dfdef4dfa857e2c3bc576b83a52ef8dbbac642d8148767260bd26ff5a502ce8f45ef1d9328&mpshare=1&scene=1&srcid=0331t2vIE7zBoX4KJ8sAYmiu&sharer_shareinfo=c75de3327a06334b052ecd6bbed4e938&sharer_shareinfo_first=c75de3327a06334b052ecd6bbed4e938&exportkey=n_ChQIAhIQbydE2f5QN%2F8NV8rZLaZD5BKWAgIE97dBBAEAAAAAAIZSOuxXfUoAAAAOpnltbLcz9gKNyK89dVj0Lx2bRWCUwv8Xex90XOjsSH3kwk5M4aft96%2F9bNdtm1x3JfHiG4CVrdcviPXSDQMPXUIYHVIb6Us%2FcLqXOTHTeiA65IayaPrn7QtvIU37Xb6vvoaT%2B0fqheLGCuLAbYII4tl%2FNEfoEoann3JNJSs%2F8WDulsXc9wdTZJUUVz%2F5bpSsWD%2FC961Tgxdq%2F0reIVLUr0rRof1Bjg%2Fm2%2B28M1nRwRFgiUGJTMUaYcxR0v1xMXtgfxCDCYHKm%2FbPP9cTcuvQHbPbMIdIbh%2BxuyRP3YSfJoZ%2FSIp6vUni17ptn7Q42%2F5pXZhEgaJ1gT09gTMZz%2F6%2F&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCO4bX0qfTHXUp75rQVA25yM%2BK%2FLgF6h1gRpa3jwH8z7WA%3D%3D&wx_header=0#rd","urlHash":4052966580},"8fe72408-0526-4129-9d55-1058968bcfb6":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"8fe72408-0526-4129-9d55-1058968bcfb6","title":"twitter.com/jefffhj/status/1685894233784516608","url":"https://twitter.com/jefffhj/status/1685894233784516608","urlHash":2564509041},"9094c7a5-79bb-4cd2-a9a1-f6544cb12851":{"favIconUrl":"fallback","id":"9094c7a5-79bb-4cd2-a9a1-f6544cb12851","title":"IDEA-Research/Grounded-Segment-Anything: Grounded-SAM: Marrying Grounding DINO with Segment Anything & Stable Diffusion & Recognize Anything - Automatically Detect , Segment and Generate Anything","url":"https://github.com/IDEA-Research/Grounded-Segment-Anything/tree/main","urlHash":685397382},"9096da03-f413-495c-9144-400d3bb87030":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"9096da03-f413-495c-9144-400d3bb87030","title":"Looped Transformers as Programmable Computers | PDF","url":"https://arxiv.org/pdf/2301.13196.pdf","urlHash":1944810129},"90b09d09-71b2-4054-8bef-64caf223fd49":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"90b09d09-71b2-4054-8bef-64caf223fd49","title":"ReFT: Representation Finetuning for Language Models | PDF","url":"https://arxiv.org/pdf/2404.03592.pdf","urlHash":3974015883},"9129aa26-f320-4214-8ffc-707dace1ceb5":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"9129aa26-f320-4214-8ffc-707dace1ceb5","title":"Simple random search provides a competitive approach to reinforcement learning | PDF","url":"https://arxiv.org/pdf/1803.07055.pdf","urlHash":3027096240},"91a274c1-3904-4250-8286-9e5e8c6ef500":{"favIconUrl":"fallback","id":"91a274c1-3904-4250-8286-9e5e8c6ef500","title":"Hugging Face Reads - 01/2021 - Sparsity and Pruning - Research - Hugging Face Forums","url":"https://discuss.huggingface.co/t/hugging-face-reads-01-2021-sparsity-and-pruning/3144","urlHash":2150872272},"91b0ab53-863b-413d-b411-7d114a0bcf8a":{"favIconUrl":"https://wikiwandv2-19431.kxcdn.com/icons/favicon.ico","id":"91b0ab53-863b-413d-b411-7d114a0bcf8a","title":"Critique of Pure Reason - Wikiwand","url":"https://www.wikiwand.com/en/Critique_of_Pure_Reason","urlHash":174543452},"92048e92-e35c-4f91-87ac-c07933995577":{"favIconUrl":"fallback","id":"92048e92-e35c-4f91-87ac-c07933995577","title":"I2D2 Inductive Knowledge Distillation with NeuroLogic and Self-Imitation - Arxiv-2212.09246","url":"https://arxiv.org/pdf/2212.09246.pdf","urlHash":3796508013},"924392eb-54ce-451c-b12a-f3f949459c9d":{"favIconUrl":"fallback","id":"924392eb-54ce-451c-b12a-f3f949459c9d","title":"When MAML Can Adapt Fast and How to Assist When It Cannot","url":"https://arxiv.org/pdf/1910.13603.pdf","urlHash":3535396055},"926caf2e-f344-4d77-a2ad-065edec5b137":{"favIconUrl":"fallback","id":"926caf2e-f344-4d77-a2ad-065edec5b137","title":"Adversarial Data Collection - Google Slides","url":"https://docs.google.com/presentation/d/1bZFTW7c-mH5yQOUYmI4vzymJB6Pf7w1Bki-QyviaL7g/edit#slide=id.g11acd991225_0_330","urlHash":4175343206},"9279a752-1327-41dc-8ae3-9c5b1b089635":{"favIconUrl":"fallback","id":"9279a752-1327-41dc-8ae3-9c5b1b089635","title":"Patching open-vocabulary models by interpolating weights - Arxiv-2208.05592","url":"https://arxiv.org/pdf/2208.05592.pdf","urlHash":3278395063},"9286fbcf-b68b-4962-bd7a-8a03f4429c7f":{"favIconUrl":"fallback","id":"9286fbcf-b68b-4962-bd7a-8a03f4429c7f","title":"Data-Efficient Hierarchical Reinforcement Learning","url":"https://proceedings.neurips.cc/paper/2018/file/e6384711491713d29bc63fc5eeb5ba4f-Paper.pdf","urlHash":1111892420},"928dbfb1-b2a4-43c4-bd2b-67c6ab21078b":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"928dbfb1-b2a4-43c4-bd2b-67c6ab21078b","title":"hiyouga/FastEdit: 🩹Editing large language models within 10 seconds⚡","url":"https://github.com/hiyouga/FastEdit","urlHash":2804303177},"92ba2442-a6ed-429a-b55f-f9bd6af379ed":{"favIconUrl":"fallback","id":"92ba2442-a6ed-429a-b55f-f9bd6af379ed","title":"Announcing the NeurIPS 2022 Awards – NeurIPS Blog","url":"https://blog.neurips.cc/2022/11/21/announcing-the-neurips-2022-awards/","urlHash":727061136},"92d94431-5873-459b-89f9-5514e2267e60":{"favIconUrl":"fallback","id":"92d94431-5873-459b-89f9-5514e2267e60","title":"Efficient Transformers A Survey - Arxiv-2009.06732","url":"https://arxiv.org/pdf/2009.06732.pdf","urlHash":2464571037},"92e48bfc-b1b4-4e0d-96d5-82636c0935d9":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"92e48bfc-b1b4-4e0d-96d5-82636c0935d9","title":"Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for LLM Alignment | Abstract","url":"https://arxiv.org/abs/2310.00212","urlHash":3240066272},"92e9ed35-ed19-4dcc-a0ee-34f92ead8cfa":{"favIconUrl":"fallback","id":"92e9ed35-ed19-4dcc-a0ee-34f92ead8cfa","title":"CSC2541 Winter 2022","url":"https://www.cs.toronto.edu/~rgrosse/courses/csc2541_2022/","urlHash":1449306304},"9352ae2d-944c-46d8-bf8b-d6b12b25886c":{"favIconUrl":"https://www.google.com/favicon.ico","id":"9352ae2d-944c-46d8-bf8b-d6b12b25886c","title":"Safe RLHF: Safe Reinforcement Learning from Human Feedback - Google Search","url":"https://www.google.com/search?q=Safe%20RLHF:%20Safe%20Reinforcement%20Learning%20from%20Human%20Feedback%0A","urlHash":4282890761},"935346e5-1095-45cc-bd46-a4df5168a5cc":{"favIconUrl":"https://www.google.com/favicon.ico","id":"935346e5-1095-45cc-bd46-a4df5168a5cc","title":"除夜を歩く-有栖川有栖「江神二郎の洞察」 - Google Search","url":"https://www.google.com/search?q=%E9%99%A4%E5%A4%9C%E3%82%92%E6%AD%A9%E3%81%8F-%E6%9C%89%E6%A0%96%E5%B7%9D%E6%9C%89%E6%A0%96%E3%80%8C%E6%B1%9F%E7%A5%9E%E4%BA%8C%E9%83%8E%E3%81%AE%E6%B4%9E%E5%AF%9F%E3%80%8D#ip=1","urlHash":3968703551},"93584556-bb9d-4ee5-8847-76925fa8e24c":{"favIconUrl":"fallback","id":"93584556-bb9d-4ee5-8847-76925fa8e24c","title":"Differentiating through an associative parallel scan","url":"https://justintchiu.com/blog/pscan_diff/","urlHash":114923077},"9359990d-b0e5-4d99-ae63-62d5b8483467":{"favIconUrl":"fallback","id":"9359990d-b0e5-4d99-ae63-62d5b8483467","title":"Perfectly Normal","url":"https://www.perfectlynormal.co.uk/","urlHash":1231191306},"9359d77c-7f10-401c-833f-219e5b9c2c1c":{"favIconUrl":"fallback","id":"9359d77c-7f10-401c-833f-219e5b9c2c1c","title":"Growing Neural Cellular Automata","url":"https://distill.pub/2020/growing-ca/","urlHash":2535563396},"93612b1f-cb2d-494f-87fb-e653192016ad":{"favIconUrl":"fallback","id":"93612b1f-cb2d-494f-87fb-e653192016ad","title":"(1) AK on X: \"Scaling TransNormer to 175 Billion Parameters paper page: https://t.co/7LBDE5QyVM present TransNormerLLM, the first linear attention-based Large Language Model (LLM) that outperforms conventional softmax attention-based models in terms of both accuracy and efficiency.… https://t.co/UiDURyNIYD\" / X","url":"https://twitter.com/_akhaliq/status/1684735080831582208","urlHash":2430594930},"936ddb76-f9d1-4d11-83fb-a159e7d60596":{"favIconUrl":"fallback","id":"936ddb76-f9d1-4d11-83fb-a159e7d60596","title":"On Continual Model Refinement in Out-of-Distribution Data Streams - Arxiv-2205.02014","url":"https://arxiv.org/pdf/2205.02014.pdf","urlHash":3453978658},"937314c0-c0d7-463c-941f-14d013abc363":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"937314c0-c0d7-463c-941f-14d013abc363","title":"facebook/dragon-plus-context-encoder · Hugging Face","url":"https://huggingface.co/facebook/dragon-plus-context-encoder","urlHash":2570092486},"93766505-7c7b-452a-ba10-0661379c4958":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"93766505-7c7b-452a-ba10-0661379c4958","title":"OpenBMB/ChatDev: Create Customized Software using Natural Language Idea (through LLM-powered Multi-Agent Collaboration)","url":"https://github.com/OpenBMB/ChatDev","urlHash":3099895969},"93a0c55d-7ffd-4bde-b7fd-80f7254b3e76":{"favIconUrl":"fallback","id":"93a0c55d-7ffd-4bde-b7fd-80f7254b3e76","title":"Feature Reuse with ANIL - learn2learn","url":"http://learn2learn.net/tutorials/anil_tutorial/ANIL_tutorial/","urlHash":2129847588},"93a5b2cf-f76e-4ed2-b782-e6affa228766":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"93a5b2cf-f76e-4ed2-b782-e6affa228766","title":"Continual Learning with Differential Privacy | PDF","url":"https://arxiv.org/pdf/2110.05223.pdf","urlHash":112473784},"93b5902a-0364-433c-a23b-0d78f32dec41":{"favIconUrl":"fallback","id":"93b5902a-0364-433c-a23b-0d78f32dec41","title":"Discovering Latent Knowledge in Language Models Without Supervision - Arxiv-2212.03827","url":"https://arxiv.org/pdf/2212.03827.pdf","urlHash":184474768},"93c4f549-dd15-4119-ba0a-1dbe8967f87c":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"93c4f549-dd15-4119-ba0a-1dbe8967f87c","title":"sail-sg/EditAnything: Edit anything in images powered by segment-anything, ControlNet, StableDiffusion, etc.","url":"https://github.com/sail-sg/EditAnything","urlHash":3178002872},"93c6aa15-b8e1-49ec-8f2b-1ba5c3fe8165":{"favIconUrl":"fallback","id":"93c6aa15-b8e1-49ec-8f2b-1ba5c3fe8165","title":"基于Conditional Layer Normalization的条件文本生成 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/7124","urlHash":2286304591},"942c1b86-11bc-4fbd-9cec-f81db8092e6c":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"942c1b86-11bc-4fbd-9cec-f81db8092e6c","title":"LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model | Abstract","url":"https://arxiv.org/abs/2304.15010","urlHash":2858762226},"94d059a9-35ec-4c4e-afa1-182ca1330111":{"favIconUrl":"fallback","id":"94d059a9-35ec-4c4e-afa1-182ca1330111","title":"微软提出Control-GPT：用GPT-4实现可控文本到图像生成！","url":"https://mp.weixin.qq.com/s?__biz=MzIzNzU4OTAxMQ==&mid=2247513092&idx=2&sn=0b93183e69ac83ed6fe2f391c0aabaef&chksm=e8c4b378dfb33a6e6c9cea62ff6dd7e928d8bdf46163b31086b100c7cf74ca7a30a502992b49&mpshare=1&scene=1&srcid=0701Vb2Ae3uS07UdC0hVqmaO&sharer_sharetime=1688170790674&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQkiQPPc6IcAXefSDUrQVW1hKWAgIE97dBBAEAAAAAAJAIFSJGtYkAAAAOpnltbLcz9gKNyK89dVj0ASfNgU718p06%2FVqjnMsGq9bGDxdomGjll1rHn%2FoEohbtG%2BWujydmxnrVeSqitl6u9%2BeXSLMqSz7p%2BSOHZm0X47zf89vS2GJZCkYSpabexyvyDYuTbyIBY55jIs2dOLSszdr6aY6KvMus0HhmeswdHHnfT2kUtF70%2B9sFDekjHrDY%2BdnBo9169O2wqAPZTcp9Qug%2FB8pw4JbZbDD%2BH%2FGNP91Q04pux0fnfLHshoBOTCUnxPN%2FDsE0zD%2F2SLHSwh%2BsqNLxq0GKkseba2m%2BykMMCmvNzbZbRuyJIIGt0OsDzpqxTmCaNpSGSq%2BbBob49gqw&acctmode=0&pass_ticket=008ST7aYmR5%2BnSZVNboizWxzuO%2FU8nRkEm1r8atqUeWgAvu9opXrcHOr5P%2B65kga&wx_header=0#rd","urlHash":4086490939},"95086fab-bef6-4fde-945b-4f301d7b7290":{"favIconUrl":"fallback","id":"95086fab-bef6-4fde-945b-4f301d7b7290","title":"evidentiality_arxiv_2021.pdf","url":"https://akariasai.github.io/files/evidentiality_arxiv_2021.pdf","urlHash":800048163},"952ecadf-d98a-4331-9c20-eceec25785d7":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"952ecadf-d98a-4331-9c20-eceec25785d7","title":"宇宙探偵ノーグレイ (豆瓣)","url":"https://book.douban.com/subject/27604835/","urlHash":1260687341},"9568cb92-eec5-4fae-b196-4a049fe0f790":{"favIconUrl":"fallback","id":"9568cb92-eec5-4fae-b196-4a049fe0f790","title":"Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models - Arxiv-2110.07736","url":"https://arxiv.org/pdf/2110.07736.pdf","urlHash":1980349599},"95732be6-d221-4861-a28f-8b45ec289f5c":{"favIconUrl":"https://cdn.semanticscholar.org/3cf37988806f7507/img/darkmode/favicon-32x32.png","id":"95732be6-d221-4861-a28f-8b45ec289f5c","title":"[PDF] Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting | Semantic Scholar","url":"https://www.semanticscholar.org/paper/Language-Models-Don't-Always-Say-What-They-Think%3A-Turpin-Michael/7dc928f41e15f65f1267bd87b0fcfcc7e715cb56","urlHash":2478263265},"95844e2f-e7fc-4e5c-9ae0-e75491760d74":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"95844e2f-e7fc-4e5c-9ae0-e75491760d74","title":"今日Arxiv最热NLP大模型论文：Llama-2上下文扩大48倍的方法来了，港大发布，无需训练","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247576559&idx=2&sn=d5e47934b6a59f803640695a22a46644&chksm=970e8339a0790a2f5b09868e79950acb6f5ca04b81f73aa18fafcdbc36696a1bb0a9dd461324&mpshare=1&scene=1&srcid=0303BOqDVmrHKFXOHaiQLqnk&sharer_shareinfo=4ecea97361fda551ec18b154c0790535&sharer_shareinfo_first=4ecea97361fda551ec18b154c0790535&exportkey=n_ChQIAhIQV1dMOzFpxnzs4ltQxTZ2SRKWAgIE97dBBAEAAAAAADBQBFcYOKQAAAAOpnltbLcz9gKNyK89dVj000KKh9Ex3b6BXeEKrBFYllgtT2ZIPdJ8vIi4itefInZNmFxAtCzz5DcDZ4NHNyL3xdVyaR7wSP%2FyDe2cvszDCsq7dXq%2FyQY26eQO92%2Fyd%2Fl1cDFg1maWzlgMbqwGWCbV80%2Bu3qmiUCeHIZStwRLuoZ3IAf7tU6PgEOJtDQeZwMaRM5BeS6kV6yqpe1brcYayI%2BvSv1wFQ9UyySBrm61DWTcDc5uaGu58E0WdE31CiDZwDyX63gmlifcnNE1T7ZSe50C51%2BwmtrE2xBLkfVTgiZo%2FDknMi%2BCklMufFTm4An7lJVqwFJ1nnNFrw3N6aOuv&acctmode=0&pass_ticket=2PIOTp07NumM73b6%2BDXCh%2BnkNx8%2F1ykJABKPHCCPJcOn1LmrPp2YFtitH8a4aLIv2kKvbE90m9f5rQs7PS%2BHFQ%3D%3D&wx_header=0#rd","urlHash":1728620672},"95a52022-820f-4763-9480-374c77bba7e2":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"95a52022-820f-4763-9480-374c77bba7e2","title":"Data Distributional Properties Drive Emergent In-Context Learning in Transformers | Abstract","url":"https://arxiv.org/abs/2205.05055","urlHash":2067688136},"95c02ad0-0e09-4558-9108-c03916f0b432":{"favIconUrl":"fallback","id":"95c02ad0-0e09-4558-9108-c03916f0b432","title":"Measuring Faithfulness in Chain-of-Thought Reasoning","url":"https://www-files.anthropic.com/production/files/measuring-faithfulness-in-chain-of-thought-reasoning.pdf","urlHash":2115148220},"9601518b-9e8a-4243-bfa5-0e53732674b0":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"9601518b-9e8a-4243-bfa5-0e53732674b0","title":"Daniel Kang on X: \"OpenAI announced GPT-4 fine-tuning this week. Fine-tuning can remove RLHF protections from weak models, but is GPT-4 susceptible? Unfortunately yes: removing RLHF protections from GPT-4 is trivial Paper: https://t.co/DiNcMpj4wp 🧵1/6\" / X","url":"https://twitter.com/daniel_d_kang/status/1723048642003587526","urlHash":2015011644},"960ae934-aa23-4559-a921-3af15dbf26a8":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"960ae934-aa23-4559-a921-3af15dbf26a8","title":"让人惊叹的Johnson-Lindenstrauss引理：应用篇 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/8706","urlHash":1865684379},"96152890-8042-4d07-93fb-324991215b18":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"96152890-8042-4d07-93fb-324991215b18","title":"AutoAgents: A Framework for Automatic Agent Generation | PDF","url":"https://arxiv.org/pdf/2309.17288.pdf","urlHash":1813330666},"96244c4e-1221-4f63-99b3-95bb5c65c91c":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"96244c4e-1221-4f63-99b3-95bb5c65c91c","title":"AK on X: \"Alibaba releases AnyText Multilingual Visual Text Generation And Editing demo: https://t.co/upj0iVqI0u https://t.co/nhN0Fra3Dh\" / X","url":"https://twitter.com/_akhaliq/status/1741239193215344810","urlHash":540708422},"963586df-5d60-42d6-acfa-a674eb85c3b5":{"favIconUrl":"fallback","id":"963586df-5d60-42d6-acfa-a674eb85c3b5","title":"《一人之下》中提到的《金枝》 - 知乎","url":"https://zhuanlan.zhihu.com/p/394497512","urlHash":2144381069},"965c2fb2-da09-43ad-bf0e-9968caeebbfb":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"965c2fb2-da09-43ad-bf0e-9968caeebbfb","title":"AK on X: \"Tuna: Instruction Tuning using Feedback from Large Language Models paper page: https://t.co/qmLmLyhONP Instruction tuning of open-source large language models (LLMs) like LLaMA, using direct outputs from more powerful LLMs such as Instruct-GPT and GPT-4, has proven to be a… https://t.co/4hyWSIpf1k\" / X","url":"https://twitter.com/_akhaliq/status/1716301330283671719","urlHash":760237484},"969c3202-87b4-40a4-b671-ef2ee8b4142b":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"969c3202-87b4-40a4-b671-ef2ee8b4142b","title":"Are Emergent Abilities in Large Language Models just In-Context Learning? | PDF","url":"https://arxiv.org/pdf/2309.01809.pdf","urlHash":366189245},"96b41ec1-3a28-4058-bef3-6eadc24789e9":{"favIconUrl":"fallback","id":"96b41ec1-3a28-4058-bef3-6eadc24789e9","title":"A Comprehensive Survey on Segment Anything Model for Vision and Beyond - Arxiv-2305.08196","url":"https://arxiv.org/pdf/2305.08196.pdf","urlHash":519584118},"96bf680c-ca4d-45bc-acff-ef90cb473228":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"96bf680c-ca4d-45bc-acff-ef90cb473228","title":"Quanquan Gu on X: \"🚨SPIN vs. DPO: SPIN uses the SFT dataset, while DPO demands human preferences with additional labeling overhead. Can we make DPO more label efficient? Introducing Active DPO (ADPO) - streamline DPO with a 50% reduction in labeled human preference data! 🚀…\" / X","url":"https://twitter.com/QuanquanGu/status/1758279361072165061","urlHash":951111979},"96d36051-cc5b-4a3a-8a57-6ef7cd59fa81":{"favIconUrl":"fallback","id":"96d36051-cc5b-4a3a-8a57-6ef7cd59fa81","title":"Geometric Deep Learning Grids, Groups, Graphs, Geodesics, and Gauges - Arxiv-2104.13478","url":"https://arxiv.org/abs/2104.13478","urlHash":437783876},"96d80cb2-9596-453a-b504-67f9c31e204b":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/favicon-32x32.png","id":"96d80cb2-9596-453a-b504-67f9c31e204b","title":"Reddit - Dive into anything","url":"https://www.reddit.com/r/reinforcementlearning/comments/x076or/has_hierarchical_reinforcement_learning_been/","urlHash":1929512766},"96df627a-17fd-4a72-a975-6204b7ced665":{"favIconUrl":"https://www.google.com/favicon.ico","id":"96df627a-17fd-4a72-a975-6204b7ced665","title":"斩首T字之谜 - Google Search","url":"https://www.google.com/search?q=%20%E6%96%A9%E9%A6%96T%E5%AD%97%E4%B9%8B%E8%B0%9C","urlHash":390075088},"96e2c7e5-790e-44c5-b041-5aadefd54552":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"96e2c7e5-790e-44c5-b041-5aadefd54552","title":"MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training | PDF","url":"https://arxiv.org/pdf/2403.09611.pdf","urlHash":1239909620},"96f962d3-1416-4dcc-8768-60f255ba8e1f":{"favIconUrl":"fallback","id":"96f962d3-1416-4dcc-8768-60f255ba8e1f","title":"针对不平衡问题建模的有趣Loss。","url":"https://mp.weixin.qq.com/s?__biz=Mzk0NDE5Nzg1Ng==&mid=2247504550&idx=1&sn=596768cc4fa51609e24fae65f358fd0f&exportkey=n_ChQIAhIQGLP9agIdyiNmJWfUH89bEBKWAgIE97dBBAEAAAAAAEGAME%2BqmqoAAAAOpnltbLcz9gKNyK89dVj0XvEc%2BYw6BaG3SknrLbZXdJnVGSMwFInAWBOMjn7TO6hubqf3U4hZeQB77L17y3JUpKaYv5eZClEwlSlsC2zgNH6hwr4ByGxVGWNUgplpY76XLOAGSJb%2F%2BFNgXCvqPSZYJHcdqB6J%2FKbL5QJVacp0yoyk59SRgmMIpBkePMX2ZdoJpJwhaiM8EsvmeWqy%2FXG9%2Fd%2BDNmsV6r32b7ugTroXbq98Bm29fqN1XbiOfK5HrWlpNJQK8wdPph9av1xewTmPUVNjJfCJl41jijqwj1jqEnJ6wT2Xxs325%2B2lAkrl1DRSoJ%2FQpgYawii55H4kXjhV&acctmode=0&pass_ticket=dk1%2BYeI9KcxVieaewIrrrbKjqtemDbE%2BLsWThaEB6q2JREvUaxd36WH3Kv19J6NO&wx_header=0","urlHash":234901065},"97065b15-d4f3-4379-8e1a-3edba60b7891":{"favIconUrl":"https://g.csdnimg.cn/static/logo/favicon32.ico","id":"97065b15-d4f3-4379-8e1a-3edba60b7891","title":"我的求学十年(00至10)：从中学到大学，年少轻狂立大志_涟源一中2006年高考金榜-CSDN博客","url":"https://blog.csdn.net/v_JULY_v/article/details/115611238?spm=1001.2014.3001.5502","urlHash":480929569},"9723297e-c367-4b71-91ca-165c331fd401":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"9723297e-c367-4b71-91ca-165c331fd401","title":"Jascha Sohl-Dickstein on X: \"Have you ever done a dense grid search over neural network hyperparameters? Like a *really dense* grid search? It looks like this (!!). Blueish colors correspond to hyperparameters for which training converges, redish colors to hyperparameters for which training diverges. https://t.co/yqJlschvVK\" / X","url":"https://twitter.com/jaschasd/status/1756930242965606582?utm_source=substack&utm_medium=email","urlHash":589348725},"97268f9f-e3c9-4be6-b330-620dfacdafe3":{"favIconUrl":"fallback","id":"97268f9f-e3c9-4be6-b330-620dfacdafe3","title":"生成对抗网络系列(2)——GAN提高 - 知乎","url":"https://zhuanlan.zhihu.com/p/34635690","urlHash":1629196292},"9735b38a-db46-491d-a7ec-13805da4ca23":{"favIconUrl":"fallback","id":"9735b38a-db46-491d-a7ec-13805da4ca23","title":"The Dawn of LMMs Preliminary Explorations with GPT-4V(ision) - Arxiv-2309.17421","url":"https://arxiv.org/abs/2309.17421?utm_source=substack&utm_medium=email","urlHash":888356641},"9739e432-c1fd-44c3-a407-81e816f9e91e":{"favIconUrl":"fallback","id":"9739e432-c1fd-44c3-a407-81e816f9e91e","title":"Language Models as Inductive Reasoners - Arxiv-2212.10923","url":"https://arxiv.org/pdf/2212.10923.pdf","urlHash":2212924625},"975908a6-ef29-4c95-8664-d795f4448d78":{"favIconUrl":"fallback","id":"975908a6-ef29-4c95-8664-d795f4448d78","title":"deep bidirectional language-knowledge graph pretraining - Google Search","url":"https://www.google.com/search?q=deep+bidirectional+language-knowledge+graph+pretraining&oq=deep+bidire&aqs=chrome.0.0i20i263i512j69i57j0i512l2j0i22i30l3j0i390i650l3.9220j1j1&sourceid=chrome&ie=UTF-8","urlHash":2763187724},"9762a2fb-37cb-49b0-b2fa-efdd0916330d":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"9762a2fb-37cb-49b0-b2fa-efdd0916330d","title":"twitter.com/Francis_YAO_/status/1674287337344253955","url":"https://twitter.com/Francis_YAO_/status/1674287337344253955","urlHash":2960399912},"976485f7-5ee9-43bb-a5b2-4fc4e8920e61":{"favIconUrl":"fallback","id":"976485f7-5ee9-43bb-a5b2-4fc4e8920e61","title":"Captum · Model Interpretability for PyTorch","url":"https://captum.ai/tutorials/Segmentation_Interpret","urlHash":1148611333},"977ffbcf-31df-49f2-a783-197fb35057ac":{"favIconUrl":"fallback","id":"977ffbcf-31df-49f2-a783-197fb35057ac","title":"6.S898 Deep Learning, Fall 2021","url":"https://phillipi.github.io/6.s898/2021/index.html","urlHash":527172038},"97b4545f-bf7b-4f6c-9d2e-a292a5ca6ce1":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"97b4545f-bf7b-4f6c-9d2e-a292a5ca6ce1","title":"twitter.com/omarsar0/status/1683856037277732869","url":"https://twitter.com/omarsar0/status/1683856037277732869","urlHash":3685183067},"97c4fa83-04b5-4e2e-a11b-1a1903f37b55":{"favIconUrl":"fallback","id":"97c4fa83-04b5-4e2e-a11b-1a1903f37b55","title":"陈丹琦ACL学术报告来了！详解大模型「外挂」数据库7大方向3大挑战，3小时干货满满","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247685490&idx=3&sn=168271a413eab96b27c528bd72220119&exportkey=n_ChQIAhIQGUE5ITgauj%2F6wVKAT%2FXe9RKWAgIE97dBBAEAAAAAAD1zA1%2BVWTsAAAAOpnltbLcz9gKNyK89dVj0fAC8kzt6PwJE27IMMuxgbhGlk7Y2fHsio2teVMWMV2h1XisIHVctAovBpU1409RwIAhfXv7gBxRI5i08nXSqGeSyetDHpSN%2BWoxEbzkoR3tivyjsONCfRlRxXaRWglSPYkCS7hfC5a%2BsS8Z5XWIGEW9269e9Ds3cWRZgj0QYGUdUJN2BMj1S1Arj6Wje3tWD7DqE%2FWN5QrsAArlYGcWBV%2FSxa8ju7xU%2FlXraFk38oNz9aMKTYM%2BeI%2FPWQ4bllmpNOV6c9JcI24IL1bs7WZj02%2FF7o%2BJT%2FH5QWGymuVClzaA1K5QLEWozz58M5psM2HeC&acctmode=0&pass_ticket=jGk7NGJez4szK27HNlQag7C0h9RzfoGny%2BC2XpwLIDpPw88ZKa%2FcIWsSSqbJ8uG%2F&wx_header=0","urlHash":120349416},"97da05c0-cc3d-4c9e-8ca5-00f61d2bba69":{"favIconUrl":"fallback","id":"97da05c0-cc3d-4c9e-8ca5-00f61d2bba69","title":"GPT-4使用混合大模型？研究证明MoE+指令调优确实让大模型性能超群","url":"https://mp.weixin.qq.com/s?__biz=MzU3NjE4NjQ4MA==&mid=2247547216&idx=2&sn=d453f51c49eaf71124d84b4f755e3ca4&exportkey=n_ChQIAhIQzvAwvMRnRYX62OUzVrCxGBKWAgIE97dBBAEAAAAAAFEyI1FJjeoAAAAOpnltbLcz9gKNyK89dVj0AsS5edfW%2F0AARMItCVNjnQ9Qtxftci74exT5wbZZUAm%2FNQheOXYnieWOlK0mHG6fVhoSGNbhc4Aek0c4PVZvSaKkili3qj35J96PRtuUF9c1rxjX%2FK7hGQ9tp%2BvkCyFLe74kwyxIq2Evj%2BpkJXvjZMLjZwCn76Bz5O2i7fkm0dlMoMSv3nvqyhjt5uugUSxWHsuhhUli7EzGiceu0GA0fMl3uEmMEB719Mgjpy1ToEdrqgd45eDIR47xdd3QkwhCXL7J%2BqToMBNbhRNYpNuVKANmcYJZ7wwb3N5W1fbQoO6eejHVf1lmQLmvgPbLOZf%2B&acctmode=0&pass_ticket=FdpCzSNZafAQhZn84BmNm1cpPxMWoK%2Bdk0ZzlkW8mqaHqxmw6cLkpbSS0rQ3XTbh&wx_header=0","urlHash":2144938522},"9811f2f0-7d30-4cd2-bcca-e326420f4bf0":{"favIconUrl":"https://www.google.com/favicon.ico","id":"9811f2f0-7d30-4cd2-bcca-e326420f4bf0","title":"gpt4 architecture leak - Google Search","url":"https://www.google.com/search?q=gpt4+architecture+leak&oq=gpt4+architecture+leak&aqs=chrome..69i57j0i10i512j0i390i650l4.4809j0j1&sourceid=chrome&ie=UTF-8","urlHash":243056503},"98584169-0c0e-480d-9edb-a0ba3f88b738":{"favIconUrl":"fallback","id":"98584169-0c0e-480d-9edb-a0ba3f88b738","title":"https://arxiv.org/pdf/2201.02993.pdf","url":"https://arxiv.org/pdf/2201.02993.pdf","urlHash":1868081834},"986bab0d-db64-40f8-bf23-dbccfc8beefd":{"favIconUrl":"fallback","id":"986bab0d-db64-40f8-bf23-dbccfc8beefd","title":"Learning with Differentiable Perturbed Optimizers - Google Search","url":"https://www.google.com/search?q=Learning%20with%20Differentiable%20Perturbed%20Optimizers","urlHash":307518589},"9878566a-1862-4f24-9085-e92d3758418e":{"favIconUrl":"fallback","id":"9878566a-1862-4f24-9085-e92d3758418e","title":"ChildTuning：试试把Dropout加到梯度上去？ - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/8764","urlHash":1961438058},"988eff0e-7139-4088-a48a-3c8303ecbc8e":{"favIconUrl":"fallback","id":"988eff0e-7139-4088-a48a-3c8303ecbc8e","title":"卡夫卡笔记及箴言补充_卡夫卡吧_百度贴吧","url":"https://tieba.baidu.com/p/1246919155?pn=1","urlHash":2844400837},"98d181f4-40c3-4762-8f91-c1f169ed1f9f":{"favIconUrl":"fallback","id":"98d181f4-40c3-4762-8f91-c1f169ed1f9f","title":"Differentiating Metropolis-Hastings to Optimize Intractable Densities - Arxiv-2306.07961","url":"https://arxiv.org/pdf/2306.07961.pdf","urlHash":2120599664},"9925b09a-8e96-475b-9f33-2e1557005808":{"favIconUrl":"fallback","id":"9925b09a-8e96-475b-9f33-2e1557005808","title":"SCOTT Self-Consistent Chain-of-Thought Distillation - Arxiv-2305.01879","url":"https://arxiv.org/pdf/2305.01879.pdf","urlHash":754985608},"997cb84c-1e0f-4da1-95e2-e43271afa4be":{"favIconUrl":"fallback","id":"997cb84c-1e0f-4da1-95e2-e43271afa4be","title":"Tune As You Scale: Hyperparameter Optimization For Compute Efficient Training","url":"https://arxiv.org/pdf/2306.08055.pdf","urlHash":1576928366},"9992a83d-64a7-4b76-a085-8293ef053448":{"favIconUrl":"fallback","id":"9992a83d-64a7-4b76-a085-8293ef053448","title":"Tensor Programs V Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer - Arxiv-2203.03466","url":"https://arxiv.org/abs/2203.03466v2","urlHash":2552486795},"99d284f2-2637-4365-83d6-d11157ea6e92":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"99d284f2-2637-4365-83d6-d11157ea6e92","title":"On Evaluating Adversarial Robustness of Large Vision-Language Models | PDF","url":"https://arxiv.org/pdf/2305.16934.pdf","urlHash":4058369912},"99de62e9-b006-4d2a-8ce7-0a4ac73aa1d8":{"favIconUrl":"fallback","id":"99de62e9-b006-4d2a-8ce7-0a4ac73aa1d8","title":"Deep learning theory lecture notes","url":"https://mjt.cs.illinois.edu/dlt/#rademacher-complexity","urlHash":1348144683},"99f73011-c0c8-4349-846b-1e1e124aeb41":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"99f73011-c0c8-4349-846b-1e1e124aeb41","title":"Fabian Schaipp on X: \"New blog post : AdamW is often considered to \"decouple learning rate and weight decay\". But this is not entirely true if you use AdamW from Pytorch. 🗞️ Full post: https://t.co/hh5963NffH https://t.co/U0K73I0njH\" / X","url":"https://twitter.com/FSchaipp/status/1759561213359321400","urlHash":210225288},"9a03ee71-52d9-4f00-ab43-5160db3cb854":{"favIconUrl":"fallback","id":"9a03ee71-52d9-4f00-ab43-5160db3cb854","title":"Towards Reasoning in Large Language Models A Survey - Arxiv-2212.10403","url":"https://arxiv.org/pdf/2212.10403.pdf","urlHash":955972947},"9a24c330-f10e-4a86-93e9-d14581f8dea5":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"9a24c330-f10e-4a86-93e9-d14581f8dea5","title":"Skill Induction and Planning with Latent Language | PDF","url":"https://arxiv.org/pdf/2110.01517.pdf","urlHash":3450530096},"9a2f7de1-f491-44d4-8f2e-f6b77d8f599f":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"9a2f7de1-f491-44d4-8f2e-f6b77d8f599f","title":"Weijia Shi on X: \"Introduce In-Context Pretraining🖇️: train LMs on contexts of related documents. Improving 7B LM by simply reordering pretrain docs 📈In-context learning +8% 📈Faithful +16% 📈Reading comprehension +15% 📈Retrieval augmentation +9% 📈Long-context reason +5% https://t.co/cXyikcCifD https://t.co/QZoQ5a67tY\" / X","url":"https://twitter.com/WeijiaShi2/status/1714321297411285450","urlHash":957040659},"9a3e49da-cff4-43bb-b25f-71c6eaf25951":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"9a3e49da-cff4-43bb-b25f-71c6eaf25951","title":"SemSup-XC: Semantic Supervision for Zero and Few-shot Extreme Classification | PDF","url":"https://arxiv.org/pdf/2301.11309.pdf","urlHash":2717526419},"9a50a0f6-c451-4122-b5b9-fe5fba7ca0f0":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"9a50a0f6-c451-4122-b5b9-fe5fba7ca0f0","title":"Learning to Retrieve In-Context Examples for Large Language Models | PDF","url":"https://arxiv.org/pdf/2307.07164.pdf","urlHash":1643863403},"9a51f86c-803a-4482-8539-77da4837ba6a":{"favIconUrl":"fallback","id":"9a51f86c-803a-4482-8539-77da4837ba6a","title":"paultsw/nice_pytorch: Nonlinear Independent Components Estimation (Dinh et al, 2014) in PyTorch.","url":"https://github.com/paultsw/nice_pytorch","urlHash":3437504931},"9a784d23-2df5-4198-a4b5-5d965744f262":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"9a784d23-2df5-4198-a4b5-5d965744f262","title":"Certifying LLM Safety against Adversarial Prompting | PDF","url":"https://arxiv.org/pdf/2309.02705.pdf","urlHash":3031513443},"9aa3373c-8794-4646-8d18-a7dfe9c02003":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"9aa3373c-8794-4646-8d18-a7dfe9c02003","title":"Felix on X: \"I think those guys just reinvented frankenMoEs... (credit to @maximelabonne for the blog post excerpt) https://t.co/pirHa2ujmj\" / X","url":"https://twitter.com/felix_red_panda/status/1778545880020246665","urlHash":991416208},"9aaefc30-dec5-4085-af57-c07abec6d0af":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"9aaefc30-dec5-4085-af57-c07abec6d0af","title":"Learning to Compress Prompts with Gist Tokens | PDF","url":"https://arxiv.org/pdf/2304.08467.pdf","urlHash":3985362841},"9ab82417-9c9e-4a77-be7b-ee7a4e3bb650":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"9ab82417-9c9e-4a77-be7b-ee7a4e3bb650","title":"全世界机器人共用一个大脑，谷歌DeepMind已经完成了第一步","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650905569&idx=3&sn=e42c51479585d6c38c420c03913d65da&chksm=84e45f9fb393d689b74ec38c17137e2a6f8eb1f17ba852caffe8c20fcf651e63f5744b9cfcc3&mpshare=1&scene=1&srcid=01255kMXk8yi9QDA2vsVDp3D&sharer_shareinfo=5e125550a9c77905eb778183b38a75a5&sharer_shareinfo_first=5e125550a9c77905eb778183b38a75a5&exportkey=n_ChQIAhIQdv%2B86tjlPL84vDEKvpkw0xKWAgIE97dBBAEAAAAAAHiiGTIGcYAAAAAOpnltbLcz9gKNyK89dVj0LVV9NH0gSVlm37SR8D6M9k7SuVlzDFMGDrmkWs38vAixksrUIwv7KHIu6Cd%2ByjxQrpE7OLozJ4e9ZfxTfOUn045OCpOapy4Bw7scNfulAmfhSKrRAC7tA8RLtdi%2FvEFAyieDkyLiE1IOhWotAzOcuWeOYyfieSI28Sy2%2FZVZKwKH2r7y%2FMBaVaaHKpdF5g7S4eXUoyLndWGYUYNy83WIPacgC1ab%2BnXc62IpXe3re5ch3bXeCRzcmSDzNB2iIaq8qSMTS96Dllvi1do4upJDQrTNPDp6HVZzSGhQhPQBbYzJ6G757eR%2BGJiqPbVlABPE&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HM3IqFGN8gu4sTyE3mn7APcGaG9AofTMkUu9HAjE3tV9w%3D%3D&wx_header=0#rd","urlHash":2358238682},"9ab99abf-57f3-4836-9dc8-6e60a268fcd4":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"9ab99abf-57f3-4836-9dc8-6e60a268fcd4","title":"twitter.com/_philschmid/status/1690646568779616256","url":"https://twitter.com/_philschmid/status/1690646568779616256","urlHash":158362017},"9abf4e69-21d2-405e-bc85-1abc2e76afad":{"favIconUrl":"fallback","id":"9abf4e69-21d2-405e-bc85-1abc2e76afad","title":"Emerging Properties in Self-Supervised Vision Transformers - Arxiv-2104.14294","url":"https://arxiv.org/pdf/2104.14294.pdf","urlHash":2220178525},"9acb8811-2a9c-478e-9c06-6300d97e093d":{"favIconUrl":"fallback","id":"9acb8811-2a9c-478e-9c06-6300d97e093d","title":"The Curse of Recursion: Training on Generated Data Makes Models Forget","url":"https://arxiv.org/pdf/2305.17493.pdf","urlHash":447540026},"9b1043ec-420e-44fa-8206-3d05724851b2":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"9b1043ec-420e-44fa-8206-3d05724851b2","title":"tmabraham/ddpo-pytorch: Reproduction of DDPO paper (RLHF for diffusion)","url":"https://github.com/tmabraham/ddpo-pytorch","urlHash":1095016852},"9b38db6f-4513-4c1a-9311-ae69dae77cd9":{"favIconUrl":"https://www.google.com/favicon.ico","id":"9b38db6f-4513-4c1a-9311-ae69dae77cd9","title":"Robustness of Demonstration-based Learning Under Limited Data Scenario - Google Search","url":"https://www.google.com/search?q=Robustness+of+Demonstration-based+Learning+Under+Limited+Data+Scenario&oq=Robustness+of+Demonstration-based+Learning+Under+Limited+Data+Scenario&aqs=chrome.0.69i59j69i61l2.188j0j1&sourceid=chrome&ie=UTF-8","urlHash":1803526901},"9b5715a5-6d83-42a5-86a6-78057436e008":{"favIconUrl":"https://opendilab.github.io/DI-engine/_static/images/favicon.ico","id":"9b5715a5-6d83-42a5-86a6-78057436e008","title":"RL Algorithms Cheat Sheet — DI-engine 0.1.0 documentation","url":"https://opendilab.github.io/DI-engine/12_policies/index.html","urlHash":403745911},"9b667131-ddb3-4ae0-bdb9-45a9f3d2166a":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"9b667131-ddb3-4ae0-bdb9-45a9f3d2166a","title":"【自翻】【武田绫乃】漠然与五体（重发试试）","url":"https://www.douban.com/note/833554818/?_i=3221336KLQjbnS,1224224oZQdRGV","urlHash":2757446386},"9b7b9434-eb3f-452c-a59d-f15cedcf26ed":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"9b7b9434-eb3f-452c-a59d-f15cedcf26ed","title":"OpenAI on X: \"We applied GPT-4 to interpretability — automatically proposing explanations for GPT-2's 300k neurons — and found neurons responding to concepts like similes, “things done correctly,” or expressions of certainty. We aim to use Al to help us understand Al: https://t.co/mUsGOg6T69 https://t.co/knCUxnL5CY\" / X","url":"https://twitter.com/OpenAI/status/1655982364273831936","urlHash":945201746},"9b827c0a-e05b-4534-8650-7e0dfab556e7":{"favIconUrl":"fallback","id":"9b827c0a-e05b-4534-8650-7e0dfab556e7","title":"StitchNet Composing Neural Networks from Pre-Trained Fragments - Arxiv-2301.01947","url":"https://arxiv.org/abs/2301.01947","urlHash":436127475},"9ba20deb-ab74-4c89-b28f-75b5538a3110":{"favIconUrl":"fallback","id":"9ba20deb-ab74-4c89-b28f-75b5538a3110","title":"Fine-Grained Human Feedback Gives Better Rewards for Language Model Training","url":"https://arxiv.org/abs/2306.01693","urlHash":676605010},"9ba42614-ccb4-4d88-9d5b-09846092862e":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"9ba42614-ccb4-4d88-9d5b-09846092862e","title":"Diffusion Models already have a Semantic Latent Space | PDF","url":"https://arxiv.org/pdf/2210.10960.pdf","urlHash":1567984751},"9bc8a599-5859-4b89-b793-10b020d6a526":{"favIconUrl":"fallback","id":"9bc8a599-5859-4b89-b793-10b020d6a526","title":"Walter Benjamin (Stanford Encyclopedia of Philosophy)","url":"https://plato.stanford.edu/entries/benjamin/","urlHash":3546355498},"9bc93df3-cd47-4f29-bcbe-19c4906abdc9":{"favIconUrl":"fallback","id":"9bc93df3-cd47-4f29-bcbe-19c4906abdc9","title":"苏州大学赵某造黄谣以满足他的绿帽癖——精神分析论被绿享乐的快感结构与原始动机","url":"https://mp.weixin.qq.com/s/NqiWnQzjz66vGHj_LiJ8LQ","urlHash":4058114122},"9bd79ee5-5ade-4083-952e-69c05142f267":{"favIconUrl":"https://ssl.gstatic.com/atari/images/public/favicon.ico","id":"9bd79ee5-5ade-4083-952e-69c05142f267","title":"NeurIPS 2023 Tutorial","url":"https://sites.google.com/view/neurips2023law","urlHash":2778166138},"9c032091-66ee-4266-9cbf-c744dc32143f":{"favIconUrl":"https://transformer-circuits.pub/favicon.ico","id":"9c032091-66ee-4266-9cbf-c744dc32143f","title":"Transformer Circuits Thread","url":"https://transformer-circuits.pub/","urlHash":593163202},"9c54bf2d-3a39-47e5-93ab-e90e353daf40":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"9c54bf2d-3a39-47e5-93ab-e90e353daf40","title":"图写真形 (豆瓣)","url":"https://book.douban.com/subject/36124365/","urlHash":676090880},"9c6c7744-bc55-46f8-b1b2-fa196b7b7a3b":{"favIconUrl":"fallback","id":"9c6c7744-bc55-46f8-b1b2-fa196b7b7a3b","title":"Contextual Representation Learning beyond Masked Language Modeling - Arxiv-2204.04163","url":"https://arxiv.org/abs/2204.04163","urlHash":2843573407},"9c77a595-462c-4935-be11-a0b1bac08002":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"9c77a595-462c-4935-be11-a0b1bac08002","title":"Evaluating Large Language Models: A Comprehensive Survey | Abstract","url":"https://arxiv.org/abs/2310.19736?utm_source=substack&utm_medium=email","urlHash":1844400812},"9cd527b5-3905-412e-8d52-a0be0df75af0":{"favIconUrl":"fallback","id":"9cd527b5-3905-412e-8d52-a0be0df75af0","title":"MetaPoison: Practical General-purpose Clean-label Data Poisoning","url":"https://arxiv.org/pdf/2004.00225.pdf","urlHash":609707673},"9cf87265-1d62-4d57-a5eb-1fc14059790d":{"favIconUrl":"fallback","id":"9cf87265-1d62-4d57-a5eb-1fc14059790d","title":"How to DP-fy ML A Practical Guide to Machine Learning with Differential Privacy - Arxiv-2303.00654","url":"https://arxiv.org/pdf/2303.00654.pdf","urlHash":2678255302},"9d07b2f9-90b0-4571-ba5e-00c10abd962e":{"favIconUrl":"fallback","id":"9d07b2f9-90b0-4571-ba5e-00c10abd962e","title":"Can language models learn from explanations in context? - Arxiv-2204.02329","url":"https://arxiv.org/abs/2204.02329","urlHash":1847282152},"9d1f8594-95df-4ce7-871e-ae2b4f8122b7":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"9d1f8594-95df-4ce7-871e-ae2b4f8122b7","title":"(1) CLS on X: \"Long context LMs have been on the rise, but I keep wondering: do any tasks actually need super long contexts? 🤔 I’m somewhat convinced by an emerging line of “context compression” methods that shorten the contexts and retain the performance, examples in 🧵 (1/n)\" / X","url":"https://twitter.com/ChengleiSi/status/1742977971890352362","urlHash":722585763},"9d27a6d7-208b-4f7e-9b91-7f791ebbb301":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"9d27a6d7-208b-4f7e-9b91-7f791ebbb301","title":"Evaluating the Zero-shot Robustness of Instruction-tuned Language Models | Abstract","url":"https://arxiv.org/abs/2306.11270","urlHash":3122746118},"9d3aab25-51cf-4775-b6e4-e810e77a99cf":{"favIconUrl":"fallback","id":"9d3aab25-51cf-4775-b6e4-e810e77a99cf","title":"活人祭献、巫魔朝拜：你所知道的克苏鲁，其实源自于这些真实宗教","url":"https://www.gcores.com/articles/133848","urlHash":848717582},"9d45131c-1e7e-4707-9cbf-824c017a95d9":{"favIconUrl":"fallback","id":"9d45131c-1e7e-4707-9cbf-824c017a95d9","title":"Scalable Differential Privacy with Certified Robustness in Adversarial Learning","url":"https://proceedings.mlr.press/v119/phan20a.html","urlHash":4111574099},"9d5c2dd3-eb85-4a8b-a587-055850a5b8be":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"9d5c2dd3-eb85-4a8b-a587-055850a5b8be","title":"The Perils & Promises of Fact-checking with Large Language Models | PDF","url":"https://arxiv.org/pdf/2310.13549.pdf","urlHash":4003651580},"9da107a9-3061-499b-a304-1716424ad050":{"favIconUrl":"https://cdn.semanticscholar.org/3cf37988806f7507/img/darkmode/favicon-32x32.png","id":"9da107a9-3061-499b-a304-1716424ad050","title":"[PDF] Localizing Lying in Llama: Understanding Instructed Dishonesty on True-False Questions Through Prompting, Probing, and Patching | Semantic Scholar","url":"https://www.semanticscholar.org/paper/Localizing-Lying-in-Llama%3A-Understanding-Instructed-Campbell-Ren/44348660a9b5a6a5ee83333587c64ed6cc84a0b1","urlHash":1461140445},"9da88e7d-cb0d-4180-9f0b-6441bc38f7ed":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/favicon-32x32.png","id":"9da88e7d-cb0d-4180-9f0b-6441bc38f7ed","title":"Augmentoolkit — Easily Generate Quality Multi-Turn Data based on Human-Written Documents, using Local Models. Painlessly Finetune AI on Specific Domains. : LocalLLaMA","url":"https://www.reddit.com/r/LocalLLaMA/comments/18xz9it/augmentoolkit_easily_generate_quality_multiturn/","urlHash":1854407254},"9dab00a6-b4c3-4a2d-89bd-91d0fb1437ad":{"favIconUrl":"fallback","id":"9dab00a6-b4c3-4a2d-89bd-91d0fb1437ad","title":"采生折割 - Wikiwand","url":"https://www.wikiwand.com/zh/%E9%87%87%E7%94%9F%E6%8A%98%E5%89%B2","urlHash":3536363562},"9dd5af28-ad76-4b32-b32e-38b2eb3216f4":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/favicon-32x32.png","id":"9dd5af28-ad76-4b32-b32e-38b2eb3216f4","title":"Reddit - Dive into anything","url":"https://www.reddit.com/r/reinforcementlearning/comments/13d4ic6/what_are_the_limitations_of_hierarchical/","urlHash":688904172},"9ddd8796-2946-4b7a-b891-a59ab333e215":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"9ddd8796-2946-4b7a-b891-a59ab333e215","title":"Training language models to follow instructions with human feedback | PDF","url":"https://arxiv.org/pdf/2203.02155.pdf","urlHash":134041516},"9e38025c-e02c-4c2f-92a0-fa00351a4aeb":{"favIconUrl":"fallback","id":"9e38025c-e02c-4c2f-92a0-fa00351a4aeb","title":"uclanlp/awesome-fairness-papers: Papers on fairness in NLP","url":"https://github.com/uclanlp/awesome-fairness-papers","urlHash":3023702110},"9e400d34-fe16-42e5-a7b7-34a36320634e":{"favIconUrl":"fallback","id":"9e400d34-fe16-42e5-a7b7-34a36320634e","title":"bamos/HowToTrainYourMAMLPytorch: The original code for the paper \"How to train your MAML\" along with a replication of the original \"Model Agnostic Meta Learning\" (MAML) paper in Pytorch.","url":"https://github.com/bamos/HowToTrainYourMAMLPytorch","urlHash":805376821},"9e515664-33b1-4e58-905e-ef472649c3e0":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"9e515664-33b1-4e58-905e-ef472649c3e0","title":"Yu Su on X: \"New multimodal web agent paper to appear at #CVPR2024 👇 While it's now well accepted that visual signals are critical for web agents, as shown in SeeAct and several recent papers, we actually have an even earlier work on multimodality that had been silently under review at…\" / X","url":"https://twitter.com/ysu_nlp/status/1764127797314769118","urlHash":1923603161},"9e58594e-8771-4350-ad70-78ec4b32a96b":{"favIconUrl":"fallback","id":"9e58594e-8771-4350-ad70-78ec4b32a96b","title":"krasserm/bayesian-machine-learning: Notebooks about Bayesian methods for machine learning","url":"https://github.com/krasserm/bayesian-machine-learning","urlHash":2561975535},"9e5e4870-c755-42db-940f-e5e28b1d22c0":{"favIconUrl":"fallback","id":"9e5e4870-c755-42db-940f-e5e28b1d22c0","title":"Logic-Driven Context Extension and Data Augmentation for Logical Reasoning of Text - Arxiv-2105.03659","url":"https://arxiv.org/pdf/2105.03659.pdf","urlHash":1999741980},"9e5ee15f-194b-476e-b27c-637a02c3bbd8":{"favIconUrl":"fallback","id":"9e5ee15f-194b-476e-b27c-637a02c3bbd8","title":"求道之人，不问寒暑（六） - 知乎","url":"https://zhuanlan.zhihu.com/p/261412153","urlHash":2283994067},"9e6cb536-1c96-4621-9057-bfaf366be1ee":{"favIconUrl":"fallback","id":"9e6cb536-1c96-4621-9057-bfaf366be1ee","title":"pdf","url":"https://openreview.net/pdf?id=xtaX3WyCj1","urlHash":1507051695},"9ea766cb-5f1f-4157-aa0b-ec98fc04a0ac":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"9ea766cb-5f1f-4157-aa0b-ec98fc04a0ac","title":"Prompt Waywardness: The Curious Case of Discretized Interpretation of Continuous Prompts | PDF","url":"https://arxiv.org/pdf/2112.08348.pdf","urlHash":2810034438},"9ebf2b5b-5d10-411e-ad05-442866b084b1":{"favIconUrl":"fallback","id":"9ebf2b5b-5d10-411e-ad05-442866b084b1","title":"llm-sampling-paper","url":"https://people.csail.mit.edu/renda/llm-sampling-paper","urlHash":1369603897},"9ed60ddb-a14c-4b05-a1e7-a346b389b573":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"9ed60ddb-a14c-4b05-a1e7-a346b389b573","title":"推理大戦 (豆瓣)","url":"https://book.douban.com/subject/36595914/","urlHash":1820140969},"9eddc582-2000-41d0-9abc-c8a61d0bec17":{"favIconUrl":"fallback","id":"9eddc582-2000-41d0-9abc-c8a61d0bec17","title":"存在与时间 (豆瓣)","url":"https://book.douban.com/subject/25939476/","urlHash":4171890637},"9f2fc7b8-a1ec-4bc2-92cd-79febd448b27":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"9f2fc7b8-a1ec-4bc2-92cd-79febd448b27","title":"Sungdong Kim on X: \"🤔 Do we always need a human preference for effective LLM alignment after an SFT stage? Our answer is NO 🙅‍♂️ We present a ✨preference-free alignment approach✨, leveraging an off-the-shelf retriever with effective regularizer functions: Regularized Relevance Reward (R^3). [1/n] https://t.co/OzrovBkkZH\" / X","url":"https://twitter.com/SungdongKim4/status/1755936449860612524","urlHash":1092347817},"9f3da9f5-34af-4c0d-ac54-185749a52f5c":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"9f3da9f5-34af-4c0d-ac54-185749a52f5c","title":"Jindong Wang on X: \"Introducing a new research direction: *Catastrophic Inheritance*:https://t.co/uvMhNPdLXh 🤡Bias in black-box large-scale pre-training data will be inherited to foundation models, leading to catastrophic impacts 💡We aim to Understand, Interpret, and Mitigate the effects https://t.co/THzBu5aKjs\" / X","url":"https://twitter.com/jd92wang/status/1760281734128550361","urlHash":328525243},"9fc6b6de-009f-4b5e-aba5-b6da27d9b0d4":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"9fc6b6de-009f-4b5e-aba5-b6da27d9b0d4","title":"Qian Liu on X: \"🔥If data is the oil, have we exhausted the mine? Introducing our latest work, 🎉. \"From Zero to Hero: Examining the Power of Symbolic Tasks in Instruction Tuning\"💪 💡TL;DR: Generate tons of train examples via symbolic tasks to boost data quantity for instruction tuning🚀 1/3 https://t.co/SV9RioMyDP\" / X","url":"https://twitter.com/sivil_taram/status/1648294728553877505","urlHash":1099507269},"a007b058-6947-46d3-b4b3-931deeefb312":{"favIconUrl":"fallback","id":"a007b058-6947-46d3-b4b3-931deeefb312","title":"On the Difficulty of Membership Inference Attacks - CVPR-2021_17609415","url":"https://openaccess.thecvf.com/content/CVPR2021/papers/Rezaei_On_the_Difficulty_of_Membership_Inference_Attacks_CVPR_2021_paper.pdf","urlHash":1760445378},"a0476c6e-fe58-4966-892d-c633b04191c3":{"favIconUrl":"fallback","id":"a0476c6e-fe58-4966-892d-c633b04191c3","title":"learn2learn.nn - learn2learn","url":"http://learn2learn.net/docs/learn2learn.nn/","urlHash":3635864759},"a04790fd-9330-4438-9d96-9e56e8a1049b":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"a04790fd-9330-4438-9d96-9e56e8a1049b","title":"侦探往事 (豆瓣)","url":"https://book.douban.com/subject/35544979/","urlHash":619393569},"a09637f2-cad2-4256-aee9-c17ee003966e":{"favIconUrl":"fallback","id":"a09637f2-cad2-4256-aee9-c17ee003966e","title":"Syntactic Data Augmentation Increases Robustness to Inference Heuristics - Arxiv-2004.11999","url":"https://arxiv.org/pdf/2004.11999.pdf","urlHash":4167277907},"a0a2c991-a14b-4b95-ba65-30bb0386f0f7":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a0a2c991-a14b-4b95-ba65-30bb0386f0f7","title":"Aran Komatsuzaki on X: \"AdaPlanner: Adaptive Planning from Feedback with Language Models Proposes a closed-loop approach, AdaPlanner, which allows the LLM agent to refine its self-generated plan adaptively in response to environmental feedback. Outperforms SotA baselines (e.g. Reflexion) with better… https://t.co/PDByF5zLnL\" / X","url":"https://twitter.com/arankomatsuzaki/status/1662995440483065858","urlHash":1369192761},"a0a77edf-ba2f-4f76-b268-ac4f5264fd24":{"favIconUrl":"fallback","id":"a0a77edf-ba2f-4f76-b268-ac4f5264fd24","title":"Scalable Penalized Regression for Noise Detection in Learning with Noisy Labels - Arxiv-2203.07788","url":"https://arxiv.org/abs/2203.07788","urlHash":1482655377},"a0d46181-caa8-477e-8eaa-3c9983a667d0":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"a0d46181-caa8-477e-8eaa-3c9983a667d0","title":"Dissecting Recall of Factual Associations in Auto-Regressive Language Models | Abstract","url":"https://arxiv.org/abs/2304.14767","urlHash":961155624},"a0f54ee8-2787-460d-9c5d-83521c03dab5":{"favIconUrl":"fallback","id":"a0f54ee8-2787-460d-9c5d-83521c03dab5","title":"amazon-science/mm-cot: Official implementation for \"Multimodal Chain-of-Thought Reasoning in Language Models\" (stay tuned and more will be updated)","url":"https://github.com/amazon-science/mm-cot","urlHash":3938669832},"a0f97380-c39e-4b05-893a-959fb4202f98":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"a0f97380-c39e-4b05-893a-959fb4202f98","title":"(1) Shahul Es on X: \"LoRA is not a drop-in replacement for Full Finetuning. Even though it reduces the compute requirements by 3x it comes with certain limitations. The data preparation needed for both is also different. 🔑 - LoRA requires much more data to converge compared to full FT. This can be… https://t.co/UibQzBWgGQ\" / X","url":"https://twitter.com/Shahules786/status/1689343198404161536","urlHash":2201837748},"a1101238-35cd-438a-bd3c-d5f86ed63dbb":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"a1101238-35cd-438a-bd3c-d5f86ed63dbb","title":"大模型隐蔽后门震惊马斯克：平时人畜无害，提到关键字瞬间“破防”","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247713210&idx=3&sn=ce7a6d53f4313ddee302939c3cd337c8&chksm=e8df36c8dfa8bfdea936469e7a75d9b42e501921e6af1ad572388d572cb89fff7bcb7991f125&mpshare=1&scene=1&srcid=0115mh8ZZuNPXHA18EOIZlXY&sharer_shareinfo=0965d693aa41671b70f6043882a86ead&sharer_shareinfo_first=0965d693aa41671b70f6043882a86ead&exportkey=n_ChQIAhIQMVzrRXH0JV0J%2B0nhdvGzlhKWAgIE97dBBAEAAAAAALg%2FE2dm3bMAAAAOpnltbLcz9gKNyK89dVj004fSON6ss9tZwhF10SgckR0oOm820Kytls7nuVBplafZok2gy52Cu4OttjveaG4MYXdplvGkGltHp7mWpZUwI%2B5tKJp0%2F%2F8MyZlUROiWsmRxCC4FqQRP4r%2By58V2w9%2FQcyOY1c2aY7i%2Fp%2BAcqDLqFk9C6MxCZ11yv%2Blq5R%2FyLE7BtdFN%2BisFrdKKOrgkHGfjVU%2BBZ5DUNN8eoS5j1kscMujEMYUc%2FXkPdu%2FH1zsbdjfxDN7SEmoUc2W6iYRM%2FVXgXCs%2BV4MEAib8V535kZkQmaVM%2FjxD4uS9FeQ5MRLjxWUvaOqUUxgqjo%2B%2BGCo%2BmuT%2F&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsa7%2F6a24VUmnF2ktRSI23succ6Kivosq1rdmsvyDmlSSQ%3D%3D&wx_header=0#rd","urlHash":1577374655},"a1199307-1a69-4e84-a9dc-8ccca5ba2b52":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"a1199307-1a69-4e84-a9dc-8ccca5ba2b52","title":"How do Language Models Bind Entities in Context? | Abstract","url":"https://arxiv.org/abs/2310.17191","urlHash":3180257458},"a1c5807f-3c8e-4938-a6ec-d9a58ba55926":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"a1c5807f-3c8e-4938-a6ec-d9a58ba55926","title":"大模型RLHF的trick","url":"https://mp.weixin.qq.com/s?__biz=MzIwNDY1NTU5Mg==&mid=2247486087&idx=1&sn=948eb9c0077e6eb360c6c61bf9ef1bca&exportkey=n_ChQIAhIQJrDdU8gF9cZMR4IX8MkQ7BKWAgIE97dBBAEAAAAAACt4GQ3lavkAAAAOpnltbLcz9gKNyK89dVj0UudbvNOmunNqva%2FMHMWYqOHc9KC8tkDmstEwGQ3iuhEim8kuDXzba5e9r9HiU%2FjcCwkHcENDRrmR%2BuvJvMTlB0Zx9QtcIJG7ZM80KpaowDDbjGe7sR1qZ7eJfTG8vetgOJuonDOACQiSQPBoQ095tlj5UOl1ZHIYK4F9cah7ngcsuV8GXehBjy0r6hXROAvAKRi9fnFX5HbWmi9TUWmiUa90aAyMdo7LiDWJTy3a33H1YCISZqPxr7G7lPrdE%2BQOQLYhg2FLSC%2BSxpjA%2FH%2Ftx2E3Uz9HGYK%2Fe4W24Yjr3%2FkNBvCtUH2fFpdVHn%2FgdAhQ&acctmode=0&pass_ticket=i9w4c4vZRr0gS%2B5VCnj0ykAi9DWrD3meGtRWj49B5JdUXiQe5jU9JTNAh%2BEkhX0z&wx_header=0","urlHash":1489270755},"a1de1f99-25f0-43ce-a396-59917fe299c1":{"favIconUrl":"fallback","id":"a1de1f99-25f0-43ce-a396-59917fe299c1","title":"Explaining Neural Scaling Laws - Arxiv-2102.06701","url":"https://arxiv.org/abs/2102.06701","urlHash":206471362},"a1e8ab2d-f1b2-49d2-b9a5-fe17def29094":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"a1e8ab2d-f1b2-49d2-b9a5-fe17def29094","title":"xmu-xiaoma666/External-Attention-pytorch: 🍀 Pytorch implementation of various Attention Mechanisms, MLP, Re-parameter, Convolution, which is helpful to further understand papers.⭐⭐⭐","url":"https://github.com/xmu-xiaoma666/External-Attention-pytorch#re-parameter-series","urlHash":2861463892},"a2122eb0-0cb1-4a23-929b-18b54718b103":{"favIconUrl":"fallback","id":"a2122eb0-0cb1-4a23-929b-18b54718b103","title":"The Shattered Gradients Problem If resnets are the answer, then what is the question? - Arxiv-1702.08591","url":"https://arxiv.org/abs/1702.08591","urlHash":1953694350},"a2221f16-2e20-4012-a456-5068b9261317":{"favIconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","id":"a2221f16-2e20-4012-a456-5068b9261317","title":"'Fundamental' vs 'applied' mechanistic interpretability research — LessWrong","url":"https://www.lesswrong.com/posts/uvEyizLAGykH8LwMx/fundamental-vs-applied-mechanistic-interpretability-research","urlHash":3934178919},"a2599b0a-0e01-45d7-b642-0de731380be8":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"a2599b0a-0e01-45d7-b642-0de731380be8","title":"Abstract Visual Reasoning with Tangram Shapes | PDF","url":"https://arxiv.org/pdf/2211.16492.pdf","urlHash":1250753656},"a26c5b2b-12d3-4e72-b274-6b99ddc122b2":{"favIconUrl":"https://www.google.com/favicon.ico","id":"a26c5b2b-12d3-4e72-b274-6b99ddc122b2","title":"ウィンチェスター・マーダー・ミステリー・ハウスの殺人 斜线堂有纪 - Google Search","url":"https://www.google.com/search?q=%E3%82%A6%E3%82%A3%E3%83%B3%E3%83%81%E3%82%A7%E3%82%B9%E3%82%BF%E3%83%BC%E3%83%BB%E3%83%9E%E3%83%BC%E3%83%80%E3%83%BC%E3%83%BB%E3%83%9F%E3%82%B9%E3%83%86%E3%83%AA%E3%83%BC%E3%83%BB%E3%83%8F%E3%82%A6%E3%82%B9%E3%81%AE%E6%AE%BA%E4%BA%BA+%E6%96%9C%E7%BA%BF%E5%A0%82%E6%9C%89%E7%BA%AA&newwindow=1&sxsrf=ALiCzsY22DCy0gy8dhM0p5w9_C_IdngQ8A%3A1668490859025&ei=ayZzY_WSAfXQ5NoP9POHkAc&ved=0ahUKEwi19NnnvK_7AhV1KFkFHfT5AXIQ4dUDCBA&uact=5&oq=%E3%82%A6%E3%82%A3%E3%83%B3%E3%83%81%E3%82%A7%E3%82%B9%E3%82%BF%E3%83%BC%E3%83%BB%E3%83%9E%E3%83%BC%E3%83%80%E3%83%BC%E3%83%BB%E3%83%9F%E3%82%B9%E3%83%86%E3%83%AA%E3%83%BC%E3%83%BB%E3%83%8F%E3%82%A6%E3%82%B9%E3%81%AE%E6%AE%BA%E4%BA%BA+%E6%96%9C%E7%BA%BF%E5%A0%82%E6%9C%89%E7%BA%AA&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIHCAAQHhCiBDIFCAAQogQyBQgAEKIEMgcIABAeEKIESgQIQRgBSgQIRhgAUL0QWMsbYOMiaANwAHgAgAGNBIgB4gSSAQUxLjUtMZgBAKABAcABAQ&sclient=gws-wiz-serp","urlHash":3220396777},"a26d9b01-771c-4089-a357-0d4546051bdc":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a26d9b01-771c-4089-a357-0d4546051bdc","title":"AK on X: \"Training Chain-of-Thought via Latent-Variable Inference paper page: https://t.co/8Bwb9I0CZr Large language models (LLMs) solve problems more accurately and interpretably when instructed to work out the answer step by step using a ``chain-of-thought'' (CoT) prompt. One can also… https://t.co/M1CVJgQDli\" / X","url":"https://twitter.com/_akhaliq/status/1732216845640311232","urlHash":2189720085},"a28cb657-7add-45f6-8d67-070a7dcbd382":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a28cb657-7add-45f6-8d67-070a7dcbd382","title":"twitter.com/HelloSurgeAI/status/1651948207025401857","url":"https://twitter.com/HelloSurgeAI/status/1651948207025401857","urlHash":2452183381},"a28f9d30-ae62-49be-abda-1d60e02e1dd6":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"a28f9d30-ae62-49be-abda-1d60e02e1dd6","title":"解析大模型中的Scaling Law","url":"https://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&mid=2247487446&idx=1&sn=afd917b8f4211a4ac1ce5833c352755b&exportkey=n_ChQIAhIQ2toiULtcS1Z7RCMKuIyW%2FxKWAgIE97dBBAEAAAAAAB85DFoKBSgAAAAOpnltbLcz9gKNyK89dVj0g63hGvhRpuBxsEW0NtRuZplVIVlQVRf5vEuzuSx1VUbTyqj6pWLtvdO%2BVjMqN8L6d6a%2FQdhL8IvkqAkgzwW9LiXxb6nG6rxL%2FDIBkVI1TPyoM2%2Bz1y4yJiL0ohQZkwc%2Fk3ARVE14RNzV3ilCEWfO24EvEfs9GpAULaSSQVcjoG7mQZLzctca8ktFpi4KIJ5%2BSL9T0HsuUr09aE3Y4AHg2q2FlZSWQmdNCQAxXPaZwtdKb%2B3J4kwSbJXYIwAxPtawzWkeSMKNZRJJfX0GnTE2N7wjaO7jhFa8Wkht%2FRe7SkBn5FoaE2TviVpD7783Bf3M&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsYOdT5fKbLXTzQ6Kvw8yT3IkH4oh4Xu%2BDM7CJdxbLYvjA%3D%3D&wx_header=0","urlHash":2727079114},"a296482f-ca31-45af-9a69-eedef2a0d4c8":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"a296482f-ca31-45af-9a69-eedef2a0d4c8","title":"Recognize Anything: A Strong Image Tagging Model | PDF","url":"https://arxiv.org/pdf/2306.03514.pdf","urlHash":4138041244},"a2a94d73-1917-48cb-9f8e-854bbc39b68e":{"favIconUrl":"fallback","id":"a2a94d73-1917-48cb-9f8e-854bbc39b68e","title":"Nirant on Twitter: \"1/ Amazing LLM Patterns blog! Strongly recommend making this your bedside read for tonight Want to mention LLM Request Hedging inspired by FrugalGPT, which gives more knobs to tune latency, quality and cost: Two main metrics: 1. Latency 2. Quality https://t.co/9dlssbUTkJ\" / X","url":"https://twitter.com/NirantK/status/1686640566199898112","urlHash":333930344},"a2b7e2fb-6a91-4909-850b-db9ccd967724":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a2b7e2fb-6a91-4909-850b-db9ccd967724","title":"Cameron R. Wolfe, Ph.D. on X: \"I just wrote a long-form overview of RLHF, its origins/motivation, and the impact it has had on the generative AI movement. My conclusion? RLHF is (arguably) the key advancement that made modern generative LLMs possible. Here’s why… TL;DR: Prior to RLHF, we primary relied upon… https://t.co/Pg8GIOz4fA\" / X","url":"https://twitter.com/cwolferesearch/status/1724486576992886985","urlHash":3336974741},"a2c0ffff-a97f-4507-9a51-c121e1584051":{"favIconUrl":"fallback","id":"a2c0ffff-a97f-4507-9a51-c121e1584051","title":"Contrastive Learning for Unpaired Image-to-Image Translation - Arxiv-2007.15651","url":"https://arxiv.org/abs/2007.15651","urlHash":1599524640},"a31c1794-def2-4b3a-91aa-8c041a64cff1":{"favIconUrl":"fallback","id":"a31c1794-def2-4b3a-91aa-8c041a64cff1","title":"kadirnar/segment-anything-video: MetaSeg: Packaged version of the Segment Anything repository","url":"https://github.com/kadirnar/segment-anything-video","urlHash":1871991178},"a334900c-9299-4d2f-97e4-c338c8ee6fe7":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"a334900c-9299-4d2f-97e4-c338c8ee6fe7","title":"Studying Large Language Model Generalization with Influence Functions | PDF","url":"https://arxiv.org/pdf/2308.03296.pdf","urlHash":2745370129},"a340038f-9869-4198-939c-e802ddd64c14":{"favIconUrl":"https://www.google.com/favicon.ico","id":"a340038f-9869-4198-939c-e802ddd64c14","title":"江户时代的趣味 - Google Search","url":"https://www.google.com/search?q=%E6%B1%9F%E6%88%B7%E6%97%B6%E4%BB%A3%E7%9A%84%E8%B6%A3%E5%91%B3&oq=%E6%B1%9F%E6%88%B7%E6%97%B6%E4%BB%A3%E7%9A%84%E8%B6%A3%E5%91%B3&aqs=chrome..69i57j0i546l2j69i60.149j0j1&sourceid=chrome&ie=UTF-8","urlHash":2651205745},"a3638a17-fc21-462b-8dd0-48851b54c4c6":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a3638a17-fc21-462b-8dd0-48851b54c4c6","title":"twitter.com/arankomatsuzaki/status/1724613041155608951","url":"https://twitter.com/arankomatsuzaki/status/1724613041155608951","urlHash":3041347348},"a369ac59-0aab-4454-a625-507314d3b065":{"favIconUrl":"fallback","id":"a369ac59-0aab-4454-a625-507314d3b065","title":"Interpretation of Neural Networks is Fragile - Arxiv-1710.10547","url":"https://arxiv.org/abs/1710.10547","urlHash":1345325784},"a373482e-23c1-447b-a881-09a612beaa45":{"favIconUrl":"fallback","id":"a373482e-23c1-447b-a881-09a612beaa45","title":"Retentive or Forgetful? Diving into the Knowledge Memorizing Mechanism of Language Models - Arxiv-2305.09144","url":"https://arxiv.org/abs/2305.09144","urlHash":947147219},"a39bcd95-d06b-442e-9b7e-d2083c7580af":{"favIconUrl":"fallback","id":"a39bcd95-d06b-442e-9b7e-d2083c7580af","title":"Contrastive Learning with Boosted Memorization - PMLR-2022-zhou22l","url":"https://proceedings.mlr.press/v162/zhou22l/zhou22l.pdf","urlHash":63852956},"a3ce4743-f584-49c0-a5f1-bcf36c53560f":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"a3ce4743-f584-49c0-a5f1-bcf36c53560f","title":"华盛顿大学撰文反驳微软，我们无法删除大模型关于哈利波特的记忆","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247579762&idx=1&sn=06daff955a08ea6d984914d876cc22de&chksm=970e90a4a07919b210bb1d17296a38ffaf6bc8bb399f36dd3bf922352140b62f6e3737f6ed47&mpshare=1&scene=1&srcid=040277GMszWNPE9CtBLJZ4rD&sharer_shareinfo=e915ed4462dce00ee772cecd2ca64994&sharer_shareinfo_first=e915ed4462dce00ee772cecd2ca64994&exportkey=n_ChQIAhIQUTI%2B5jBHyywjrhox5jLdrBKWAgIE97dBBAEAAAAAAPwxAYsdclEAAAAOpnltbLcz9gKNyK89dVj0YpBk6cy2UFGQRxM6jvXd%2BRwof91K9RL0Aa0iBG3dPsZgDIk2h4nbxqwrlhgCvEkLpCMxwubl%2BU37OZNCcB4VNGg8C1LK7jk5euxYlRXnMynxfajez8dZxwsfCq3ij8erouPeDafM24oDx4eZLLce9PENKpCGAIarLbIlVxc%2FHvRbDSScV6TbPEt6KfMb4nlSkej0pHODp6nIHfmUtMDTortoPwP8pZ16Mwp7oEmCb0A0Rn1V3xeIYt23EXXYwV6v%2B44Fbw7rOVW5qmDci4aINXDlyWaW1CQSXFraE3lrNezrMbdN9eD%2BWk%2FbfDhXy9BX&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCN6FMUEIsPoFN57lQ9KLbehD3hUxkw%2BTnMnMYLsd9f5bA%3D%3D&wx_header=0#rd","urlHash":1105676381},"a3e98adf-6241-483d-8cf3-e6f95ed20957":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a3e98adf-6241-483d-8cf3-e6f95ed20957","title":"Mckay Wrigley on X: \"This remains the highest signal-per-word page on the internet. https://t.co/jWIt6yXu1c https://t.co/V2kZXLcDxf\" / X","url":"https://twitter.com/mckaywrigley/status/1695152025234022533","urlHash":2581534729},"a3fbe785-d00d-41d7-b188-931fcf786095":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/badged-favicon-32x32.png","id":"a3fbe785-d00d-41d7-b188-931fcf786095","title":"(5) LLM Web-UI recommendations : LocalLLaMA","url":"https://www.reddit.com/r/LocalLLaMA/comments/1847qt6/llm_webui_recommendations/","urlHash":2524919543},"a44873d8-5c9b-4230-ab4d-1d2bdaf755ca":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"a44873d8-5c9b-4230-ab4d-1d2bdaf755ca","title":"通过提高提示多样性更高效地蒸馏LLM的数据","url":"https://mp.weixin.qq.com/s?__biz=MzkwMjUwNTg3OA==&mid=2247483980&idx=1&sn=0073d010582742a7c66ed18a1a30ac66&chksm=c0a536b5f7d2bfa39e46a7c3c7ffbae92a9b65df9b51cdb2ca9057ea49f1d90e5558a05b17ee&mpshare=1&scene=1&srcid=0813BN1pnaXvGaKcvwJ7FhlZ&sharer_sharetime=1691905109267&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQ0mVdMuDe0VJWfYNIgENkvRKWAgIE97dBBAEAAAAAABMEINYKj2IAAAAOpnltbLcz9gKNyK89dVj0lbSkCWdBE1Hmy3ljbvA2R1ZKrFNFYYk0wEiwbK26CCfhtgHfySWTSZ3zJAAwt6XglUEoET3Klz7NM2n7YXI0%2FJYpNj9vIcW8VH%2BGk22EGJHrO%2FMBLm%2FWKFWNE6RWbYWTiQcX%2BfSJKDuNMtGUmi0K48TA%2BROyRuZp8WLBVT4frNqTowilR0ALf%2FHwQE%2Bd%2FMjlHEXfqt4hhIpicap6ylk39mdxNIaJ498kuW%2Bcm3xI11N3FJzn%2F94fyEAZ4KRAVK1BGlHz42llcypncet2J2wPzj8WRgjesy5Vmk072wF%2FVIzFn6KXbeXVKmqqPF9f37sE&acctmode=0&pass_ticket=8AEXW%2B7%2BoGUtU6JcuK2UU0hRaBC7NMw3d6PhbKlvNf1999ZkVwdkCHtwBDQE5aAl&wx_header=0#rd","urlHash":1449073457},"a4593e73-66ce-4dd7-9cf1-44a0eaac042a":{"favIconUrl":"fallback","id":"a4593e73-66ce-4dd7-9cf1-44a0eaac042a","title":"Using Natural Language and Program Abstractions to Instill Human Inductive Biases in Machines - Arxiv-2205.11558","url":"https://arxiv.org/abs/2205.11558","urlHash":3938221492},"a46b39fd-3feb-40a3-8ed3-317367ff92e0":{"favIconUrl":"fallback","id":"a46b39fd-3feb-40a3-8ed3-317367ff92e0","title":"Think before you speak Training Language Models With Pause Tokens - Arxiv-2310.02226","url":"https://arxiv.org/abs/2310.02226?utm_source=substack&utm_medium=email","urlHash":1010983399},"a4758a5a-9ccc-4c08-9776-77695a27ec37":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a4758a5a-9ccc-4c08-9776-77695a27ec37","title":"Sumit on X: \"2D Matryoshka Sentence Embeddings Presents Two-dimensional Matryoshka Sentence Embedding, enabling flexible sentence embedding learning by making both embedding dimensions and model depths configurable to improve efficiency. 📝https://t.co/1v2PxeZUa2 👨🏽‍💻https://t.co/EoBEC9hCGK https://t.co/g5wnamMT1h\" / X","url":"https://twitter.com/_reachsumit/status/1760902388842729672","urlHash":2130907011},"a47dfcd4-8dee-4418-b65c-8de8dddf3a38":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"a47dfcd4-8dee-4418-b65c-8de8dddf3a38","title":"Interpretability at Scale: Identifying Causal Mechanisms in Alpaca | PDF","url":"https://arxiv.org/pdf/2305.08809.pdf","urlHash":2341941618},"a4d64de4-deaf-49ac-ba12-e1d3ff956614":{"favIconUrl":"fallback","id":"a4d64de4-deaf-49ac-ba12-e1d3ff956614","title":"A Theory on Adam Instability in Large-Scale Machine Learning","url":"https://arxiv.org/abs/2304.09871?ref=blog.salesforceairesearch.com","urlHash":1869738234},"a4e5a89e-eb40-406a-9d0f-32aa4c9debbe":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"a4e5a89e-eb40-406a-9d0f-32aa4c9debbe","title":"大漠奇闻录 (豆瓣)","url":"https://book.douban.com/subject/36029749/","urlHash":2697133519},"a4eb4e47-3952-46ca-be12-3b92e09a20d1":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a4eb4e47-3952-46ca-be12-3b92e09a20d1","title":"elvis on X: \"Redefining Retrieval in RAG A nice comprehensive study that focuses on the components needed to improve the retrieval component of a RAG system. Confirms that the position of relevant information should be placed near the query. The model will struggle to attend to the… https://t.co/zLouMdmXBy\" / X","url":"https://twitter.com/omarsar0/status/1751803310267314509?utm_source=substack&utm_medium=email","urlHash":2065859654},"a4fffbab-e80e-4afe-80d8-5228833d405b":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"a4fffbab-e80e-4afe-80d8-5228833d405b","title":"Decoupled Neural Interfaces using Synthetic Gradients | Abstract","url":"https://arxiv.org/abs/1608.05343","urlHash":3606948269},"a5236af8-787f-4621-8a1d-f587ccbdd8d2":{"favIconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","id":"a5236af8-787f-4621-8a1d-f587ccbdd8d2","title":"interpreting GPT: the logit lens — LessWrong","url":"https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens","urlHash":3167702473},"a547e615-2d43-4a00-bf06-51e4e9f0b664":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a547e615-2d43-4a00-bf06-51e4e9f0b664","title":"Jascha Sohl-Dickstein on X: \"Have you ever done a dense grid search over neural network hyperparameters? Like a *really dense* grid search? It looks like this (!!). Blueish colors correspond to hyperparameters for which training converges, redish colors to hyperparameters for which training diverges. https://t.co/yqJlschvVK\" / X","url":"https://twitter.com/jaschasd/status/1756930242965606582","urlHash":3559111250},"a55169be-da9c-47e8-a7f7-7d20f68616f6":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a55169be-da9c-47e8-a7f7-7d20f68616f6","title":"twitter.com/GregKamradt/status/1722386725635580292","url":"https://twitter.com/GregKamradt/status/1722386725635580292","urlHash":3275214376},"a55cce89-a344-46cc-aa5e-a6050e3277a4":{"favIconUrl":"fallback","id":"a55cce89-a344-46cc-aa5e-a6050e3277a4","title":"Francis Bach - INRIA - ENS - PSL","url":"https://www.di.ens.fr/~fbach/","urlHash":1170574821},"a565ffc1-c01b-40a8-a9e0-8bcb054d3004":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"a565ffc1-c01b-40a8-a9e0-8bcb054d3004","title":"Butterfly World (豆瓣)","url":"https://book.douban.com/subject/35468015/","urlHash":3432001505},"a5a32970-5fa9-4edd-b21c-ba3cd4f4f5e5":{"favIconUrl":"fallback","id":"a5a32970-5fa9-4edd-b21c-ba3cd4f4f5e5","title":"高效Transformer层出不穷，谷歌团队综述文章一网打尽 - 知乎","url":"https://zhuanlan.zhihu.com/p/259765593","urlHash":2236571285},"a5c7754b-0546-483d-b3b5-2e57bb686203":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"a5c7754b-0546-483d-b3b5-2e57bb686203","title":"Implicit Chain of Thought Reasoning via Knowledge Distillation | PDF","url":"https://arxiv.org/pdf/2311.01460.pdf","urlHash":721374352},"a5ccddd0-dd97-4bde-a1d4-788982062cdf":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"a5ccddd0-dd97-4bde-a1d4-788982062cdf","title":"(2) Rose @ EACL 🇲🇹 on X: \"Let's build a future where every question leads to deeper understanding…for both students and teachers! 💡 Big thanks to @arankomatsuzaki for featuring our Backtracing work!! 🙏 https://t.co/kj4Qf3611E\" / X","url":"https://twitter.com/rose_e_wang/status/1765777234546298927","urlHash":2836217393},"a5dfa9ef-35f8-4aae-9a8b-78a600dfb427":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"a5dfa9ef-35f8-4aae-9a8b-78a600dfb427","title":"语言模型悄悄偷懒？新研究：​上下文太长，模型会略过中间不看","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650885029&idx=4&sn=ac01576a8957b41529dd3c877d262d5e&exportkey=n_ChQIAhIQWGIQvkew6OhM%2B5NEOgWPMRKWAgIE97dBBAEAAAAAAEX0ALxP2VoAAAAOpnltbLcz9gKNyK89dVj0fF20ckT%2FICHYBBzwC68OTReY%2BWgdLrb0FO%2BjgzSI8mJUoMxep0AiVqatdsSXxo5iZufAs736cAzKhVfIdGriVA7o%2FEfJwp5bkjHJNbfTfKiHSARuU0kL0zxt1%2FDhcN6VaMZZaJkaElZTV%2FeQGaCF2G0Gx7sOacppLNbzj0%2BWjMqpyCXTaFgF7rCBd1i%2F4xmYrOX8jFd9bvUBjslu%2F2WbyP17lS0TxV3EFTqnbqpq3okH%2B3wLrSpkz3EIgTZhdaDQRmx%2BVvgvIOftpfd%2Fvrwo%2Fajq4BOuNfCdrN4z5qhUnI1b0pae5%2F9%2FZvZOQJ9qwq9J&acctmode=0&pass_ticket=p7NjDRrZOunE7hCfSO44XSUcmvxnSKuyzEO6xNI%2F96Dd%2BlcNMtIj1iVeIN7KQM43&wx_header=0","urlHash":4112195240},"a6474aa7-35b4-451e-88fd-e9e32911ff5b":{"favIconUrl":"https://blog.langchain.dev/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png","id":"a6474aa7-35b4-451e-88fd-e9e32911ff5b","title":"Reflection Agents","url":"https://blog.langchain.dev/reflection-agents/","urlHash":3897701907},"a65d5a9c-b936-460b-a03c-cc2d0601cb4c":{"favIconUrl":"fallback","id":"a65d5a9c-b936-460b-a03c-cc2d0601cb4c","title":"Adversarial Examples Are Not Bugs, They Are Features - Arxiv-1905.02175","url":"https://arxiv.org/abs/1905.02175","urlHash":4191327968},"a680346f-b20b-4d23-8ec4-de9ae1ec953a":{"favIconUrl":"fallback","id":"a680346f-b20b-4d23-8ec4-de9ae1ec953a","title":"Understanding RL Vision","url":"https://distill.pub/2020/understanding-rl-vision/","urlHash":1125556853},"a68b9d7c-6291-4de9-b985-ff5c53cc3645":{"favIconUrl":"fallback","id":"a68b9d7c-6291-4de9-b985-ff5c53cc3645","title":"tuero/perturbations-differential-pytorch: Differentiable Optimizers with Perturbations in Pytorch","url":"https://github.com/tuero/perturbations-differential-pytorch","urlHash":4244404098},"a69c4b3c-0514-47d5-9520-672a8dbfbad3":{"favIconUrl":"fallback","id":"a69c4b3c-0514-47d5-9520-672a8dbfbad3","title":"DPOK Reinforcement Learning for Fine-tuning Text-to-Image Diffusion Models - Arxiv-2305.16381","url":"https://arxiv.org/pdf/2305.16381.pdf","urlHash":1237944286},"a6b80d23-d592-4995-bbef-40e50cc3c902":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"a6b80d23-d592-4995-bbef-40e50cc3c902","title":"Peter J. Liu on X: \"interesting paper on arxiv posted recently \"Arrows of Time for Large Language Models\" https://t.co/QJbp23jqUe TL;DR: it is easier for larger models to predict in forward direction (next-token), rather than backward (prev-token). The larger the model, the more pronounced the…\" / X","url":"https://twitter.com/peterjliu/status/1757126668374970736","urlHash":2346557520},"a6d708b7-4d20-4e85-902f-22efb5f35de2":{"favIconUrl":"fallback","id":"a6d708b7-4d20-4e85-902f-22efb5f35de2","title":"Red Teaming Language Models with Language Models - Arxiv-2202.03286","url":"https://arxiv.org/abs/2202.03286","urlHash":973471561},"a6daf6af-d98a-4e7d-94d1-9cadb26239dd":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"a6daf6af-d98a-4e7d-94d1-9cadb26239dd","title":"When and why vision-language models behave like bags-of-words, and what to do about it? | Abstract","url":"https://arxiv.org/abs/2210.01936","urlHash":2174935954},"a6e3b00a-bdc7-40dc-a0f4-5e1d84bdda18":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"a6e3b00a-bdc7-40dc-a0f4-5e1d84bdda18","title":"Bring Your Own Data! Self-Supervised Evaluation for Large Language Models | Abstract","url":"https://arxiv.org/abs/2306.13651","urlHash":750799092},"a6e50119-952a-44f5-9e22-e1e2442969ad":{"favIconUrl":"fallback","id":"a6e50119-952a-44f5-9e22-e1e2442969ad","title":"Diffusion Policy - Generative modelling of robotic control trajectories","url":"https://cdn-uploads.piazza.com/paste/lm5975m520u5jg/4028fccee5657c6491b9cec9ab744634a7784ee1de26d6f0ef6e0cf39626addf/Diffusion_Policy_Presentation.pdf","urlHash":3282149491},"a6fd65a8-3697-4ce9-b106-e626eccf2e7d":{"favIconUrl":"fallback","id":"a6fd65a8-3697-4ce9-b106-e626eccf2e7d","title":"eriklindernoren/PyTorch-GAN: PyTorch implementations of Generative Adversarial Networks.","url":"https://github.com/eriklindernoren/PyTorch-GAN","urlHash":429221091},"a71f25a3-19e9-4637-8cc7-f3d38a3dd308":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"a71f25a3-19e9-4637-8cc7-f3d38a3dd308","title":"Theoretical Limitations of Self-Attention in Neural Sequence Models | PDF","url":"https://arxiv.org/pdf/1906.06755.pdf","urlHash":1097716830},"a75a4f5d-f300-4614-841d-6eddcd502370":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a75a4f5d-f300-4614-841d-6eddcd502370","title":"AK on X: \"Reformatted Alignment The quality of finetuning data is crucial for aligning large language models (LLMs) with human values. Current methods to improve data quality are either labor-intensive or prone to factual errors caused by LLM hallucinations. This paper explores elevating… https://t.co/lbjWpMTOMB\" / X","url":"https://twitter.com/_akhaliq/status/1759821621676724441","urlHash":3778071445},"a767782d-7765-43a7-be5b-99248b2b60ee":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"a767782d-7765-43a7-be5b-99248b2b60ee","title":"Evaluation and Analysis of Hallucination in Large Vision-Language Models | Abstract","url":"https://arxiv.org/abs/2308.15126","urlHash":876160341},"a785441f-79ab-4d5d-8af0-77f91fd5ab06":{"favIconUrl":"fallback","id":"a785441f-79ab-4d5d-8af0-77f91fd5ab06","title":"Training Language Models with Language Feedback | PDF","url":"https://arxiv.org/pdf/2204.14146.pdf","urlHash":4052786358},"a7922bfe-f3de-4ec4-9501-f7763cf54512":{"favIconUrl":"https://www.google.com/favicon.ico","id":"a7922bfe-f3de-4ec4-9501-f7763cf54512","title":"沉睡的名侦探与雷电密室 - Google Search","url":"https://www.google.com/search?q=%E6%B2%89%E7%9D%A1%E7%9A%84%E5%90%8D%E4%BE%A6%E6%8E%A2%E4%B8%8E%E9%9B%B7%E7%94%B5%E5%AF%86%E5%AE%A4","urlHash":3207890073},"a7ba7be9-1dd1-496c-8b28-33297276759e":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"a7ba7be9-1dd1-496c-8b28-33297276759e","title":"OpenAI新模型用的嵌入技术被网友扒出来了","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650905836&idx=1&sn=e13c53b34118e58bafd05c48d8cb0772&chksm=84e45892b393d1840dc871792ed65968487ae153ef943aec8024a2ec71966e7938c9331c06a9&mpshare=1&scene=1&srcid=0128ASFx3Bry9rp5UoY3dLQl&sharer_shareinfo=5c2a97120e94d51bc981b9396c94c312&sharer_shareinfo_first=5c2a97120e94d51bc981b9396c94c312&exportkey=n_ChQIAhIQcR7Sx2GnjIc6wzPHcfbxoxKWAgIE97dBBAEAAAAAAE1CKv3nHBUAAAAOpnltbLcz9gKNyK89dVj090Sc4haKjRQw90WsuYupCXo0SkHywAlk5HGeT39YzVY6NCCV5b8SLd3v72sHjaD5O9Qf0RVpk3VBRjDnlN%2F4vBAl%2F5fqvDu51ktTWhO8KAusidDMCjS4eHY9O3uLQB5R5Sn35l4qJQoaJ2We%2Bny3RGFKssQtHEpQHDjwPvaKf04PUBRdhCDftAV1jXvju59DPNtJZgRHrGAFR5SeGX7s4oRmGOI8mvXRiRCDlshtBhm89FanOd4tERulexG0qH%2FqFAxLRtCeujWjSWIdVkgJ%2BzS3mTsP93pkTQf4rwLpGQFYZOyO3WRoBPQf1EGEL9NY&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HPkkfn1P0QqnTJzsemJ9S%2F549PJT1g6D2gMuBPe05tFrg%3D%3D&wx_header=0#rd","urlHash":39743790},"a7c7ec30-9976-4d65-936f-fb5c3b6586e1":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"a7c7ec30-9976-4d65-936f-fb5c3b6586e1","title":"停在三樓 (豆瓣)","url":"https://book.douban.com/subject/26720073/","urlHash":2837302487},"a7cfa601-9c98-4385-969a-4d3c237f376e":{"favIconUrl":"https://www.google.com/favicon.ico","id":"a7cfa601-9c98-4385-969a-4d3c237f376e","title":"没有房屋的街道 - Google Search","url":"https://www.google.com/search?q=%E6%B2%A1%E6%9C%89%E6%88%BF%E5%B1%8B%E7%9A%84%E8%A1%97%E9%81%93","urlHash":2812839986},"a7d6b3d8-4e7b-487d-9a78-a88828600bd5":{"favIconUrl":"fallback","id":"a7d6b3d8-4e7b-487d-9a78-a88828600bd5","title":"thunlp/PromptPapers: Must-read papers on prompt-based tuning for pre-trained language models.","url":"https://github.com/thunlp/PromptPapers","urlHash":2124549074},"a7d935c1-a556-4d6e-90d3-ec3484295423":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"a7d935c1-a556-4d6e-90d3-ec3484295423","title":"On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving | Abstract","url":"https://arxiv.org/abs/2311.05332?utm_source=substack&utm_medium=email","urlHash":960211338},"a7f86832-b0ad-43f2-8d21-4983f571b769":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"a7f86832-b0ad-43f2-8d21-4983f571b769","title":"Language models show human-like content effects on reasoning tasks | Abstract","url":"https://arxiv.org/abs/2207.07051","urlHash":4001228208},"a8017712-ac61-4cce-9996-499bedfa2fac":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"a8017712-ac61-4cce-9996-499bedfa2fac","title":"死在南方 (豆瓣)","url":"https://book.douban.com/subject/1966505/","urlHash":1282581055},"a80a8c64-36f5-48bc-bb86-26e93178f55b":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"a80a8c64-36f5-48bc-bb86-26e93178f55b","title":"重磅！OpenAI被“Open”！GPT-4可复制！","url":"https://mp.weixin.qq.com/s?__biz=MzIwNDA0NTczNA==&mid=2735222232&idx=1&sn=93f840143f154364d88ccb0bf81ed8c7&exportkey=n_ChQIAhIQWasUcs9DEPSMpvIltdqahxKWAgIE97dBBAEAAAAAALJOCXcmGlQAAAAOpnltbLcz9gKNyK89dVj0Zrpj3jz2PiMdu%2Bs7w69EqXFBj0KAvUSDMlANRyZ%2BkO4GcN0fEDjJJvX2mCMyeL08RtY84KaDTRQA1skGIqvPVSOQ9sC8HsP%2BqyGsf850DJlMeMD%2FzNolRdUjkuQYA%2FAefLYglQH8r3o3hN2kEczYZgIWcf2b8yGd2IXcp%2FWNh9I8rtsW1%2FhBGbRLqvsJTZehY4tdopmRAg2Cvl9q6dBz7kn5ZZuVMx%2B%2BqJTw%2Bgsd7yC5sWLYv3Ivd5eBhJFwWYqSmD2Fyc56i3mvWDleA7r2AKdhvXh8QmJOoGwCyvJeJpM3wMtlcDUM9uj9jXDPuWro&acctmode=0&pass_ticket=omk3BMLlbIfKU9ic0Ej%2FzA4T8sn%2BydzhN4jkmY8YO2NUlBverz6TsP8mqU5QMNc2&wx_header=0","urlHash":1044905518},"a822113a-6bf5-4740-ab1b-0acc338ece77":{"favIconUrl":"https://ssl.gstatic.com/colaboratory-static/common/36baee5adf8280432ec6933ecf0d0196/img/favicon.ico","id":"a822113a-6bf5-4740-ab1b-0acc338ece77","title":"puzzles.ipynb - Colaboratory","url":"https://colab.research.google.com/github/srush/LLM-Training-Puzzles/blob/main/puzzles.ipynb#scrollTo=cc24dadb","urlHash":978099025},"a8365043-17d1-4bd0-9e54-71668c6f2bf4":{"favIconUrl":"fallback","id":"a8365043-17d1-4bd0-9e54-71668c6f2bf4","title":"Differentiable Image Parameterizations","url":"https://distill.pub/2018/differentiable-parameterizations/","urlHash":426505312},"a86ba149-556b-4420-b9d5-96e75e46431b":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"a86ba149-556b-4420-b9d5-96e75e46431b","title":"六藏图 (豆瓣)","url":"https://book.douban.com/subject/35687505/","urlHash":1077448226},"a873cc97-d50f-48f7-b47e-6052ad537745":{"favIconUrl":"fallback","id":"a873cc97-d50f-48f7-b47e-6052ad537745","title":"Diffusion Self-Guidance for Controllable Image Generation - Arxiv-2306.00986","url":"https://arxiv.org/pdf/2306.00986.pdf","urlHash":1614930486},"a88dea16-e21a-4634-a8d1-2641911ed34c":{"favIconUrl":"fallback","id":"a88dea16-e21a-4634-a8d1-2641911ed34c","title":"Towards Training GNNs using Explanation Directed Message Passing","url":"https://arxiv.org/pdf/2211.16731.pdf","urlHash":657236656},"a8902c80-7ea2-4c3d-ae02-f206010ba9c2":{"favIconUrl":"fallback","id":"a8902c80-7ea2-4c3d-ae02-f206010ba9c2","title":"(24 封私信 / 81 条消息) 如何评价2020年4月23日Netflix原创动画《攻壳机动队SAC_2045》？ - 知乎","url":"https://www.zhihu.com/question/305055900/answer/1177727168","urlHash":2358361830},"a8cb5e65-63b3-4633-b134-7266d7366022":{"favIconUrl":"fallback","id":"a8cb5e65-63b3-4633-b134-7266d7366022","title":"读《Neural Turing Machines》 - 知乎","url":"https://zhuanlan.zhihu.com/p/22513016","urlHash":770511944},"a8d7f2c8-9849-4009-b325-a3b0c5c317dc":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a8d7f2c8-9849-4009-b325-a3b0c5c317dc","title":"Boshi Wang on X: \"Are LLMs reasoning based on deep understandings of truth and logic? Can LLMs hold &amp; defend their own \"reasoning\"? Our #EMNLP23 findings paper (https://t.co/tlwsGODZry) explores testing LLMs' reasoning by engaging them in a debate that probes deeper into their understanding. https://t.co/J60Kdd1tQt\" / X","url":"https://twitter.com/BoshiWang2/status/1712278857653375246","urlHash":674516165},"a907d362-0b8b-47d4-95b7-0e0d324d4cf7":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a907d362-0b8b-47d4-95b7-0e0d324d4cf7","title":"Caiming Xiong on X: \"We present 🧩Retroformer🧩, iteratively improving LLM agents by learning a plug-in retrospective model, that through the process of policy gradient optimization, automatically refines the prompts with env-specific rewards. arXiv: https://t.co/zITi65Z14q #LanguageAgents #LLM https://t.co/efDrAmb3Br\" / X","url":"https://twitter.com/CaimingXiong/status/1688978047192776704","urlHash":2030141447},"a9107bd4-82e4-499f-84c6-3371d673b865":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"a9107bd4-82e4-499f-84c6-3371d673b865","title":"Scott Niekum on X: \"What if RLHF is making the wrong assumptions about what human preferences mean? Our new paper explores the consequences of assuming that preferences are driven by reward if they are instead primarily driven by regret (as established in our prior work). https://t.co/UWaFtjvYp3 1/3\" / X","url":"https://twitter.com/scottniekum/status/1710094508073828424","urlHash":4228436433},"a9125c6f-7855-451b-a107-bd52bbd2bc10":{"favIconUrl":"https://openreview.net/favicon.ico","id":"a9125c6f-7855-451b-a107-bd52bbd2bc10","title":"Associative Memories with Heavy-Tailed Data | OpenReview","url":"https://openreview.net/forum?id=hyPoaUJwXI","urlHash":3839034312},"a9187d46-90e5-4f40-8175-7e27aecc3ae5":{"favIconUrl":"fallback","id":"a9187d46-90e5-4f40-8175-7e27aecc3ae5","title":"Geometric foundations of Deep Learning","url":"https://towardsdatascience.com/geometric-foundations-of-deep-learning-94cdd45b451d","urlHash":2705031741},"a9312f34-16a2-44d5-909b-52eaae8ac9fd":{"favIconUrl":"fallback","id":"a9312f34-16a2-44d5-909b-52eaae8ac9fd","title":"Consistency Models - Arxiv-2303.01469","url":"https://arxiv.org/pdf/2303.01469.pdf","urlHash":2455152519},"a945a253-1611-42e8-bb79-29a6aac9e32b":{"favIconUrl":"fallback","id":"a945a253-1611-42e8-bb79-29a6aac9e32b","title":"certified defense for data poisioning attacks - Google Search","url":"https://www.google.com/search?q=certified+defense+for+data+poisioning+attacks&newwindow=1&sxsrf=ALiCzsZAvWLMkcNthxxT8acwMJQiWs7QoQ%3A1672965002579&ei=imu3Y77pIvuk5NoPkPWWuAo&ved=0ahUKEwi-1syl2LH8AhV7ElkFHZC6BacQ4dUDCBA&uact=5&oq=certified+defense+for+data+poisioning+attacks&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIGCAAQFhAeMgUIABCGAzIFCAAQhgMyBQgAEIYDMgUIABCGAzoKCAAQRxDWBBCwAzoECCMQJzoFCAAQgAQ6BQgAEKIEOgcIABAeEKIEOgUIIRCgAToFCCEQqwI6CAghEBYQHhAdOgoIIRAWEB4QDxAdOgcIIRCgARAKSgQIQRgASgQIRhgAUIADWNIxYJ0yaAFwAXgBgAGaAYgB1h2SAQUxMS4yNJgBAKABAcgBCMABAQ&sclient=gws-wiz-serp","urlHash":1466941263},"a9492998-1efa-4e6f-9263-42a716327f77":{"favIconUrl":"fallback","id":"a9492998-1efa-4e6f-9263-42a716327f77","title":"Imagic Text-Based Real Image Editing with Diffusion Models - Arxiv-2210.09276","url":"https://arxiv.org/abs/2210.09276","urlHash":213861162},"a949d948-ac0c-44c8-887a-f1cdff91e47a":{"favIconUrl":"fallback","id":"a949d948-ac0c-44c8-887a-f1cdff91e47a","title":"Symbolic Knowledge Distillation from General Language Models to Commonsense Models - Arxiv-2110.07178","url":"https://arxiv.org/pdf/2110.07178.pdf","urlHash":653228948},"a94efbac-494a-4d53-9e61-5b98293b117c":{"favIconUrl":"fallback","id":"a94efbac-494a-4d53-9e61-5b98293b117c","title":"yoonholee/DivDis","url":"https://github.com/yoonholee/DivDis","urlHash":1794210479},"a9593d2d-bc25-4df9-8437-ac0c295af358":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"a9593d2d-bc25-4df9-8437-ac0c295af358","title":"homanp/superagent: 🥷 Run AI-agents with an API","url":"https://github.com/homanp/superagent","urlHash":1093566252},"a9c10b94-9d29-4739-9bc6-a14c7ad19d52":{"favIconUrl":"fallback","id":"a9c10b94-9d29-4739-9bc6-a14c7ad19d52","title":"小镇奇谈-七月-微信读书","url":"https://weread.qq.com/web/reader/ed7320e0726cbfe4ed746c2?","urlHash":1097788671},"a9c83c85-8b71-4474-8fee-f71357bcd323":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"a9c83c85-8b71-4474-8fee-f71357bcd323","title":"DiffVL: Scaling Up Soft Body Manipulation using Vision-Language Driven Differentiable Physics | PDF","url":"https://arxiv.org/pdf/2312.06408.pdf","urlHash":842783883},"a9cf9fbd-9b76-4852-9733-010ebb1ca332":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"a9cf9fbd-9b76-4852-9733-010ebb1ca332","title":"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond | PDF","url":"https://arxiv.org/pdf/2304.13712.pdf","urlHash":37257546},"aa03c19e-0360-4f65-a135-6ea92cc65e66":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"aa03c19e-0360-4f65-a135-6ea92cc65e66","title":"200 Concrete Open Problems in Mechanistic Interpretability: Introduction — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/LbrPTJ4fmABEdEnLf/200-concrete-open-problems-in-mechanistic-interpretability#Overview_of_Sequence","urlHash":3627818305},"aa1dfa7b-c95c-40ea-86dc-8c53a9ebcec5":{"favIconUrl":"https://underline.io/favicon/favicon.ico","id":"aa1dfa7b-c95c-40ea-86dc-8c53a9ebcec5","title":"Underline | On the Blind Spots of Model-Based Evaluation Metrics for Text Generation","url":"https://underline.io/events/395/sessions/15275/lecture/76183-on-the-blind-spots-of-model-based-evaluation-metrics-for-text-generation","urlHash":2311088719},"aa39fe89-065e-45bc-9556-f18f0209ec7b":{"favIconUrl":"fallback","id":"aa39fe89-065e-45bc-9556-f18f0209ec7b","title":"Early-Learning Regularization Prevents Memorization of Noisy Labels","url":"https://arxiv.org/abs/2007.00151","urlHash":1478497634},"aa3aaee9-51f1-4f0c-b35e-0c911878f350":{"favIconUrl":"fallback","id":"aa3aaee9-51f1-4f0c-b35e-0c911878f350","title":"(1) Aran Komatsuzaki on X: \"LLaVA-RLHF: Aligning Large Multimodal Models with Factually Augmented RLHF A novel aligned end-to-end trained large multimodal model that combines a CLIP and Vicuna for general-purpose visual and language understanding https://t.co/BHkMAT0Ksl https://t.co/spRn7E2MJA\" / X","url":"https://twitter.com/arankomatsuzaki/status/1706839311306621182","urlHash":2590181992},"aa46c1bd-922f-400e-97c2-dcb40836133a":{"favIconUrl":"fallback","id":"aa46c1bd-922f-400e-97c2-dcb40836133a","title":"CoNAL Anticipating Outliers with Large Language Models - Arxiv-2211.15718","url":"https://arxiv.org/pdf/2211.15718.pdf","urlHash":807695921},"aa63ebb6-e3e3-4825-921f-c7aedbeff444":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"aa63ebb6-e3e3-4825-921f-c7aedbeff444","title":"RUCAIBox/POPE: The official GitHub page for ''Evaluating Object Hallucination in Large Vision-Language Models''","url":"https://github.com/RUCAIBox/POPE","urlHash":511564083},"aab7d139-dee6-40cb-b9c8-c346ed8ec3bf":{"favIconUrl":"https://proceedings.mlr.press/v80/assets/images/favicon-pmlr.ico","id":"aab7d139-dee6-40cb-b9c8-c346ed8ec3bf","title":"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples","url":"https://proceedings.mlr.press/v80/athalye18a.html","urlHash":235976735},"aaf29799-5e50-435b-925b-fd1eebd5d52f":{"favIconUrl":"fallback","id":"aaf29799-5e50-435b-925b-fd1eebd5d52f","title":"LAMBADA Backward Chaining for Automated Reasoning in Natural Language - Arxiv-2212.13894","url":"https://arxiv.org/abs/2212.13894","urlHash":3189450112},"ab0e9932-7bcc-4f3e-8cd9-1c09d8a7c406":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"ab0e9932-7bcc-4f3e-8cd9-1c09d8a7c406","title":"Seeking Interns/RAs for Mechanistic Interpretability Projects — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/Kx9K7tLFf8rxcnNLT/seeking-interns-ras-for-mechanistic-interpretability","urlHash":2902869045},"ab451035-d6b4-4514-ab14-6eec2a8cbc0c":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"ab451035-d6b4-4514-ab14-6eec2a8cbc0c","title":"Bin Lin on X: \"🌋MoE-LLaVA with just 3B activated parameters outperforms the LLaVA-1.5-7B on an average of 9 benchmarks, and the 2.2B version even surpasses the LLaVA-1.5-13B in object hallucination benchmark. 🤗We have open-sourced all data, code, and models. Code: https://t.co/0il56m57qp\" / X","url":"https://twitter.com/LinBin46984/status/1753403875531375003?utm_source=substack&utm_medium=email","urlHash":3979875782},"ab717e4e-85f5-495d-a21a-818ba7242dc9":{"favIconUrl":"fallback","id":"ab717e4e-85f5-495d-a21a-818ba7242dc9","title":"ChatAug Leveraging ChatGPT for Text Data Augmentation - Arxiv-2302.13007","url":"https://arxiv.org/pdf/2302.13007.pdf","urlHash":1241825578},"ab8d2e6f-22d0-4ef6-82a2-cf4cc5d0f64b":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"ab8d2e6f-22d0-4ef6-82a2-cf4cc5d0f64b","title":"On the Adversarial Robustness of Multi-Modal Foundation Models | Abstract","url":"https://arxiv.org/abs/2308.10741","urlHash":242660182},"abad647d-c43c-4c5b-aa83-ce9d49e8ef1c":{"favIconUrl":"fallback","id":"abad647d-c43c-4c5b-aa83-ce9d49e8ef1c","title":"diffusion instance segmentation - Google Search","url":"https://www.google.com/search?q=diffusion+instance+segmentation&oq=diffusion+instance+segmentation&aqs=chrome..69i57j0i22i30j0i390l4.10158j0j1&sourceid=chrome&ie=UTF-8","urlHash":1190432225},"abb3e490-cb85-4dc0-b2ca-9c2707c6aeba":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"abb3e490-cb85-4dc0-b2ca-9c2707c6aeba","title":"twitter.com/_jasonwei/status/1693688114626052410","url":"https://twitter.com/_jasonwei/status/1693688114626052410","urlHash":3490967432},"abcce4e4-905c-4a7d-9840-573804cb0137":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"abcce4e4-905c-4a7d-9840-573804cb0137","title":"Retrieval meets Long Context Large Language Models | PDF","url":"https://arxiv.org/pdf/2310.03025.pdf","urlHash":1716759825},"abf5b369-3a1d-493e-a027-6bd57aea8572":{"favIconUrl":"fallback","id":"abf5b369-3a1d-493e-a027-6bd57aea8572","title":"JonasGeiping/breaching: Breaching privacy in federated learning scenarios for vision and text","url":"https://github.com/JonasGeiping/breaching","urlHash":3974010820},"ac0831cb-a479-4f90-9e89-9d3c31b5390d":{"favIconUrl":"https://scholar.google.com/favicon.ico","id":"ac0831cb-a479-4f90-9e89-9d3c31b5390d","title":"‪Somesh Jha‬ - ‪Google Scholar‬","url":"https://scholar.google.com/citations?hl=en&user=BaI7l8QAAAAJ&view_op=list_works&sortby=pubdate","urlHash":166894526},"ac0af513-4341-41d8-986f-779060d4d052":{"favIconUrl":"fallback","id":"ac0af513-4341-41d8-986f-779060d4d052","title":"MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model","url":"https://showlab.github.io/magicanimate/","urlHash":52861902},"ac28ff87-1923-4a12-a502-27d613ee705f":{"favIconUrl":"fallback","id":"ac28ff87-1923-4a12-a502-27d613ee705f","title":"Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks - Arxiv-2203.03929","url":"https://arxiv.org/pdf/2203.03929.pdf","urlHash":3799351367},"ac34802d-c1b8-40f2-a672-0af255881913":{"favIconUrl":"fallback","id":"ac34802d-c1b8-40f2-a672-0af255881913","title":"Eric Jang: Normalizing Flows Tutorial, Part 1: Distributions and Determinants","url":"https://blog.evjang.com/2018/01/nf1.html","urlHash":2211460097},"ac4d2713-74d6-42aa-b231-f6b5b1b06423":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"ac4d2713-74d6-42aa-b231-f6b5b1b06423","title":"TariqAHassan/S4Torch: PyTorch implementation of Structured State Space for Sequence Modeling (S4), based on Annotated S4.","url":"https://github.com/TariqAHassan/S4Torch?tab=readme-ov-file","urlHash":2301553712},"ac4fb169-1d96-49a4-a92d-85da9ebb6333":{"favIconUrl":"fallback","id":"ac4fb169-1d96-49a4-a92d-85da9ebb6333","title":"A Closer Look at Large Language Models Emergent Abilities","url":"https://yaofu.notion.site/A-Closer-Look-at-Large-Language-Models-Emergent-Abilities-493876b55df5479d80686f68a1abd72f","urlHash":3442828805},"ac695dda-7d8e-4e8b-851f-3cca9a64e842":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"ac695dda-7d8e-4e8b-851f-3cca9a64e842","title":"Learning to summarize from human feedback | PDF","url":"https://arxiv.org/pdf/2009.01325.pdf","urlHash":2410270316},"ac6b7cdc-26b5-4e36-8742-4afd309ca4c9":{"favIconUrl":"fallback","id":"ac6b7cdc-26b5-4e36-8742-4afd309ca4c9","title":"The Soteriological Machine (Reading Benjamin’s Theses I & II) – The Wasted World","url":"https://thewastedworld.com/2023/02/11/reading-benjamins-theses-p1/","urlHash":1202891296},"ac8fd655-8f3e-42ba-a891-0d958171b67b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"ac8fd655-8f3e-42ba-a891-0d958171b67b","title":"Yizhong Wang on X: \"🦙🐪🐫 So many instruction tuning datasets came out recently! How valuable are they, and how far are open models really from proprietary ones like ChatGPT? 🧐We did a systematic exploration, and built Tülu---a suite of LLaMa-tuned models up to 65B! 📜https://t.co/cFE2JUD6Zc https://t.co/WfIfVntqex\" / X","url":"https://twitter.com/yizhongwyz/status/1667171231278219267","urlHash":1881952299},"ac91febd-0327-4d2a-9c03-1061b8f46859":{"favIconUrl":"https://scholar.google.com/favicon.ico","id":"ac91febd-0327-4d2a-9c03-1061b8f46859","title":"Analyzing commonsense emergence in few-shot knowledge... - Google Scholar","url":"https://scholar.google.com/scholar?q=%20Analyzing%20commonsense%20emergence%20in%20few-shot%20knowledge%20models","urlHash":2492117470},"acc5e3c3-9b4f-4280-8f62-39c78ec35d3b":{"favIconUrl":"fallback","id":"acc5e3c3-9b4f-4280-8f62-39c78ec35d3b","title":"[1706.03691] Certified Defenses for Data Poisoning Attacks","url":"https://arxiv.org/abs/1706.03691","urlHash":3366462216},"acc607c5-98c9-4b99-8884-6aea1d309498":{"favIconUrl":"fallback","id":"acc607c5-98c9-4b99-8884-6aea1d309498","title":"Truly Batch Apprenticeship Learning with Deep Successor Features - Arxiv-1903.10077","url":"https://arxiv.org/pdf/1903.10077.pdf","urlHash":3701903559},"acd9ceb8-7d71-49ad-b5fe-14f8b0487431":{"favIconUrl":"fallback","id":"acd9ceb8-7d71-49ad-b5fe-14f8b0487431","title":"美国讲稿笔记-序言 - 知乎","url":"https://zhuanlan.zhihu.com/p/159241206","urlHash":170496099},"acde1aad-53f3-40e1-ab94-527b038abc98":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"acde1aad-53f3-40e1-ab94-527b038abc98","title":"H$_2$O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models | PDF","url":"https://arxiv.org/pdf/2306.14048.pdf","urlHash":2364666983},"acf9c0b7-23bc-466a-bee6-18ef04d5dc97":{"favIconUrl":"https://www.52shuku.vip/favicon.ico","id":"acf9c0b7-23bc-466a-bee6-18ef04d5dc97","title":"盲人与狗_水天一色【完结】在线阅读_52书库","url":"https://www.52shuku.vip/tuili/hsv.html","urlHash":1399349625},"ad381fbf-da02-4b09-8619-76108c7f9639":{"favIconUrl":"https://huggingface.co/favicon.ico","id":"ad381fbf-da02-4b09-8619-76108c7f9639","title":"Paper page - Bytes Are All You Need: Transformers Operating Directly On File Bytes","url":"https://huggingface.co/papers/2306.00238","urlHash":1279941635},"ad3c19c9-20ce-4772-8579-7a10b3df7c4f":{"favIconUrl":"fallback","id":"ad3c19c9-20ce-4772-8579-7a10b3df7c4f","title":"An Examination of the Compositionality of Large Generative Vision-Language Models - Arxiv-2308.10509","url":"https://arxiv.org/abs/2308.10509","urlHash":1806881057},"ad794b68-13df-44b4-804a-c880a94f3b27":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"ad794b68-13df-44b4-804a-c880a94f3b27","title":"AK on X: \"MoE-LLaVA Mixture of Experts for Large Vision-Language Models demo: https://t.co/fyflRntRE5 paper page: https://t.co/zRfcL1oP0s with just 3 billion sparsely activated parameters, MoE-LLaVA demonstrates performance comparable to the LLaVA-1.5-7B on various visual understanding… https://t.co/Q93onJDVA5\" / X","url":"https://twitter.com/_akhaliq/status/1752170730907680862","urlHash":1665065609},"ad7e455a-5fe5-437e-a9e9-6aed66d985ea":{"favIconUrl":"https://www.youtube.com/s/desktop/9844cff5/img/favicon_32x32.png","id":"ad7e455a-5fe5-437e-a9e9-6aed66d985ea","title":"(16) Singular Learning Theory & Alignment Summit 2023 - YouTube","url":"https://www.youtube.com/@SLTSummit/search","urlHash":2794662754},"ad7e8db2-656f-4673-a88e-19cb7335722d":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"ad7e8db2-656f-4673-a88e-19cb7335722d","title":"CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding | PDF","url":"https://arxiv.org/pdf/2311.03354.pdf","urlHash":3629372491},"ad8d668a-43a0-46f6-bdf1-777b4875e9b1":{"favIconUrl":"https://images.ctfassets.net/ohf186sfn6di/7J4cBC9SXCWMoqqCIqI0GI/affe205261bb8cff47501a0ada0f2268/ea-logo-square-1200x1200__1_.png?h=50","id":"ad8d668a-43a0-46f6-bdf1-777b4875e9b1","title":"Why mechanistic interpretability does not and cannot contribute to long-term AGI safety (from messages with a friend) — EA Forum","url":"https://forum.effectivealtruism.org/posts/jwQiBinSagD5LK32X/why-mechanistic-interpretability-does-not-and-cannot","urlHash":1079646728},"ad93287e-8cb4-4edf-8eb8-cab45dba6ca2":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"ad93287e-8cb4-4edf-8eb8-cab45dba6ca2","title":"Gangwoo Kim on X: \"🤔 Seeking deeper alignment between LLMs and retrieval systems for enhancing search accuracy? Introducing ✨ RetPO ✨: A novel framework advancing conversational search by optimizing LMs to produce effective search queries with retrievers' preferences. [1/7] 🧵 https://t.co/QopsFsYfi5\" / X","url":"https://twitter.com/gangwoo_kim/status/1762401683823616179","urlHash":1817788883},"ada0e270-a9ce-4ef4-9013-2c460edf3329":{"favIconUrl":"fallback","id":"ada0e270-a9ce-4ef4-9013-2c460edf3329","title":"Preventing Verbatim Memorization in Language Models Gives a False Sense of Privacy","url":"https://arxiv.org/pdf/2210.17546.pdf","urlHash":4019975107},"adbe6e53-9dab-4407-a2a7-5f61da3e83bf":{"favIconUrl":"fallback","id":"adbe6e53-9dab-4407-a2a7-5f61da3e83bf","title":"What does this subreddit think of bunpro.jp? : LearnJapanese","url":"https://www.reddit.com/r/LearnJapanese/comments/98dxbv/what_does_this_subreddit_think_of_bunprojp/","urlHash":3127453783},"ade50701-9dfd-4db8-8a24-31038bcdddfb":{"favIconUrl":"fallback","id":"ade50701-9dfd-4db8-8a24-31038bcdddfb","title":"对Reformer的深入解读 - 知乎","url":"https://zhuanlan.zhihu.com/p/115741192","urlHash":2141001110},"adf3e95e-b2ff-4047-a28d-ec1dae19acd0":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"adf3e95e-b2ff-4047-a28d-ec1dae19acd0","title":"ShengranHu/Thought-Cloning: [NeurIPS '23 Spotlight] Thought Cloning: Learning to Think while Acting by Imitating Human Thinking","url":"https://github.com/ShengranHu/Thought-Cloning","urlHash":420559922},"ae080bcb-1fab-4508-b35a-0d7110e28528":{"favIconUrl":"fallback","id":"ae080bcb-1fab-4508-b35a-0d7110e28528","title":"stefanoteso/awesome-explanatory-supervision: List of relevant resources for machine learning from explanatory supervision","url":"https://github.com/stefanoteso/awesome-explanatory-supervision","urlHash":1767641628},"ae2e113c-5c15-476a-9ee8-31dac453b24d":{"favIconUrl":"fallback","id":"ae2e113c-5c15-476a-9ee8-31dac453b24d","title":"ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory","url":"https://arxiv.org/abs/2306.03901","urlHash":4196801951},"ae48d106-0af9-4f03-9341-1d752249e02f":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"ae48d106-0af9-4f03-9341-1d752249e02f","title":"twitter.com/sijialiu17/status/1757950318158229941","url":"https://twitter.com/sijialiu17/status/1757950318158229941","urlHash":3378228894},"aeb2807b-992d-4b5f-b3aa-c7fac4bad70e":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"aeb2807b-992d-4b5f-b3aa-c7fac4bad70e","title":"Finding Dataset Shortcuts with Grammar Induction | PDF","url":"https://arxiv.org/pdf/2210.11560.pdf","urlHash":4056492746},"aecb330a-8da2-4034-ad1b-90aa3c6283a3":{"favIconUrl":"fallback","id":"aecb330a-8da2-4034-ad1b-90aa3c6283a3","title":"Submix Practical Private Prediction for Large-Scale Language Models - Arxiv-2201.00971","url":"https://arxiv.org/pdf/2201.00971.pdf","urlHash":132942110},"aed99d9d-6a74-4ef1-8549-de20073bfa6c":{"favIconUrl":"https://rl4lms.apps.allenai.org/favicon.ico","id":"aed99d9d-6a74-4ef1-8549-de20073bfa6c","title":"RL4LMs","url":"https://rl4lms.apps.allenai.org/","urlHash":219612264},"aef419d3-ca36-463d-bb29-008188887d0a":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"aef419d3-ca36-463d-bb29-008188887d0a","title":"Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation | PDF","url":"https://arxiv.org/pdf/2302.09664.pdf","urlHash":3179039635},"aef6d6fa-37e5-4092-8997-ccfefc4fc395":{"favIconUrl":"fallback","id":"aef6d6fa-37e5-4092-8997-ccfefc4fc395","title":"Poisoning Web-Scale Training Datasets is Practical - Arxiv-2302.10149","url":"https://arxiv.org/abs/2302.10149","urlHash":3198953028},"af21ef0f-35dc-43b5-a4cf-5953e4b4b423":{"favIconUrl":"fallback","id":"af21ef0f-35dc-43b5-a4cf-5953e4b4b423","title":"Normcore LLM Reads","url":"https://gist.github.com/veekaybee/be375ab33085102f9027853128dc5f0e","urlHash":2944058604},"af5bb978-1467-43c8-9e87-d73ee80e0c6d":{"favIconUrl":"fallback","id":"af5bb978-1467-43c8-9e87-d73ee80e0c6d","title":"Teaching Small Language Models to Reason - Arxiv-2212.08410","url":"https://arxiv.org/pdf/2212.08410.pdf","urlHash":103996996},"af64b13a-dd95-4965-ad7d-e1761f1a667e":{"favIconUrl":"fallback","id":"af64b13a-dd95-4965-ad7d-e1761f1a667e","title":"https://arxiv.org/pdf/2206.01832.pdf","url":"https://arxiv.org/pdf/2206.01832.pdf","urlHash":321909376},"af6ab83a-ce1c-4c54-bb8f-8d8827c605e2":{"favIconUrl":"fallback","id":"af6ab83a-ce1c-4c54-bb8f-8d8827c605e2","title":"上交社刊《过去之书》《未来之书》个人评价","url":"https://www.douban.com/note/838649960/?_i=9006047KLQjbnS","urlHash":2092320191},"afa3386b-9b85-46cb-b92b-71925e045c9f":{"favIconUrl":"fallback","id":"afa3386b-9b85-46cb-b92b-71925e045c9f","title":"Charles Eliot Norton Lectures - Wikiwand","url":"https://www.wikiwand.com/en/Charles_Eliot_Norton_Lectures","urlHash":1003761078},"afcc3465-920d-4909-bc88-ab3a8e5a99f5":{"favIconUrl":"fallback","id":"afcc3465-920d-4909-bc88-ab3a8e5a99f5","title":"Graph of Thoughts Solving Elaborate Problems with Large Language Models - Arxiv-2308.09687","url":"https://arxiv.org/abs/2308.09687v2?utm_source=substack&utm_medium=email","urlHash":220341956},"afdd4e93-3872-4bce-93b3-c5ed57b6b533":{"favIconUrl":"fallback","id":"afdd4e93-3872-4bce-93b3-c5ed57b6b533","title":"Just Train Twice Improving Group Robustness without Training Group Information - PMLR-2021-liu21f","url":"http://proceedings.mlr.press/v139/liu21f/liu21f.pdf","urlHash":3635612065},"afddbba9-2b7e-4346-89cb-783034e06de7":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"afddbba9-2b7e-4346-89cb-783034e06de7","title":"Multi-Component Learning and S-Curves — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/RKDQCB6smLWgs2Mhr/multi-component-learning-and-s-curves","urlHash":194513186},"afe70dea-bae1-431e-8b0b-c76c35e08602":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/badged-favicon-32x32.png","id":"afe70dea-bae1-431e-8b0b-c76c35e08602","title":"(5) Testing the new BnB 4-bit or \"qlora\" vs GPTQ Cuda : LocalLLaMA","url":"https://www.reddit.com/r/LocalLLaMA/comments/13uvbxe/testing_the_new_bnb_4bit_or_qlora_vs_gptq_cuda/","urlHash":1541899612},"b0409585-6739-42cf-898f-b00c5afb1436":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"b0409585-6739-42cf-898f-b00c5afb1436","title":"One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning | PDF","url":"https://arxiv.org/pdf/2306.07967.pdf","urlHash":2415231743},"b051a1bc-fa03-425a-be7e-87e7b602e37a":{"favIconUrl":"fallback","id":"b051a1bc-fa03-425a-be7e-87e7b602e37a","title":"Alex Graves新作贝叶斯流网络，解决离散数据生成问题，满论文都是数学公式","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650887575&idx=2&sn=51f5fa12f2f618e18a19622afb2b90bc&chksm=84e491e9b39318ff879eb8ebde08b0daf996bbae8c9e49a5c5dfbe1941b19abb3e5a442d4c6e&mpshare=1&scene=1&srcid=1001QsBtCIPx651olGA5l66M&sharer_shareinfo=d13360dcd166399dff919cfbe8ec144e&sharer_shareinfo_first=d13360dcd166399dff919cfbe8ec144e&exportkey=n_ChQIAhIQigc3wdflmFBq5JT6wKJj5RKWAgIE97dBBAEAAAAAAM5cGPSfg24AAAAOpnltbLcz9gKNyK89dVj008o6HTlUjap6EjdFn%2FYwqywKLS%2BorYBLOOYXdcmfeapXh%2BQIUg0xiWWwmtzMW5Kpqs1ADUxDsYd%2F55A3CNH3%2Buw26nokichY23HB5URwgt0Z2J3diy1i%2F%2F9zpoAi33eBBPS4cU33uZR9AGGqiGYqWEG8Ve2OcvXeOm%2FKDvz10Gk54h8e3IPGLqIltMbsy1NOQCZbDvnwSR1ZsVTooJTiXmsUQcAymKtWVDzpNEdxm7KPvvr3OKaHeZulqotn3i%2Fs3vnjSoUv6UW5W54QQvBNN9U0VeOGio6fg13vUEh9pJF3VArC6r7SLqLhJ2zHJutu&acctmode=0&pass_ticket=l6yOyLYzh3umjHVlfhgvUGA%2F4PLSMl8UeYSilizrcCE833IXn0g7MCrl%2F1%2FfIkgg&wx_header=0#rd","urlHash":1567841403},"b0661611-c049-4b62-97ac-18b33c2a819c":{"favIconUrl":"fallback","id":"b0661611-c049-4b62-97ac-18b33c2a819c","title":"Large Language Models are In-Context Semantic Reasoners rather than Symbolic Reasoners","url":"https://arxiv.org/pdf/2305.14825.pdf","urlHash":1526090976},"b070e0c9-fa47-4c31-b02f-927b57c3fa64":{"favIconUrl":"fallback","id":"b070e0c9-fa47-4c31-b02f-927b57c3fa64","title":"对抗训练浅谈：意义、方法和思考（附Keras实现） - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/7234","urlHash":1197238615},"b09b5c00-92a1-4d47-a4eb-b4ed54087208":{"favIconUrl":"fallback","id":"b09b5c00-92a1-4d47-a4eb-b4ed54087208","title":"Ethical-Advice Taker Do Language Models Understand Natural Language Interventions? - Arxiv-2106.01465","url":"https://arxiv.org/pdf/2106.01465.pdf","urlHash":217690617},"b0a1700e-0d64-4573-9423-2c11123b6921":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"b0a1700e-0d64-4573-9423-2c11123b6921","title":"你没有看过的全新版本，Transformer数学原理揭秘","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650902507&idx=2&sn=09e4e4c13746975c6f6eb01b3ddc9176&exportkey=n_ChQIAhIQxSmXFKAy54qnxATNsGC27xKJAgIE97dBBAEAAAAAADQYJAtl%2FgQAAAAOpnltbLcz9gKNyK89dVj0fv1oGgiQTDHN0qeSnziBga6A2v0rNAd7dEXfVGRN%2BFZqHcFtJJ2J8Y0hZn0ByPKQjRiyLTonyr4HH%2BuEaI2NKGMoa4t%2BCja4ZFZY%2BA70bcFDzJXK5%2BCbaNRfnXLT8OVVNePx%2BF1abaMeKlweqAqyAn9U0qzXHJJmakCUGWeKqGKyFiv0MDKVswPY%2BGBIxp6P9Qb8nThbJRqQsZaM8OC9nBMS723zfB2iJhYZEYeEDBwCiCkmQba0fntfLq%2Fi0bTQR9j2QCCkBIDxTuldd1swbkJ%2FLiJzow80qdsps%2BfM%2BLU6yTs%3D&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsZrgDlg9Nsic%2F%2Broj6ZTaIF0e0jAhYZ%2FOVfwgsLzTgMqw%3D%3D&wx_header=0","urlHash":1416590192},"b0ce7407-5b86-4b7d-80e4-beda305b5862":{"favIconUrl":"fallback","id":"b0ce7407-5b86-4b7d-80e4-beda305b5862","title":"ChatGPT盛行的当下，向量数据库为大模型配备了一个超级大脑","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650885185&idx=4&sn=440d1445bd5c294875cab0e74442a821&exportkey=n_ChQIAhIQ%2BKXZ9UFtYuToD%2FXgKZ762RKWAgIE97dBBAEAAAAAAMjHFNGUUfYAAAAOpnltbLcz9gKNyK89dVj0UbvuIQfeCDrcHV4wTK26v4ts1vupgGghqcAI9uMzLAC56aUiVqe03WXJu3TweTVYBFHE%2BR38W2Y9AgQ1R4LtHWFKPSkRwwMQe44YFKCp1IULuzN1rJneyDdlIEi%2BVW7QoJoZpRCMTQCk5XfgapTgwUK%2BvsTjUX4z8nAST2sx1MOuUZ8iTGtu783TwmdYKiPK3Ov4pTQ75rxiKR%2FSBZ7tqO99Kii8AIKDoxN%2FsApiFPi9GN3qeuD0Btq3foQ5AP76wffH%2BlqjHBIAuoO9PVqmC2EnDKu3PNo8tHhnByw3MDBjzOnWJjmgORoRzLv5ROn2&acctmode=0&pass_ticket=xcQ8LyB5AcI0M2ARCIAOB4iPGy6lm7FryuVtgD6O5Ka3kadchZsuGNBR6lYQr86E&wx_header=0","urlHash":351020586},"b0f93922-1f7f-4a7c-9b78-6848454a72a6":{"favIconUrl":"fallback","id":"b0f93922-1f7f-4a7c-9b78-6848454a72a6","title":"Aligning Text-to-Image Models using Human Feedback - Arxiv-2302.12192","url":"https://arxiv.org/pdf/2302.12192.pdf","urlHash":819913065},"b122139b-642f-4894-9d81-7256155b8e47":{"favIconUrl":"fallback","id":"b122139b-642f-4894-9d81-7256155b8e47","title":"Learning Curve Theory - Arxiv-2102.04074","url":"https://arxiv.org/abs/2102.04074","urlHash":186781070},"b1236b1d-b89a-4fc7-bb12-eaffc01ccef6":{"favIconUrl":"https://www.craft.do/share/static/favicon.ico","id":"b1236b1d-b89a-4fc7-bb12-eaffc01ccef6","title":"RLHF Papers","url":"https://bikes-flash-oak.craft.me/NHvR6dsCVNNW8L","urlHash":3180478382},"b14da689-d5d3-4bde-bb69-68a7acbfc977":{"favIconUrl":"fallback","id":"b14da689-d5d3-4bde-bb69-68a7acbfc977","title":"视觉Transformer中ReLU替代softmax，DeepMind新招让成本速降","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650890814&idx=2&sn=f6d67b60338159ec2c72bca9730041bd&chksm=84e4a640b3932f5696ca5ec03e9da08211f7eaedd60e496bdb6286b10f9fb0b39b82148f2035&mpshare=1&scene=1&srcid=1001e96YxYOIfHPj45WqEHqF&sharer_shareinfo=d9e2c714785dd2ea34298a9cdff6fc77&sharer_shareinfo_first=d9e2c714785dd2ea34298a9cdff6fc77&exportkey=n_ChQIAhIQJjcgxpRC5cc1QxosqkhqCBKWAgIE97dBBAEAAAAAAKYXMw9dNy0AAAAOpnltbLcz9gKNyK89dVj040cyt4Y7%2FX8L1du4cfJ5sKEvFlPnbtoCFOf3piF2FKSCamCsPtKxAk7ByylK6IYrsEgywb31Ecy5hRU7CBJSVubX5Pb9nBoQTSedUx4UuubFqvyHhZPweWY20V2WAV16IoZDPVTZ74IS5OlwGK%2Bi8HiZZz7b0e%2B0LTmmFMjDmJRuBYeoJAm00OVhY8A1Pp%2FwiLu0rswJ%2BA1mhy1K%2BKgvckzaOJC4FfYhXljtpusqvtHI9GruNR%2FgDB%2Bq5s5JOpvbZrrJaSvkwbmrW60FkHi%2F%2BX0agcSWzoL4fmB7GOXnEDpbVTuCQoyckD1IR%2BoOl33R&acctmode=0&pass_ticket=LNGTvqUpzwCYVPdidlzCHCJKpkV2ZvxI%2BuakUgzUbo%2FWQZnuSgCwcAhyOtNpmm30&wx_header=0#rd","urlHash":1799038738},"b150dd68-98ca-4fd6-899e-231eec092beb":{"favIconUrl":"fallback","id":"b150dd68-98ca-4fd6-899e-231eec092beb","title":"Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective","url":"https://arxiv.org/abs/2305.15408","urlHash":3779635082},"b1511741-5751-4271-ba98-a21ea1bbd7a6":{"favIconUrl":"fallback","id":"b1511741-5751-4271-ba98-a21ea1bbd7a6","title":"Algorithm Comparison Matrix · Captum","url":"https://captum.ai/docs/algorithms_comparison_matrix","urlHash":2019787196},"b192fd39-b4f0-43ef-9ae2-a7f2e5a3d23b":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"b192fd39-b4f0-43ef-9ae2-a7f2e5a3d23b","title":"Solving the Mechanistic Interpretability challenges: EIS VII Challenge 1 — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/sTe78dNJDGywu9Dz6/solving-the-mechanistic-interpretability-challenges-eis-vii","urlHash":412016408},"b1abb7a6-e546-4c6d-b68c-a17093685d2f":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"b1abb7a6-e546-4c6d-b68c-a17093685d2f","title":"AAAI 2024：大模型如何掌握复杂工具？看孔子框架的教学之道","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247571867&idx=2&sn=dde4c09284044a49a2f7cd7e661f8db8&chksm=970ef14da079785bd42d97c5f49476cad4b374f7a25e62759997a25a3da5c34541ea7823faab&mpshare=1&scene=1&srcid=0115seLN8NtFKLNkP25jAOyq&sharer_shareinfo=06bc2a7a62eca1859b3d90e56a1ab010&sharer_shareinfo_first=06bc2a7a62eca1859b3d90e56a1ab010&exportkey=n_ChQIAhIQeHiWHsqMEMnY7va59FHhzRKWAgIE97dBBAEAAAAAAJpiNI0pbxMAAAAOpnltbLcz9gKNyK89dVj0D%2BAU3JjhimLKYmTng%2B3v7iqnHoa6YIOZHdsCqe3YepcYlXo4WZiSG%2BIs%2FgiHAPd6v7OXcuzUoydPBHIPq4HuPaNIngQ3xyYYNbEsL7qKEeftXoPvkQtPfW5uO2%2BY%2B1f0q%2FpyuBeJMe9FJqIbUPeNYkAS%2BESbxlzQzY%2FRxjkIMRdk1hoQ6YEM%2Bk83p7aOSlM0ZA5rA3e7bkzO2TFJMdi%2B277UmHrJ3QG8RsOCa3d1e9hryO%2B1IeSqPNZjuNuFtMyxWRqEC2G2Sw4kxQ3tY481AZiiUrGUGVq5W2IVYd%2BRzPQ6qFb6%2B6yJCQzETmDvybrD&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsZMklbgSYRx367a%2BhodCsO3B13siAlYGyCg0utawInnwQ%3D%3D&wx_header=0#rd","urlHash":420594240},"b1b1a3d5-26d4-4ea6-ac58-5a4c3a6afdee":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"b1b1a3d5-26d4-4ea6-ac58-5a4c3a6afdee","title":"Jason Wei on X: \"Enjoyed visiting UC Berkeley’s Machine Learning Club yesterday, where I gave a talk on doing AI research. Slides: https://t.co/KjyqkLn2hO In the past few years I’ve worked with and observed some extremely talented researchers, and these are the trends I’ve noticed: 1. When…\" / X","url":"https://twitter.com/_jasonwei/status/1715080315587440719","urlHash":3014187745},"b1c4a230-b828-48eb-9f8a-c5460d46e1b4":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"b1c4a230-b828-48eb-9f8a-c5460d46e1b4","title":"Daniel Johnson on X: \"New paper: How can you tell when a model is hallucinating? Let it cheat! An expert doesn't need to cheat, so if your model learns to cheat, there must be something it doesn't know. Our general new approach for measuring uncertainty: https://t.co/AyO6n8UecG https://t.co/5Dwt5z2ENF\" / X","url":"https://twitter.com/_ddjohnson/status/1758145482386231575","urlHash":1811342939},"b1ded8c4-3138-4b9f-ad3f-6362762dc23b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"b1ded8c4-3138-4b9f-ad3f-6362762dc23b","title":"Dan Friedman on X: \"We often interpret neural nets by studying simplified representations (e.g. low-dim visualization). But how faithful are these simplifications to the original model? In our new preprint, we found some surprising \"interpretability illusions\"... 1/6 https://t.co/LU3VS2fWFJ\" / X","url":"https://twitter.com/danfriedman0/status/1733179591563350226","urlHash":2093796967},"b218604f-931f-4a7a-9860-d3f1abc4b191":{"favIconUrl":"fallback","id":"b218604f-931f-4a7a-9860-d3f1abc4b191","title":"2303 09618 - Google Search","url":"https://www.google.com/search?q=2303+09618&oq=2303+09618&aqs=chrome..69i57j69i60l3.7869j0j1&sourceid=chrome&ie=UTF-8","urlHash":3254682999},"b221817c-671c-4a4d-a9b5-198ceeccb765":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"b221817c-671c-4a4d-a9b5-198ceeccb765","title":"mit-han-lab/streaming-llm: [ICLR 2024] Efficient Streaming Language Models with Attention Sinks","url":"https://github.com/mit-han-lab/streaming-llm","urlHash":314715040},"b236660f-29c0-46ec-a621-18a9e13e68ed":{"favIconUrl":"https://github.githubassets.com/favicons/favicon.svg","id":"b236660f-29c0-46ec-a621-18a9e13e68ed","title":"OpenLLMAI/OpenRLHF: A Ray-based High-performance RLHF framework (for large models)","url":"https://github.com/OpenLLMAI/OpenRLHF?tab=readme-ov-file","urlHash":2816923378},"b23c2784-ad82-4b29-ace9-54a57ce65759":{"favIconUrl":"fallback","id":"b23c2784-ad82-4b29-ace9-54a57ce65759","title":"Making Pre-trained Language Models Better Few-shot Learners - Arxiv-2012.15723","url":"https://arxiv.org/pdf/2012.15723.pdf","urlHash":859490371},"b23c2f48-b21b-4010-8e71-ac710379ca65":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"b23c2f48-b21b-4010-8e71-ac710379ca65","title":"Rethinking Benchmark and Contamination for Language Models with Rephrased Samples | Abstract","url":"https://arxiv.org/abs/2311.04850","urlHash":157053173},"b25ca8ca-4797-4cdc-aa73-6e5854f96d9c":{"favIconUrl":"fallback","id":"b25ca8ca-4797-4cdc-aa73-6e5854f96d9c","title":"阅读安伯托•艾柯，是一种解毒","url":"https://www.gcores.com/articles/118629","urlHash":1704910712},"b264252f-0340-4a76-9ac5-8fdfe996e77b":{"favIconUrl":"fallback","id":"b264252f-0340-4a76-9ac5-8fdfe996e77b","title":"ImageReward Learning and Evaluating Human Preferences for Text-to-Image Generation - Arxiv-2304.05977","url":"https://arxiv.org/pdf/2304.05977.pdf","urlHash":1219402349},"b278bf30-96cd-4af1-b650-72ee2854afbe":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"b278bf30-96cd-4af1-b650-72ee2854afbe","title":"Samuel Albanie on X: \"FactScore - evaluating factual precision of LM outputs is costly - LMs (+ retrieval) can help - Find big diffs in factual prec. of LMs (e.g. GPT-4 vs StableLM) https://t.co/t8fxhFEZ8G By @sewon__min, @kalpeshk2011, @ml_perception @LukeZettlemoyer, @HannaHajishirzi et al. https://t.co/BcMy2p0rjl\" / X","url":"https://twitter.com/SamuelAlbanie/status/1662853059515392005","urlHash":4076240681},"b2883352-45a4-47d1-9a60-e2224edbc030":{"favIconUrl":"fallback","id":"b2883352-45a4-47d1-9a60-e2224edbc030","title":"Wild-Time: A Benchmark of in-the-Wild Distribution Shift over Time","url":"https://arxiv.org/pdf/2211.14238.pdf","urlHash":460939437},"b2be4e0c-d5af-422f-8313-3f28f1ba861f":{"favIconUrl":"fallback","id":"b2be4e0c-d5af-422f-8313-3f28f1ba861f","title":"CVPR2023","url":"https://mp.weixin.qq.com/s?__biz=Mzg3MTcxMTE2Mg==&mid=2247491885&idx=1&sn=1a639675c011421517e3942d7775a22b&chksm=cef8c9f8f98f40eed283a16fa795efff0236ed11464ad13fed0c4679165e9a0cb10e57024298&mpshare=1&scene=1&srcid=0717UtzaATHVMvIB5pdcRx5p&sharer_sharetime=1689584190115&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQMqjXliEkRKWglBX2uVy%2BWRKWAgIE97dBBAEAAAAAABLSAd9owg0AAAAOpnltbLcz9gKNyK89dVj0soJslqZNu%2FEI4Fasdotl3e24kczQGu6imPytJmQSOfUfnGYyI7PkRWwI8Nf1ALYCJL6ogBIB8iJHCBPxd0rIYATRP%2F0a2Vf3qpqGak4yXgLR07a5qppDxj6sMnnVk3weL4Q3DVbjjqrhC%2FmOiA%2B2kXb%2FFCAVNl7rBjUyjnVSdh3MtWbKqGxQpxgHSivHIpgFY7Jhm7LgslmDQyTMhxDT%2BJM5FWei7ZEhywO3h9vwNLDGCTd4eQxUOBiWmKSfRbFHFFBHkadMgMr6yVbun7hFmBrBBg77hTIy2CQrEKQYNvp%2FtkI6gUuasCONaKmiaC8l&acctmode=0&pass_ticket=oSl6X6lqSCJslLWFafA138TBShcb0Y6Awo7VnyLPnaMGU7AadqMq8FXH6dNbNXiq&wx_header=0#rd","urlHash":2290481716},"b2be948e-ebf3-4f03-a201-68a2952849ce":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"b2be948e-ebf3-4f03-a201-68a2952849ce","title":"lucidrains/x-transformers: A simple but complete full-attention transformer with a set of promising experimental features from various papers","url":"https://github.com/lucidrains/x-transformers","urlHash":1478327585},"b2d67acb-acc4-4e1a-9220-4aeaef35d216":{"favIconUrl":"fallback","id":"b2d67acb-acc4-4e1a-9220-4aeaef35d216","title":"Vector_and_Matrix_Derivatives-1.pdf","url":"https://cdn-uploads.piazza.com/paste/kstd6rn7gfj2xa/d141b3471443145c7413a7dd8ddea576fd8c0710a292de74c429364ed60ac129/Vector_and_Matrix_Derivatives-1.pdf","urlHash":2496448049},"b2ed54ea-1d2d-4b9b-8fd6-821b42b5aaee":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"b2ed54ea-1d2d-4b9b-8fd6-821b42b5aaee","title":"无需RLHF显著提升GPT-4/Llama2性能，北大团队提出Aligner对齐新范式","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650907274&idx=2&sn=a4163acf758a084ed84a145d23f09a62&chksm=84e466f4b393efe28a99eb1495c52ccaaf4da8ccfa7ae22e129e41a3ba62129a69c03003ebb4&mpshare=1&scene=1&srcid=0207wccoErb8p4mhc7OyyX11&sharer_shareinfo=63ee1cd79e07a61cf81825ba63d2b03a&sharer_shareinfo_first=63ee1cd79e07a61cf81825ba63d2b03a&exportkey=n_ChQIAhIQWjY1vo%2FIgxNTbG9OMcGwWRKWAgIE97dBBAEAAAAAAIhqIQEf4lwAAAAOpnltbLcz9gKNyK89dVj0Io1QhSt%2FEb9BWfMpgXqHQNka3esq%2B65UTPQXjQTr8ckBnRTzvAkLOrKjfDW59E49hI73JbG1WOvbrKG7GpRZO8SY%2FbtNQqRi6G2O17ZRihgHk%2Bb%2FZVYgow2RLvOzIogdEemWsxyBXxtPAlT3k%2Fr2PLtSfP%2BYoZ4%2BjmpAmBiIq3g8C8xyK9i7CZgOehFWysgyrGBn3DLAaDMJiVhmY%2BZ%2FROdO3iUCt48Z%2FLE%2FW0u80Cb%2FQyvaJsSUDdK261CqaE2BIHeS5GdA75NkbKzvecFq0xpkKoaRVyd5LE7jUKT84j3OXnkmYKnbvAXnD9vibPe%2F&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HMJNJhBWQ0wf5EP32TjmdcUhfvsFmxLZLQD%2BgoLBTD%2BIg%3D%3D&wx_header=0#rd","urlHash":2497882268},"b2f1c846-d93e-4d2f-bdfa-f01713e0a41c":{"favIconUrl":"fallback","id":"b2f1c846-d93e-4d2f-bdfa-f01713e0a41c","title":"为防大模型作恶，斯坦福新方法让模型「遗忘」有害任务信息，模型学会「自毁」了","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247694303&idx=5&sn=7078952ea41d4e90eb83e19be9462aa0&exportkey=n_ChQIAhIQ1WJ6FGfD1oGsDErPycGlLhKWAgIE97dBBAEAAAAAABBJBH01afIAAAAOpnltbLcz9gKNyK89dVj0eL5zMNfF1uXyLoox428b93NXIYAT5KbAyvj07ee87a7O9H3Z5iRY%2F4QSCe03%2Bukhs3m0uFk%2FvYxrwAw2jmNPWaXb4tPJzw3v1N5dkj8UdAgs54IYc1vUNjhaTaZROjfb7gAk0tAuiprwXu2gL7bZVtxEscJjvu1j3NhwLsov5J7AaHgKwcqSVKPXtTCGGFgiJD8iB7P7udqPf5uUtkBFyZIFrX1iH7xJgORgmezmhKmv5eDeae3hZPIFU7NBI1fnlZ5sOG1Khd5sGlhRUjhX3BOUHTbOcomlCcU%2BilLxHr%2BuO5NI0rvdmMS3fT71GzUD&acctmode=0&pass_ticket=uXkGF5TvEirPFvotddIbUV6X%2FfYWuinN7oCb09rEjt5yvJzsdBPr8TZulFv1UiVN&wx_header=0","urlHash":2485930132},"b306808f-41a8-41eb-809c-9340c8245321":{"favIconUrl":"fallback","id":"b306808f-41a8-41eb-809c-9340c8245321","title":"Calibration, Entropy Rates, and Memory in Language Models","url":"https://arxiv.org/abs/1906.05664","urlHash":4116919529},"b35beb1d-e1c4-4953-bd36-747c0c75094a":{"favIconUrl":"fallback","id":"b35beb1d-e1c4-4953-bd36-747c0c75094a","title":"How Should Pre-Trained Language Models Be Fine-Tuned Towards Adversarial Robustness? - NeurIPS-2021_22b1f2e0","url":"https://proceedings.neurips.cc/paper/2021/file/22b1f2e0983160db6f7bb9f62f4dbb39-Paper.pdf","urlHash":2579836121},"b371f6f0-b01c-4ee7-9fe1-708d1756856d":{"favIconUrl":"fallback","id":"b371f6f0-b01c-4ee7-9fe1-708d1756856d","title":"你一定从未看过如此通俗易懂的YOLO系列(从v1到v5)模型解读 (上) - 知乎","url":"https://zhuanlan.zhihu.com/p/183261974","urlHash":1469503993},"b39b82c5-22b5-4b68-a4e5-b682b26c7b57":{"favIconUrl":"https://www.google.com/favicon.ico","id":"b39b82c5-22b5-4b68-a4e5-b682b26c7b57","title":"有栖川有栖 比海更深的河川 - Google Search","url":"https://www.google.com/search?q=%E6%9C%89%E6%A0%96%E5%B7%9D%E6%9C%89%E6%A0%96+%E6%AF%94%E6%B5%B7%E6%9B%B4%E6%B7%B1%E7%9A%84%E6%B2%B3%E5%B7%9D&oq=%E6%9C%89%E6%A0%96%E5%B7%9D%E6%9C%89%E6%A0%96+%E6%AF%94%E6%B5%B7%E6%9B%B4%E6%B7%B1%E7%9A%84%E6%B2%B3%E5%B7%9D&aqs=chrome..69i57j33i160l4.2154j0j1&sourceid=chrome&ie=UTF-8","urlHash":3279600383},"b3bec075-bf21-4955-8f9d-00e4d704e2c1":{"favIconUrl":"fallback","id":"b3bec075-bf21-4955-8f9d-00e4d704e2c1","title":"CodaLab Worksheets","url":"https://worksheets.codalab.org/worksheets/0xbdd35bdd83b14f6287b24c9418983617/","urlHash":2095649503},"b3cd67d7-710c-4e19-99b3-631e76e5fef1":{"favIconUrl":"fallback","id":"b3cd67d7-710c-4e19-99b3-631e76e5fef1","title":"On Learning to Summarize with Large Language Models as References","url":"https://arxiv.org/abs/2305.14239","urlHash":2036886367},"b3e29d68-0134-4c0b-998b-d2c800faf295":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"b3e29d68-0134-4c0b-998b-d2c800faf295","title":"大模型对齐阶段的Scaling Laws","url":"https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&mid=2247495763&idx=1&sn=1fd3e1a70e188dcab7e480cc153e32ff&chksm=9bba7937accdf021c40792e7d442e984d384bee9cb80081b11075a8e45d55f63e9123e573afb&mpshare=1&scene=1&srcid=04015fAU6pMeMDntQdclKIst&sharer_shareinfo=dadfdf469f4bdf7dd55ef31c50347874&sharer_shareinfo_first=dadfdf469f4bdf7dd55ef31c50347874&exportkey=n_ChQIAhIQ2BmKUTtK%2Bw%2FJb%2BzG4xtTxhKWAgIE97dBBAEAAAAAAObUOCq0dmgAAAAOpnltbLcz9gKNyK89dVj0w5x6syUsYTompMBREG2tIayKVNgMI8vUxF3GWUi1XwJA4jHpF7uYWcqOT2n0VTgpM8Xk1hY1tmNF%2F7oyzvHCC4KTs5Ep3YEHOX6FR%2B8kwlhctKzZkOQtte15XVd7C6SqLLkkpL7cYjMI3HSABYM8XzJrC43J9sVenXZDXHByN2sheq22Fx%2Be2iaTEk1ppNXPvgZSGhvyhSiZ7KqLfOKH528CabtiuVNJBBJtN7ZpQXld%2BCRBJ5AAcXJeDWDYM0Ia%2BCq9zGMIk2K9amm3koO%2BnqKYvUgUK9ZndSGXi90xGLkHsiR8UA80mOUvE7LxH2kz&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCN6FMUEIsPoFN57lQ9KLbehD3hUxkw%2BTnMnMYLsd9f5bA%3D%3D&wx_header=0#rd","urlHash":2657091893},"b41a2207-1bed-40fe-ab1e-4a955bde42c6":{"favIconUrl":"fallback","id":"b41a2207-1bed-40fe-ab1e-4a955bde42c6","title":"Transformers Learn Shortcuts to Automata - Arxiv-2210.10749","url":"https://arxiv.org/pdf/2210.10749.pdf","urlHash":2899421808},"b421f4a1-e3d7-4519-aac0-78710c8c8a67":{"favIconUrl":"fallback","id":"b421f4a1-e3d7-4519-aac0-78710c8c8a67","title":"卡夫卡：箴言录——对罪愆、苦难、希望和真正的道路的观察","url":"http://miniyuan.com/simple/?t1013.html","urlHash":2465794608},"b4486090-8bdf-4e51-93d6-28900f75f404":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"b4486090-8bdf-4e51-93d6-28900f75f404","title":"Text Generation by Learning from Demonstrations | PDF","url":"https://arxiv.org/pdf/2009.07839.pdf","urlHash":3908998262},"b45f79c4-da18-4a23-bef6-425ad95e4570":{"favIconUrl":"fallback","id":"b45f79c4-da18-4a23-bef6-425ad95e4570","title":"Meaning without reference in large language models - Arxiv-2208.02957","url":"https://arxiv.org/abs/2208.02957","urlHash":220788912},"b460599c-c0ce-4c33-9fe7-0a8bdbca8e5a":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"b460599c-c0ce-4c33-9fe7-0a8bdbca8e5a","title":"ChatGPT的准确率直线提升23.7%！香港理工大学提出大模型黑箱知识注入","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247570752&idx=2&sn=921978397fdfba8e5148459c4923492c&chksm=970efd96a0797480ef2443be7955b69cae27e14f510e44d44e2a4713f68b3e452190ca7f083a&mpshare=1&scene=1&srcid=0226F14jBW3KXtffydXsmOsO&sharer_shareinfo=749e739ffdb11ce82a575473ae8c82a0&sharer_shareinfo_first=749e739ffdb11ce82a575473ae8c82a0&exportkey=n_ChQIAhIQsQcD11cSZdthYimnQz6XHBKWAgIE97dBBAEAAAAAABpfBC2mZFIAAAAOpnltbLcz9gKNyK89dVj0OtqKt%2FmOSGOBH%2Fxm0JWEA2rPUZCNlxiPLF2nHGTf0jXA%2FI2Bz52Op%2B5bKhKFck1qmIgWt776u%2FQAWVEydhAxCpAb8Btpw3NLczlqyYv1LRblUkf0EziVhSr1ClM7DJesuqx6n5oryB8gAZUL%2BmHsxGLGQY%2BTk8FZf17UDSNYUsLVCb6HzUuIuGoXLFLKbVN4xrO%2FyeQ9U0WnwNxIl%2Fel7qZaVaiBcGFzXq%2Fam4urZy6A4nK7TC0p9S%2BjUb6JlQCRfsAHZS1jqqxCzHIR127PGok4rVtZtzJ048%2FLWCs%2B9RizCGMazSS3vgQgQ8qP2FDN&acctmode=0&pass_ticket=2PIOTp07NumM73b6%2BDXCh%2BnkNx8%2F1ykJABKPHCCPJcNE1kFFZNNoOC5oWqp%2B74rLcKoKeSLy7cQGia40cFuoxA%3D%3D&wx_header=0#rd","urlHash":2623014144},"b4c0de1a-f9cd-42ee-9492-6c75511f8884":{"favIconUrl":"fallback","id":"b4c0de1a-f9cd-42ee-9492-6c75511f8884","title":"修改Transformer结构，设计一个更快更好的MLM模型 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/7661","urlHash":2443350432},"b4fe1d9f-bf68-483a-94f6-fca98ee21fec":{"favIconUrl":"https://chat.xlang.ai/xlang.ico","id":"b4fe1d9f-bf68-483a-94f6-fca98ee21fec","title":"XLang Agents","url":"https://chat.xlang.ai/","urlHash":168525574},"b5136288-f32e-482d-93bc-a61fdb0fc987":{"favIconUrl":"fallback","id":"b5136288-f32e-482d-93bc-a61fdb0fc987","title":"Interpretability Beyond Feature Attribution Quantitative Testing with Concept Activation Vectors (TCAV) - Arxiv-1711.11279","url":"https://arxiv.org/pdf/1711.11279.pdf","urlHash":1319344358},"b527233f-f496-4cc4-a7f4-0eab2f758527":{"favIconUrl":"fallback","id":"b527233f-f496-4cc4-a7f4-0eab2f758527","title":"reinforcement learning - need help understanding the benefit of score function estimator - Cross Validated","url":"https://stats.stackexchange.com/questions/377287/need-help-understanding-the-benefit-of-score-function-estimator","urlHash":1615760336},"b577994f-4083-43c0-913b-d8031559c86f":{"favIconUrl":"fallback","id":"b577994f-4083-43c0-913b-d8031559c86f","title":"constraint reasoning gpt - Google Search","url":"https://www.google.com/search?q=constraint+reasoning+gpt&oq=constraint+reasoning&gs_lcrp=EgZjaHJvbWUqCAgAEEUYJxg7MggIABBFGCcYOzIJCAEQRRg7GIAEMggIAhAAGBYYHjIKCAMQABgPGBYYHjIICAQQABgWGB4yCAgFEAAYFhgeMgoIBhAAGA8YFhgeMgoIBxAAGIYDGIoFMgoICBAAGIYDGIoFMgoICRAAGIYDGIoF0gEIMjU5MWowajGoAgCwAgA&sourceid=chrome&ie=UTF-8","urlHash":439016754},"b57d411a-d693-4883-934d-711dc2b0b438":{"favIconUrl":"fallback","id":"b57d411a-d693-4883-934d-711dc2b0b438","title":"芥川龙之介 鼻子 - Google Search","url":"https://www.google.com/search?q=%E8%8A%A5%E5%B7%9D%E9%BE%99%E4%B9%8B%E4%BB%8B+%E9%BC%BB%E5%AD%90&newwindow=1&sxsrf=APwXEdfen7dLmRDQynuCcKRBGKZY3F8dqQ%3A1682056708372&ei=BCZCZMCuFtih5NoPwpuBqAc&ved=0ahUKEwjAwODEpbr-AhXYEFkFHcJNAHUQ4dUDCBA&uact=5&oq=%E8%8A%A5%E5%B7%9D%E9%BE%99%E4%B9%8B%E4%BB%8B+%E9%BC%BB%E5%AD%90&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIFCC4QgAQyCAgAEAgQHhAPMggIABAIEB4QDzIQCC4QgAQQ3AQQ3gQQ4AQYAToFCAAQgAQ6BwgAEIAEEAw6BwguEIAEEAw6BggAEAQQHjoICAAQBBAeEA86EgguEIAEEAwQ3AQQ3gQQ4AQYAUoECEEYAVDyBVi1GGChGWgBcAB4AIABZ4gBlgSSAQM1LjGYAQCgAQHAAQHaAQYIARABGBQ&sclient=gws-wiz-serp","urlHash":3614208452},"b5a7ae0b-0a0f-4007-8c77-ba3c02ee33c4":{"favIconUrl":"fallback","id":"b5a7ae0b-0a0f-4007-8c77-ba3c02ee33c4","title":"How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources | PDF","url":"https://arxiv.org/pdf/2306.04751.pdf","urlHash":4117360399},"b5b86fc2-a1e0-49f9-81e5-67636302edc1":{"favIconUrl":"https://static.zhihu.com/heifetz/favicon.ico","id":"b5b86fc2-a1e0-49f9-81e5-67636302edc1","title":"大语言模型中的涌现现象是不是伪科学？ - 知乎","url":"https://www.zhihu.com/question/587177332/answer/3012764207","urlHash":1066313938},"b62a90c2-a4ca-400d-a748-d332284a5edc":{"favIconUrl":"fallback","id":"b62a90c2-a4ca-400d-a748-d332284a5edc","title":"A Comprehensive Survey on Pretrained Foundation Models A History from BERT to ChatGPT - Arxiv-2302.09419","url":"https://arxiv.org/pdf/2302.09419.pdf","urlHash":597378043},"b64865e0-be1d-46b1-b557-ee9d1177cb9d":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"b64865e0-be1d-46b1-b557-ee9d1177cb9d","title":"Exploring the Relationship between In-Context Learning and Instruction Tuning | PDF","url":"https://arxiv.org/pdf/2311.10367v1.pdf","urlHash":1819395174},"b66db5e9-cfe9-4b56-ae63-b23c7983e6a0":{"favIconUrl":"fallback","id":"b66db5e9-cfe9-4b56-ae63-b23c7983e6a0","title":"RealFormer：Real 简单，Real 有效 - 知乎","url":"https://zhuanlan.zhihu.com/p/340329943","urlHash":2043104273},"b673535c-7423-4790-8205-7bc03141a572":{"favIconUrl":"fallback","id":"b673535c-7423-4790-8205-7bc03141a572","title":"ID-Pose Sparse-view Camera Pose Estimation by Inverting Diffusion Models - Arxiv-2306.17140","url":"https://arxiv.org/pdf/2306.17140.pdf","urlHash":4100686978},"b6925d26-5e6d-484d-ba4f-441b7036c21c":{"favIconUrl":"fallback","id":"b6925d26-5e6d-484d-ba4f-441b7036c21c","title":"z-x-yang/Segment-and-Track-Anything: An open-source project dedicated to tracking and segmenting any objects in videos, either automatically or interactively. The primary algorithms utilized include the Segment Anything Model (SAM) for key-frame segmentation and Associating Objects with Transformers (AOT) for efficient tracking and propagation purposes.","url":"https://github.com/z-x-yang/segment-and-track-anything","urlHash":3754559761},"b69e4f79-62b5-4196-b4e4-d769adbda90f":{"favIconUrl":"fallback","id":"b69e4f79-62b5-4196-b4e4-d769adbda90f","title":"知乎 - 安全中心","url":"https://link.zhihu.com/?target=https%3A//www.cnblogs.com/xuanyuyt/p/7222867.html","urlHash":1582853845},"b6a1d52e-8491-430d-a4ef-98d1fc5b1360":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"b6a1d52e-8491-430d-a4ef-98d1fc5b1360","title":"Jacob Andreas on X: \"Speculative (!!!) paper arguing that big LMs can model agency &amp; communicative intent: https://t.co/WYaedqx9TT (somehow in EMNLP findings). Briefly: 1. LMs do not in general have beliefs or goals. An LM trained on the Internet models a distribution over next tokens *marginalized* https://t.co/tZ8eFUhWOq\" / X","url":"https://twitter.com/jacobandreas/status/1600118539263741952","urlHash":2320570093},"b6b8912a-10b0-414e-bee7-fadcc2f984aa":{"favIconUrl":"fallback","id":"b6b8912a-10b0-414e-bee7-fadcc2f984aa","title":"Why Momentum Really Works","url":"https://distill.pub/2017/momentum/","urlHash":570014327},"b6f847c6-5bcb-47c7-ad4f-b7432cf61844":{"favIconUrl":"fallback","id":"b6f847c6-5bcb-47c7-ad4f-b7432cf61844","title":"On the reproducibility of \"Exacerbating Algorithmic Bias through Fairness Attacks\" - Google Search","url":"https://www.google.com/search?q=On+the+reproducibility+of+%22Exacerbating+Algorithmic+Bias+through+Fairness+Attacks%22&sourceid=chrome&ie=UTF-8","urlHash":2127750481},"b71cee4f-c083-4e7d-824a-d1210e5c2b41":{"favIconUrl":"fallback","id":"b71cee4f-c083-4e7d-824a-d1210e5c2b41","title":"Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model","url":"https://arxiv.org/abs/2212.00490","urlHash":1792328743},"b7546a52-394a-4541-9a93-7efc56ff149a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"b7546a52-394a-4541-9a93-7efc56ff149a","title":"Aymeric on X: \"Information Retrieval: Who wins, GPT-4-Turbo or a RAG based on GPT4? I extended the \"Needle in a Haystack\" test created by @GregKamradt &amp; the result is clear: 🏆 𝗥𝗔𝗚 𝘄𝗶𝗻𝘀 🏆 &gt; its edge becomes clear for the longest document sizes. @huggingface Links below ⬇ https://t.co/hZB6GuX7yx\" / X","url":"https://twitter.com/AymericRoucher/status/1730636318592414152","urlHash":2321126406},"b794ad53-48ce-46a0-84e9-1d599fbc5fb3":{"favIconUrl":"fallback","id":"b794ad53-48ce-46a0-84e9-1d599fbc5fb3","title":"Shortcutted Commonsense: Data Spuriousness in Deep Learning of Commonsense Reasoning","url":"https://aclanthology.org/2021.emnlp-main.113.pdf","urlHash":3093613292},"b7ab3abd-a706-4d11-aa29-a3d0f4d6f3d3":{"favIconUrl":"fallback","id":"b7ab3abd-a706-4d11-aa29-a3d0f4d6f3d3","title":"Distributionally Robust Models with Parametric Likelihood Ratios - Arxiv-2204.06340","url":"https://arxiv.org/pdf/2204.06340.pdf","urlHash":1755007832},"b7d4efb5-4497-4ed5-a22c-5a141e2cae72":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"b7d4efb5-4497-4ed5-a22c-5a141e2cae72","title":"twitter.com/ShayneRedford/status/1630252829578231809","url":"https://twitter.com/ShayneRedford/status/1630252829578231809","urlHash":1911927678},"b7dcc8e8-b11b-432e-baba-05a3d96739df":{"favIconUrl":"https://blog.langchain.dev/content/images/size/w256h256/2024/03/Twitter_ProfilePicture.png","id":"b7dcc8e8-b11b-432e-baba-05a3d96739df","title":"LangGraph for Code Generation","url":"https://blog.langchain.dev/code-execution-with-langgraph/","urlHash":3588533639},"b7fc58fe-6a25-4f7d-a046-74e60b8076cd":{"favIconUrl":"https://miro.medium.com/v2/resize:fill:192:192/1*cciPf4CUXd_Zyux0Jg0yBQ.png","id":"b7fc58fe-6a25-4f7d-a046-74e60b8076cd","title":"Mechanistic anomaly detection and ELK | by Paul Christiano | AI Alignment","url":"https://ai-alignment.com/mechanistic-anomaly-detection-and-elk-fb84f4c6d0dc","urlHash":625723680},"b826276a-cc1d-4b96-bd7a-00e0bc47d541":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"b826276a-cc1d-4b96-bd7a-00e0bc47d541","title":"AK on X: \"GPT-4V(ision) is a Generalist Web Agent, if Grounded paper page: https://t.co/qv2hrI06Lj The recent development on large multimodal models (LMMs), especially GPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries of multimodal models beyond traditional… https://t.co/8VLwvhdVPA\" / X","url":"https://twitter.com/_akhaliq/status/1742725185726198022","urlHash":3442546396},"b83b818b-5166-4505-b2de-0617e3b95782":{"favIconUrl":"fallback","id":"b83b818b-5166-4505-b2de-0617e3b95782","title":"一文总览知识蒸馏概述","url":"https://posts.careerengine.us/p/5e040074089a4c71be7da859","urlHash":138537283},"b8ac19f8-0079-4cb2-9053-dfb2463ac446":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"b8ac19f8-0079-4cb2-9053-dfb2463ac446","title":"Data Curation Alone Can Stabilize In-context Learning | PDF","url":"https://arxiv.org/pdf/2212.10378.pdf","urlHash":4116258450},"b8c5c5cb-89c1-4455-b34a-91b372f050e0":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"b8c5c5cb-89c1-4455-b34a-91b372f050e0","title":"陈丹琦团队新作：Llama-2上下文扩展至128k，10倍吞吐量仅需1/6内存","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247718864&idx=4&sn=f37726f6edd5526561a41d1df5f2b8a4&chksm=e8df20a2dfa8a9b478b618d85c4b0bb460b43e43fb279e91c2013e39978c74f8bf1083f1f00a&mpshare=1&scene=1&srcid=0301jZp0Tq4nmEQq5Pr1pq9R&sharer_shareinfo=e0080cb6ece4b586d1697a9f563d4df7&sharer_shareinfo_first=e0080cb6ece4b586d1697a9f563d4df7&exportkey=n_ChQIAhIQfLuDmpnWXv8ZJYRDlVSnVxKWAgIE97dBBAEAAAAAAKb5CRFQmxAAAAAOpnltbLcz9gKNyK89dVj0jRY1EviMqPIZ5qjlusVCRxZ7xvoGCYn29OfvEPCrkFKOeY8mcuyo5Ux2YsFASXE4GLc7vfSIFxwfoun2TMuCAeNpwYw1As2CCZmTcMiqow8gq8OL%2B2Mmgm05W3XLJuuVttHJta3umRJT4Lo62xQn87ugFvMxbhDepvZwzJt26Clz7b2p97WNiasSwqYk45F6%2B9Cib2HTXdRIxpShBrBuOzJUQfsJdqgjC2Xa6RegcoMbJPE25H4EA6oP0XOtvi%2FCzhpMpVe5QbBtyAzAzth836Rqsm2Mf2IaWLIaiuADa09DorPmxgzewe1nutc1yyzP&acctmode=0&pass_ticket=2PIOTp07NumM73b6%2BDXCh%2BnkNx8%2F1ykJABKPHCCPJcOEKod52%2Ba5d1xtzgtd7P59cFbZfItdlcXiEkW%2FSyKIyw%3D%3D&wx_header=0#rd","urlHash":2006158215},"b8d5d188-0370-4376-8202-050ca3c94699":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"b8d5d188-0370-4376-8202-050ca3c94699","title":"Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers | Abstract","url":"https://arxiv.org/abs/2212.10559","urlHash":3829726548},"b91be660-94de-4cf6-8683-3c911cf38fe3":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"b91be660-94de-4cf6-8683-3c911cf38fe3","title":"How good are deep models in understanding the generated images? | PDF","url":"https://arxiv.org/pdf/2208.10760.pdf","urlHash":2967624274},"b934f372-100b-4c44-a998-8a69ddc687eb":{"favIconUrl":"fallback","id":"b934f372-100b-4c44-a998-8a69ddc687eb","title":"LLM Calibration and Automatic Hallucination Detection via Pareto Optimal Self-supervision","url":"https://arxiv.org/abs/2306.16564","urlHash":2344068277},"b958e72a-1377-4430-90e3-fb2ca48adcc3":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"b958e72a-1377-4430-90e3-fb2ca48adcc3","title":"Eliciting Human Preferences with Language Models | PDF","url":"https://arxiv.org/pdf/2310.11589.pdf","urlHash":3136524952},"b95973d5-20e1-4c13-b64a-e6042844ba30":{"favIconUrl":"fallback","id":"b95973d5-20e1-4c13-b64a-e6042844ba30","title":"Counterfactual Memorization in Neural Language Models","url":"https://arxiv.org/pdf/2112.12938.pdf","urlHash":1878364746},"b9754266-39da-4348-b0fc-dc340c95aa92":{"favIconUrl":"fallback","id":"b9754266-39da-4348-b0fc-dc340c95aa92","title":"DPZero: Private Fine-Tuning of Language Models without Backpropagation | PDF","url":"https://arxiv.org/pdf/2310.09639.pdf","urlHash":2752622249},"b979df37-1275-442f-b410-131d6012227e":{"favIconUrl":"fallback","id":"b979df37-1275-442f-b410-131d6012227e","title":"Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation","url":"https://arxiv.org/abs/2212.00774","urlHash":1120933501},"b9b5a849-d9c3-422a-9883-7ef7186c15b3":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"b9b5a849-d9c3-422a-9883-7ef7186c15b3","title":"Aran Komatsuzaki on X: \"DistiLLM: Towards Streamlined Distillation for Large Language Models Up to 4.3x speedup compared to recent KD methods. repo: https://t.co/8e3ZiqOy0W abs: https://t.co/eBn4GFsWA8 https://t.co/QeBNdWrF4k\" / X","url":"https://twitter.com/arankomatsuzaki/status/1755059693687275584","urlHash":2402805997},"b9ba237f-fcb9-42aa-b39e-c13192958f19":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"b9ba237f-fcb9-42aa-b39e-c13192958f19","title":"Making Pre-trained Language Models Better Few-shot Learners | Abstract","url":"https://arxiv.org/abs/2012.15723","urlHash":3902441436},"b9f29d8f-4cce-42d7-93a5-acf5dc839f30":{"favIconUrl":"fallback","id":"b9f29d8f-4cce-42d7-93a5-acf5dc839f30","title":"[2212.02773] DiffusionInst: Diffusion Model for Instance Segmentation","url":"https://arxiv.org/abs/2212.02773","urlHash":745120151},"ba0383c1-052d-47cd-a26d-fd5f564b8b2e":{"favIconUrl":"fallback","id":"ba0383c1-052d-47cd-a26d-fd5f564b8b2e","title":"xlang-ai/text2reward: Code for Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning","url":"https://github.com/xlang-ai/text2reward","urlHash":4212466585},"ba182eeb-c198-4991-9f39-c6df80d70906":{"favIconUrl":"fallback","id":"ba182eeb-c198-4991-9f39-c6df80d70906","title":"Large Transformer Model Inference Optimization","url":"https://lilianweng.github.io/posts/2023-01-10-inference-optimization/","urlHash":2078737558},"ba1fdea0-14fb-44db-9d4d-04fe1d0d2f1f":{"favIconUrl":"fallback","id":"ba1fdea0-14fb-44db-9d4d-04fe1d0d2f1f","title":"如何划分一个跟测试集更接近的验证集？ - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/7805","urlHash":3654632149},"ba5fcc3b-b4e0-40ea-a764-415f495c6153":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"ba5fcc3b-b4e0-40ea-a764-415f495c6153","title":"Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language Models | Abstract","url":"https://arxiv.org/abs/2401.10647","urlHash":752073065},"baa7f950-196b-42d5-adad-52c6300d8c39":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"baa7f950-196b-42d5-adad-52c6300d8c39","title":"「图结构学习」新思路！港大等提出GraphEdit模型：用LLM删除噪声边，全局理解节点间依赖关系","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652453563&idx=4&sn=962ef1d1d03e936a36aa7b0c1b81c858&chksm=f12a4e4ac65dc75c4e6e6362b42f868ffd8606e32c9f13307a28d1c2420e070351a833888b15&mpshare=1&scene=1&srcid=0406Im0wUzDiuL1BkYTrP9wF&sharer_shareinfo=f27329483bce13de3621838a738a988f&sharer_shareinfo_first=f27329483bce13de3621838a738a988f&exportkey=n_ChQIAhIQocYXPvFgUyhboLZdziM%2BSxKWAgIE97dBBAEAAAAAAIRJOlH3LOAAAAAOpnltbLcz9gKNyK89dVj0SAa%2FhvHV511m3Cql%2FbxIMsxo7GapAfQAHGhZGw%2FZWgjx%2BCKhAyzV5zupIa6aDVmqP58rg%2Fic%2BovSGQKcxjnqC81K4gyppg5ZuvxOLLNmPXx0kZizoEDGOANPm1qmtrvKTfYeCZtOachMfTaEzamkQTyGZHxRapIqwndt0sSHHSvmTPD9CTucuhR8GIoRpQPPVb0ygxOQWNxp1x7QjkHSpGRlbzAz2ai3%2F2n581DcA58B4MxZBWETHp3KwARrt0vOdkVRYnWAlK%2BiehRrDlX3JRU9iWUYzT%2BFo8QUBMJXbv8UvnJR8J0%2Fi2O%2BAtRaskOs&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCOFSqZbJ895PKFSxtAnEyOW%2BE4g4n9D2aZeObBZV%2F%2F3Aw%3D%3D&wx_header=0#rd","urlHash":4125374433},"bad3f624-4bca-4aff-ad8a-9f0f43d949ba":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"bad3f624-4bca-4aff-ad8a-9f0f43d949ba","title":"lhao499/RingAttention: Transformers with Arbitrarily Large Context","url":"https://github.com/lhao499/RingAttention","urlHash":1205695300},"baef21b8-82ad-4258-b6ae-2a8ec6d74a8d":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"baef21b8-82ad-4258-b6ae-2a8ec6d74a8d","title":"Automatically Auditing Large Language Models via Discrete Optimization | PDF","url":"https://arxiv.org/pdf/2303.04381.pdf","urlHash":3281674834},"baef84e8-85bb-4c94-9b9d-32147f87d4a9":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"baef84e8-85bb-4c94-9b9d-32147f87d4a9","title":"Zhiqing Sun @ NeurIPS’23 on X: \"🚀 Can RLAIF fully replace RLHF to align language models from scratch, enhancing both their alignment and capabilities? SALMON introduces a principle-following reward model in the realm of self-alignment, using just 6 ICL exemplars and 31 principles to outperform LLaMA-2-Chat! https://t.co/0APw116AUM\" / X","url":"https://twitter.com/EdwardSun0909/status/1712157706864513116","urlHash":271046282},"bb681d72-ab2a-419a-9da7-c692a030a268":{"favIconUrl":"fallback","id":"bb681d72-ab2a-419a-9da7-c692a030a268","title":"训练1000层的Transformer究竟有什么困难？ - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/8978","urlHash":3176958560},"bb9b3804-9c5d-409e-9a3e-7c7e0a1c6da3":{"favIconUrl":"fallback","id":"bb9b3804-9c5d-409e-9a3e-7c7e0a1c6da3","title":"NeurIPS 2022 best papers - Google Search","url":"https://www.google.com/search?q=NeurIPS+2022+best+papers&newwindow=1&sxsrf=ALiCzsb8ZFY7XK_IsIonniRyVV31KUdnrw%3A1670970420677&ei=NPyYY_2AKY3QkPIPwMiUqAQ&ved=0ahUKEwj96ury0ff7AhUNKEQIHUAkBUUQ4dUDCBA&uact=5&oq=NeurIPS+2022+best+papers&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIFCAAQgAQyBQgAEIYDOgoIABBHENYEELADOgUIABCiBDoICCEQwwQQoAFKBAhBGABKBAhGGABQhQVYqw1gyQ9oAnABeACAAc0BiAHSCZIBBTAuNi4xmAEAoAEByAEIwAEB&sclient=gws-wiz-serp","urlHash":151461913},"bbb499e1-550c-4858-b789-de31b157350b":{"favIconUrl":"fallback","id":"bbb499e1-550c-4858-b789-de31b157350b","title":"Inverse scaling can become U-shaped - Arxiv-2211.02011","url":"https://arxiv.org/pdf/2211.02011.pdf","urlHash":1985637782},"bc1514ec-6ab0-4a8b-b20f-236406e67056":{"favIconUrl":"fallback","id":"bc1514ec-6ab0-4a8b-b20f-236406e67056","title":"[1903.09860] Data Poisoning against Differentially-Private Learners: Attacks and Defenses","url":"https://arxiv.org/abs/1903.09860","urlHash":1021044865},"bc20f866-c7de-4e82-b465-b478e19ed9cc":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"bc20f866-c7de-4e82-b465-b478e19ed9cc","title":"Aran Komatsuzaki on X: \"FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets repo: https://t.co/6w3QFnrLiD abs: https://t.co/SKAM3r0oku https://t.co/0qh6s1R3fJ\" / X","url":"https://twitter.com/arankomatsuzaki/status/1682192939387060224","urlHash":1100366614},"bc67db1c-53da-4f26-8223-1a812ed11946":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"bc67db1c-53da-4f26-8223-1a812ed11946","title":"What Does BERT Look At? An Analysis of BERT's Attention | PDF","url":"https://arxiv.org/pdf/1906.04341.pdf","urlHash":240377236},"bc863141-e62c-4261-a657-f1cf2a73089a":{"favIconUrl":"fallback","id":"bc863141-e62c-4261-a657-f1cf2a73089a","title":"(2) [D] Yet another case of plagiarism in ICCV. The ICCV 2021 paper \"Learnable Boundary Guided Adversarial Training\"(arxiv 2011.11164) with the BMVC 2020 paper \"Adversarial Concurrent Training: Optimizing Robustness and Accuracy Trade-off of Deep Neural Networks\" (arxiv 2008.07015) : MachineLearning","url":"https://www.reddit.com/r/MachineLearning/comments/vbwe8k/d_yet_another_case_of_plagiarism_in_iccv_the_iccv/","urlHash":3035007080},"bc87b64a-4a0a-4fe7-b510-15bfd61437a9":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"bc87b64a-4a0a-4fe7-b510-15bfd61437a9","title":"Suchin Gururangan on X: \"Introducing time vectors! Time vectors are a simple way adapt LMs to new time periods; our results suggest that time is encoded in the weights of finetuned models. Led by my incredible undergrad mentee, Kai Nylund! Paper: https://t.co/S3ZtdbBoRc Code: https://t.co/IH6y7iioFD /1 https://t.co/mgUSbbH9lV\" / X","url":"https://twitter.com/ssgrn/status/1738256456250470853","urlHash":897725437},"bc8e92da-d973-497f-a8db-b62e0e54cdf9":{"favIconUrl":"https://www.google.com/favicon.ico","id":"bc8e92da-d973-497f-a8db-b62e0e54cdf9","title":"消失的砂蛾家 - Google Search","url":"https://www.google.com/search?q=%E6%B6%88%E5%A4%B1%E7%9A%84%E7%A0%82%E8%9B%BE%E5%AE%B6","urlHash":2890867447},"bcc3ccb6-9690-4f1f-a08e-c4784cddcc66":{"favIconUrl":"fallback","id":"bcc3ccb6-9690-4f1f-a08e-c4784cddcc66","title":"最简单的self-supervised方法 - 知乎","url":"https://zhuanlan.zhihu.com/p/355523266","urlHash":1404705674},"bcc4ff8d-aa02-4205-9c10-b995fb074563":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"bcc4ff8d-aa02-4205-9c10-b995fb074563","title":"twitter.com/jd92wang/status/1684073545931051009","url":"https://twitter.com/jd92wang/status/1684073545931051009","urlHash":2566397891},"bcc62768-578d-4470-9827-4dd360bf6189":{"favIconUrl":"fallback","id":"bcc62768-578d-4470-9827-4dd360bf6189","title":"wronnyhuang/metapoison: Craft poisoned data using MetaPoison","url":"https://github.com/wronnyhuang/metapoison#algorithm-overview","urlHash":1626844274},"bcc81d76-0dd2-4625-8e20-637f4f940af0":{"favIconUrl":"fallback","id":"bcc81d76-0dd2-4625-8e20-637f4f940af0","title":"The Stable Entropy Hypothesis and Entropy-Aware Decoding An Analysis and Algorithm for Robust Natural Language Generation - Arxiv-2302.06784","url":"https://arxiv.org/abs/2302.06784","urlHash":735465665},"bcd489d7-50ae-4fe5-aa91-f78dc2526b5a":{"favIconUrl":"fallback","id":"bcd489d7-50ae-4fe5-aa91-f78dc2526b5a","title":"(42 封私信 / 80 条消息) 模型的Robustness和Generalization是什么关系？ - 知乎","url":"https://www.zhihu.com/question/410332622","urlHash":3214983878},"bce9a1d2-2105-4118-939b-e99af67dd53f":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"bce9a1d2-2105-4118-939b-e99af67dd53f","title":"QuIP: 2-Bit Quantization of Large Language Models With Guarantees | Abstract","url":"https://arxiv.org/abs/2307.13304","urlHash":366967375},"bd132ecb-0e11-45f6-81eb-54122bc08d25":{"favIconUrl":"fallback","id":"bd132ecb-0e11-45f6-81eb-54122bc08d25","title":"a primer on bertology - Google Search","url":"https://www.google.com/search?q=a+primer+on+bertology&oq=a+primer+on+bertology&aqs=chrome..69i57j0i22i30j69i64l2.2896j0j1&sourceid=chrome&ie=UTF-8","urlHash":2205661200},"bd2cf572-6365-4db6-bc9e-ac0202d4ced9":{"favIconUrl":"fallback","id":"bd2cf572-6365-4db6-bc9e-ac0202d4ced9","title":"Probabilistic Model-Agnostic Meta-Learning","url":"https://arxiv.org/pdf/1806.02817.pdf","urlHash":3159416823},"bd481916-2e81-4c88-9b06-ae8d69379a43":{"favIconUrl":"fallback","id":"bd481916-2e81-4c88-9b06-ae8d69379a43","title":"Fine-Tuning Pretrained Language Models Weight Initializations, Data Orders, and Early Stopping - Arxiv-2002.06305","url":"https://arxiv.org/pdf/2002.06305.pdf","urlHash":1328608375},"bd61ce02-8045-47b8-92df-dfb14c0b43f0":{"favIconUrl":"fallback","id":"bd61ce02-8045-47b8-92df-dfb14c0b43f0","title":"How single-shot detector (SSD) works?","url":"https://developers.arcgis.com/python/guide/how-ssd-works/","urlHash":2823480473},"bdb49c60-27a1-477c-bd61-d9985bb0b98a":{"favIconUrl":"fallback","id":"bdb49c60-27a1-477c-bd61-d9985bb0b98a","title":"How to train your MAML","url":"https://arxiv.org/abs/1810.09502","urlHash":3870824081},"bdefc8ae-df09-493c-b057-684164f23e36":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"bdefc8ae-df09-493c-b057-684164f23e36","title":"Seesaw Loss for Long-Tailed Instance Segmentation | PDF","url":"https://arxiv.org/pdf/2008.10032.pdf","urlHash":2569813616},"be472e95-bd31-45e9-b5fd-ae72281e58bb":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"be472e95-bd31-45e9-b5fd-ae72281e58bb","title":"LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models | PDF","url":"https://arxiv.org/pdf/2309.12307.pdf","urlHash":1732240925},"be5b8c72-3e8d-4048-944b-fcdae2fc7f45":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"be5b8c72-3e8d-4048-944b-fcdae2fc7f45","title":"elvis on X: \"Here's a list of my favorite LLM papers I read this month: 1/ Zephyr LLM - a 7B parameter model with competitive performance to ChatGPT on AlpacaEval; applies distilled supervised fine-tuning to improve task accuracy and distilled direct performance optimization on AI feedback…\" / X","url":"https://twitter.com/omarsar0/status/1718990821519659516","urlHash":643726864},"bea34725-9670-41d6-b639-51b78d6a10ca":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"bea34725-9670-41d6-b639-51b78d6a10ca","title":"Tracr: Compiled Transformers as a Laboratory for Interpretability | PDF","url":"https://arxiv.org/pdf/2301.05062.pdf","urlHash":2856643233},"bebe47e1-7ea8-475f-b9ea-454c9576d04a":{"favIconUrl":"https://kexue.fm/usr/themes/geekg/favicon.ico","id":"bebe47e1-7ea8-475f-b9ea-454c9576d04a","title":"VQ一下Key，Transformer的复杂度就变成线性了 - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/9844","urlHash":1282017133},"bed1209d-302c-4dc0-984f-771fe9bec136":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"bed1209d-302c-4dc0-984f-771fe9bec136","title":"isl-org/ZoeDepth: Metric depth estimation from a single image","url":"https://github.com/isl-org/ZoeDepth#zoedepth-combining-relative-and-metric-depth-official-implementation--","urlHash":2316793729},"bed410ea-20cf-4747-bb08-545254a5dff1":{"favIconUrl":"fallback","id":"bed410ea-20cf-4747-bb08-545254a5dff1","title":"(313) Let's Play Planescape Torment - 02 Mortuary Level 2 - YouTube","url":"https://www.youtube.com/watch?v=NuTf6SZul20&list=PLzw_r3FRBpcOPmDhUkdf9YRE9PYpzaWz0&index=4","urlHash":1152054565},"beeb28cd-0658-4052-92b1-a198b00af325":{"favIconUrl":"fallback","id":"beeb28cd-0658-4052-92b1-a198b00af325","title":"A Collection of Unmitigated Pedantry – Page 5 – A look at history and popular culture","url":"https://acoup.blog/page/5/","urlHash":1853568917},"bf3a298b-1b9b-4bd8-aef2-ceaebce5f0a0":{"favIconUrl":"https://tsmatz.files.wordpress.com/2017/11/cropped-sitelogo.jpg?w=32","id":"bf3a298b-1b9b-4bd8-aef2-ceaebce5f0a0","title":"Implement Model Parallelism in LLMs – tsmatz","url":"https://tsmatz.wordpress.com/2023/09/21/model-parallelism/","urlHash":263844596},"bf479fad-fca9-4efa-9d54-f8017a95609c":{"favIconUrl":"fallback","id":"bf479fad-fca9-4efa-9d54-f8017a95609c","title":"Adversarial Concurrent Training Optimizing Robustness and Accuracy Trade-off of Deep Neural Networks - Arxiv-2008.07015","url":"https://arxiv.org/abs/2008.07015","urlHash":4023564093},"bf78c7c6-7d1a-41f6-8c93-cd518deba06b":{"favIconUrl":"https://www.google.com/favicon.ico","id":"bf78c7c6-7d1a-41f6-8c93-cd518deba06b","title":"《多米诺少女》 - Google Search","url":"https://www.google.com/search?q=%0A%E3%80%8A%E5%A4%9A%E7%B1%B3%E8%AF%BA%E5%B0%91%E5%A5%B3%E3%80%8B","urlHash":3343282784},"bfb0f44c-dbda-40b1-ab1c-a715c43885dc":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"bfb0f44c-dbda-40b1-ab1c-a715c43885dc","title":"srush/GPU-Puzzles: Solve puzzles. Learn CUDA.","url":"https://github.com/srush/GPU-Puzzles","urlHash":966755570},"bfc472bc-c86f-4d02-b423-4d4535348c6e":{"favIconUrl":"https://wikiwandv2-19431.kxcdn.com/icons/favicon.ico","id":"bfc472bc-c86f-4d02-b423-4d4535348c6e","title":"Transcendental idealism - Wikiwand","url":"https://www.wikiwand.com/en/Transcendental_idealism","urlHash":553826425},"bfd013ed-3863-4f9f-a5d8-bf8132535be4":{"favIconUrl":"fallback","id":"bfd013ed-3863-4f9f-a5d8-bf8132535be4","title":"COS 597Q AI Safety","url":"https://sites.google.com/view/cos598aisafety/","urlHash":3778121923},"bfd1aefc-b1b4-476b-82a7-708c3acc4d15":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"bfd1aefc-b1b4-476b-82a7-708c3acc4d15","title":"Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution | Abstract","url":"https://arxiv.org/abs/2310.16834","urlHash":3187485395},"bfda56f2-e59a-4e65-99ce-c2925b9c6eb1":{"favIconUrl":"https://www.google.com/favicon.ico","id":"bfda56f2-e59a-4e65-99ce-c2925b9c6eb1","title":"Large Language Models Can Self-improve - Google Search","url":"https://www.google.com/search?q=Large%20Language%20Models%20Can%20Self-improve","urlHash":181205551},"c00629c5-5209-4ca4-9f56-a7f2519bb6b0":{"favIconUrl":"fallback","id":"c00629c5-5209-4ca4-9f56-a7f2519bb6b0","title":"石榴记小说在线阅读 - 小椴 - 武侠小说网","url":"https://wx.tianyabooks.com/book/xdwx1/","urlHash":67418766},"c012bc37-3ebe-42bc-8fda-fd0751883584":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c012bc37-3ebe-42bc-8fda-fd0751883584","title":"Seongyun Lee on X: \"We are excited to introduce 🌋 Volcano, a multimodal model that revises hallucination in responses through self-feedback. It achieves state-of-the-art on multimodal hallucination benchmarks. https://t.co/LShtnasgjZ\" / X","url":"https://twitter.com/sylee_ai/status/1724364980622114849","urlHash":1172487478},"c02ed538-a7bb-496f-b855-f092e6dc2de6":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c02ed538-a7bb-496f-b855-f092e6dc2de6","title":"jack morris on X: \"fun idea I tested out this morning: Language model fine-tuning in embedding space here's the idea: learn a model of *embeddings* of a certain text distribution; then, to generate text, sample embedding and map back to text with vec2text this lets us generate language without… https://t.co/9PPI9q5KiM\" / X","url":"https://twitter.com/jxmnop/status/1734961947227897983","urlHash":3987550705},"c0508d45-5791-4447-86f5-6de739bc52a1":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"c0508d45-5791-4447-86f5-6de739bc52a1","title":"清华微软开源全新提示词压缩工具，长度骤降80%！GitHub怒砍3.1K星","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652460534&idx=4&sn=3c06fb8e1a6777d1663931497394ec75&chksm=f12a2107c65da811c0b30c1c626f7dc4a297d77e9f8570dbaff75428628715822b646a201138&mpshare=1&scene=1&srcid=0325UouF7TPXYwloIKI4y9rt&sharer_shareinfo=f82747ad1c8691a43e770b7ce551e2fd&sharer_shareinfo_first=f82747ad1c8691a43e770b7ce551e2fd&exportkey=n_ChQIAhIQ8E%2FS%2BZG2Bq%2BSqRq%2BnvWlThKWAgIE97dBBAEAAAAAAPQZAQdtGCMAAAAOpnltbLcz9gKNyK89dVj0lfLfHwH%2Bv8kSwcVefDrfrH4h9mdHdaazUHjCgEgKQhxqKcVQ45xMxpohjNhSpQomgbgwbgSlWf%2BRki9JL8JXqLZVEY%2FNv2Dx2LyEUDpZNz1lowPFQxwA86X73QAiDGlKZmkY6WIjdpNLxLzNKiwDy0O5%2F5PRdddu5nt60spVohl9yQ%2FmAWGhVBubSanJpiHR5r8X3aVIV0z%2FLPbxwZgeqgc774Qlo5cDoh4QZwcM1T4BPB6eXSM5Dcxx8EiOvB2UUVNgPQNN99LF2lWBrAf9ZMxniJ6F5LARBBs4W3Wjr5ajGGcfCHIqKgefA1gO36I%2F&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCOWwy3r814dCBB%2FXF%2FH8jxPeS70DR541pRsySfcElj50Q%3D%3D&wx_header=0#rd","urlHash":2466336466},"c051997f-01eb-4b9b-95aa-528e1537bc93":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"c051997f-01eb-4b9b-95aa-528e1537bc93","title":"Pixel Aligned Language Models | Abstract","url":"https://arxiv.org/abs/2312.09237","urlHash":2986276682},"c066d29a-1260-4692-8aa9-a8b8ca822bf2":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"c066d29a-1260-4692-8aa9-a8b8ca822bf2","title":"RealFormer：把残差转移到Attention矩阵上面去 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/8027","urlHash":2917537480},"c0864925-b1da-4ed2-b921-530c8bb00932":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"c0864925-b1da-4ed2-b921-530c8bb00932","title":"langgraph/examples/web-navigation/web_voyager.ipynb at main · langchain-ai/langgraph","url":"https://github.com/langchain-ai/langgraph/blob/main/examples/web-navigation/web_voyager.ipynb","urlHash":4208793584},"c0898cd5-4346-4a6c-a825-03b32318697a":{"favIconUrl":"https://www.google.com/favicon.ico","id":"c0898cd5-4346-4a6c-a825-03b32318697a","title":"predictability and surprise in large generative models - Google Search","url":"https://www.google.com/search?q=predictability+and+surprise+in+large+generative+models&oq=Predictability+and+Surprise+in+Large+Generative+Models&aqs=chrome.0.35i39j0i390l3j69i61j69i60.2084j0j1&sourceid=chrome&ie=UTF-8","urlHash":271851272},"c0c580ae-fad5-4500-9e19-91ba8ca34637":{"favIconUrl":"fallback","id":"c0c580ae-fad5-4500-9e19-91ba8ca34637","title":"Understanding and Utilizing Deep Neural Networks Trained with Noisy Labels","url":"https://proceedings.mlr.press/v97/chen19g/chen19g.pdf","urlHash":3518235943},"c0c764d9-1cf4-4503-8760-036f9a8fe313":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"c0c764d9-1cf4-4503-8760-036f9a8fe313","title":"Improving Factuality and Reasoning in Language Models through Multiagent Debate | PDF","url":"https://arxiv.org/pdf/2305.14325.pdf","urlHash":3361585667},"c10c90aa-73d0-4658-a860-d2fab31a5e82":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c10c90aa-73d0-4658-a860-d2fab31a5e82","title":"Kyunghyun Cho on X: \"a random thought on RAG, inspired by the (successful) phd defense of @mrdrozdov (the committee consists of @andrewmccallum, @MohitIyyer, @JonathanBerant, @HamedZamani and me) https://t.co/JkiUGjW0PC https://t.co/xwFRTOrJqt\" / X","url":"https://twitter.com/kchonyc/status/1758227767722947037","urlHash":1649983506},"c13a499c-18e3-449d-9d41-0d481431d0b1":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"c13a499c-18e3-449d-9d41-0d481431d0b1","title":"涙香迷宮 短评","url":"https://book.douban.com/subject/26728812/comments/","urlHash":1941645871},"c1488719-75d7-44bb-a668-41200ef30079":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c1488719-75d7-44bb-a668-41200ef30079","title":"Aran Komatsuzaki on X: \"Transformers Can Achieve Length Generalization But Not Robustly Length generalization remains fragile, significantly influenced by factors like random weight initialization and training data order https://t.co/aVTXAMwOn0 https://t.co/1cJQxB5Cqn\" / X","url":"https://twitter.com/arankomatsuzaki/status/1757948361540554809","urlHash":1074566383},"c1590af1-517e-48a6-874b-78327b19b3fa":{"favIconUrl":"fallback","id":"c1590af1-517e-48a6-874b-78327b19b3fa","title":"Gradient Estimation Using Stochastic Computation Graphs - Arxiv-1506.05254","url":"https://arxiv.org/pdf/1506.05254.pdf","urlHash":372160207},"c19e0700-c6c7-4313-bcb5-ac3b00ff138a":{"favIconUrl":"https://cdn.semanticscholar.org/b5fbde4a4847434e/img/darkmode/favicon-32x32.png","id":"c19e0700-c6c7-4313-bcb5-ac3b00ff138a","title":"Transformers Can Be Expressed In First-Order Logic with Majority | Semantic Scholar","url":"https://www.semanticscholar.org/paper/Transformers-Can-Be-Expressed-In-First-Order-Logic-Merrill-Sabharwal/c901f3aa4dc4aaa45bd624401691e305d8573b2e","urlHash":2470710019},"c1dd8690-cd89-4670-91f4-c403b3e93896":{"favIconUrl":"https://www.google.com/favicon.ico","id":"c1dd8690-cd89-4670-91f4-c403b3e93896","title":"邪教の神 - Google Search","url":"https://www.google.com/search?q=%E9%82%AA%E6%95%99%E3%81%AE%E7%A5%9E","urlHash":765788410},"c1fcdc0d-20a2-4c09-acc8-d4ccda43e0be":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"c1fcdc0d-20a2-4c09-acc8-d4ccda43e0be","title":"Analyzing and Mitigating Object Hallucination in Large Vision-Language Models | PDF","url":"https://arxiv.org/pdf/2310.00754.pdf","urlHash":235623791},"c2383779-91f1-4b52-b684-c4dc51bcd043":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"c2383779-91f1-4b52-b684-c4dc51bcd043","title":"本店招牌菜 (豆瓣)","url":"https://book.douban.com/subject/30458315/","urlHash":1731020068},"c264cbda-9afa-4cb6-a1c4-a7f4a681a4b8":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c264cbda-9afa-4cb6-a1c4-a7f4a681a4b8","title":"Sherry Yang on X: \"Introducing Universal Simulator (UniSim), an interactive simulator of the real world. Interactive website: https://t.co/c3aQazNYXq Paper: https://t.co/1IdxKQAHsd https://t.co/E1CUbn3lrm\" / X","url":"https://twitter.com/mengjiao_yang/status/1712153304757915925","urlHash":1588282828},"c276f136-3710-48c3-8fe2-760321a85b55":{"favIconUrl":"fallback","id":"c276f136-3710-48c3-8fe2-760321a85b55","title":"Learning to rank using gradient descent 知乎 - Google Search","url":"https://www.google.com/search?q=Learning+to+rank+using+gradient+descent+%E7%9F%A5%E4%B9%8E&newwindow=1&sxsrf=ALiCzsb7rXPRYJd0HBK0d_3R7rnzJz1ZCg%3A1656810633838&ei=iezAYoPYMsjPkPIPkOegyA8&oq=Learning+to+rank+using+gradient+descent+%E7%9F%A5%E4%B9%8E&gs_lcp=ChNtb2JpbGUtZ3dzLXdpei1zZXJwEAM6BwgAEEcQsAM6BwgAELADEEM6BggAEB4QFjoFCAAQhgM6BQghEKABSgQIQRgAUMMNWMMXYIcZaAFwAXgAgAGcAYgBswKSAQMwLjKYAQCgAQHIAQvAAQE&sclient=mobile-gws-wiz-serp","urlHash":1676150892},"c280a938-ba31-4386-904e-552bde60bdb1":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c280a938-ba31-4386-904e-552bde60bdb1","title":"AK on X: \"Agent-FLAN Designing Data and Methods of Effective Agent Tuning for Large Language Models Open-sourced Large Language Models (LLMs) have achieved great success in various NLP tasks, however, they are still far inferior to API-based models when acting as agents. How to https://t.co/Ib6EKfQfp4\" / X","url":"https://twitter.com/_akhaliq/status/1770302813152690259?utm_source=substack&utm_medium=email","urlHash":2179938862},"c2892429-e2ee-4f4a-8ae2-a16754aa8469":{"favIconUrl":"fallback","id":"c2892429-e2ee-4f4a-8ae2-a16754aa8469","title":"鼻子（芥川龙之介著短篇小说）_百度百科","url":"https://baike.baidu.com/item/%E9%BC%BB%E5%AD%90/1331266","urlHash":2226480186},"c2a94995-02b4-4443-803b-f2538c6d5a3a":{"favIconUrl":"fallback","id":"c2a94995-02b4-4443-803b-f2538c6d5a3a","title":"Bullseye Polytope: A Scalable Clean-Label Poisoning Attack with Improved Transferability","url":"https://arxiv.org/pdf/2005.00191.pdf","urlHash":3391756380},"c2e8d387-bddc-4f8d-ab38-ec813b61d049":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c2e8d387-bddc-4f8d-ab38-ec813b61d049","title":"AK on X: \"ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent paper page: https://t.co/6nb1q96q5u Answering complex natural language questions often necessitates multi-step reasoning and integrating external information. Several systems have combined knowledge retrieval… https://t.co/EcaCJCOPPF\" / X","url":"https://twitter.com/_akhaliq/status/1736581357705314731","urlHash":3625623242},"c2f1e397-da38-4d3e-b437-ee334355d2d9":{"favIconUrl":"data:image/svg+xml,%0A                  <svg%0A                    width=\"96\"%0A                    height=\"96\"%0A                    viewBox=\"0 0 96 96\"%0A                    fill=\"none\"%0A                    style=\"color:rgba(0,0,0,1);fill:rgba(81,218,76,1)\"%0A                    xmlns=\"http://www.w3.org/2000/svg\">%0A                  <rect width=\"96\" height=\"96\"/>%0A                  <path d=\"M78.8303 41.4616C79.637 39.0379 79.9168 36.4697 79.651 33.9291C79.3852 31.3885 78.5798 28.9339 77.2888 26.7296C75.3745 23.3959 72.4506 20.7564 68.9389 19.1921C65.4273 17.6277 61.5095 17.2193 57.7507 18.0258C56.0552 16.1152 53.9712 14.5888 51.6382 13.5487C49.3051 12.5086 46.7768 11.9788 44.2224 11.9948C40.3794 11.9857 36.6328 13.1972 33.5226 15.4546C30.4125 17.7119 28.0995 20.8985 26.917 24.5551C24.4136 25.0679 22.0486 26.1094 19.9801 27.61C17.9117 29.1105 16.1876 31.0355 14.923 33.2561C12.9938 36.5809 12.1704 40.4326 12.5717 44.2556C12.973 48.0787 14.5782 51.6755 17.1558 54.5272C16.3487 56.9509 16.0686 59.519 16.3342 62.0596C16.5998 64.6003 17.405 67.0549 18.6958 69.2592C20.6102 72.593 23.5341 75.2325 27.0457 76.7968C30.5573 78.3612 34.4752 78.7695 38.2339 77.963C39.9291 79.874 42.0131 81.4007 44.3462 82.4408C46.6793 83.4809 49.2078 84.0105 51.7623 83.9941C55.6081 84.0053 59.358 82.794 62.4706 80.5351C65.5832 78.2762 67.8974 75.0865 69.079 71.4267C71.5826 70.9144 73.9478 69.8731 76.0163 68.3725C78.0849 66.8719 79.8089 64.9467 81.073 62.7257C82.9995 59.4007 83.8204 55.5498 83.4173 51.7282C83.0143 47.9065 81.4081 44.3116 78.8303 41.4616ZM51.9099 79.2873C48.3273 79.2873 45.5538 78.1873 43.1309 76.1646C43.2402 76.105 43.4318 76 43.5567 75.9233L57.8927 67.6425C58.2527 67.438 58.5517 67.1412 58.7587 66.7827C58.9658 66.4242 59.0735 66.0169 59.0708 65.6029V45.392L65.1316 48.8908C65.1633 48.9068 65.1905 48.9303 65.211 48.9593C65.2316 48.9882 65.2447 49.0217 65.2494 49.0569V65.7902C65.248 73.3826 58.9274 79.2873 51.9099 79.2873ZM22.778 66.9059C21.197 64.1743 20.6272 60.9736 21.1684 57.8643C21.2749 57.9281 21.4608 58.0417 21.5942 58.1183L35.9302 66.3991C36.2874 66.6082 36.6938 66.7184 37.1076 66.7184C37.5215 66.7184 37.9279 66.6082 38.285 66.3991L55.7877 56.293V63.2906C55.7898 63.3264 55.783 63.3621 55.7679 63.3946C55.7528 63.427 55.7298 63.4552 55.7011 63.4766L41.209 71.844C38.1091 73.6293 34.4277 74.112 30.9724 73.1862C27.517 72.2604 24.5701 70.0018 22.778 66.9059ZM19.001 35.6094C20.5754 32.8745 23.0615 30.7803 26.0242 29.6933C26.0242 29.8168 26.0242 30.0354 26.0242 30.1873V46.7489C26.0212 47.1626 26.1287 47.5696 26.3356 47.9279C26.5424 48.2862 26.8411 48.5828 27.2009 48.7872L44.7021 58.8919L38.6427 62.3907C38.6127 62.4103 38.5784 62.4222 38.5428 62.4254C38.5072 62.4287 38.4713 62.4231 38.4383 62.4092L23.9448 54.0347C20.8494 52.2436 18.5907 49.2981 17.6639 45.8441C16.7371 42.39 17.218 38.7094 19.001 35.6094ZM68.7909 47.196L51.2882 37.0899L57.3476 33.5925C57.3776 33.5729 57.4119 33.561 57.4475 33.5577C57.4832 33.5545 57.519 33.5601 57.552 33.574L72.0455 41.9442C74.2647 43.2275 76.0724 45.1162 77.2572 47.3894C78.4421 49.6626 78.955 52.2263 78.7359 54.7804C78.5169 57.3344 77.575 59.7733 76.0204 61.8116C74.4658 63.8498 72.3628 65.4032 69.9576 66.2898V49.2329C69.961 48.8204 69.8548 48.4145 69.6498 48.0566C69.4448 47.6987 69.1483 47.4017 68.7909 47.196ZM74.8219 38.1118C74.7154 38.0465 74.5295 37.9344 74.3961 37.8578L60.0601 29.577C59.7027 29.3685 59.2964 29.2586 58.8827 29.2586C58.469 29.2586 58.0627 29.3685 57.7053 29.577L40.2026 39.6831V32.6855C40.2006 32.6497 40.2075 32.6141 40.2226 32.5816C40.2377 32.5492 40.2606 32.521 40.2892 32.4995L54.7813 24.1392C57.0015 22.859 59.5404 22.2375 62.1008 22.3474C64.6613 22.4574 67.1375 23.2941 69.2398 24.7599C71.3421 26.2257 72.9836 28.2598 73.9721 30.6243C74.9606 32.9888 75.2554 35.5859 74.8219 38.1118ZM36.9082 50.5898L30.8473 47.091C30.8152 47.0756 30.7876 47.0522 30.767 47.0232C30.7464 46.9941 30.7335 46.9603 30.7295 46.9249V30.1873C30.7312 27.6237 31.463 25.1137 32.8394 22.951C34.2158 20.7882 36.1797 19.0623 38.5014 17.9752C40.823 16.8881 43.4063 16.4848 45.9488 16.8125C48.4914 17.1402 50.8879 18.1854 52.858 19.8256C52.7487 19.8853 52.5585 19.9903 52.4322 20.0669L38.0962 28.3478C37.7367 28.5525 37.4381 28.8491 37.2311 29.2073C37.0241 29.5655 36.9161 29.9723 36.9181 30.386L36.9082 50.5898ZM40.1998 43.4928L47.9952 38.9904L55.7905 43.49V52.4918L47.9952 56.9899L40.1998 52.4904V43.4928Z\" fill=\"currentColor\"/>%0A                  </svg>","id":"c2f1e397-da38-4d3e-b437-ee334355d2d9","title":"Language models can explain neurons in language models","url":"https://openai.com/research/language-models-can-explain-neurons-in-language-models","urlHash":2754160646},"c31a4188-7070-46f4-8d61-d633712179b1":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c31a4188-7070-46f4-8d61-d633712179b1","title":"Aran Komatsuzaki on X: \"V-IRL: Grounding Virtual Intelligence in Real Life Presents an open-source framework for embodied agent and open-world computer vision research proj: https://t.co/O6bzlqPcGe repo: https://t.co/RlaL11XQkr abs: https://t.co/6riykUnS1C https://t.co/Xqda3WKhVI\" / X","url":"https://twitter.com/arankomatsuzaki/status/1754695888348274838","urlHash":4047896486},"c36da87e-41d6-4ecf-97ee-8bf977f4b1e2":{"favIconUrl":"fallback","id":"c36da87e-41d6-4ecf-97ee-8bf977f4b1e2","title":"Single Shot Detector (SSD). What is SSD?","url":"https://gullayeshwantkumarruler.medium.com/single-shot-detector-ssd-a299f437f6ef","urlHash":2150314259},"c37892df-a525-494f-a595-fe99426cc450":{"favIconUrl":"fallback","id":"c37892df-a525-494f-a595-fe99426cc450","title":"未来千年文学备忘录 - 搜索结果 - 知乎","url":"https://www.zhihu.com/search?q=%E6%9C%AA%E6%9D%A5%E5%8D%83%E5%B9%B4%E6%96%87%E5%AD%A6%E5%A4%87%E5%BF%98%E5%BD%95&type=content","urlHash":1282127958},"c37a4f86-764d-4363-a3e0-466d4144edee":{"favIconUrl":"fallback","id":"c37a4f86-764d-4363-a3e0-466d4144edee","title":"存在与虚无 - 搜索结果 - 知乎","url":"https://www.zhihu.com/search?q=%E5%AD%98%E5%9C%A8%E4%B8%8E%E8%99%9A%E6%97%A0&type=content","urlHash":3575476337},"c39e6e12-f9a1-45b4-a781-0e4813a1fe4c":{"favIconUrl":"fallback","id":"c39e6e12-f9a1-45b4-a781-0e4813a1fe4c","title":"统治扩散模型的U-Net要被取代了，谢赛宁等引入Transformer提出DiT","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650864226&idx=3&sn=44a9b991a0eba9b16ca8fc575d9e3685&chksm=84e53e1cb392b70a7382611dee0cec478c1180f573013aadf2c086f35bdda6ea4c728b9edead&mpshare=1&scene=1&srcid=1224kJ13eUE0cNf2GNH9AT5u&sharer_sharetime=1671836770873&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQ0HpEpWPPojp71BqhZscKARKUAgIE97dBBAEAAAAAAGAFKyyeEGQAAAAOpnltbLcz9gKNyK89dVj0NXuugfCzE2O8UZH3z06gk9Ug2obhOOxzF%2FNn6NA%2BHa%2B%2BGxhG5Zye4PG8yss5WXq99b8ElQB8eEfxDojjXexz33q8iQA7yeYAEntpQy3xT9iwfIrtq4Lux1%2BH61Xw06xitYu%2Filu4Geww0h604oyF0cfxz1kIQcC4X40ajXQ28lmQn5%2BGxqo7cOQWzhFVhEyUUpHF1h9NopX5PYwHtj%2Fm8Z7bvfUfzOnLNpu61m5SBm3qmtvENC8jmvwDr3o1QzmNY0%2FJOi7snzG0ie40p5dMEIzpgg01%2BfvthmCafw5k6mFWXH9fExhrokXmsgQqSA%3D%3D&acctmode=0&pass_ticket=RuGGTB4SplvCwKsI2KQuIGeMic0YEMrpZC0xdlI2bqbLFRwR3pxiQhTHo50quxu1e65Mg%2Ffoz1ivddwfWjHoWA%3D%3D&wx_header=0#rd","urlHash":1940859527},"c39ea286-ed32-4450-996d-8d8a24b8b024":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"c39ea286-ed32-4450-996d-8d8a24b8b024","title":"(3) Pan Lu on X: \"Model editing has been an effective way to reduce hallucinations in LLMs, instead of undergoing resource-intensive retraining. 🤯However, our study, led by @JasonForJoy, @kaiwei_chang, &amp; @VioletNPeng, reveals that current methods inadvertently impair the general skills of LLMs.… https://t.co/Q6tD5Z2LxH\" / X","url":"https://twitter.com/lupantech/status/1749570926566601063","urlHash":2716793272},"c4189adf-6865-4e4a-9bd0-fc6190a20e90":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c4189adf-6865-4e4a-9bd0-fc6190a20e90","title":"Ellen Wu on X: \"F in RLHF is overall preference, which conveys limited info🙁 We introduce Fine-Grained RLHF🚀and train LMs with explicit feedback like \"sentence 1 is not factual\", \"sentence 2 is toxic\" More effective &amp; enables LM customization https://t.co/hQaopuG2QM https://t.co/UqizqhLGcl https://t.co/kYHRrn3tlL\" / X","url":"https://twitter.com/zeqiuwu1/status/1665785626552049665","urlHash":1352976111},"c43ff2e7-b38f-455a-ae6e-5c78375b7fd3":{"favIconUrl":"fallback","id":"c43ff2e7-b38f-455a-ae6e-5c78375b7fd3","title":"Captum · Model Interpretability for PyTorch","url":"https://captum.ai/api/","urlHash":973385699},"c4536252-a3d0-4e8f-a4da-6421e9d16810":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"c4536252-a3d0-4e8f-a4da-6421e9d16810","title":"Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models | Abstract","url":"https://arxiv.org/abs/2401.01335?utm_source=substack&utm_medium=email","urlHash":3283724031},"c492e52f-0d83-4aff-b21a-cec1c79f4a6b":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"c492e52f-0d83-4aff-b21a-cec1c79f4a6b","title":"Battle of the Backbones: A Large-Scale Comparison of Pretrained Models across Computer Vision Tasks | Abstract","url":"https://arxiv.org/abs/2310.19909?utm_source=substack&utm_medium=email","urlHash":183827198},"c498c501-3668-43f0-9878-ff1ab89d4d8b":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"c498c501-3668-43f0-9878-ff1ab89d4d8b","title":"Vision-Language Models as a Source of Rewards | Abstract","url":"https://arxiv.org/abs/2312.09187","urlHash":2287310892},"c4a37d15-8883-492f-a22f-5b1cd0f3e411":{"favIconUrl":"fallback","id":"c4a37d15-8883-492f-a22f-5b1cd0f3e411","title":"Eric Jang","url":"https://blog.evjang.com/","urlHash":465384838},"c4b0ddc0-c644-45b3-8985-2e7dbbf0f6ec":{"favIconUrl":"fallback","id":"c4b0ddc0-c644-45b3-8985-2e7dbbf0f6ec","title":"tgxs002/HPSv2: Human Preference Score v2: A Solid Benchmark for Evaluating Human Preferences of Text-to-Image Synthesis","url":"https://github.com/tgxs002/HPSv2","urlHash":3333984578},"c4d3c175-0a37-48db-9a2f-0fcb62b40ad8":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c4d3c175-0a37-48db-9a2f-0fcb62b40ad8","title":"Yam Peleg on X: \"@_jasonwei I have to say that I do not agree. These emergent properties aren't \"really emergent\" but simply exists in some shape or from in the data that the model has been trained on during it's base training. (yes this \"shape or form\" can be obscure..) During clm training the model…\" / X","url":"https://twitter.com/Yampeleg/status/1687839882025095169","urlHash":1862230878},"c4eccd60-b44f-4e92-b644-238c0e3c590e":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"c4eccd60-b44f-4e92-b644-238c0e3c590e","title":"read-agent.github.io/assets/read_agent_demo.ipynb at main · read-agent/read-agent.github.io","url":"https://github.com/read-agent/read-agent.github.io/blob/main/assets/read_agent_demo.ipynb","urlHash":1755558419},"c50933d5-e152-4710-9243-58a8a509aa42":{"favIconUrl":"fallback","id":"c50933d5-e152-4710-9243-58a8a509aa42","title":"The Reformer - Pushing the limits of language modeling","url":"https://huggingface.co/blog/reformer","urlHash":4133385474},"c54e1de3-6df7-436f-bce1-f81f75504f99":{"favIconUrl":"fallback","id":"c54e1de3-6df7-436f-bce1-f81f75504f99","title":"FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence","url":"https://proceedings.neurips.cc/paper/2020/hash/06964dce9addb1c5cb5d6e3d9838f733-Abstract.html","urlHash":3786625761},"c5768efd-6ea8-40eb-8148-6ac67dce9b99":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c5768efd-6ea8-40eb-8148-6ac67dce9b99","title":"Prasann Singhal on X: \"Why does RLHF make outputs longer? https://t.co/Huols1JbQJ w/ @tanyaagoyal @JiachengNLP @gregd_nlp On 3 “helpfulness” settings - Reward models correlate strongly with length - RLHF makes outputs longer - *only* optimizing for length reproduces most RLHF gains 🧵 below: https://t.co/XuUR2KSyKp\" / X","url":"https://twitter.com/prasann_singhal/status/1710303478096986595","urlHash":3751017003},"c5c08a29-107a-464f-b2a4-906cc27855d9":{"favIconUrl":"https://www.harmdevries.com/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_32x32_fill_lanczos_center_3.png","id":"c5c08a29-107a-464f-b2a4-906cc27855d9","title":"Go smol or go home | Harm de Vries","url":"https://www.harmdevries.com/post/model-size-vs-compute-overhead/","urlHash":1892991813},"c5c8a119-4853-4d6e-bbb6-700125674829":{"favIconUrl":"https://www.sto.cx/favicon.ico","id":"c5c8a119-4853-4d6e-bbb6-700125674829","title":"[英]安东尼*伯克莱《毒巧克力命案》_全文在線閱讀_思兔","url":"https://www.sto.cx/book-27723-1.html","urlHash":4123743357},"c5d60d98-e3f3-4733-8626-9bc760baa6c3":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"c5d60d98-e3f3-4733-8626-9bc760baa6c3","title":"Attention机制竟有bug，Softmax是罪魁祸首，影响所有Transformer","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650885185&idx=1&sn=9ad720fe3cc910961abcdf14b4ce869d&exportkey=n_ChQIAhIQS3ZAbcI4t4Hxl7rx%2BphMvBKWAgIE97dBBAEAAAAAALCoI%2FafZjYAAAAOpnltbLcz9gKNyK89dVj0FW6au9Ox%2F68b6V9fx4nbi%2FiuCKwGT1imKyZ72t1%2FM%2FqvdFFe1uvy7FcdS7qMcF7EVVLJksWbxH0oVPIRTnnsEzgzsjuyU%2BHXpPeG5gSWDuX4D1YicEK%2BEYg4JFcNsKDv2ClNczmKNpwyHk8PFXmVX2wFRvkXe0WyzIpG2gKL8rzBUBm1VsLfFC7N8mucKoam%2BmhTARkiCT4M2CqaLDwTQLmJymLSpRntiasfiaHPXaqVqBjP1LvC9hfhrT3qfrUORGIHVbM9LLMKgbfR6wa10QbIEpNWCCCmfaW5MEcWsYjG5dB3ak7JY6vWTBFOo6RH&acctmode=0&pass_ticket=QZdJ8UXaUisGuHM4kPbJZ581BD%2F%2Fu5zba2lQfyyNFZAzTDSSoO6xb0LByFuIXv7i&wx_header=0","urlHash":1150959091},"c61cad5c-680b-4047-8ade-8047e5af4522":{"favIconUrl":"fallback","id":"c61cad5c-680b-4047-8ade-8047e5af4522","title":"HIVE Harnessing Human Feedback for Instructional Visual Editing - Arxiv-2303.09618","url":"https://arxiv.org/pdf/2303.09618.pdf","urlHash":3058981446},"c66e0400-d22d-4c4f-be14-3e63976b6792":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c66e0400-d22d-4c4f-be14-3e63976b6792","title":"Samuel Paccoud on X: \"RLHF is doomed. We will have to crowdsource the finetuning of à few opensource LLM the way wikipedia was built. This take by @ylecun on LLM is priceless 🤯https://t.co/ySvTssn8fH\" / X","url":"https://twitter.com/sampaccoud/status/1667409987486855168","urlHash":3498603585},"c698e970-ece8-478d-8292-7cbd04bad8d2":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"c698e970-ece8-478d-8292-7cbd04bad8d2","title":"战国·白云谣 (豆瓣)","url":"https://book.douban.com/subject/35501248/","urlHash":1756684421},"c6a7e124-56d8-4cd7-8f5b-dcf4a99646aa":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"c6a7e124-56d8-4cd7-8f5b-dcf4a99646aa","title":"Llemma: An Open Language Model For Mathematics | Abstract","url":"https://arxiv.org/abs/2310.10631?utm_source=substack&utm_medium=email","urlHash":1494404288},"c6ac2b81-7afa-4a62-bc3b-3185fda344bc":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c6ac2b81-7afa-4a62-bc3b-3185fda344bc","title":"Leo Tronchon on X: \"2024 is the year of multimodal, but also of synthetic data! 👨‍🔬 GPT4-V is pretty good at image to code, but most open-source VLMs struggle. Since there were no scaled Image2Code datasets, we decided to generate, our own, WebSight : https://t.co/MoSkZDhHSg We used both…\" / X","url":"https://twitter.com/LeoTronchon/status/1746952870824394953","urlHash":4196751272},"c6b01bdd-6532-4cef-8256-2998b5ac229e":{"favIconUrl":"fallback","id":"c6b01bdd-6532-4cef-8256-2998b5ac229e","title":"Learning with not Enough Data Part 2: Active Learning","url":"https://lilianweng.github.io/posts/2022-02-20-active-learning/","urlHash":3998480869},"c6e38d33-0e1b-4015-82e5-80c6d3d7b570":{"favIconUrl":"fallback","id":"c6e38d33-0e1b-4015-82e5-80c6d3d7b570","title":"Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating Spurious Correlations in Entity Typing - Arxiv-2205.12640","url":"https://arxiv.org/pdf/2205.12640.pdf","urlHash":2446432771},"c724c17c-093f-4cbe-8ffa-f557115b148d":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c724c17c-093f-4cbe-8ffa-f557115b148d","title":"Aran Komatsuzaki on X: \"FELM: Benchmarking Factuality Evaluation of Large Language Models Reveals that while retrieval aids factuality evaluation, current LLMs are far from satisfactory to faithfully detect factual errors. abs: https://t.co/hsq8Gi97Cb data: https://t.co/4qYYLLXHZR https://t.co/xhSG2LOgDg\" / X","url":"https://twitter.com/arankomatsuzaki/status/1709212709634318468","urlHash":1087047865},"c74c8a32-0927-4d1a-8d03-ec2d6bc507a8":{"favIconUrl":"fallback","id":"c74c8a32-0927-4d1a-8d03-ec2d6bc507a8","title":"fitteddp_annotated.pdf","url":"https://shamulent.github.io/RL_2023/Lectures/fitteddp_annotated.pdf","urlHash":1116518669},"c77f214c-44f0-482c-90bf-b0a01aa50918":{"favIconUrl":"fallback","id":"c77f214c-44f0-482c-90bf-b0a01aa50918","title":"Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback","url":"https://arxiv.org/pdf/2204.05862.pdf","urlHash":386166186},"c7b9b7a5-c529-456b-89e8-b7e7ccfc425a":{"favIconUrl":"fallback","id":"c7b9b7a5-c529-456b-89e8-b7e7ccfc425a","title":"BERT-of-Theseus：基于模块替换的模型压缩方法 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/7575","urlHash":3389522952},"c7fd96c5-0918-4b6d-8c5c-25c542aa554d":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"c7fd96c5-0918-4b6d-8c5c-25c542aa554d","title":"Learning Transformer Programs | PDF","url":"https://arxiv.org/pdf/2306.01128.pdf","urlHash":3603222762},"c8084f28-f9fe-4f84-8150-760c4e4ee891":{"favIconUrl":"fallback","id":"c8084f28-f9fe-4f84-8150-760c4e4ee891","title":"No True State-of-the-Art? OOD Detection Methods are Inconsistent across Datasets - Arxiv-2109.05554","url":"https://arxiv.org/pdf/2109.05554.pdf","urlHash":1116869283},"c80f5bad-d5fa-4f10-afd4-8670a3d7c864":{"favIconUrl":"fallback","id":"c80f5bad-d5fa-4f10-afd4-8670a3d7c864","title":"💡Illustrating the Reformer - 知乎","url":"https://zhuanlan.zhihu.com/p/139220925","urlHash":1337329852},"c8189035-7837-42fb-9959-08d6978ab3f7":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"c8189035-7837-42fb-9959-08d6978ab3f7","title":"Making Large Language Models A Better Foundation For Dense Retrieval | Abstract","url":"https://arxiv.org/abs/2312.15503v1?utm_source=substack&utm_medium=email","urlHash":2020886933},"c8295f25-011a-43ef-be61-3bb148236f16":{"favIconUrl":"fallback","id":"c8295f25-011a-43ef-be61-3bb148236f16","title":"【萝卜日记第32期】十年后仍是虚构作品—机动警察剧场版&真人版 - 知乎","url":"https://zhuanlan.zhihu.com/p/149310341","urlHash":712922125},"c853f1f7-8536-4d1b-8d1b-2f26cf7c67b3":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c853f1f7-8536-4d1b-8d1b-2f26cf7c67b3","title":"AK on X: \"ByteDance presents ReFT Reasoning with Reinforced Fine-Tuning paper page: https://t.co/CjKumrLXsm One way to enhance the reasoning capability of Large Language Models (LLMs) is to conduct Supervised Fine-Tuning (SFT) using Chain-of-Thought (CoT) annotations. This approach does… https://t.co/ii53e57xue\" / X","url":"https://twitter.com/_akhaliq/status/1747820246268887199","urlHash":2878734918},"c875821c-c523-4853-ad65-b899d5026220":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c875821c-c523-4853-ad65-b899d5026220","title":"twitter.com/KaitlynZhou/status/1630692104686157827","url":"https://twitter.com/KaitlynZhou/status/1630692104686157827","urlHash":3267043748},"c889c11a-8af1-4aa5-a0c1-0bb7882ce92b":{"favIconUrl":"fallback","id":"c889c11a-8af1-4aa5-a0c1-0bb7882ce92b","title":"Hungarian algorithm - Wikiwand","url":"https://www.wikiwand.com/en/Hungarian_algorithm","urlHash":3832780452},"c8fd2ace-1846-4b10-9964-6ab70102faee":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"c8fd2ace-1846-4b10-9964-6ab70102faee","title":"Aran Komatsuzaki on X: \"PandaGPT: One Model to Instruction-Follow Them All Combines the multimodal encoders from ImageBind and the LLM from Vicuna to perform as a general-purpose instruction-follower on various modalities. proj: https://t.co/ARhyk8jnBj spaces: https://t.co/fMjBApDOr0 repo:… https://t.co/YxCfw4hqB3\" / X","url":"https://twitter.com/arankomatsuzaki/status/1662998272154259457","urlHash":1650215583},"c924c979-0a65-4cf8-aa1a-277f7065db7f":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"c924c979-0a65-4cf8-aa1a-277f7065db7f","title":"artidoro/frank: FRANK: Factuality Evaluation Benchmark","url":"https://github.com/artidoro/frank","urlHash":3269659312},"c937334b-e4da-466f-a63d-10c763f94b66":{"favIconUrl":"fallback","id":"c937334b-e4da-466f-a63d-10c763f94b66","title":"A Study on ReLU and Softmax in Transformer - Arxiv-2302.06461","url":"https://arxiv.org/pdf/2302.06461.pdf","urlHash":1224442849},"c93dfc43-c2cc-4a92-a418-1be4ed5d86b8":{"favIconUrl":"fallback","id":"c93dfc43-c2cc-4a92-a418-1be4ed5d86b8","title":"CMU 刘鹏飞：NLP的第四范式 - 知乎","url":"https://zhuanlan.zhihu.com/p/397004230","urlHash":337187663},"c94909f3-f27a-4731-ba8c-85dc654b1ab7":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"c94909f3-f27a-4731-ba8c-85dc654b1ab7","title":"Wider and Deeper LLM Networks are Fairer LLM Evaluators | PDF","url":"https://arxiv.org/pdf/2308.01862.pdf","urlHash":1071077465},"c96aec69-466b-4f59-9ada-83278c76f3a3":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"c96aec69-466b-4f59-9ada-83278c76f3a3","title":"Editing a classifier by rewriting its prediction rules | Abstract","url":"https://arxiv.org/abs/2112.01008","urlHash":1436555628},"c9a122d0-9db0-4af0-a163-95a1ea02b53c":{"favIconUrl":"fallback","id":"c9a122d0-9db0-4af0-a163-95a1ea02b53c","title":"opendilab/awesome-RLHF: A curated list of reinforcement learning with human feedback resources (continually updated)","url":"https://github.com/opendilab/awesome-RLHF","urlHash":398642439},"c9b543fc-a155-446c-b84d-8f8efb5b72bb":{"favIconUrl":"fallback","id":"c9b543fc-a155-446c-b84d-8f8efb5b72bb","title":"maml ++ - Google Search","url":"https://www.google.com/search?q=maml+%2B%2B&oq=maml+%2B%2B&aqs=chrome..69i57j69i65j69i61.1197j0j1&sourceid=chrome&ie=UTF-8","urlHash":344918643},"ca521068-4860-4824-8b42-c1d0530d56c7":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"ca521068-4860-4824-8b42-c1d0530d56c7","title":"Extracting Training Data from Diffusion Models | PDF","url":"https://arxiv.org/pdf/2301.13188.pdf","urlHash":803310930},"ca843290-d994-4c67-afac-85c57d7effd0":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"ca843290-d994-4c67-afac-85c57d7effd0","title":"Yuqing Yang on X: \"How can we make LLMs more ‘honest’? To address this, we propose a new alignment framework, enabling LLMs to candidly answer questions they know and humbly admit to those they do not. paper: https://t.co/Tq7Hn4IMBi website: https://t.co/4UNThJTfK0 🧵(1/7) https://t.co/i6EAQS8k5O\" / X","url":"https://twitter.com/yyqcode/status/1737114284273160267","urlHash":996024474},"caa0ad8e-662c-4a56-a7e3-e176d4144f54":{"favIconUrl":"fallback","id":"caa0ad8e-662c-4a56-a7e3-e176d4144f54","title":"Frankfurt School: On the Concept of History by Walter Benjamin","url":"https://www.marxists.org/reference/archive/benjamin/1940/history.htm","urlHash":4006446050},"caa5950d-d192-411a-97e9-366adba2e0be":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"caa5950d-d192-411a-97e9-366adba2e0be","title":"论文阅读：当博弈论和LLM碰撞，显著提升现有 LM 解码程序的性能。","url":"https://mp.weixin.qq.com/s?__biz=MzkwOTQ0Njg4OA==&mid=2247484350&idx=1&sn=e601cc3245dbd01b1567381b6c5c8456&exportkey=n_ChQIAhIQ0RTCo4vEodTRqQC5tkX7iBKWAgIE97dBBAEAAAAAAI%2FiCvkUrccAAAAOpnltbLcz9gKNyK89dVj0EQaYxTYzCzxjlGJJdTJGy70uOW1z9GeNs4aTmKMMTGMQtCy4YahYe%2BbnIUA9FW9N6kY0LpdnKYXkP9ZmaXlqRaRbvpc%2F6qoz921givh8Ija%2FN%2FOaqsBMn5Mul6aAYc%2BtZpeTujzomSDOTW74myPL5yaqD%2BTrEyBiSe2zh6qjJ8O%2BKooT550Tae8ZqWR6xqnXiP27i48z2M1iGpxRzRVCmzv12SFJBxqqi0UGwSRGXZAHsh94C4L9XdYj3VwWXV4qMXdKy%2Fq3dhFwn5jXEb6ZxQxiVlPzN%2FIlinbM9D2Cmy6caNnDW2Ug9oWxeuMRE2et&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsY0778umch5zpLwhrz8oSj2pZz4cTlI4DhD7V2fQNj0iA%3D%3D&wx_header=0","urlHash":2836132865},"cae831fd-bfc5-4c4e-ad1e-6d2ddd4901a2":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"cae831fd-bfc5-4c4e-ad1e-6d2ddd4901a2","title":"Allen Nie (🇺🇦) @NeurIPS23 on X: \"LLM Alignment News🔥: we measure the alignment between 46 popular LLMs and 5150 people on their implicit preferences when making causal and moral decisions in a NeurIPS paper with @tobigerstenberg, @tatsu_hashimoto, and @chrispiech. 📰: https://t.co/c48KAdgzPG 🧵1/6\" / X","url":"https://twitter.com/Allen_A_N/status/1724858703571218644","urlHash":1192024035},"caf8b0a3-0c9d-4e29-87b6-c1ad27621c2f":{"favIconUrl":"https://transformer-circuits.pub/favicon.ico","id":"caf8b0a3-0c9d-4e29-87b6-c1ad27621c2f","title":"Mechanistic Interpretability, Variables, and the Importance of Interpretable Bases","url":"https://transformer-circuits.pub/2022/mech-interp-essay/index.html","urlHash":2410500236},"cb3e7e65-7c33-467a-bcee-64a3ba61e073":{"favIconUrl":"fallback","id":"cb3e7e65-7c33-467a-bcee-64a3ba61e073","title":"jeffhj/LM-reasoning: This repository contains a collection of papers and resources on Reasoning in Large Language Models.","url":"https://github.com/jeffhj/LM-reasoning","urlHash":1683332089},"cb48416c-a9e4-4be1-be13-7f64e316da86":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"cb48416c-a9e4-4be1-be13-7f64e316da86","title":"Few-shot Learning with Noisy Labels | PDF","url":"https://arxiv.org/pdf/2204.05494.pdf","urlHash":1631528821},"cb743032-7221-46f2-8e23-ad7af56ab9ed":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"cb743032-7221-46f2-8e23-ad7af56ab9ed","title":"DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining | PDF","url":"https://arxiv.org/pdf/2305.10429.pdf","urlHash":1904660049},"cbd9c01f-520d-4ffa-86c0-ba1e20fcdf45":{"favIconUrl":"fallback","id":"cbd9c01f-520d-4ffa-86c0-ba1e20fcdf45","title":"Losses - PyTorch Metric Learning","url":"https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#ncaloss","urlHash":1965724919},"cbf4aaa1-b4e8-4aa7-aa53-b25406cb4edc":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"cbf4aaa1-b4e8-4aa7-aa53-b25406cb4edc","title":"elvis on X: \"Unlocking the Potential of ChatGPT Another nice overview of ChatGPT and its applications, limitations, and future directions. This overview is much shorter but covers some really important points. https://t.co/EPvLm5JlQa https://t.co/jduJpmT3jc\" / X","url":"https://twitter.com/omarsar0/status/1643989136469278722","urlHash":2391020173},"cbf512c5-3d95-4805-8497-0466193de6c7":{"favIconUrl":"fallback","id":"cbf512c5-3d95-4805-8497-0466193de6c7","title":"lucidrains/feedback-transformer-pytorch: Implementation of Feedback Transformer in Pytorch","url":"https://github.com/lucidrains/feedback-transformer-pytorch","urlHash":2522842783},"cc0f3beb-4ac5-4aa8-b21d-9fbd6ff7ceef":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"cc0f3beb-4ac5-4aa8-b21d-9fbd6ff7ceef","title":"elvis on X: \"Noticing lots of focus on LLM evaluation. ICYMI, here are the some of the top ML papers of the past week: 1/ LLMs as Database Administrators 2/ Political Biases Found in NLP Models 3/ Evaluating LLMs as Agents 4/ Studying LLM Generalization with Influence Functions 5/ Seeing… https://t.co/OkNecenchl\" / X","url":"https://twitter.com/omarsar0/status/1691072015296278528","urlHash":676466690},"cc3cace3-6472-4ffa-9b6d-26362bd22ac5":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"cc3cace3-6472-4ffa-9b6d-26362bd22ac5","title":"FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge | PDF","url":"https://arxiv.org/pdf/2305.08281.pdf","urlHash":285012475},"cc54b6b9-402c-4f49-9122-737251dd1cfa":{"favIconUrl":"fallback","id":"cc54b6b9-402c-4f49-9122-737251dd1cfa","title":"AnomalyGPT Detecting Industrial Anomalies using Large Vision-Language Models - Arxiv-2308.15366","url":"https://arxiv.org/abs/2308.15366v3","urlHash":2835709780},"cc56f167-b0c6-4d2b-af2c-c1ddfa4a99dc":{"favIconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","id":"cc56f167-b0c6-4d2b-af2c-c1ddfa4a99dc","title":"No convincing evidence for gradient descent in activation space — LessWrong","url":"https://www.lesswrong.com/posts/HHSuvG2hqAnGT5Wzp/gradient-descent-in-activation-space-a-tale-of-two-papers","urlHash":195902014},"cc66b961-fbe2-450c-b6b7-657ef9174ce5":{"favIconUrl":"fallback","id":"cc66b961-fbe2-450c-b6b7-657ef9174ce5","title":"You can't pick your neighbors, or can you? When and how to rely on retrieval in the $k$NN-LM - Arxiv-2210.15859","url":"https://arxiv.org/abs/2210.15859","urlHash":4099133683},"cc706f41-df72-4513-9c15-e28969b282cd":{"favIconUrl":"https://static.zhihu.com/heifetz/favicon.ico","id":"cc706f41-df72-4513-9c15-e28969b282cd","title":"A100/H100 太贵，何不用 4090？ - 知乎","url":"https://zhuanlan.zhihu.com/p/655402388?utm_id=0","urlHash":3716139216},"cc83f25c-b069-47e9-9ce0-b4928649bd3f":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"cc83f25c-b069-47e9-9ce0-b4928649bd3f","title":"Inference-Time Intervention: Eliciting Truthful Answers from a Language Model | PDF","url":"https://arxiv.org/pdf/2306.03341.pdf","urlHash":3179833187},"ccc618a1-7c3d-406e-afb6-904f0d2464fe":{"favIconUrl":"http://www.guishangtuili.com/favicon.ico","id":"ccc618a1-7c3d-406e-afb6-904f0d2464fe","title":"第五届第一题《兰亭序-十字街记》创作感想 - 推理赛事 - 诡殇推理论坛 - Powered by Discuz!","url":"http://www.guishangtuili.com/forum.php?mod=viewthread&tid=9036","urlHash":1061857164},"cce010b3-671e-48db-aadb-05ec5f023797":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"cce010b3-671e-48db-aadb-05ec5f023797","title":"Anna Ivanova on X: \"Three years in the making - our big review/position piece on the capabilities of large language models (LLMs) from the cognitive science perspective. Thread below! 1/ https://t.co/CwW9qwBpgo\" / X","url":"https://twitter.com/neuranna/status/1615737072207400962","urlHash":679849139},"cd1986f4-2600-4ff1-a69c-05c486a0dbd8":{"favIconUrl":"fallback","id":"cd1986f4-2600-4ff1-a69c-05c486a0dbd8","title":"Towards Robustness to Label Noise in Text Classification via Noise Modeling - Arxiv-2101.11214","url":"https://arxiv.org/abs/2101.11214","urlHash":1051720840},"cd2d0dc8-3240-4d81-a99c-777229f5b8aa":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"cd2d0dc8-3240-4d81-a99c-777229f5b8aa","title":"Evaluating Object Hallucination in Large Vision-Language Models | PDF","url":"https://arxiv.org/pdf/2305.10355.pdf","urlHash":876739350},"cd2f9d62-1c91-47fb-8e64-ccb203f611cb":{"favIconUrl":"fallback","id":"cd2f9d62-1c91-47fb-8e64-ccb203f611cb","title":"函数光滑化杂谈：不可导函数的可导逼近 - 科学空间|Scientific Spaces","url":"https://www.spaces.ac.cn/archives/6620","urlHash":1945307877},"cd60ecea-3433-4a0d-8fdf-16523a9ee437":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"cd60ecea-3433-4a0d-8fdf-16523a9ee437","title":"John Nay on X: \"Making Small LLMs Good at Planning -Symbolic procedural knowledge distillation enhances implicit knowledge in small models + an inference-time algo for structured reasoning -Much smaller models can beat larger teacher LLMs' at Counterfactual Planning https://t.co/UHDatisfPe https://t.co/3BJZAg9Kkz\" / X","url":"https://twitter.com/johnjnay/status/1664079539905994752","urlHash":1841371617},"cd8f5c15-b8d6-434e-9628-a870db958054":{"favIconUrl":"fallback","id":"cd8f5c15-b8d6-434e-9628-a870db958054","title":"Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision - 知乎","url":"https://zhuanlan.zhihu.com/p/36699314","urlHash":2288934486},"cd97bef6-3691-4fd3-bdee-dcd8ca3f2151":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"cd97bef6-3691-4fd3-bdee-dcd8ca3f2151","title":"twitter.com/Shahules786/status/1691137834835640320","url":"https://twitter.com/Shahules786/status/1691137834835640320","urlHash":3161686294},"cdee6d6b-73de-4342-9c0d-d0e6c118cb60":{"favIconUrl":"fallback","id":"cdee6d6b-73de-4342-9c0d-d0e6c118cb60","title":"Bayesian Deep Learning and a Probabilistic Perspective of Generalization - NeurIPS-2020_322f6246","url":"https://proceedings.neurips.cc/paper/2020/file/322f62469c5e3c7dc3e58f5a4d1ea399-Paper.pdf","urlHash":1742756840},"cdf3ac08-a19b-404e-b75f-47ef387205ff":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"cdf3ac08-a19b-404e-b75f-47ef387205ff","title":"twitter.com/huybery/status/1661536683429605376","url":"https://twitter.com/huybery/status/1661536683429605376","urlHash":858249982},"ce39c4fb-d291-4766-88e1-f0ee2aadb3e5":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"ce39c4fb-d291-4766-88e1-f0ee2aadb3e5","title":"Controlling Overestimation Bias with Truncated Mixture of Continuous Distributional Quantile Critics | Abstract","url":"https://arxiv.org/abs/2005.04269","urlHash":2242384802},"ce94acc9-3f81-49fa-ab81-b7140da5449f":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"ce94acc9-3f81-49fa-ab81-b7140da5449f","title":"Swarnadeep Saha on X: \"Talking of weak-to-strong generalization, our #NeurIPS2023 paper shows that it might be possible for weaker teachers to teach stronger students with the right kind of intervention functions. Read more here 👉 https://t.co/lgbRALjajA https://t.co/BTfEereswv\" / X","url":"https://twitter.com/swarnaNLP/status/1735364199960760595","urlHash":3439278483},"ced49039-a246-4786-892e-aa17eba031de":{"favIconUrl":"fallback","id":"ced49039-a246-4786-892e-aa17eba031de","title":"EMNLP 2022 最佳论文揭晓！这脑洞绝了….","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247539037&idx=1&sn=e7214950088bb67210cfc356ad770c17&chksm=970f718ba078f89db9a19155b1a112cb6e425e7191a3a4999aa560b0f47f1a59c18da964f751&mpshare=1&scene=1&srcid=1218rcOan93DpU8Vvc3Ojum3&sharer_sharetime=1671346137769&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQs9SxE%2BQdpPGOSMrFFd0xPxKWAgIE97dBBAEAAAAAAEgyLmzBLUcAAAAOpnltbLcz9gKNyK89dVj0M2CtOBjpjUPagWPQECC1RBblws6Ten6W0n99v2zMc3lt%2BK8l2mG%2F45WTJnz37S%2B5nv%2F26WzMHhjWXVxy3LlnN4y4WK7jnFkn5GVo3UneBfDcXO3Xxj9BFBN4Ja4xo7Q0CMHvV5gntvjHHTXVSqXL49TLcM8P6c7T94iZ2zgdl2cK6kxHhMe1QycXh3PzFIR%2BFWMat3iBtZnsWPx1D7DeLdKQNtnzwM49tSwtv0%2BDQMsLQMICgxpYndeur6KKTUM3QJttD4BiLs0mAzCFbdYVUILLslPNN%2F%2BvstkpLi3PA32%2B1GZQalbKdUxEq6ZN8Mjt&acctmode=0&pass_ticket=B%2Fr2wa0S%2FM5lL%2FB24fD%2FIrSWC3GeT01IvggTYRYcwurIfNm7WOoqiOpddrAS3DLlwj1c8hYtXV9J7sTP2lwaxg%3D%3D&wx_header=0#rd","urlHash":1999806024},"ceda37eb-6a2a-4d4f-9d7a-514eb63ec941":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"ceda37eb-6a2a-4d4f-9d7a-514eb63ec941","title":"tracr/tracr/compiler/lib.py at main · google-deepmind/tracr · GitHub","url":"https://github.com/google-deepmind/tracr/blob/main/tracr/compiler/lib.py","urlHash":3343881522},"cefeb889-cbf9-4063-b142-67e98dd81e7d":{"favIconUrl":"fallback","id":"cefeb889-cbf9-4063-b142-67e98dd81e7d","title":"GreaseLM Graph REASoning Enhanced Language Models for Question Answering - Arxiv-2201.08860","url":"https://arxiv.org/pdf/2201.08860.pdf","urlHash":2351025858},"cf0fd6b9-1573-4234-afee-0d0ae9b13e00":{"favIconUrl":"fallback","id":"cf0fd6b9-1573-4234-afee-0d0ae9b13e00","title":"Chapter 2 in Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto.","url":"https://waxworksmath.com/Authors/N_Z/Sutton/RLAI_1st_Edition/WWW/chapter_2.html","urlHash":274144557},"cf10c556-bff7-492b-8c52-7da71f879e37":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"cf10c556-bff7-492b-8c52-7da71f879e37","title":"DeAL: Decoding-time Alignment for Large Language Models | PDF","url":"https://arxiv.org/pdf/2402.06147.pdf","urlHash":1980255703},"cf1e9c5a-4b25-4b72-8ac9-237f160f1fc3":{"favIconUrl":"fallback","id":"cf1e9c5a-4b25-4b72-8ac9-237f160f1fc3","title":"RIPPLe/example_manifesto.yaml at paul_refactor · neulab/RIPPLe","url":"https://github.com/neulab/RIPPLe/blob/paul_refactor/manifestos/example_manifesto.yaml","urlHash":2038394380},"cf45617c-9db1-460b-bd0d-531187ed5f87":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"cf45617c-9db1-460b-bd0d-531187ed5f87","title":"GPT-4内幕大泄露！1.8万亿巨量参数，13万亿token训练，斥资6300万美元","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652350213&idx=2&sn=dca4f89f694fb5f4bde888f9c95303b2&exportkey=n_ChQIAhIQzMXtPn5qqJb%2F3b%2FM6nK%2FzhKWAgIE97dBBAEAAAAAAMbfAGz1ecMAAAAOpnltbLcz9gKNyK89dVj0xRjblO6vhzqP4MA9Ow4wA9N2pZ%2Fx0CUJVB1zYXV3tuhTr2kiyiPupazlnisanw5kxoDxXQWIjVosssZcFKl9SQkbDSeYBMVuLFyXJ2vi3fGyUNMTn5gc%2BQpI%2BhN%2B3Hrf%2BPhiM91JMA6DxmSWfxGjtM6CkgXnYwvOUAbqBJa4GZ59pS1k34j1Z41jqO8HbsTlSuboHVDHHume%2FFRD2MpwZLvOzdKKLa6pQ8bgGayQSO%2Frgo7sZyejNYna3SDYvjQHsXF32CqT5vTeNMb7E2hleAVwTyoFgX%2BV1Gqz2VPPWYmMgFYbe4OEjSK02eNjc54g&acctmode=0&pass_ticket=bzht7Z1UAzSUthxF%2FYXEGFdIDgBKUAEmsTW0uymOPBfK9kHKxYYr4nQjFzdY%2FQDZ&wx_header=0","urlHash":3840627821},"cf4d3d16-1452-4591-b180-d5e27d56ca5a":{"favIconUrl":"fallback","id":"cf4d3d16-1452-4591-b180-d5e27d56ca5a","title":"A Survey on Evaluation of Large Language Models","url":"https://arxiv.org/pdf/2307.03109.pdf","urlHash":2006268128},"cf4ed58e-b64e-4fd4-bb24-a7696146e1bc":{"favIconUrl":"fallback","id":"cf4ed58e-b64e-4fd4-bb24-a7696146e1bc","title":"LVLM-eHub A Comprehensive Evaluation Benchmark for Large Vision-Language Models - Arxiv-2306.09265","url":"https://arxiv.org/abs/2306.09265","urlHash":1918166761},"cf4ee064-58b3-4ba4-bb72-f35b87b45ea9":{"favIconUrl":"fallback","id":"cf4ee064-58b3-4ba4-bb72-f35b87b45ea9","title":"分类 信息时代 下的文章 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/category/Big-Data/19/","urlHash":2077699771},"cf65c35d-c3ad-41f9-af7a-f61a33cf2f48":{"favIconUrl":"https://www.google.com/favicon.ico","id":"cf65c35d-c3ad-41f9-af7a-f61a33cf2f48","title":"迈向魔界的十七步-柄刀一 - Google Search","url":"https://www.google.com/search?q=%E8%BF%88%E5%90%91%E9%AD%94%E7%95%8C%E7%9A%84%E5%8D%81%E4%B8%83%E6%AD%A5-%E6%9F%84%E5%88%80%E4%B8%80","urlHash":3565564199},"cf6a207a-6c90-4063-ba84-714ed6250428":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"cf6a207a-6c90-4063-ba84-714ed6250428","title":"valeman/awesome-conformal-prediction: A professionally curated list of awesome Conformal Prediction videos, tutorials, books, papers, PhD and MSc theses, articles and open-source libraries.","url":"https://github.com/valeman/awesome-conformal-prediction","urlHash":589140293},"cf81db61-f8f6-4348-af5e-57bd951031ad":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"cf81db61-f8f6-4348-af5e-57bd951031ad","title":"压缩下一个token通向超过人类的智能","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650873616&idx=4&sn=9c75a7db001fbe2d667ec4c72ed4fe0b&chksm=84e4db6eb3935278a3a908653077d80219d8844e3542d69d065d01c8a07b9abe0791297f8417&mpshare=1&scene=1&srcid=0411WdygUvTPq1KkJ2MRlvjO&sharer_sharetime=1683767852831&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQYkaL1kFlcNzkUpoNdtbXHRKWAgIE97dBBAEAAAAAAGVTI1JSjF0AAAAOpnltbLcz9gKNyK89dVj0xMZt2QHpiCS8KjQ0WC3mN7CiQ4hKQvypiVGTdpIcqIE53H80BtooHJdIm3O9vDXB5vUmyWdKijhxXi0%2BtRiDb6rgrTp9K1I88gSjGUGPTABqPJBfr8JOtDpDgUJmuBQ3UXPVRjCzq%2FgnBleBVstjEonX5q6kXH3GVrju8Mg%2FBEOU7VtS8JQXTmmYbKDbv2LpkyUnELtTpHoqritQCrrft7QX0HguCNOj6yhlH0Qvzi3eeC585%2FI5aJ5uxZ9gwr1zvHd9pfITGdFjOkmJXQhfebKymeL6cA%2Bhl49dAbgPeAY8rQPJkF0J9PeWnNq0bZDU&acctmode=0&pass_ticket=CVx8wIecFZpLiqLziB53fbV73WifzfjFL8ONivSufgi4lZgofUv%2F0Z7fWrb3twfLtFX3TWXH%2FZ2bbtHkV8LmKA%3D%3D&wx_header=0#rd","urlHash":2578359807},"cfa9fe1a-df03-4b66-a698-db2308dddf73":{"favIconUrl":"fallback","id":"cfa9fe1a-df03-4b66-a698-db2308dddf73","title":"Rethinking with Retrieval Faithful Large Language Model Inference - Arxiv-2301.00303","url":"https://arxiv.org/abs/2301.00303","urlHash":2067657633},"cfd5dc36-a45f-472a-8874-52859b77b50a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"cfd5dc36-a45f-472a-8874-52859b77b50a","title":"Archit Sharma on X: \"High-quality human feedback for RLHF is expensive 💰. AI feedback is emerging as a scalable alternative, but are we using AI feedback effectively? Not yet; RLAIF improves perf *only* when LLMs are SFT'd on a weak teacher. Simple SFT on a strong teacher can outperform RLAIF! 🧵-&gt; https://t.co/J67RsjOtUY\" / X","url":"https://twitter.com/archit_sharma97/status/1759990862623453568","urlHash":359101441},"cfdf8f04-78aa-4bac-86eb-0413e56d5d27":{"favIconUrl":"fallback","id":"cfdf8f04-78aa-4bac-86eb-0413e56d5d27","title":"Group Equivariant Convolutional Networks - Arxiv-1602.07576","url":"https://arxiv.org/pdf/1602.07576.pdf","urlHash":1431392686},"d015261d-53c6-4165-b396-0ca88a27b516":{"favIconUrl":"fallback","id":"d015261d-53c6-4165-b396-0ca88a27b516","title":"An empirical model of large-batch training - Google Search","url":"https://www.google.com/search?q=An+empirical+model+of+large-batch+training&sourceid=chrome&ie=UTF-8","urlHash":807102578},"d015700a-4f55-499b-b7ae-5e482dd84233":{"favIconUrl":"fallback","id":"d015700a-4f55-499b-b7ae-5e482dd84233","title":"最近在推装甲恶鬼村正，心情很沉重，善恶相抵真是傲慢的设定 178","url":"https://nga.178.com/read.php?tid=36851734","urlHash":871000014},"d02bd9af-929f-4b21-a8a3-e5dd760fecc4":{"favIconUrl":"fallback","id":"d02bd9af-929f-4b21-a8a3-e5dd760fecc4","title":"A Simple Baseline for Open-Vocabulary Semantic Segmentation with Pre-trained Vision-language Model - Arxiv-2112.14757","url":"https://arxiv.org/abs/2112.14757","urlHash":3550108773},"d03780d9-31a1-401a-b18a-c37d4ed183e7":{"favIconUrl":"fallback","id":"d03780d9-31a1-401a-b18a-c37d4ed183e7","title":"Proximity-Informed Calibration for Deep Neural Networks - Arxiv-2306.04590","url":"https://arxiv.org/pdf/2306.04590.pdf","urlHash":1572163270},"d0410231-e0bc-491f-9631-ba2b1702e750":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"d0410231-e0bc-491f-9631-ba2b1702e750","title":"elvis on X: \"Visualization-of-Thought Elicits Spatial Reasoning in LLMs Inspired by a human cognitive capacity to imagine unseen worlds, this new work proposes Visualization-of-Thought (VoT) prompting to elicit spatial reasoning in LLMs. VoT enables LLMs to \"visualize\" their reasoning… https://t.co/6RFmSutwDN\" / X","url":"https://twitter.com/omarsar0/status/1776082343813403063?utm_source=substack&utm_medium=email","urlHash":2520050382},"d0486a6c-afe8-4e8f-986c-0192885989b0":{"favIconUrl":"fallback","id":"d0486a6c-afe8-4e8f-986c-0192885989b0","title":"https://arxiv.org/pdf/2201.10055.pdf","url":"https://arxiv.org/pdf/2201.10055.pdf","urlHash":3170073069},"d074f017-2350-4b80-8aa8-c75346bf2fff":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"d074f017-2350-4b80-8aa8-c75346bf2fff","title":"Progressive Prompts: Continual Learning for Language Models | PDF","url":"https://arxiv.org/pdf/2301.12314.pdf","urlHash":3031198692},"d09f6b0c-2e15-41ed-bdcc-77cb3d03331d":{"favIconUrl":"fallback","id":"d09f6b0c-2e15-41ed-bdcc-77cb3d03331d","title":"Emb-GAM an Interpretable and Efficient Predictor using Pre-trained Language Models - Arxiv-2209.11799","url":"https://arxiv.org/pdf/2209.11799.pdf","urlHash":207641509},"d0a74205-8eb6-4098-8c45-0142c63cd734":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"d0a74205-8eb6-4098-8c45-0142c63cd734","title":"Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling | PDF","url":"https://arxiv.org/pdf/2304.01373.pdf","urlHash":1272914878},"d0af8671-a573-4640-bad2-dbfba6f5ab12":{"favIconUrl":"fallback","id":"d0af8671-a573-4640-bad2-dbfba6f5ab12","title":"APOLLO A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning - Arxiv-2212.09282","url":"https://arxiv.org/pdf/2212.09282.pdf","urlHash":3692362421},"d0b2baeb-8fbc-492d-b3b1-3a13f6496232":{"favIconUrl":"fallback","id":"d0b2baeb-8fbc-492d-b3b1-3a13f6496232","title":"深度学习中的Lipschitz约束：泛化与生成模型 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/6051","urlHash":942208939},"d0dfba57-1b09-41de-ac47-c22399442bdc":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"d0dfba57-1b09-41de-ac47-c22399442bdc","title":"elvis on X: \"Hallucination in Large Vision-Language Models This paper discusses hallucination issues and techniques to mitigate hallucination in Large Vision-Language Models (LVLM). It introduces LVLM hallucination evaluation methods and benchmarks. Provides tips and a good analysis of… https://t.co/AvNdjUdG3k\" / X","url":"https://twitter.com/omarsar0/status/1753449211931079101?utm_source=substack&utm_medium=email","urlHash":2732181160},"d0ec772b-0ba9-4a75-b5b2-b2948aa5f4ca":{"favIconUrl":"https://images.squarespace-cdn.com/content/v1/6502259e5d663b5ef39d98ba/a33980fd-66d8-4c31-8a29-6be6643e2979/favicon.ico?format=100w","id":"d0ec772b-0ba9-4a75-b5b2-b2948aa5f4ca","title":"MATS Program","url":"https://www.matsprogram.org/","urlHash":516853908},"d0efa1c1-c30e-4ea4-ab91-4b33d4e145a2":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"d0efa1c1-c30e-4ea4-ab91-4b33d4e145a2","title":"Sohee Yang on X: \"🚨 New Paper 🚨 LLMs excel at storing facts &amp; in-context reasoning like CoT. But do they latently💭 reason over their parametric knowledge without answering step-by-step? We found positive evidence 👀 But it varies for different relation types, and scaling doesn't help much! 1/N https://t.co/8kmu4kM3Bf\" / X","url":"https://twitter.com/soheeyang_/status/1762885793427734818","urlHash":1526759846},"d1049c6d-261e-49f0-a277-384321c1da7b":{"favIconUrl":"https://www.99csw.com/favicon.ico","id":"d1049c6d-261e-49f0-a277-384321c1da7b","title":"不速之客的自助餐:开胃酒 案发之后_克里斯蒂安娜·布兰德_在线阅读_九九藏书网","url":"https://www.99csw.com/book/8195/286410.htm","urlHash":1192060039},"d124bef7-9829-454d-a262-b7c9a27527ad":{"favIconUrl":"fallback","id":"d124bef7-9829-454d-a262-b7c9a27527ad","title":"BERTopic：NLP主题模型的未来！","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247529719&idx=1&sn=e282c8dc4a235992241813f9b88e7e7c&exportkey=n_ChQIAhIQzlxFJyQcqV3DdMuHZ6eL8BKWAgIE97dBBAEAAAAAADsTAQcK5esAAAAOpnltbLcz9gKNyK89dVj0Gw%2FaIHS%2ByF8kjmlLyB%2FHHjuvW%2BIDTyXDFNiPKDxIn%2BiStHRu0yl1dtD61NZfa4fhWHte%2FdvfP9vBYPYKuCc3b%2B%2BA0UEvXu24%2B0T%2BMz3DltccB%2F7cFwzli%2BM4xP9Oj4ExyczYCLXd4PFwSeoT87TxoL6FBmF%2BR2U9OKfHmFX%2B%2BIbJY3fBUsoUQSoAKsg3X2oUDSQVxRF1akGRx%2FG1pA1%2BfYdm6T7ST5fQ8GwzHQ%2BXd4EtTrkQI5hVK3Ah6j%2FJPCYUUaUr1ZA7luYsXuWU4NBipVj6BRHL2%2BlqAGnGns49njsmZvI1KN1jKpRdQaTUef16&acctmode=0&pass_ticket=dk1%2BYeI9KcxVieaewIrrrbKjqtemDbE%2BLsWThaEB6q0xYaDUhGjWF2iTn%2BxYLPlk&wx_header=0","urlHash":1080431694},"d15484f5-8458-4bd6-b101-23342cce49ad":{"favIconUrl":"https://www.redditstatic.com/desktop2x/img/favicon/favicon-32x32.png","id":"d15484f5-8458-4bd6-b101-23342cce49ad","title":"Reddit - Dive into anything","url":"https://www.reddit.com/r/reinforcementlearning/comments/10xtvwr/curriculum_vs_hierarchical_rl/","urlHash":3169416846},"d15eb684-26ee-4a74-a47a-2739b7dafc22":{"favIconUrl":"fallback","id":"d15eb684-26ee-4a74-a47a-2739b7dafc22","title":"self-organising-systems/transformers_learn_icl_by_gd at master · google-research/self-organising-systems","url":"https://github.com/google-research/self-organising-systems/tree/master/transformers_learn_icl_by_gd","urlHash":3934627270},"d19b0eea-94c5-4639-ae2d-feca58be3922":{"favIconUrl":"https://assets.squarespace.com/universal/default-favicon.ico","id":"d19b0eea-94c5-4639-ae2d-feca58be3922","title":"Some intuitions about large language models — Jason Wei","url":"https://www.jasonwei.net/blog/some-intuitions-about-large-language-models","urlHash":3166612054},"d1d6a02a-d4c4-4202-a684-1d5c7a43fc6c":{"favIconUrl":"fallback","id":"d1d6a02a-d4c4-4202-a684-1d5c7a43fc6c","title":"对Hugging Face开源模型精准投毒！LLM切脑后变身PoisonGPT，用虚假事实洗脑60亿人","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652349939&idx=3&sn=54b2ca4d0ddf092c8883ad3625e13dd8&exportkey=n_ChQIAhIQXoCiXb75L%2F2I%2B9mK3yfsdhKWAgIE97dBBAEAAAAAABquNzbyltUAAAAOpnltbLcz9gKNyK89dVj0%2FvFZjyk2hMbkOSQaKyckyljUBM2eGPvGDw7pQOqAS6lPDFFZleAdbCqs9ilt0Lwt0%2BOGIMCdUTJiCNBliiLBn5JKmBZh8pqzTmnaW4OZ3miWbGrIso1mvaKy6N07mlFV7mmCbeqPjt12zpSShmAd3jcUi3qISJho0GxdHlMULZT8DeSQSGIkQRc%2BRml91yAlvuxAgO85eKaaYkTAf5fF1qszGVfSr4FZjpi1TzHT4SVxS8fbX61pczVR%2Bf8R8kBKMEtL%2F%2F%2B7uYwCOt68obxPfjDT%2FeGD954Rl0kftEse%2Fna9PTKi7Ifx929HaCu7iee6&acctmode=0&pass_ticket=EpWDvbyW1KPdgTerO4GidxUaU%2FC6knp0DScCYUIUNh2KdD4X8wkXV9N%2BHyE%2F%2Bb%2F5&wx_header=0","urlHash":1217938857},"d1d7d149-ab78-46c8-a6b0-c86dcd67a848":{"favIconUrl":"fallback","id":"d1d7d149-ab78-46c8-a6b0-c86dcd67a848","title":"The Aphorisms of Franz Kafka","url":"https://press.princeton.edu/books/hardcover/9780691205922/the-aphorisms-of-franz-kafka","urlHash":2361658118},"d1e96813-a92a-4fdc-a1b0-6333bf6e1804":{"favIconUrl":"https://plato.stanford.edu/favicon.ico","id":"d1e96813-a92a-4fdc-a1b0-6333bf6e1804","title":"Gottfried Wilhelm Leibniz (Stanford Encyclopedia of Philosophy)","url":"https://plato.stanford.edu/entries/leibniz/","urlHash":3673975972},"d1eec573-c753-4c4a-88fd-ab0d438b8ab4":{"favIconUrl":"https://cdn.semanticscholar.org/b5fbde4a4847434e/img/darkmode/favicon-32x32.png","id":"d1eec573-c753-4c4a-88fd-ab0d438b8ab4","title":"[PDF] A Toy Model of Universality: Reverse Engineering How Networks Learn Group Operations | Semantic Scholar","url":"https://www.semanticscholar.org/paper/A-Toy-Model-of-Universality%3A-Reverse-Engineering-Chughtai-Chan/5969eff0e72e4a5bc0c7392c700be74a01ac2822","urlHash":62300965},"d214c87c-f0d7-4563-9fb3-c20da9b38c17":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"d214c87c-f0d7-4563-9fb3-c20da9b38c17","title":"Daniel Paleka on X: \"What happened this month in AI/ML safety research. 🧵 (1/8)\" / X","url":"https://twitter.com/dpaleka/status/1641742172759396352","urlHash":484370512},"d24d9077-e8ef-4685-8eb4-7c2b3c5d01fc":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"d24d9077-e8ef-4685-8eb4-7c2b3c5d01fc","title":"Hao Liu on X: \"We curated a very large dataset of diverse long videos and texts and proposed a two-stage training to enable large context world model on video and language. We expand Llama2's context progressively from 4K to 1M on language and video to manage compute cost. https://t.co/nt8TrxqYIa\" / X","url":"https://twitter.com/haoliuhl/status/1757828397185839174","urlHash":3953093961},"d257054d-e2c4-4548-8e14-79c8100b76f6":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"d257054d-e2c4-4548-8e14-79c8100b76f6","title":"Scaling Laws for Reward Model Overoptimization | Abstract","url":"https://arxiv.org/abs/2210.10760","urlHash":2275209790},"d28ace27-f79b-466e-94cc-6f94960dd2af":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"d28ace27-f79b-466e-94cc-6f94960dd2af","title":"Jan Leike on X: \"Really exciting new work on automated interpretability: We ask GPT-4 to explain firing patterns for individual neurons in LLMs and score those explanations. https://t.co/Fmu8IAb7Hy\" / X","url":"https://twitter.com/janleike/status/1655982055736643585","urlHash":261156253},"d2d8eb0e-a5c5-4fdb-951a-53075a9fef93":{"favIconUrl":"fallback","id":"d2d8eb0e-a5c5-4fdb-951a-53075a9fef93","title":"Snorkel - 搜索结果 - 知乎","url":"https://www.zhihu.com/search?q=Snorkel&type=content","urlHash":4121534908},"d2f2f306-6574-49c6-a693-cdbf0b75804a":{"favIconUrl":"fallback","id":"d2f2f306-6574-49c6-a693-cdbf0b75804a","title":"On Adaptive Attacks to Adversarial Example Defenses","url":"https://proceedings.neurips.cc/paper/2020/hash/11f38f8ecd71867b42433548d1078e38-Abstract.html","urlHash":2112736529},"d3009d55-8dfe-495b-a01a-bbd2fe1e658e":{"favIconUrl":"fallback","id":"d3009d55-8dfe-495b-a01a-bbd2fe1e658e","title":"7 Papers & Radios","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650864860&idx=5&sn=0a35281f4335fd751099cca8548a8048&chksm=84e538a2b392b1b48a60ac2fb6c5023da30112c51c7c34848ebae905672afe259a3061721bc5&mpshare=1&scene=1&srcid=0116TfX12tQz0Ta30fXd5FYL&sharer_sharetime=1673842963015&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQ%2FJBMsjFi4m9MEi4uMB191xKWAgIE97dBBAEAAAAAAMq1JxAf7fYAAAAOpnltbLcz9gKNyK89dVj0POOsT8RU%2BUXt8FnqyeMPDoH4JTwn45mFbNNsxZP61jM8t1VebMCfu8psKk6QhsO%2BvhOBsRJG5uRXE8GXUj9HEIJOiemuXRt8HzubcmvyH12hXAYouTpNGomoTZP1ASdrznt9Ve194nMCdPE%2FxI4YFmfhO2WPFyqrlfxnlD7mWflZwgG%2BCgRSjso3fL4DNZ3YdSY5Kbzou7y4imDzNS3j3ryx4Smj4BXcZ7vTxd9j%2BijUwS%2B4DJVpTm9Dldv4M7H5quHFpHtud9L1T2gZug07dBH33Fv9yW3PLMuSZgZnLJeGi3q5a%2FtCI9pmPVz%2BdFk2&acctmode=0&pass_ticket=3HIlKyjzTAFL%2FxFljj2tEtyLfkTobYOBU23FblbSLUoESymFRz29uU1%2FRX7h6w2gnrjMHpQi8dKB1psxTVfoFA%3D%3D&wx_header=0#rd","urlHash":4259020096},"d3071400-c92c-4a95-8a0b-d3c2e6f59fe7":{"favIconUrl":"fallback","id":"d3071400-c92c-4a95-8a0b-d3c2e6f59fe7","title":"Alignment via Mutual Information","url":"https://aclanthology.org/2023.conll-1.32.pdf","urlHash":3810226852},"d321b268-a44b-43b2-ad15-5db7e2373bd9":{"favIconUrl":"fallback","id":"d321b268-a44b-43b2-ad15-5db7e2373bd9","title":"DISCO Distilling Phrasal Counterfactuals with Large Language Models - Arxiv-2212.10534","url":"https://arxiv.org/abs/2212.10534","urlHash":954011304},"d3665a8d-91e4-4f86-91ee-ffb0757d39d7":{"favIconUrl":"fallback","id":"d3665a8d-91e4-4f86-91ee-ffb0757d39d7","title":"On Learning to Summarize with Large Language Models as References","url":"https://arxiv.org/pdf/2305.14239.pdf","urlHash":931426593},"d3765705-d0af-4820-805a-e5c71c09d38a":{"favIconUrl":"fallback","id":"d3765705-d0af-4820-805a-e5c71c09d38a","title":"toliz/fairness-attacks: Re-implementation of the paper \"Exacerbating Algorithmic Bias through Fairness Attacks\"","url":"https://github.com/toliz/fairness-attacks","urlHash":2539610363},"d393e196-af49-4d37-be36-bf599572d4c8":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"d393e196-af49-4d37-be36-bf599572d4c8","title":"A Survey on In-context Learning | PDF","url":"https://arxiv.org/pdf/2301.00234.pdf","urlHash":3465716604},"d3b5e31e-89c7-45a6-a982-a455f9673ffc":{"favIconUrl":"fallback","id":"d3b5e31e-89c7-45a6-a982-a455f9673ffc","title":"What You See is What You Read? Improving Text-Image Alignment Evaluation - Arxiv-2305.10400","url":"https://arxiv.org/pdf/2305.10400.pdf","urlHash":422046295},"d3ba3124-dd78-406d-ae87-d481dc467c53":{"favIconUrl":"fallback","id":"d3ba3124-dd78-406d-ae87-d481dc467c53","title":"UX-Decoder/Segment-Everything-Everywhere-All-At-Once: Official implementation of the paper \"Segment Everything Everywhere All at Once\"","url":"https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once","urlHash":3279979490},"d3c0dbd5-d8d4-4477-b434-a3fb39529842":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"d3c0dbd5-d8d4-4477-b434-a3fb39529842","title":"Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback | PDF","url":"https://arxiv.org/pdf/2302.12813.pdf","urlHash":1926058123},"d3da43ea-1b20-4a4e-891d-28d66185f930":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"d3da43ea-1b20-4a4e-891d-28d66185f930","title":"Automatic Evaluation of Attribution by Large Language Models | Abstract","url":"https://arxiv.org/abs/2305.06311","urlHash":1529516548},"d3e39182-3916-4946-b668-f2396c902855":{"favIconUrl":"fallback","id":"d3e39182-3916-4946-b668-f2396c902855","title":"中国近代史 蒋廷黻 - 搜索结果 - 知乎","url":"https://www.zhihu.com/search?q=%E4%B8%AD%E5%9B%BD%E8%BF%91%E4%BB%A3%E5%8F%B2%20%E8%92%8B%E5%BB%B7%E9%BB%BB&type=content","urlHash":1842523621},"d3e55775-476f-4e0a-9ef7-51e932fdc4ae":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"d3e55775-476f-4e0a-9ef7-51e932fdc4ae","title":"Clarifying mesa-optimization — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/NpJkFLBJEq7JQt7oy/clarifying-mesa-optimization","urlHash":2757001399},"d3ed8b23-fb1a-4860-9b8f-f324681a5438":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"d3ed8b23-fb1a-4860-9b8f-f324681a5438","title":"Quality-Diversity through AI Feedback | Abstract","url":"https://arxiv.org/abs/2310.13032","urlHash":3855295698},"d3fd2204-646b-43a1-ba83-15a9d006d69c":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"d3fd2204-646b-43a1-ba83-15a9d006d69c","title":"Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic | Abstract","url":"https://arxiv.org/abs/2309.13339?utm_source=substack&utm_medium=email","urlHash":3414374936},"d3feb378-df27-43bc-8cfe-274335769c87":{"favIconUrl":"fallback","id":"d3feb378-df27-43bc-8cfe-274335769c87","title":"Probing Across Time What Does RoBERTa Know and When? - Arxiv-2104.07885","url":"https://arxiv.org/pdf/2104.07885.pdf","urlHash":1056499307},"d40123ea-b0e9-4c4d-92b7-c93340149fee":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"d40123ea-b0e9-4c4d-92b7-c93340149fee","title":"AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning | Abstract","url":"https://arxiv.org/abs/2303.10512","urlHash":4193642069},"d42236d7-ccbe-4236-8010-6ac5dd5193a2":{"favIconUrl":"https://www.google.com/favicon.ico","id":"d42236d7-ccbe-4236-8010-6ac5dd5193a2","title":"streamingllm - Google Search","url":"https://www.google.com/search?q=streamingllm&oq=streami&gs_lcrp=EgZjaHJvbWUqDggAEEUYJxg7GIAEGIoFMg4IABBFGCcYOxiABBiKBTIGCAEQRRg5MgYIAhBFGDwyBggDEEUYPDIGCAQQRRg8MgYIBRBFGDwyBggGEEUYPDIGCAcQRRg80gEIMTM0MmowajGoAgCwAgA&sourceid=chrome&ie=UTF-8","urlHash":2322235576},"d48b58ea-7d60-4da9-b586-b4622ee1ffc5":{"favIconUrl":"fallback","id":"d48b58ea-7d60-4da9-b586-b4622ee1ffc5","title":"突破瓶颈，打造更强大的Transformer - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/7325","urlHash":1660159427},"d4aa43eb-1518-42e1-a60e-a811e6a54815":{"favIconUrl":"fallback","id":"d4aa43eb-1518-42e1-a60e-a811e6a54815","title":"The Gumbel trick – Machine Learning Research Blog","url":"https://francisbach.com/the-gumbel-trick/","urlHash":3878951210},"d4af6d3b-be1b-4d03-b0a2-efee239806b9":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"d4af6d3b-be1b-4d03-b0a2-efee239806b9","title":"samuela/git-re-basin: Code release for \"Git Re-Basin: Merging Models modulo Permutation Symmetries\"","url":"https://github.com/samuela/git-re-basin","urlHash":4053658430},"d4c4716f-07fc-4865-9535-58e6f6964ce0":{"favIconUrl":"fallback","id":"d4c4716f-07fc-4865-9535-58e6f6964ce0","title":"VisionLLM Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks - Arxiv-2305.11175","url":"https://arxiv.org/pdf/2305.11175.pdf","urlHash":1274965000},"d4d18cb4-851c-4e85-bc23-653d7d944691":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"d4d18cb4-851c-4e85-bc23-653d7d944691","title":"likenneth/honest_llama: Inference-Time Intervention: Eliciting Truthful Answers from a Language Model","url":"https://github.com/likenneth/honest_llama","urlHash":1055115541},"d4f33f92-668d-4d4e-ac1f-4443687a9419":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"d4f33f92-668d-4d4e-ac1f-4443687a9419","title":"twitter.com/Yampeleg/status/1691198756668968960","url":"https://twitter.com/Yampeleg/status/1691198756668968960","urlHash":2603081554},"d57a1349-2cab-4dc7-a10c-903f89f3d22d":{"favIconUrl":"fallback","id":"d57a1349-2cab-4dc7-a10c-903f89f3d22d","title":"Tracking Everything Everywhere All at Once - Arxiv-2306.05422","url":"https://arxiv.org/abs/2306.05422","urlHash":3915344343},"d58cfd66-7d17-4a48-8495-8aa9910ed668":{"favIconUrl":"fallback","id":"d58cfd66-7d17-4a48-8495-8aa9910ed668","title":"Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions - Arxiv-2212.10509","url":"https://arxiv.org/pdf/2212.10509.pdf","urlHash":3962805304},"d596840d-4026-4ab3-a270-2c49264a6203":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"d596840d-4026-4ab3-a270-2c49264a6203","title":"MegaBlocks: Efficient Sparse Training with Mixture-of-Experts | PDF","url":"https://arxiv.org/pdf/2211.15841.pdf","urlHash":431231208},"d59be67a-69e6-4405-b64e-288b1bf0876a":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"d59be67a-69e6-4405-b64e-288b1bf0876a","title":"Towards a Unified View of Parameter-Efficient Transfer Learning | PDF","url":"https://arxiv.org/pdf/2110.04366.pdf","urlHash":477618331},"d5c4b3dc-f095-4e4b-8794-0313a3b26b11":{"favIconUrl":"fallback","id":"d5c4b3dc-f095-4e4b-8794-0313a3b26b11","title":"ICML 2022","url":"https://icml.cc/virtual/2022/tutorial/18440","urlHash":3922618281},"d5c60aeb-350d-46cf-b99b-dae3e72e8de6":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"d5c60aeb-350d-46cf-b99b-dae3e72e8de6","title":"Towards Automated Circuit Discovery for Mechanistic Interpretability | PDF","url":"https://arxiv.org/pdf/2304.14997.pdf","urlHash":2234110673},"d610a191-2aae-441a-95aa-a472192a3848":{"favIconUrl":"fallback","id":"d610a191-2aae-441a-95aa-a472192a3848","title":"美国讲稿 (豆瓣)","url":"https://book.douban.com/subject/10555538/","urlHash":2573075239},"d61d0b35-1e9e-4918-a70b-370c40ed581d":{"favIconUrl":"fallback","id":"d61d0b35-1e9e-4918-a70b-370c40ed581d","title":"Xpitfire/symbolicai: Compositional Differentiable Programming Library","url":"https://github.com/Xpitfire/symbolicai","urlHash":415586641},"d677496a-0109-4336-b93e-937626a5a1cd":{"favIconUrl":"fallback","id":"d677496a-0109-4336-b93e-937626a5a1cd","title":"Training Diffusion Models with Reinforcement Learning - Arxiv-2305.13301","url":"https://arxiv.org/pdf/2305.13301.pdf","urlHash":3329055846},"d6c9ff11-7e9f-4280-9b97-c37783e8bbde":{"favIconUrl":"fallback","id":"d6c9ff11-7e9f-4280-9b97-c37783e8bbde","title":"GDL Course","url":"https://geometricdeeplearning.com/lectures/","urlHash":1976577947},"d6d8c219-f43f-4058-b6ce-f12764bd1c56":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"d6d8c219-f43f-4058-b6ce-f12764bd1c56","title":"ActiveVisionLab/Awesome-LLM-3D: Awesome-LLM-3D: a curated list of Multi-modal Large Language Model in 3D world Resources","url":"https://github.com/ActiveVisionLab/Awesome-LLM-3D?tab=readme-ov-file","urlHash":194629551},"d6f286da-c628-4ec3-8fc4-31817bee3be3":{"favIconUrl":"fallback","id":"d6f286da-c628-4ec3-8fc4-31817bee3be3","title":"COLD Decoding: Energy-based Constrained Text Generation with Langevin Dynamics - Google Search","url":"https://www.google.com/search?q=COLD+Decoding%3A+Energy-based+Constrained+Text+Generation+with+Langevin+Dynamics&oq=COLD+Decoding%3A+Energy-based+Constrained+Text+Generation+with+Langevin+Dynamics&aqs=chrome..69i57.207j0j1&sourceid=chrome&ie=UTF-8","urlHash":2973117666},"d6f9a423-a914-42c5-bf97-1f02dae5c0c0":{"favIconUrl":"fallback","id":"d6f9a423-a914-42c5-bf97-1f02dae5c0c0","title":"Reddit - Dive into anything","url":"https://www.reddit.com/r/philosophy/comments/e9okfd/walter_benjamins_last_work_scrawled_across_the/","urlHash":3856118425},"d710cb67-3c6c-4b49-81ae-94e494759d69":{"favIconUrl":"fallback","id":"d710cb67-3c6c-4b49-81ae-94e494759d69","title":"Patterns, Predictions, and Actions","url":"https://mlstory.org/","urlHash":920054738},"d71b2c4a-e6fd-4d42-8442-bd414377e80a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"d71b2c4a-e6fd-4d42-8442-bd414377e80a","title":"twitter.com/arankomatsuzaki/status/1668788750569320450","url":"https://twitter.com/arankomatsuzaki/status/1668788750569320450","urlHash":1097494881},"d7218778-0827-47c6-9dfc-b2bf728bfc0c":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"d7218778-0827-47c6-9dfc-b2bf728bfc0c","title":"A Benchmark for Learning to Translate a New Language from One Grammar Book | PDF","url":"https://arxiv.org/pdf/2309.16575.pdf","urlHash":139921905},"d749388e-11f9-463a-9c91-ed35ed64ffea":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"d749388e-11f9-463a-9c91-ed35ed64ffea","title":"多模态大模型学杂了能力反下降？新研究：MoE+通用专家解决冲突","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247711325&idx=3&sn=bf7c466d9c56036fc486887eaec3de4a&chksm=e8df0d2fdfa88439be61c302347e0de5b70f2d7bc01e59d154a23cf97ebf78fc5dae2b4b294c&mpshare=1&scene=1&srcid=0120SdEJUQyDEdSPYeVbyXiN&sharer_shareinfo=72f24b7d451bc3df96ba0930b4b7e45d&sharer_shareinfo_first=72f24b7d451bc3df96ba0930b4b7e45d&exportkey=n_ChQIAhIQlUnSi1Dy3rpU15mShN9o7BKWAgIE97dBBAEAAAAAAJr5B2T6%2F9gAAAAOpnltbLcz9gKNyK89dVj0Z5i4WRjANrl7bXIGp3yTmoGHNDk9KFCaVwR3YmmEquBA1iqdr5R%2BMsyU8kh4cT8Z%2BZ7Ou%2BLjBpaYDylmVCkIVFjrbzqO42o7ZfkDB7%2B4l2BUX2rXZn8chJ1Cq0L8nENrPh74PxwK7MQg3lFkRlYcf1MakQXs6rYsKLVUPDoUvvEaxK5Opuv2Tjb%2FQn%2F%2BHMb%2FthKe48MkdPAKC8u02hP6GtPnQB5eLqq7n0%2FzY3gqBa9I1BACqLw8TqMv2ZeRXH1IPPZycY%2Fc%2F35YwWYLBwLKpls9zHJgSCoL7lqMt7FNqq%2BHVT3GIUFxb9IkW340mwoX&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HO3H%2FaOhoR4I0bdM6fmeXsBrtQqa4e%2FOhHriDAm6ypJJQ%3D%3D&wx_header=0#rd","urlHash":2184524096},"d7572dfd-3f77-4ec2-b1e7-e79a2de6e2f3":{"favIconUrl":"fallback","id":"d7572dfd-3f77-4ec2-b1e7-e79a2de6e2f3","title":"Kosmos-2 Grounding Multimodal Large Language Models to the World - Arxiv-2306.14824","url":"https://arxiv.org/abs/2306.14824","urlHash":3884043051},"d7615a30-dd7d-48f2-a2eb-2c80760dd172":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"d7615a30-dd7d-48f2-a2eb-2c80760dd172","title":"Training Language Models with Language Feedback at Scale | Abstract","url":"https://arxiv.org/abs/2303.16755","urlHash":3007904610},"d76d6c30-6120-4ff2-aeb7-dabf50e7a16c":{"favIconUrl":"fallback","id":"d76d6c30-6120-4ff2-aeb7-dabf50e7a16c","title":"Are Representations Built from the Ground Up? An Empirical Examination of Local Composition in Language Models - Arxiv-2210.03575","url":"https://arxiv.org/pdf/2210.03575.pdf","urlHash":1079725409},"d76d9785-f991-48a5-91e4-facaaab3430c":{"favIconUrl":"fallback","id":"d76d9785-f991-48a5-91e4-facaaab3430c","title":"Overthrow of the Roman monarchy - Wikiwand","url":"https://www.wikiwand.com/en/Overthrow_of_the_Roman_monarchy","urlHash":1111050242},"d77ff7b0-da76-4925-915e-2d12273819b5":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"d77ff7b0-da76-4925-915e-2d12273819b5","title":"清华提出 SoRA，参数量只有 LoRA 的 70%，表现更好！","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247568281&idx=2&sn=7562f0f17b707f27189aa201d31021ab&exportkey=n_ChQIAhIQrONVAXncvsR9TWUy0YDIjhKWAgIE97dBBAEAAAAAAMoXJL75fIgAAAAOpnltbLcz9gKNyK89dVj0JC5UT9uZWsLvh6iL0Bt5YsddbGQNxPS5L4WqUNkGaVh1JPVX6CseiKxtn7kLBflHwZOT7i%2BG%2BkgN1GFRd%2F4wEuumic5XgR7EFruTdhFiJlBWKQ7y2wZrWPTN3pTBT7qUfg2w8o9yfYOksIIjnyghFZyrwShCrzwWlJdAzizzmWgISGVNIx0ascTDd8IMZfZsFND3eD0yDOHswAWw8xAyGy1HVboIBPjhm%2F%2Fyqy8nOaBlcIUCMSJhHDPBA%2FQ4TGPZkTYWQxOL8GTQNFDKSLjb7kDTfzn7PFAW2OFTl4IsXNhOZ6fQk4ig%2BgGtEU1HzeZL&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsYxy77QScXY0jhYXrqIPT1Iyz4jcJFVfJmU2PccAeC%2F0A%3D%3D&wx_header=0","urlHash":2671950063},"d7c684c8-8670-4d13-927d-11b4623c2262":{"favIconUrl":"fallback","id":"d7c684c8-8670-4d13-927d-11b4623c2262","title":"搜索: 美国讲稿","url":"https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E8%AE%B2%E7%A8%BF","urlHash":588921186},"d8243774-8763-4b02-9767-9ed766d8844a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"d8243774-8763-4b02-9767-9ed766d8844a","title":"twitter.com/seano_research/status/1704260944938049604","url":"https://twitter.com/seano_research/status/1704260944938049604","urlHash":263462330},"d85dd492-8f49-4769-a96f-40b77fb28914":{"favIconUrl":"fallback","id":"d85dd492-8f49-4769-a96f-40b77fb28914","title":"On Neural Differential Equations - Arxiv-2202.02435","url":"https://arxiv.org/abs/2202.02435","urlHash":3774969776},"d870b828-6dcc-4677-8fac-25201efc5874":{"favIconUrl":"fallback","id":"d870b828-6dcc-4677-8fac-25201efc5874","title":"武大上交联手，大语言模型消除幻觉，双向自回归建功","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247556158&idx=3&sn=168d4e43cb0a39dcc239f2122cdce9fe&chksm=970f34e8a078bdfe242822a7fcdcdab2f0bcbca032f27e97547a37d2b0d9b042dc3c5e833883&mpshare=1&scene=1&srcid=0813jFJzig5wWdAEUp1dVgB7&sharer_sharetime=1691905077219&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQ0DQBfagmUROPYhlD6r2wehKWAgIE97dBBAEAAAAAAJPGALzhK44AAAAOpnltbLcz9gKNyK89dVj0PDsx6iRjNDQG2p1PsCb5jnvYUiqLU1Qqdh9ZO7nh6eCu%2FyFRMz9wCKVZyUER9FJLuwIdqt6S0j3wGtcJS05EMR1SMv9LyT%2FoBrjcyXziYZqP74vVWlScBx2qmV35TayaLxTw%2BK1p%2BEozbOwFy3UPSF7eDNvugHWrGu6xI3whEg605CuURdxOpH%2FkK8HckHy7f4njdx3OLDbfITMfI8ebcgKXst9OVlreAR8hxzQuQS4czUaH1NjhQ75DnPPvC8BjYUHUkslyMCoWD8rhzgHNtUfJc0xgBPeWNRxXyqEywOy6h%2B2E4Uzg8sV6vv%2FQT79z&acctmode=0&pass_ticket=yUk5KxTaMI8%2BEiwrpQ8Yf3ssZBuqGONcnPxFlEDFpl%2BVmW6544lX%2FZtquiFF4fNn&wx_header=0#rd","urlHash":1816527887},"d8b94bc7-c102-455f-8e46-ef4c9faf940b":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"d8b94bc7-c102-455f-8e46-ef4c9faf940b","title":"Explaining by Removing: A Unified Framework for Model Explanation | Abstract","url":"https://arxiv.org/abs/2011.14878","urlHash":49426206},"d8c9c132-8462-433a-b82e-4ddb05eb2b44":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"d8c9c132-8462-433a-b82e-4ddb05eb2b44","title":"On the Blind Spots of Model-Based Evaluation Metrics for Text Generation | PDF","url":"https://arxiv.org/pdf/2212.10020.pdf","urlHash":3430204685},"d8db00e9-4388-4890-b39a-aca921a229ae":{"favIconUrl":"fallback","id":"d8db00e9-4388-4890-b39a-aca921a229ae","title":"Learning with not Enough Data Part 1: Semi-Supervised Learning","url":"https://lilianweng.github.io/posts/2021-12-05-semi-supervised/","urlHash":3682972654},"d8f95278-c801-4c07-835f-026b32df5c92":{"favIconUrl":"fallback","id":"d8f95278-c801-4c07-835f-026b32df5c92","title":"李航统计学习方法（第一章） - 知乎","url":"https://zhuanlan.zhihu.com/p/107944440","urlHash":953217105},"d905ea22-e5dd-4c09-85a1-538726de4d98":{"favIconUrl":"fallback","id":"d905ea22-e5dd-4c09-85a1-538726de4d98","title":"Transformer模型有多少种变体？复旦邱锡鹏教授团队做了全面综述","url":"https://posts.careerengine.us/p/60c2ebb480e090697baeb2a3","urlHash":2696872648},"d909b7af-365b-4309-918d-737ed76649e9":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"d909b7af-365b-4309-918d-737ed76649e9","title":"Do Language Models Perform Generalizable Commonsense Inference? | PDF","url":"https://arxiv.org/pdf/2106.11533.pdf","urlHash":1591798302},"d912e728-0190-403f-8b1f-c79bdef63036":{"favIconUrl":"fallback","id":"d912e728-0190-403f-8b1f-c79bdef63036","title":"Fooling Partial Dependence via Data Poisoning","url":"https://arxiv.org/pdf/2105.12837.pdf","urlHash":299484675},"d9264fcd-88e9-4ea8-bc8a-692fe0ebe7e7":{"favIconUrl":"https://huyenchip.com/favicon.ico","id":"d9264fcd-88e9-4ea8-bc8a-692fe0ebe7e7","title":"RLHF: Reinforcement Learning from Human Feedback","url":"https://huyenchip.com/2023/05/02/rlhf.html","urlHash":806050308},"d92c8a30-12b5-44e3-8bbb-e5724e8d3987":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"d92c8a30-12b5-44e3-8bbb-e5724e8d3987","title":"アンデッドガール・マーダーファルス 3 (豆瓣)","url":"https://book.douban.com/subject/35380220/","urlHash":2121269688},"d92ccab7-3b6b-4062-9819-39b8abd2c5e7":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"d92ccab7-3b6b-4062-9819-39b8abd2c5e7","title":"LargeWorldModel/LWM","url":"https://github.com/LargeWorldModel/LWM","urlHash":1483978172},"d9359220-7f1e-4b3d-a847-3c684d715196":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"d9359220-7f1e-4b3d-a847-3c684d715196","title":"不用MoE，直接砌墙一样把模型拼接起来扩增模型规模","url":"https://mp.weixin.qq.com/s?__biz=MzkwMjUwNTg3OA==&mid=2247485261&idx=1&sn=50b5d4e8b20dd11c037afb40958e2bda&chksm=c0a533b4f7d2baa2ffab2342be9bed035fd1bde2d3dd73f5e60e47f821efe1242e4b2629000d&mpshare=1&scene=1&srcid=0115L01np8XaRTdChecPORg6&sharer_shareinfo=5db198b933158e7b546e4128cca23b0f&sharer_shareinfo_first=5db198b933158e7b546e4128cca23b0f&exportkey=n_ChQIAhIQgLebUbI%2FJfdHoBaPBiL2oRKWAgIE97dBBAEAAAAAAMHUBfbFzY0AAAAOpnltbLcz9gKNyK89dVj0DiF1CqJWRjPXWbknlUdo1frG8fi6wo9CxIKX0%2BRvxz8D1QeOrmCXnz%2BMKjaT42Y8VpU5b3upEkvzkI32XsN4If0cRMWAu%2BPH8jssFfZkDxIkQaN4t48bKPzs3cd3oUa84Db9BhhoL4AzdKbgix9P2caN60vb1vUoygo%2BD6paeByx6b01vTOpqdocOHfaAGRW7%2FOPb3DT%2BFULF7E5bw3FqRUBcwMhO%2BX7%2F1IzezuPjMbtJoLfN9ofGRi6Q%2B5TnM5fdD2gDhp%2FmHjIe7SwgVyNh5qS7VMDk9Oxk0WGwB6JesQ8gXpSljheRs61jqHDWz2A&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsYZ6zDNHseMijVQ0DwqmEBByCjiuJBFv%2Btss3yQmlbwwA%3D%3D&wx_header=0#rd","urlHash":1729138493},"d985df45-38db-412d-bafa-b2d5b06e77dc":{"favIconUrl":"fallback","id":"d985df45-38db-412d-bafa-b2d5b06e77dc","title":"深度学习中不同类型卷积的综合介绍：2D卷积、3D卷积、转置卷积、扩张卷积、可分离卷积、扁平卷积、分组卷积、随机分组卷积、逐点分组卷积等pytorch代码实现和解析。 - 知乎","url":"https://zhuanlan.zhihu.com/p/366744794","urlHash":3832181415},"d9c67fec-1530-4023-b052-214cc8eb653f":{"favIconUrl":"fallback","id":"d9c67fec-1530-4023-b052-214cc8eb653f","title":"Fishr Invariant Gradient Variances for Out-of-Distribution Generalization - PMLR-2022-rame22a","url":"https://proceedings.mlr.press/v162/rame22a/rame22a.pdf","urlHash":2667960500},"d9d831cc-175d-49c9-9ada-bc60ab18733a":{"favIconUrl":"https://www.99csw.com/favicon.ico","id":"d9d831cc-175d-49c9-9ada-bc60ab18733a","title":"尸体长发之谜·杀人方程式2_绫辻行人_在线阅读_九九藏书网","url":"https://www.99csw.com/book/7137/index.htm","urlHash":3504638096},"d9e22a14-a20e-48d9-9c9c-8e0028d99a33":{"favIconUrl":"fallback","id":"d9e22a14-a20e-48d9-9c9c-8e0028d99a33","title":"dice.pdf","url":"https://yobibyte.github.io/files/paper_notes/dice.pdf","urlHash":4174583135},"da00bf09-da92-4f3e-9320-57b3cb6e72ae":{"favIconUrl":"fallback","id":"da00bf09-da92-4f3e-9320-57b3cb6e72ae","title":"笔给你，你会怎么写《进击的巨人》结局？ - 知乎","url":"https://www.zhihu.com/question/453567336/answer/1825995877","urlHash":1916743442},"da05e3c0-a0e0-4bc4-b0d4-2db437f82ffe":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"da05e3c0-a0e0-4bc4-b0d4-2db437f82ffe","title":"Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions | PDF","url":"https://arxiv.org/pdf/2308.11483.pdf","urlHash":3256228889},"da3b6754-8460-4e1a-9e9f-06b54cfa8a41":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"da3b6754-8460-4e1a-9e9f-06b54cfa8a41","title":"Jason Wei on X: \"Clever @google/@stanford paper on LLMs from my brother @jerryweiAI. Performance boosts are great, but there is a more profound insight in this paper that was not explicitly stated: LLMs are trained on human language, but due to the nature of how language was developed (first…\" / X","url":"https://twitter.com/_jasonwei/status/1658561533335736322","urlHash":3595903037},"da40a818-29e1-413d-b66d-616aed38669f":{"favIconUrl":"fallback","id":"da40a818-29e1-413d-b66d-616aed38669f","title":"haiphanNJIT/StoBatch: Scalable Differential Privacy with Certified Robustness in Adversarial Learning (ICML'2020)","url":"https://github.com/haiphanNJIT/StoBatch","urlHash":1376050201},"da67f714-5445-4ef0-8539-a17679027f82":{"favIconUrl":"fallback","id":"da67f714-5445-4ef0-8539-a17679027f82","title":"Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in NLP Models","url":"https://arxiv.org/pdf/2103.15543.pdf","urlHash":1895820904},"da6c575f-c0bb-4155-b4f4-7d19ddc373f5":{"favIconUrl":"fallback","id":"da6c575f-c0bb-4155-b4f4-7d19ddc373f5","title":"Pre-train, Prompt, and Predict A Systematic Survey of Prompting Methods in Natural Language Processing - Arxiv-2107.13586","url":"https://arxiv.org/pdf/2107.13586.pdf","urlHash":1815598703},"da7a483f-c909-4719-b7bc-5f163bc6a640":{"favIconUrl":"fallback","id":"da7a483f-c909-4719-b7bc-5f163bc6a640","title":"Large Language Models as Analogical Reasoners - Arxiv-2310.01714","url":"https://arxiv.org/abs/2310.01714?utm_source=substack&utm_medium=email","urlHash":2002308339},"dab71eae-45b2-47c7-9ced-b445add7a468":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"dab71eae-45b2-47c7-9ced-b445add7a468","title":"Ziming Liu on X: \"Mechanistic interpretability is not only for ML or LLM, but is even more promising for Science! A few months ago, we proposed a brain-inspired method (BIMT) for NN interpretability; Now we're happy to see that it can give something back to neuroscience - Growing brains in RNNs! https://t.co/HGjZ2DkrhY\" / X","url":"https://twitter.com/ZimingLiu11/status/1712278560533348583","urlHash":3826209647},"dabd287b-c36e-4c3d-83ad-d94b4a53a52c":{"favIconUrl":"fallback","id":"dabd287b-c36e-4c3d-83ad-d94b4a53a52c","title":"superbrother - 知乎","url":"https://www.zhihu.com/people/superbrother-58/posts","urlHash":2782283579},"dae71a31-b7ab-4806-a0b4-81162bf9fbb4":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"dae71a31-b7ab-4806-a0b4-81162bf9fbb4","title":"Tianlong Chen on X: \"💭 Dreaming of tuning LLMs with inference-only memory? 🤔 🌄 Check out our ZO-LLM Benchmark, revisiting ZO for LLM tuning, across 5 LLM families &amp; 3 task complexities &amp; 4 tuning schemes ➡️ Unveiling overlooked principles &amp; 3 novel enhancements. 🔗 https://t.co/LEfyx7ervk https://t.co/tHuNG2VxqY\" / X","url":"https://twitter.com/TianlongChen4/status/1760283654738296887","urlHash":3722990594},"daf6ddc7-d1d4-457c-8e50-597eb47c996a":{"favIconUrl":"fallback","id":"daf6ddc7-d1d4-457c-8e50-597eb47c996a","title":"A Cookbook of Self-Supervised Learning - Arxiv-2304.12210","url":"https://arxiv.org/abs/2304.12210?utm_source=substack&utm_medium=email","urlHash":3038660287},"daf8a966-1031-411f-80ff-778ee3e1a4a0":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"daf8a966-1031-411f-80ff-778ee3e1a4a0","title":"twitter.com/anmarasovic/status/1729760318157455683","url":"https://twitter.com/anmarasovic/status/1729760318157455683","urlHash":456898084},"db1ead76-992a-42ca-b644-fb5a061b3abc":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"db1ead76-992a-42ca-b644-fb5a061b3abc","title":"Larger language models do in-context learning differently | PDF","url":"https://arxiv.org/pdf/2303.03846.pdf","urlHash":660610915},"db650e89-12e1-4746-87d4-310edb3b1c98":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"db650e89-12e1-4746-87d4-310edb3b1c98","title":"(1) Andrej Karpathy on X: \"I think this is mostly right. - LLMs created a whole new layer of abstraction and profession. - I've so far called this role \"Prompt Engineer\" but agree it is misleading. It's not just prompting alone, there's a lot of glue code/infra around it. Maybe \"AI Engineer\" is ~usable,\" / X","url":"https://twitter.com/karpathy/status/1674873002314563584","urlHash":2939911646},"db891d46-b961-461e-8088-083fed633001":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"db891d46-b961-461e-8088-083fed633001","title":"Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt | Abstract","url":"https://arxiv.org/abs/2210.03029","urlHash":1134188281},"db976253-6afd-40aa-acca-6d9db44c4e1b":{"favIconUrl":"fallback","id":"db976253-6afd-40aa-acca-6d9db44c4e1b","title":"Interpretability at Scale","url":"https://nlp.stanford.edu/~wuzhengx/boundless_das/index.html","urlHash":8474565},"dbab204b-7dad-44e9-a9b7-861801625ef4":{"favIconUrl":"fallback","id":"dbab204b-7dad-44e9-a9b7-861801625ef4","title":"R-Tuning: Teaching Large Language Models to Refuse Unknown Questions | PDF","url":"https://arxiv.org/pdf/2311.09677.pdf","urlHash":2194796616},"dbc8e132-b0cb-484a-a436-66a4753b21f6":{"favIconUrl":"fallback","id":"dbc8e132-b0cb-484a-a436-66a4753b21f6","title":"NICE: Non-linear Independent Components Estimation","url":"https://arxiv.org/pdf/1410.8516.pdf","urlHash":3510981871},"dbdb8a1c-52cb-417c-8ce7-6a56a9471842":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"dbdb8a1c-52cb-417c-8ce7-6a56a9471842","title":"AK on X: \"Weight subcloning: direct initialization of transformers using larger pretrained ones paper page: https://t.co/wkzdJprrfp Training large transformer models from scratch for a target task requires lots of data and is computationally demanding. The usual practice of transfer… https://t.co/SqVihaMKkn\" / X","url":"https://twitter.com/_akhaliq/status/1736566234840260724","urlHash":985096435},"dbf00824-d137-4312-af85-a286942b38b2":{"favIconUrl":"fallback","id":"dbf00824-d137-4312-af85-a286942b38b2","title":"A Visual Exploration of Gaussian Processes","url":"https://distill.pub/2019/visual-exploration-gaussian-processes/","urlHash":1849609242},"dbf209a0-60b2-4f0a-bc87-5cc66788e127":{"favIconUrl":"fallback","id":"dbf209a0-60b2-4f0a-bc87-5cc66788e127","title":"Tag2Text: Guiding Vision-Language Model via Image Tagging","url":"https://arxiv.org/abs/2303.05657","urlHash":53192355},"dbf865d0-883e-4b8b-be7a-e4111a03462c":{"favIconUrl":"fallback","id":"dbf865d0-883e-4b8b-be7a-e4111a03462c","title":"逼真复刻「完美中国情侣」！加强版Stable Diffusion免费体验，最新技术报告出炉","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652348850&idx=2&sn=4e1b31ef72b026668f045b1dba831082&chksm=f124d543c6535c55df32663a00e005a71ca62fb4253888b50020896c2a8b1c6871b48740ad64&mpshare=1&scene=1&srcid=0813eDDCLasCNo92biQZrdmG&sharer_sharetime=1691904705010&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQj4WAGYxWz3OfAloZrWWsEBKWAgIE97dBBAEAAAAAAMTTFZPIdZ8AAAAOpnltbLcz9gKNyK89dVj0wNlAIamV3hEGfBiRrQvbzz6nSXcbttqj4x1I12EBuWqrb5mhicKDDadQTFmdeh9QLubHoAt%2B9ju9e%2BsRMxzPSr8d5MJit%2FoNS0qP5LATmuGCWHqpHAiMR6s3nKcoYhcsen3nlISgToQ%2FeDU%2FoWLAq72tgvH%2B26HzAn80NuWERJljlUemrQcs%2BE%2FWyjbqmNirmo3Qvds%2BKHl9acd0zDuiKWhLU%2Bi6jkCHH8jvz%2FOaxE84ecb3wS1pYJj4vMNwfVDhYKIVHEkcCQ4f%2FhtU8dordYFYVFC4W1aBE1BZizTNr0fSzJBhfjeLR3I2%2FEiaopOn&acctmode=0&pass_ticket=Fth8VZcc%2FJbxlvWPzvb9iWIxVrCyTAw9J1B5mglWJZbwA2J9X5FBHIDwyX6R%2B8Mv&wx_header=0#rd","urlHash":2613852098},"dc0dd2f2-f872-44ff-9120-230128a33d41":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"dc0dd2f2-f872-44ff-9120-230128a33d41","title":"LLM的逆转诅咒极其正常","url":"https://mp.weixin.qq.com/s?__biz=MzU2MDc4NDI2Ng==&mid=2247483875&idx=1&sn=e0562646c171d73349ca239159ce44ca&exportkey=n_ChQIAhIQgseeqAsE%2BvUVBaBtQDKfABKWAgIE97dBBAEAAAAAANLmK8BTGk4AAAAOpnltbLcz9gKNyK89dVj0J1aNZdTQdIlGcPaVcj6SJWkG5k8530kdPqbNxwpYRgZ9rW28IUaGI2ysdJY8QO9Zrm6qfmFBpFw152LwhDHaoJNKLpvTPEABY2LgdSDLmsdsnW193guIPCez6WedB2u26ghfgXizPCZ3a88Sk6CF3jz7zCDbBHU5GnqzUWqi0iBktDosaMnqvHfOJsSr2bV1LRMu8rTaVwX%2B5jkqnJEZfbaEm5Oz1w3FbWTxoJYWu5T9nsMXH9xl6OloclxODhjDLf5T29rqxFXaAkq7PukaMP2tgXXJ9m649Sc2eFLXYwJq0mAxx5xhJPL97Ox%2BNAmR&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsbZRcIIchLwMFeoS7Gu6%2BEUZlFRjBR9sPFuA0LNNPZ0%2Bw%3D%3D&wx_header=0","urlHash":1035589853},"dc110fd7-6063-4613-a873-012ca65f9ae1":{"favIconUrl":"fallback","id":"dc110fd7-6063-4613-a873-012ca65f9ae1","title":"Explain Yourself! Leveraging Language Models for Commonsense Reasoning - Arxiv-1906.02361","url":"https://arxiv.org/pdf/1906.02361.pdf","urlHash":3537810051},"dc19fbe2-55cd-4921-bacc-7e6ad1e9cbcd":{"favIconUrl":"fallback","id":"dc19fbe2-55cd-4921-bacc-7e6ad1e9cbcd","title":"NeurIPS 2022高分论文！DeRy：让知识迁移像拼积木一样简单高效！","url":"https://mp.weixin.qq.com/s?__biz=MzUxNjcxMjQxNg==&mid=2247565529&idx=2&sn=2ebbcdee73318a925664a5db7ae9513e&chksm=f9a0b256ced73b4067f294041819e8b49f76d00ced442e9e8cb6479cb78aa53484492667308c&mpshare=1&scene=1&srcid=1218Xs2cfHnFPJf0nmsbiv4L&sharer_sharetime=1671346237329&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQWyKo5EJ9rIcEL0g2bh3bBhKWAgIE97dBBAEAAAAAAP%2FkKsKhABwAAAAOpnltbLcz9gKNyK89dVj0hLfpghxDTMMjptFK2oOMuYW6eLieNlQmpNPfvzEvRszlEWrrB%2BCykSWHVCKRCSsCXUlZZYShKvwrAw7UJeKyHiEz0V%2BNZcL6wL3vQZJ8HfSCepUxILyvEJdx9g6Klzezu%2BL8L8jEvrsnMHnoEz%2FQcTq2TMCXdFIczVpYeO1qAb6ieLhj9YIOGXkqmg0zckEbqLlK5uwqILgqe%2F1%2BVY1b9VMg%2BwvQq2Y8n8WA043qDzY3B%2FUFjTGh7ONJAGjbnFSypWE5OKy%2BaM9SSQRp1igGdv33I6hpiD2SPT%2BfyYGK44oamVyG7AoGxV8y0kww%2BlWL&acctmode=0&pass_ticket=B%2Fr2wa0S%2FM5lL%2FB24fD%2FIrSWC3GeT01IvggTYRYcwurD%2BsY4u%2Bo39nB6zH3MmZWD6TS0GPZhM5cL2jeJ87IpEA%3D%3D&wx_header=0#rd","urlHash":767906426},"dc360f80-b3d4-4ab4-bf70-663a36d90c2c":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"dc360f80-b3d4-4ab4-bf70-663a36d90c2c","title":"多模态LLM多到看不过来？先看这26个SOTA模型吧","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650906368&idx=4&sn=0227882f15738309072294f0ee09e4f7&chksm=84e45b7eb393d26835a7a23cef84bc9d0d3470a536c2206656cb8d216aba26851a47c18a9e99&mpshare=1&scene=1&srcid=0131wPA8OwCtTn0CBamukhvY&sharer_shareinfo=f96522952a2282082d007a1aa568c50e&sharer_shareinfo_first=f96522952a2282082d007a1aa568c50e&exportkey=n_ChQIAhIQ0WCdN4Ep5FwW%2FU9HV6ZCUxKWAgIE97dBBAEAAAAAAGBsDDMt6c8AAAAOpnltbLcz9gKNyK89dVj0RtSh3JNQ9mm3hTvj%2BvzKZI10JkislbuzvBLkSXKn%2BrwV7utfsWhuUuPsg4U7Ul5EZSOUKTV8rr1rNt%2BqLG%2B4C0lhLMoVl%2FKtEgfADd3NFqGAw0zTN2bKgv8taHARp91ufAbK87dbxtmPxvkr5oyELL68eXpAVhBrbhbPb6FNEXWxU9DFGKwz4ENzLPX0JoiOraGoMQmoY%2BZQ0v0nwWT%2BmC%2FGFw9PDhXOwR%2FGoKqDQvMpv7I1yg0Gc0Qq8AeDnJtXl0SDAX4CsvCx4PPv8XBCVD5oEx%2FGAKcrUTWjluzcTNxuBNx9XiHXaR8CCE6ecCff&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HM%2BUjuyKn2itWny%2FbVTTNYsdqO42VX3z59m4upHjxYzDw%3D%3D&wx_header=0#rd","urlHash":688906177},"dc4c1288-c76f-4dd9-b032-a87c18e2620b":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"dc4c1288-c76f-4dd9-b032-a87c18e2620b","title":"FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios | Abstract","url":"https://arxiv.org/abs/2307.13528","urlHash":3061668906},"dc91eeb0-a430-4451-9612-7eae692ac5e2":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"dc91eeb0-a430-4451-9612-7eae692ac5e2","title":"Matthew Finlayson on X: \"Nucleus and top-k sampling are ubiquitous, but why do they work? @johnhewtt, @alkoller, @swabhz, @Ashish_S_AI and I explain the theory and give a new method to address model errors at their source (the softmax bottleneck)! 📄 https://t.co/0zRu3x9mVg 🧑‍💻 https://t.co/A57bEb4aqb https://t.co/496MWsOWyi\" / X","url":"https://twitter.com/mattf1n/status/1709703679476125745","urlHash":452718979},"dcc91dc2-d8d4-4953-bc85-5b0c9c893399":{"favIconUrl":"fallback","id":"dcc91dc2-d8d4-4953-bc85-5b0c9c893399","title":"broderick_lecture3_spring2023","url":"https://piazza.com/class_profile/get_resource/ldjefz5a4yu69n/le4m7z1yijx13b","urlHash":4288346555},"dce20756-1372-46f2-a100-1e0bbc4cfc3d":{"favIconUrl":"fallback","id":"dce20756-1372-46f2-a100-1e0bbc4cfc3d","title":"A Barebones Guide to Mechanistic Interpretability Prerequisites — Neel Nanda","url":"https://www.neelnanda.io/mechanistic-interpretability/prereqs","urlHash":2982436219},"dce23512-5d0d-49b0-91a3-a41eb7f00ef0":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"dce23512-5d0d-49b0-91a3-a41eb7f00ef0","title":"Aditi Jha on X: \"Excited to share work from my internship with the amazing people at @MosaicML! 🎉 How should you finetune a Large Language Model for general purpose instruction following? Check out LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms! https://t.co/TRD5RPMAKt\" / X","url":"https://twitter.com/aditi_jh/status/1729535598950756406","urlHash":644947840},"dd04a2c7-2eb3-4a19-84de-ecef7f207aed":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"dd04a2c7-2eb3-4a19-84de-ecef7f207aed","title":"The elephant in the interpretability room: Why use attention as explanation when we have saliency methods? | Abstract","url":"https://arxiv.org/abs/2010.05607","urlHash":2633555175},"dd2939ae-18f8-4472-8a0f-4136a63c1bfb":{"favIconUrl":"fallback","id":"dd2939ae-18f8-4472-8a0f-4136a63c1bfb","title":"jmschrei/torchegranate: A temporary repository hosting a pomegranate re-write using PyTorch as the backend.","url":"https://github.com/jmschrei/torchegranate","urlHash":3259129363},"dd3c88d7-0b5e-46a8-9bac-43008d840145":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"dd3c88d7-0b5e-46a8-9bac-43008d840145","title":"Paul Roit on X: \"In this internship project, we pose a simple question: Can we improve the factual consistency of summarization models by guiding them with textual entailment-based rewards? And more importantly, would the resulting summaries stay informative? https://t.co/RZ4tntSpew (1/8) https://t.co/fAZcqqnLwH\" / X","url":"https://twitter.com/paul_roit/status/1665743605544124418","urlHash":4283283902},"dd40628d-bea8-43a5-bc8c-b79f846f9cfe":{"favIconUrl":"fallback","id":"dd40628d-bea8-43a5-bc8c-b79f846f9cfe","title":"Theory of Graph Neural Networks Representation and Learning - Arxiv-2204.07697","url":"https://arxiv.org/pdf/2204.07697.pdf","urlHash":3838876818},"dd41b4d1-522a-4cd8-a647-8f7f71106d28":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"dd41b4d1-522a-4cd8-a647-8f7f71106d28","title":"傍聴者 (豆瓣)","url":"https://book.douban.com/subject/35223121/","urlHash":1053564469},"dd796acb-f061-46fe-8e74-361281d1c2ca":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"dd796acb-f061-46fe-8e74-361281d1c2ca","title":"LLaMA2上下文长度暴涨至100万tokens，只需调整1个超参数｜复旦邱锡鹏团队出品","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247700234&idx=3&sn=c29a1e1dc148a0b5a90b8ccfb8ac26c1&exportkey=n_ChQIAhIQFjASMy9cPbEMNvMIQbWV7xKWAgIE97dBBAEAAAAAALBiLsnoxcEAAAAOpnltbLcz9gKNyK89dVj0vpgTz%2BpstfST%2BlaN39bGh5R4en4exkXhtrlrB7ygHOVE1rvbvS7jG3aB6vJHq87qaDnNDzO2eFnTQyb%2BOJanxmzQ0LS%2BLBSurzWg6q3aFfMQ04xTE3KG1jtD2vWiOE4XTTvpKTfR9v9x0p6FdLKNcvgxs9ciO6DSD%2F9dRF6L30qyIHX%2B1Gq7cPrsSdLgmcqbbaPT8EhUTtZOVAGFeEQKa8JRuw9mGrvPPFlhTXC0qbounelfZIyl%2BuPEA%2Bp4Gza9SkSAhCEO6gLTtt57Kmu%2BqQPwvkZqSOIgVWrIV%2BAp%2FGwhDNH4y7DkRTO6Y%2F3nCJnq&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsZJlcShTzXG9x0SI%2FMySZ48GEC1cd0eQ594jb5UPBdmCw%3D%3D&wx_header=0","urlHash":497352195},"dd82ee09-2b2f-45b7-9934-3793e8026850":{"favIconUrl":"https://pearlagent.github.io/assets/images/favicon.png","id":"dd82ee09-2b2f-45b7-9934-3793e8026850","title":"Welcome to Pearl's official website! - Pearl - A Production-ready Reinforcement Learning AI Agent Library","url":"https://pearlagent.github.io/","urlHash":41694986},"dd882fa2-0e7a-4c49-8c21-e2fc8caa7533":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"dd882fa2-0e7a-4c49-8c21-e2fc8caa7533","title":"arxiv.org/pdf/2306.00477.pdf","url":"https://arxiv.org/pdf/2306.00477.pdf","urlHash":1938239823},"dd93902e-d8df-4c92-a84d-6dc0f6a55572":{"favIconUrl":"https://underline.io/favicon/favicon.ico","id":"dd93902e-d8df-4c92-a84d-6dc0f6a55572","title":"Underline | CREST: A Joint Framework for Rationalization and Counterfactual Text Generation","url":"https://underline.io/events/395/sessions/15222/lecture/76317-crest-a-joint-framework-for-rationalization-and-counterfactual-text-generation","urlHash":3219105939},"ddb01ec7-236b-4639-9939-57fb1da46424":{"favIconUrl":"https://ssl.gstatic.com/colaboratory-static/common/e11fc3dbd9214fb6318f5e141c13f3f6/img/favicon.ico","id":"ddb01ec7-236b-4639-9939-57fb1da46424","title":"Laboratory_N2__Matching_Regression__Python_sol.ipynb - Colaboratory","url":"https://colab.research.google.com/drive/1PSa8oYDtdKQ1XuAd7GKZc6N_TdUz-vP1?usp=sharing#scrollTo=VDNfyMp3pjeG","urlHash":633252349},"ddd89c8d-0117-4bca-995e-bbbf45fc5cb3":{"favIconUrl":"fallback","id":"ddd89c8d-0117-4bca-995e-bbbf45fc5cb3","title":"non-linguistic supervision for contrastive learning of sentence embeddings - Google Search","url":"https://www.google.com/search?q=non-linguistic+supervision+for+contrastive+learning+of+sentence+embeddings&oq=Non-Linguistic+Supervision+for+Contrastive+Learning+of+Sentence+Embeddings&aqs=chrome.0.0i512.250j0j1&sourceid=chrome&ie=UTF-8","urlHash":2802763561},"ddf9439c-a9c0-4128-b643-457a58f1feb4":{"favIconUrl":"https://www.google.com/favicon.ico","id":"ddf9439c-a9c0-4128-b643-457a58f1feb4","title":"大山誠一郎 不運な犯人 - Google Search","url":"https://www.google.com/search?q=%E5%A4%A7%E5%B1%B1%E8%AA%A0%E4%B8%80%E9%83%8E+%E4%B8%8D%E9%81%8B%E3%81%AA%E7%8A%AF%E4%BA%BA&newwindow=1&sxsrf=ALiCzsbOKvKLVmUhT1HXupK1bsImheH9cQ%3A1668490953653&ei=ySZzY_qlJ9jn5NoPt5iasA4&ved=0ahUKEwi6rumUva_7AhXYM1kFHTeMBuYQ4dUDCBA&uact=5&oq=%E5%A4%A7%E5%B1%B1%E8%AA%A0%E4%B8%80%E9%83%8E+%E4%B8%8D%E9%81%8B%E3%81%AA%E7%8A%AF%E4%BA%BA&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIECCMQJ0oECEEYAUoECEYYAFCeBFi7DWDtEWgCcAB4AIABVogB6QGSAQEzmAEAoAEBwAEB&sclient=gws-wiz-serp","urlHash":2808658527},"de3d26c0-89a9-4286-9251-16a1c2375e45":{"favIconUrl":"https://www.google.com/favicon.ico","id":"de3d26c0-89a9-4286-9251-16a1c2375e45","title":"mechanistic interpretability tweet chris olah - Google Search","url":"https://www.google.com/search?q=mechanistic+interpretability+tweet+chris+olah&newwindow=1&sca_esv=578990385&sxsrf=AM9HkKkIenf-rzV9U-KIP8T3LiAFvuqsug%3A1698968074761&ei=CjJEZa6PLs-YptQP3de8MA&ved=0ahUKEwiuvNKkvaaCAxVPjIkEHd0rDwYQ4dUDCBA&uact=5&oq=mechanistic+interpretability+tweet+chris+olah&gs_lp=Egxnd3Mtd2l6LXNlcnAiLW1lY2hhbmlzdGljIGludGVycHJldGFiaWxpdHkgdHdlZXQgY2hyaXMgb2xhaDIFEAAYogRIzBpQTliUGXADeACQAQCYAW-gAaAJqgEEMTAuM7gBA8gBAPgBAcICCxAAGIoFGIYDGLADwgIFECEYqwLCAggQIRgWGB4YHcICBRAhGKAB4gMEGAEgQYgGAZAGBQ&sclient=gws-wiz-serp","urlHash":1571689261},"de4a2fbf-3974-4e2e-8f10-0529b1d3e364":{"favIconUrl":"fallback","id":"de4a2fbf-3974-4e2e-8f10-0529b1d3e364","title":"Compressing BERT Studying the Effects of Weight Pruning on Transfer Learning - Arxiv-2002.08307","url":"https://arxiv.org/abs/2002.08307","urlHash":1226149296},"de4a6a21-4dcf-4db2-80aa-4124a554c357":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"de4a6a21-4dcf-4db2-80aa-4124a554c357","title":"Taiwei Shi on X: \"🤔Enhancing LLM with RLHF is powerful, but ever wondered how to reduce costs and boost efficiency in preference data acquisition? 💰 🚀Introducing Safer-Instruct, a groundbreaking pipeline that complements humans to construct large-scale preference datasets efficiently. 🧵1/5 https://t.co/NlRHM4i5S0\" / X","url":"https://twitter.com/taiwei_shi/status/1724915173109252194","urlHash":1921272035},"de4e2fe2-0d71-4a96-9705-04d9cc975205":{"favIconUrl":"fallback","id":"de4e2fe2-0d71-4a96-9705-04d9cc975205","title":"分节感想，严重剧透（呼吸）书评","url":"https://book.douban.com/review/13890377/","urlHash":4170186879},"de5ae3c5-7717-4154-96bf-6323447e731b":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"de5ae3c5-7717-4154-96bf-6323447e731b","title":"MIT惊人证明：大语言模型就是「世界模型」？吴恩达观点再被证实，LLM竟能理解空间和时间","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652386717&idx=1&sn=1305c7074fd27fc188da2d160626acad&exportkey=n_ChQIAhIQ9w30V1%2FYqlwtA4rd302i1hKWAgIE97dBBAEAAAAAAOQAIi4iVdEAAAAOpnltbLcz9gKNyK89dVj0W%2Bh7zxSjYGEnFr7ifYXY%2B0fKCj1E47NpZCGot0oH5yxIW9TaAs3mvS6YcJQY%2BCWDLO0zFYdKtZ2pAND3VYPD5IJMC%2BnA3%2BKrQpifqbILa0O%2F5HJn1wp75X6vYSHvV1JD%2Bt4Q8aIpL12JTi7%2BS%2BjM57gtfZXxoUWYqGeUp9IubBf4IAbJHx6B35VP3Iq0ieZyBKWKU92A4MCOwwjLoH3IHM551RBq0Guz3oCKwoAejDnaTt3gpb%2Fdf58YX4GVgLknMyh1E6zNqfDk6TYrV4CK3bJFro0KbFe6o7lMiRGgcTPIypud6t9%2BqXtug4NDsD2E&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsZBbedGxcSsIwnldz4Np3mvx36YD9CsVPml4Tu903OBeg%3D%3D&wx_header=0","urlHash":1087136831},"de5f0d45-4ef5-4173-90cb-ed5aa9bdadb2":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"de5f0d45-4ef5-4173-90cb-ed5aa9bdadb2","title":"AK on X: \"Google presents When Scaling Meets LLM Finetuning The Effect of Data, Model and Finetuning Method While large language models (LLMs) often adopt finetuning to unlock their capabilities for downstream applications, our understanding on the inductive biases (especially the… https://t.co/plQjaUszQa\" / X","url":"https://twitter.com/_akhaliq/status/1762724604462686316","urlHash":12080536},"de609dad-9f3c-40b6-9b70-2f24369a2c28":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"de609dad-9f3c-40b6-9b70-2f24369a2c28","title":"A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity | PDF","url":"https://arxiv.org/pdf/2305.13169.pdf","urlHash":283279701},"de7a9d08-747f-48f6-b708-1e260a98181d":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"de7a9d08-747f-48f6-b708-1e260a98181d","title":"Language Models (Mostly) Know What They Know | PDF","url":"https://arxiv.org/pdf/2207.05221.pdf","urlHash":2492140439},"dec6afb4-1993-4303-8605-70ac9bcfc79a":{"favIconUrl":"fallback","id":"dec6afb4-1993-4303-8605-70ac9bcfc79a","title":"Why Does Surprisal From Larger Transformer-Based Language Models Provide a Poorer Fit to Human Reading Times? - Arxiv-2212.12131","url":"https://aps.arxiv.org/abs/2212.12131","urlHash":1653119530},"deeb8e6c-e905-4b70-b1d8-71166fe76f7a":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"deeb8e6c-e905-4b70-b1d8-71166fe76f7a","title":"GPT-4/Gemini大翻车，做旅行攻略成功率≈0%！复旦OSU等华人团队：Agent不会复杂任务规划","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652442972&idx=2&sn=f8a866ff62f5e170fe9eabfb14a5c52f&chksm=f12a65adc65decbbce8a8c9583cbb705bc1bed9d940e6581e3e429c2dffc0180790141503277&mpshare=1&scene=1&srcid=0206L4iLujR5XaRjnnssVe1H&sharer_shareinfo=80ad36434ef35adf95db780cfb2bab6a&sharer_shareinfo_first=6505621a2c0159231d2aeac1d20bd6aa&exportkey=n_ChQIAhIQIeEGViGTYH4SqE%2BiYXGBKRKWAgIE97dBBAEAAAAAAFIaJv15BXUAAAAOpnltbLcz9gKNyK89dVj08bnevWEToyiog%2FmIazp%2FeEzJrWnmIqNlmgEaXvbCgJyxn9fw%2B7EDo6YRX3RCiufy6xfyphRQrUTy75AS4A5EThW2oSFOdt3Lx42VNE6yLi5b%2Bjl17BoLKG4emspybzTSeru3hEL0j7E1o1txPs1P2JEa2DNwIpt2axq8t1u5uX6JjBEWZxLZhi7LUmIIyP8WOYOtOJ6zxWltl%2FQyaf7J1qwayM4FysnreNoWHLH3rYezxWmzC%2FsOlgq3JIiKs8AyAHXTG17vjIo5JCzFQvG474kimsNMQr1c4NsMWjuE%2F%2BsutM25QiDHlLK%2FajxTN7J6&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HOEF9%2BahtuS1gQSIBsGhJO58TgCVqXIixh%2B1grkZx3vYg%3D%3D&wx_header=0#rd","urlHash":1760089700},"def0a083-c585-48e4-b46b-f90af653ca43":{"favIconUrl":"fallback","id":"def0a083-c585-48e4-b46b-f90af653ca43","title":"Probing Factually Grounded Content Transfer with Factual Ablation - Arxiv-2203.10133","url":"https://arxiv.org/pdf/2203.10133.pdf","urlHash":2488829523},"defc752d-7c68-4db5-92d2-77f41a3fb620":{"favIconUrl":"https://microsoft.github.io/autogen/img/ag.ico","id":"defc752d-7c68-4db5-92d2-77f41a3fb620","title":"Examples | AutoGen","url":"https://microsoft.github.io/autogen/docs/Examples/#automated-multi-agent-chat","urlHash":3552372984},"df07f701-d902-4a88-a486-f56ba6842f81":{"favIconUrl":"fallback","id":"df07f701-d902-4a88-a486-f56ba6842f81","title":"cvlab-columbia/zero123: Zero-1-to-3: Zero-shot One Image to 3D Object: https://zero123.cs.columbia.edu/","url":"https://github.com/cvlab-columbia/zero123","urlHash":3987054524},"df48cd39-815a-450d-a0d9-7be7a94452e5":{"favIconUrl":"fallback","id":"df48cd39-815a-450d-a0d9-7be7a94452e5","title":"Lectures","url":"https://dlsyscourse.org/lectures/","urlHash":1136116730},"df497248-e0af-4537-bde2-31e4cf023e4d":{"favIconUrl":"fallback","id":"df497248-e0af-4537-bde2-31e4cf023e4d","title":"Adversarially Regularising Neural NLI Models to Integrate Logical Background Knowledge","url":"https://arxiv.org/pdf/1808.08609.pdf","urlHash":147278042},"df5494a5-9d61-48bc-a10f-056144e5e88a":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"df5494a5-9d61-48bc-a10f-056144e5e88a","title":"Pan-ML/panml: PanML is a high level generative AI/ML development and analysis library designed for ease of use and fast experimentation.","url":"https://github.com/Pan-ML/panml","urlHash":1466824369},"df55d1d1-16f7-4e35-b6f2-8f5bdfec9993":{"favIconUrl":"fallback","id":"df55d1d1-16f7-4e35-b6f2-8f5bdfec9993","title":"Analyzing Dynamic Adversarial Training Data in the Limit - Arxiv-2110.08514","url":"https://arxiv.org/pdf/2110.08514.pdf","urlHash":1679669058},"df652957-287b-4fe4-bcaa-c6a92e9ea57f":{"favIconUrl":"fallback","id":"df652957-287b-4fe4-bcaa-c6a92e9ea57f","title":"The Wasted World – History, Totality, and Time","url":"https://thewastedworld.com/","urlHash":822618871},"df8f0fe3-1353-4423-ac34-8fbdcf75cbf2":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"df8f0fe3-1353-4423-ac34-8fbdcf75cbf2","title":"(1) elvis on X: \"Recurrent Memory Finds What LLMs Miss Explores the capability of transformer-based models in extremely long context processing. Finds that both GPT-4 and RAG performance heavily rely on the first 25% of the input, which means there is room for improved context processing… https://t.co/WgcvGQjNFO\" / X","url":"https://twitter.com/omarsar0/status/1759591371126571028?utm_source=substack&utm_medium=email","urlHash":3034785271},"dfab040d-d1dc-4ef7-a65b-f4c9cdaaf03e":{"favIconUrl":"fallback","id":"dfab040d-d1dc-4ef7-a65b-f4c9cdaaf03e","title":"Implementing_SDE_Diffusion_Models","url":"https://www.peterholderrieth.com/blog/2023/Diffusion-Models-From-Scratch-1d-Manifold/","urlHash":406629031},"dfb7dae2-8d17-4186-9306-f4585036a9be":{"favIconUrl":"https://underline.io/favicon/favicon.ico","id":"dfb7dae2-8d17-4186-9306-f4585036a9be","title":"Underline | Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering","url":"https://underline.io/events/395/sessions/15223/lecture/76228-self-adaptive-in-context-learning-an-information-compression-perspective-for-in-context-example-selection-and-ordering","urlHash":2031548496},"dfd4f960-7f18-4360-971f-beed2dc654ca":{"favIconUrl":"fallback","id":"dfd4f960-7f18-4360-971f-beed2dc654ca","title":"目标检测|SSD原理与实现 - 知乎","url":"https://zhuanlan.zhihu.com/p/33544892","urlHash":3158725714},"dfecc5cc-bc95-45e3-8024-53ca59df186b":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"dfecc5cc-bc95-45e3-8024-53ca59df186b","title":"颠覆Transformer霸权！CMU普林斯顿推Mamba新架构，解决致命bug推理速度暴增5倍","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652414828&idx=1&sn=401e5e7adcf037a2c1b4167e8b616d5b&exportkey=n_ChQIAhIQzj78poUHClIgeVOwUK%2BE3RKWAgIE97dBBAEAAAAAAMARL94%2Fi6IAAAAOpnltbLcz9gKNyK89dVj06Sv6Dxqt%2Fc6UqsBLqAVW7FyqZtUpn1LO3ESE9kwbCl372ez37UiACDQP0pXTtLfOWjYJNmr7u2kbS09dr4T%2BcRbGaO%2B6tfLGJHjsFAZI2uBN929r7iRZNjnBxOd5fCgtAYTiBoIBRdNcyv0Je2mTS%2BX9JZtWlr%2B%2Bc9uX2JmHLwmTlYG7bjjjxqpdjeZFDBo%2BepZheaMfbjQnql9fEWVD6q8QVeK75pEEyxeoXx9BMeNcXmNqyMKtIErhArOaxBuQXuXBsBzU2qLpBHk9XtBuk7xZDlGUgB9nPQbjKspj7CGgwFePNA0sKuucdVDjdXWD&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsZ%2F7FbWaoQyMUyWtm02fSk4m4X4avmLR5lukt9UKB7u2Q%3D%3D&wx_header=0","urlHash":3850671481},"dffe99ba-1058-4788-8267-62c0f6ad9111":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"dffe99ba-1058-4788-8267-62c0f6ad9111","title":"Phillip Isola on X: \"One lens on synthetic data: Often you have a bunch of mappings X--&gt;Y, Y--&gt;Z, etc and you want other mappings implied by these. A simple approach is to use the given mappings to sample training data for the implied mappings. 1/3\" / X","url":"https://twitter.com/phillip_isola/status/1742729640211370218","urlHash":614417450},"e029bb69-678e-402e-ba42-067357af5bd6":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"e029bb69-678e-402e-ba42-067357af5bd6","title":"今日arXiv最热大模型论文：超越LoRA，北京大学提出预训练模型非梯度优化法","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247577744&idx=2&sn=81797d71be41b5a2af07471c7dbe00ec&chksm=970e9846a07911507e574ee6891b7c661ef78c7f19756d16f34f3901d365fc76814b50da475e&mpshare=1&scene=1&srcid=0315BLTRAUJ2JSBrbAoP1reS&sharer_shareinfo=f8f9beaa16bcd591f475f75c979b0e5a&sharer_shareinfo_first=f8f9beaa16bcd591f475f75c979b0e5a&exportkey=n_ChQIAhIQ0z%2F5VWpnmI0IenDEnlgFeBKWAgIE97dBBAEAAAAAABc%2BAQRMIcYAAAAOpnltbLcz9gKNyK89dVj0SCU5G9wmePCOr1uaLDdGbDQfAqNu4p7oLiLqwh0Pf3kLSuGqielIWYOMYRmFAGvilpYriwDFa2oPysxOisea4g0oqhQfhISoKcVqwSqSfFLz61kUEOuzf1F5zFe6x2pDb9cs5kNxS0DI8vBNyEzXvpU5D4D4B8Ei1xZamu3nzpqCX%2BsBFiAcr3JpqCqIxz%2FWNaLGj%2FR3EYBLumo3qoTFPOOsDptLBDj5ttjTKH5RP0ZYXdad6ShENM%2FKhF4SlsE%2Bje6tyeVyfKx76k%2Fr4%2FDiFqlq0iYe1Hb7%2FdZcIBKAXbnm4qVdbtZW1U%2FAh9bl0jiZ&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCPsniA7PcgndKgEcRnmWtG2eGkYjXMG7%2F1lrecZCGPNlw%3D%3D&wx_header=0#rd","urlHash":205687853},"e0471a57-9415-43f9-8b78-c1a25bc95a26":{"favIconUrl":"fallback","id":"e0471a57-9415-43f9-8b78-c1a25bc95a26","title":"谷歌复用30年前经典算法，CV引入强化学习，网友：视觉RLHF要来了？","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650869505&idx=1&sn=a71a8bb1edb1a6cb4e90a91396fdd60f&chksm=84e4cb7fb393426983ae090a49c0c0afbd36d0f4223607fdb155e14057c31b53b48d57f907c1&mpshare=1&scene=1&srcid=0412V66UAR8CB2qdxPnlPd2y&sharer_sharetime=1681301386197&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQvZhcW%2B%2FPwCaKMhdmwe%2FJihKWAgIE97dBBAEAAAAAACDdKB82VZoAAAAOpnltbLcz9gKNyK89dVj0W6Joz71LDtxEzxJxHJSaWOV%2FptDvp134oxdNg8H3k2DR5R8h5AfgRO7HM1OGPOivT2CIKpyAGXqqOIhLChxCnWxuRGrpAH1n5PNNZ%2B8sGFlsw0BJw4nL%2ByDG85sVT3Ki39uow7ljeUJXF5hGWE5%2BVqDHNJ19nfbxT%2BZL%2BIBm1FGSW%2BXQ9gg0Y9yNkMtRW41YY3rC73BNpnM67DSpY0Wr4U1f0urlRLIm4uy6ZIiuJFc07iUqeKqu5TCsUVT3g23qZGTIaLCeBvY3Y%2FUBPbDJfcn4V99IVLE2pBs5pVNgm1IEf%2FU6908470iDYuJItpof&acctmode=0&pass_ticket=DUWJdFUi1JDJOm6OXRe2ZUPZKRPw403wXxhVQ6QEDds%2FYufgjAc6HqUz9YAJpirohXg7X4jgidgIqIwWHXUUIA%3D%3D&wx_header=0#rd","urlHash":2061812015},"e090a983-d19f-408f-9da5-e24db61f7ef7":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e090a983-d19f-408f-9da5-e24db61f7ef7","title":"Fanghua Ye@EMNLP on X: \"How can we benchmark LLMs comprehensively? Is the accuracy metric sufficient for evaluation? Check out our latest work in which we test 8 LLM families, including Llama-2, Mistral, Falcon, MPT, Yi, Qwen, DeepSeek, and InternLM, via uncertainty quantification.\" / X","url":"https://twitter.com/Fanghua_Ye/status/1750185299765039335","urlHash":3955545826},"e0df4160-9494-4724-89d5-5715160055a5":{"favIconUrl":"fallback","id":"e0df4160-9494-4724-89d5-5715160055a5","title":"What are Diffusion Models?","url":"https://lilianweng.github.io/posts/2021-07-11-diffusion-models/","urlHash":3485653730},"e0dfabf6-7ea9-4049-b200-728fac40cb9f":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"e0dfabf6-7ea9-4049-b200-728fac40cb9f","title":"Sources of Hallucination by Large Language Models on Inference Tasks | PDF","url":"https://arxiv.org/pdf/2305.14552.pdf","urlHash":140170458},"e103f111-6527-418f-96db-261451461298":{"favIconUrl":"fallback","id":"e103f111-6527-418f-96db-261451461298","title":"STA414","url":"https://duvenaud.github.io/sta414/","urlHash":1941426232},"e110d474-2f28-4ec7-9166-76d3208f0b91":{"favIconUrl":"fallback","id":"e110d474-2f28-4ec7-9166-76d3208f0b91","title":"Datamodels Predicting Predictions from Training Data - Arxiv-2202.00622","url":"https://arxiv.org/abs/2202.00622","urlHash":1016622047},"e1860437-87ba-40e3-bcf5-d7b32b784d4c":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"e1860437-87ba-40e3-bcf5-d7b32b784d4c","title":"Nyströmformer：基于矩阵分解的线性化Attention方案 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/8180","urlHash":2821971602},"e191b73e-6773-433f-bcde-4765c7680731":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e191b73e-6773-433f-bcde-4765c7680731","title":"Ruiqi Zhong on X: \"This is a very general flexible &amp; general framework to automatically discover and explain patterns in image dataset. Could be used for ML models, scientific applications, etc. Check it out if you are interested!!\" / X","url":"https://twitter.com/ZhongRuiqi/status/1732432847489937855","urlHash":344114097},"e198a0bc-2e77-4ac7-98f9-416a64c85102":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"e198a0bc-2e77-4ac7-98f9-416a64c85102","title":"Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models | PDF","url":"https://arxiv.org/pdf/2101.00288.pdf","urlHash":514977264},"e1e62490-79ce-4c03-ba42-08ad416bbe48":{"favIconUrl":"https://wikiwandv2-19431.kxcdn.com/icons/favicon.ico","id":"e1e62490-79ce-4c03-ba42-08ad416bbe48","title":"Monadology - Wikiwand","url":"https://www.wikiwand.com/en/Monadology","urlHash":3007335172},"e2557fc8-48ea-4bfa-8b05-bb28bc59fd35":{"favIconUrl":"fallback","id":"e2557fc8-48ea-4bfa-8b05-bb28bc59fd35","title":"BLIP-2、InstructBLIP稳居前三！十二大模型，十六份榜单，全面测评「多模态大语言模型」","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652347745&idx=3&sn=76b3a814bcc6ccb37406533ed0480b48&chksm=f124e990c6536086a799e24d957e5aa20af33d8aa83d8c826902c8cf3867fff0bb01a8ea5ac0&mpshare=1&scene=1&srcid=07173Scbj7lRaVWOHTmX1gUv&sharer_sharetime=1689584174998&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQdmnw84nD4ABYpK0QSn1GbhKWAgIE97dBBAEAAAAAAPAqAtFv4W0AAAAOpnltbLcz9gKNyK89dVj0ARr4Qwl4LebbgzQFrveMYc0gEuhUwvYwsX45PX6dDaRzYGg35ZmUcs1QcOK6M10%2FosT6Uzk9NHaGhRJqsxmi3SPLNGjNEAerTI4J%2FvCKdXsMx7QNk8PqD3H49wC7MMLjflWxfgQX9RaSYYyIUWjcusVuGfutuKLYwjal%2F5fkMdITFoYXU3kfoI6SaBwtYQZo%2BrXTeHba1xqEflkoDsB9b91ID%2FU9LRYOVisDaH4NvEJpjtrHnBBmwVLfNbCgfJz4DkAXn0dg9lyseumAYR5aPZd0lvSU2TpfjLBfXu5PS132NccnRHpIKtRQipzwLURy&acctmode=0&pass_ticket=si1%2Bl74iP%2FzcLk04VFupFJNqczUf5p6hoEusxFsVarY6e5nbclPjvTrxEIgt66lP&wx_header=0#rd","urlHash":3228821630},"e2592844-f1ae-44e6-a4b6-a85a52ef57f7":{"favIconUrl":"fallback","id":"e2592844-f1ae-44e6-a4b6-a85a52ef57f7","title":"BundleSDF: Neural 6-DoF Tracking and 3D Reconstruction of Unknown Objects","url":"https://bundlesdf.github.io/","urlHash":3714413115},"e2966d26-5235-458c-9901-3f7dfe5c041f":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"e2966d26-5235-458c-9901-3f7dfe5c041f","title":"大模型在持续微调中的灾难性遗忘研究","url":"https://mp.weixin.qq.com/s?__biz=MzI3NTQ5MjA4OQ==&mid=2247488245&idx=1&sn=b4b07ed631e3907f0fc44443b204f02c&chksm=eb02af63dc752675f1898a47e79619578cb0458157d99f4878917120ab02a2ffa6f316593e37&mpshare=1&scene=1&srcid=1001QrbECgmD2eQ6ren06anR&sharer_shareinfo=d2ca0b14ffc01f652f965765cacd65ab&sharer_shareinfo_first=d2ca0b14ffc01f652f965765cacd65ab&exportkey=n_ChQIAhIQ1Il31eW3cdSIU8s66TNSdhKWAgIE97dBBAEAAAAAAISdJyJnEikAAAAOpnltbLcz9gKNyK89dVj0uOd7VfzXVfJCr8zZDtu2QGyA5%2FtfvwmxbVnJG5ljZP8GEN84TCOcPErwkdarZq8%2BKwAesK0k8PLv2EUVelHeHNWWwpkYLIpVRAllZMa4lWQ4FdGk6z1hQmBJXI02PVP3ixQ9pTukbdoN9nw%2FT1Y9yfZxQVllked6U2YUq%2FbIzofi62uZcw3DgsQTmZz6EPOsn4F4%2FB2uhe7sRaF6GQAKCPv4C3vWpKvQXmDpOiKFAzLaR4PajE8mVCGebq%2F2A0RmVzt8eA84y7HEv%2Fg6PAxkRCI%2FcuXpToNTNTZcyJbe8QEjzSgMPnVe5EeD85kRX1xy&acctmode=0&pass_ticket=zvXkXoflt8m%2F38Jt2d73Y9AHyKRkHSMZhK7kuKPtzbba0ddTjRdVnEk0U8b7Ws0n&wx_header=0#rd","urlHash":3826418340},"e29bddde-eb99-44eb-94a1-510e7eccf760":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"e29bddde-eb99-44eb-94a1-510e7eccf760","title":"When Do Curricula Work? | Abstract","url":"https://arxiv.org/abs/2012.03107","urlHash":790228059},"e2b9f07d-0594-4db8-a601-e478a4274b84":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"e2b9f07d-0594-4db8-a601-e478a4274b84","title":"allenai/open-instruct","url":"https://github.com/allenai/open-instruct","urlHash":2687703508},"e2c4a9cb-8221-4af2-ad18-5a6b5cab6c71":{"favIconUrl":"fallback","id":"e2c4a9cb-8221-4af2-ad18-5a6b5cab6c71","title":"查拉斯图拉如是说 : 第一部 山上的树_尼采_在线阅读_九九藏书网","url":"https://www.99csw.com/book/2744/83221.htm","urlHash":1084243048},"e2c9ac7b-1568-4f98-9cc5-74f28d599c0e":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"e2c9ac7b-1568-4f98-9cc5-74f28d599c0e","title":"大语言模型的持续预训练","url":"https://mp.weixin.qq.com/s?__biz=MzI3NTQ5MjA4OQ==&mid=2247488104&idx=1&sn=b200875e9171003978e693f854f85e32&chksm=eb02affedc7526e8b99593af918fd23ae3a9bf34a12e9646df476bbcacf9464f21b34dbfa03f&mpshare=1&scene=1&srcid=0813BLAIoKYyzTakhKNxiDsk&sharer_sharetime=1691905683758&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQGu97Ex6FpTAs3zdnTEahchKWAgIE97dBBAEAAAAAAPdSFgFnC24AAAAOpnltbLcz9gKNyK89dVj00mmPNnDs8ZFwp2IITGsiRkwBpq2AtrVP56t7MyxAEN6xckFaBZwxiJ1RH5CgwmdsVW8baNG4t9YuSUxpbYTrSKVvhjtlUVrWKq16RP2ra87FUl8gWPBIJzfLAmI3N4oK79RX5%2BedKNYcwOuLWJWnTNyXMnYNGAbGMurRCDikByKrxmMiCQNVMAaKY4Cg5ipeAJvD8agQUNM%2BJtdkcHMGdJDjRT28UZu6EcpZClYP7PtXUgNYYU0Kyy%2Fs9E7covkOSZosTI%2FAkzNJoCYwqeBtzFT228PlBpeoaxVxZ4DzVFf%2Bl9EG1T6oiQfQWk6AlzpS&acctmode=0&pass_ticket=Xz0rA8rlGEh8JDldBH03Lr%2FaSLHjBF05in9JGlZDsRIgghZE%2Fj7pOnBk6k1w%2FcKm&wx_header=0#rd","urlHash":4207804715},"e310c8a0-a4f7-4832-bcfc-225a8cb93a6d":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"e310c8a0-a4f7-4832-bcfc-225a8cb93a6d","title":"斜眼少年 (豆瓣)","url":"https://book.douban.com/subject/26394917/","urlHash":2531387587},"e329ef51-4e25-48dd-a99f-1573846359d5":{"favIconUrl":"fallback","id":"e329ef51-4e25-48dd-a99f-1573846359d5","title":"Natural Language Descriptions of Deep Visual Features - Arxiv-2201.11114","url":"https://arxiv.org/abs/2201.11114","urlHash":392680166},"e33f08c7-716d-450a-a5ca-7d0425f9e021":{"favIconUrl":"fallback","id":"e33f08c7-716d-450a-a5ca-7d0425f9e021","title":"akshaymehra24/PoisoningCertifiedDefenses: How Robust are Randomized Smoothing based Defenses to Data Poisoning? (CVPR 2021)","url":"https://github.com/akshaymehra24/PoisoningCertifiedDefenses","urlHash":3788937199},"e3761bed-ea04-410f-ac81-1c4238b7111b":{"favIconUrl":"https://thegradient.pub/content/images/size/w256h256/2018/02/icon.png","id":"e3761bed-ea04-410f-ac81-1c4238b7111b","title":"The Promise of Hierarchical Reinforcement Learning","url":"https://thegradient.pub/the-promise-of-hierarchical-reinforcement-learning/","urlHash":940919109},"e38e382f-22a1-404c-8a18-f163176c3fc5":{"favIconUrl":"fallback","id":"e38e382f-22a1-404c-8a18-f163176c3fc5","title":"Phillip Isola","url":"http://web.mit.edu/phillipi/","urlHash":1142752071},"e3d3d183-9ce8-4961-b30c-4cf191871a93":{"favIconUrl":"fallback","id":"e3d3d183-9ce8-4961-b30c-4cf191871a93","title":"华人团队颠覆CV！SEEM完美分割一切爆火，一键分割「瞬息全宇宙」","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652323193&idx=1&sn=230982170e635192850203e66a7ba9d6&exportkey=n_ChQIAhIQDeAqPlIwyw0%2BYvhB%2BvrZ2BKJAgIE97dBBAEAAAAAAOtINDAq08IAAAAOpnltbLcz9gKNyK89dVj08R5Rmnrv46wuEyqa%2BToJztJ1FvEEMfLR7x6lZbRtFU1Tx03hXrX7jN9rMIF%2BuRcsmlOH597HQ9oNki0ZOn72dA8aAwwcwIbLXOdfWV38aVqJ5rFnzimvcC3VNUyAfmUL4lYmWdX3jlOQJ2wgbWlE2er68KfQAO2057Y3YtFGYNkvuKbXsxt4zGatpfeK4znT5iOM7GEHKShJRPOhZ2cerrbSvSVUfRMcAwl8MpcCQ8Xsn0IoSIHzzYuBAxvHstekj7848CQbDLVoREYhB2nndMg21BuHGi7RcZxEaAUVh%2F2apjQ%3D&acctmode=0&pass_ticket=CVx8wIecFZpLiqLziB53fbV73WifzfjFL8ONivSufgiKWYj70cI6%2BBK%2Ff8R1c82ta%2BaKXKjkd%2B%2F9gzm88UFtjg%3D%3D&wx_header=0","urlHash":472793484},"e3dcd4de-8914-4633-9082-6be0d81ba8ea":{"favIconUrl":"fallback","id":"e3dcd4de-8914-4633-9082-6be0d81ba8ea","title":"贾佳亚团队提出LISA大模型：理解人话「分割一切」，在线可玩","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247690618&idx=4&sn=bf6cc21ca4f7e414a2f48d8089f139ce&exportkey=n_ChQIAhIQB8ZKAyOOc%2FgKQj62Lz3MTxKWAgIE97dBBAEAAAAAAJ0NNjNj1vkAAAAOpnltbLcz9gKNyK89dVj0mI5xyUzpyj%2B7VJGr6oYC4ECSamFuh8zujBo0VTXb8rrczdRLj1IzJTPcCPjqsu72oK%2F%2FkVkwWxuRVfjDVS%2BGcouGkeaB69%2B6hD5eaUd9syAr5v4kEar6djJmrY0xkTpocAjHMPMUOnOME0WsKSbZH%2BYI0ZhfIfa7bjDCwj8fgkPyRmDUOiPj9kPP%2BXGshlCOXXlZ8oDG6G9Kzg7DCEZgtfkAJzLCFdAjlL4R9M9Ll52u%2Bgyoy%2BpA2N%2FRR9oFmw8Je2KDIsXwg7diRyjVhW4Cx%2BuzEj4pTBMPEFqRsPZm%2BzfhcLjt5hOL2mte4WmDUfFF&acctmode=0&pass_ticket=J%2FH3fjzge%2BDM1xClEMCbGJW02GGyGXVsmZwSRsgJNQ24UhXdeKx8gUfjogkVBxIe&wx_header=0","urlHash":3708870336},"e3e4a284-bb37-4c9a-bd2b-fa756313eeef":{"favIconUrl":"https://www.youtube.com/s/desktop/375de707/img/favicon_32x32.png","id":"e3e4a284-bb37-4c9a-bd2b-fa756313eeef","title":"(45) (Draft-Version) GPU Puzzles: Let's Play - YouTube","url":"https://www.youtube.com/watch?v=T28-rXIqPzw","urlHash":839801174},"e3f88fd2-ad62-40ab-89cf-30919b94cd44":{"favIconUrl":"fallback","id":"e3f88fd2-ad62-40ab-89cf-30919b94cd44","title":"\"Linformer\" 拍了拍 \"被吊打的Transformers 后浪们\" - 知乎","url":"https://zhuanlan.zhihu.com/p/149890569","urlHash":337211323},"e422689e-7ea2-4ba9-beb7-0dfd977b08d0":{"favIconUrl":"fallback","id":"e422689e-7ea2-4ba9-beb7-0dfd977b08d0","title":"Understanding Diffusion Models A Unified Perspective - Arxiv-2208.11970","url":"https://arxiv.org/pdf/2208.11970.pdf","urlHash":2428295120},"e423e617-e4ac-48cf-bd73-d9c0ef45bc44":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"e423e617-e4ac-48cf-bd73-d9c0ef45bc44","title":"lobehub/lobe-chat: 🤯 Lobe Chat - an open-source, modern-design LLMs/AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Perplexity / Bedrock / Azure / Mistral / Ollama ), Multi-Modals (Vision/TTS) and plugin system. One-click FREE deployment of your private ChatGPT chat application.","url":"https://github.com/lobehub/lobe-chat","urlHash":1839334437},"e44be1a9-8e74-4a1f-ac0f-4608d3f5d783":{"favIconUrl":"fallback","id":"e44be1a9-8e74-4a1f-ac0f-4608d3f5d783","title":"别用GPT-4直出文本摘要！MIT、哥大等发布全新「密度链」提示：实体密度是摘要质量的关键","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652386377&idx=2&sn=276961a29f341f177db95bc6391cf9d2&chksm=f12b40b8c65cc9ae81b8597cec4e97dc91e88d03e29a3a64fadee715b4be81f0eb568b1988f2&mpshare=1&scene=1&srcid=1001SQZ9ciHqVUSsMhwaebkU&sharer_shareinfo=3fe058b621b2194c74bdf859badf06e6&sharer_shareinfo_first=3fe058b621b2194c74bdf859badf06e6&exportkey=n_ChQIAhIQypOYwYTkWAGJNueY6X2YFBKWAgIE97dBBAEAAAAAALKWDfgo5w0AAAAOpnltbLcz9gKNyK89dVj08ffhiDp%2F%2BhR3EK%2FKDolPpYUSSezpPEcLyjUSty2kMP1gWU4QB%2FF%2B1vMG%2F9cMNTMO6tKh2tIGwAHlx%2BMk1f%2BA33M78PnVikIjIjkxA%2FrDnFJ4gR%2BvoJOg3KK40iF%2B5Dby%2FGpdBQW7PmfWCspEbYVWsJODLus0Nkwg3ScjMUafAIHEHf4c4pg9YBFE736qizhxj19t0aKmmpE1T9nPdcElI9JCMP6daxLouwN%2BI%2F0fTU3B95hM7SGW2Li6S7ZWhWseJbXrciPiS5couS2H843Zg6KzK24Q69znMWRoPenSOiy06mJY%2B8ioBvAGwNKGglSM&acctmode=0&pass_ticket=xADBWA9IX4RhVK25OnlxaBVS6tlygBNW%2FHna467oJvOfG1qxGgB9HHWh17aMlFR%2B&wx_header=0#rd","urlHash":2458058543},"e46a8d30-6145-401e-8951-96db5523ff04":{"favIconUrl":"https://www.99csw.com/favicon.ico","id":"e46a8d30-6145-401e-8951-96db5523ff04","title":"搪瓷灵魂的比重_佐藤友哉_在线阅读_九九藏书网","url":"https://www.99csw.com/book/8812/index.htm","urlHash":2966865344},"e4746daa-caa3-490a-885e-dbbfc619339e":{"favIconUrl":"https://wikiwandv2-19431.kxcdn.com/icons/favicon.ico","id":"e4746daa-caa3-490a-885e-dbbfc619339e","title":"Critique of Practical Reason - Wikiwand","url":"https://www.wikiwand.com/en/Critique_of_Practical_Reason","urlHash":2165041282},"e4940624-db6c-4709-82ea-d9d4605d2606":{"favIconUrl":"https://static.zhihu.com/heifetz/favicon.ico","id":"e4940624-db6c-4709-82ea-d9d4605d2606","title":"ChatGPT 为什么不用 Reward-Model 的数据直接 fine-tune，而用 RL？ - 知乎","url":"https://www.zhihu.com/question/596230048","urlHash":658903721},"e4a29e1b-b88e-40df-8481-ef98b2e78ccc":{"favIconUrl":"fallback","id":"e4a29e1b-b88e-40df-8481-ef98b2e78ccc","title":"文档字越多，模型越兴奋！KOSMOS-2.5：阅读「文本密集图像」的多模态大语言模型","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652385812&idx=3&sn=0fe74f3d9cce0a5d8c476e0f135d5f91&chksm=f12b46e5c65ccff36d252984eb0ccb086f9fad8d07232ff6a329478eb3cb9d923e321c9791ca&mpshare=1&scene=1&srcid=1001AM4VGfZPveCBupbHgXYg&sharer_shareinfo=a9fb03be3b49832b9e22eadce2f0968e&sharer_shareinfo_first=a9fb03be3b49832b9e22eadce2f0968e&exportkey=n_ChQIAhIQqh2yQEbdYpMpV6G26LgAFRKWAgIE97dBBAEAAAAAAP25NZ9DLr8AAAAOpnltbLcz9gKNyK89dVj0X3Hz5vTMzuNRESE77ozxYz4YyCJU6OKCi3lDAYWK3z3ADao9yiXHagcEVMDSMX0OWSbOGIuTzbtITmx6Gy%2BNEAHWWU6qo7MqgKLqQzo4ByG99LPa%2BhgGQKs5TpxPvogJYhbpcEphwcx9S%2B%2FzLHzlr8ST2CWPqQsvbdc%2B2jnTMap0llc%2FRgASyQVN8Fz3%2F%2BUhrzyMy0v5OtpHj6sgUTmltZykN%2BJL%2FH9Ibnib5PysTVbBsrqDrKCab4%2Fl7s0mwN3wUdZ1Y4yjvbvjvjxSkyCPmgDxJ0f1SpVXzN6NjVeqYJL9KuRLs65E2Wy8xdYpnEgu&acctmode=0&pass_ticket=JEIL66%2F83IMXIzf4xmIq3qwuBsm%2FL5tP6EsxIPC6E3HKB88WajteDQkdnFRr0RXy&wx_header=0#rd","urlHash":2919584482},"e4ae5d67-cb3c-4e54-8f4a-251f37e6451d":{"favIconUrl":"fallback","id":"e4ae5d67-cb3c-4e54-8f4a-251f37e6451d","title":"Computing Receptive Fields of Convolutional Neural Networks","url":"https://distill.pub/2019/computing-receptive-fields/","urlHash":4174440570},"e4b316d1-2f62-40c9-9412-4ad04d306ce3":{"favIconUrl":"fallback","id":"e4b316d1-2f62-40c9-9412-4ad04d306ce3","title":"SpQR A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression - Arxiv-2306.03078","url":"https://arxiv.org/pdf/2306.03078.pdf","urlHash":1514625917},"e4dc54eb-17c2-4e97-96e1-5535f350d38c":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e4dc54eb-17c2-4e97-96e1-5535f350d38c","title":"Nick on X: \"Excited to share a new paper showing language models can explain the neurons of language models Since the first circuits work I’ve been nervous whether mechanistic interpretability will be able to scale as fast as AI is. “Have the AI do it” might work https://t.co/9vixi7VsPr\" / X","url":"https://twitter.com/nickcammarata/status/1655983224529485824","urlHash":2923529323},"e506f569-0081-4c2d-83c4-a3ae949a3203":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e506f569-0081-4c2d-83c4-a3ae949a3203","title":"Bill Yuchen Lin 🤖 on X: \"⚠️ Jailbreaking attacks for LLMs are crazy. How should we efficiently defend them? Check out 🛡️𝕊𝕒𝕗𝕖𝔻𝕖𝕔𝕠𝕕𝕚𝕟𝕘, a simple inference-time defense method. We found that fine-tuning with more safety data may not work well in defending wild jailbreaking attacks, while make… https://t.co/6cOCSe0mMX\" / X","url":"https://twitter.com/billyuchenlin/status/1763664306561057267","urlHash":4237290571},"e53176a1-287e-4fa6-b072-16a50de544e9":{"favIconUrl":"https://plato.stanford.edu/favicon.ico","id":"e53176a1-287e-4fa6-b072-16a50de544e9","title":"David Hume (Stanford Encyclopedia of Philosophy)","url":"https://plato.stanford.edu/entries/hume/#RelaBetwTreaEnqu","urlHash":1015141190},"e55b6e60-b544-49fe-a2a0-d4162cdfc242":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"e55b6e60-b544-49fe-a2a0-d4162cdfc242","title":"普林斯顿DeepMind用数学证明：LLM不是随机鹦鹉！「规模越大能力越强」有理论根据","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652444347&idx=3&sn=cf1be943172517c91754e553074a2440&chksm=f12a624ac65deb5c0db975735a1356f4daae92f6c666b957a2f6aaa4a949e2056cba960b3d6d&mpshare=1&scene=1&srcid=0216nrT3RAhLX21LYTkVoHVJ&sharer_shareinfo=41cff369e6656d152b5cd2a7c29b4e65&sharer_shareinfo_first=41cff369e6656d152b5cd2a7c29b4e65&exportkey=n_ChQIAhIQzmxlch2Z2Qy%2F9H7wgjq%2FxxKWAgIE97dBBAEAAAAAAEMUL8Gsx9kAAAAOpnltbLcz9gKNyK89dVj0j2YVonabt4Uz7MURx454%2Fbcy%2BZMmxaihjzYZZDBM5m2cayiKeJkAyk7OX36F43pW4WuAxn4TJ0Qo8n%2BDSBt1gpa1q9dIx23s6M1QNmz%2FSvT3JZXqgWWM82cWG6tucIj6pSn7ffeXr8U4Vl23II4e4DjTKC%2Fo9Z%2BrNro2pV3dM9AHLMVfojXgI6gpNtZ0J8Eys8GBZGZt5s85tJ1UHWFU2qwE2d6qPA2Hp1NEVH9w4YUKvtTUP6m4aQ%2FXFcUj%2Bk739hyCzpxOju4agaEepUB1NRADFfZ0G8p%2BjkxOz9ALSErAbjnbxHf7skTXED8PEYsh&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HMUWzlFAALYCR9or2QqZhgeXcBtIpuzG%2FUCNNzocyX%2FCw%3D%3D&wx_header=0#rd","urlHash":1449467935},"e5ae2fcd-db20-45bc-80a8-951c2cf44d01":{"favIconUrl":"fallback","id":"e5ae2fcd-db20-45bc-80a8-951c2cf44d01","title":"ant-research/diffusion-model-for-instance-segmentation: This repository is the code of the paper \"DiffusionInst: Diffusion Model for Instance Segmentation\".","url":"https://github.com/ant-research/diffusion-model-for-instance-segmentation","urlHash":4283793519},"e5b0e5e6-1b9f-4c26-8a36-f0150282d162":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"e5b0e5e6-1b9f-4c26-8a36-f0150282d162","title":"探索力不足？微软&卡内基梅隆大学发现：无外部干预，GPT-4等大语言模型难以自主探索","url":"https://mp.weixin.qq.com/s?__biz=MzU5OTk5OTg4Ng==&mid=2247485955&idx=1&sn=61902939b9ad2d6535a63e6094281220&chksm=fead1ee2c9da97f48deee8daf4b12b54ee1c6a83340864f99f8c8b04e7bef0df3039724410b9&mpshare=1&scene=1&srcid=0327mhIXgdxBl4KI9keOCsIE&sharer_shareinfo=3bae49873817ab229e89123df4051e43&sharer_shareinfo_first=3bae49873817ab229e89123df4051e43&exportkey=n_ChQIAhIQgPn87mO%2FcGvGmLsihs1ssxKWAgIE97dBBAEAAAAAABsKIrP%2Bx08AAAAOpnltbLcz9gKNyK89dVj0Jbrd5DUPtPQs3zvpSql6LMo8xwsUUNgMpD5ElqbKvmvcb7OyaFtIe%2Btft1AQTs9KKrB2Mu%2BUb3gqVx35WTGsk9keGeJKtDw7R5%2Fy0ZY3FqPKpykLMDd4fijSWkT6qRLYGXlJHjZUs%2BkNEWkxpq1Eh0Dfer%2BmQq%2FrXyUqLz3ho3zB%2FQsdzeH4%2Bc%2B8OwXhiqFV9tObZyBHd9juyeNNwbx%2BsiKfFsUPnE3jgL8JN%2BRtlvFmsNYKLbrmBCotZjMDNGw15e24%2FUJ8l2d%2FU%2BN7rPQvxin%2B%2BxApJr6Bdp0%2Fb3jieBaKnouNMjTXMxXvkmiH%2BrRG&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCPzYIt1bvpsUdEeeTPuztsB37ay%2BZrDhdUW3RQY4SsdpQ%3D%3D&wx_header=0#rd","urlHash":658794533},"e6208b0d-880c-427b-b921-719a9e37ac77":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"e6208b0d-880c-427b-b921-719a9e37ac77","title":"Diffusion Policy: Visuomotor Policy Learning via Action Diffusion | PDF","url":"https://arxiv.org/pdf/2303.04137.pdf","urlHash":1386062946},"e6479249-6d4f-498f-a374-1801e6c36848":{"favIconUrl":"fallback","id":"e6479249-6d4f-498f-a374-1801e6c36848","title":"54百亿参数大模型进化树重磅更新！85页盘点LLM发展史，附最详细prompt技巧","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652349576&idx=2&sn=1ba01ac4b4298b7808cb0a2291a35ef2&exportkey=n_ChQIAhIQxjHhY3FC22J1mxqGSfqN2hKWAgIE97dBBAEAAAAAAPmSGdNN3JQAAAAOpnltbLcz9gKNyK89dVj0JqcKrow%2FKP%2BLpbPMhjvDzzpeqaadpOSaINT84PG3S3C54J1oMLS3Y5c%2FJyRA212dIU2zB2ZMYPMqzM7LxrUtAXFYLudftDXS9aD%2BomBfItftDorq6B%2BnN9Kp4kQscy%2FqC5jAyQV83szzbthqq3HrcJeruvhvo80SHl2V0gl5fVTCPA7GfQQKvjuIL5Gs9lY0wCSdxQ7p5PdYY4LlixJHKwas%2BVaXGIf2fchy4TDvb%2BRoxz7BIlmvuoPBf4xsamapRoHAQOEkutwwTiHdJbY%2F2dMekHt9y6bMkCC%2FKMex8J5lwnC3MPas3%2F5waaR7sIN2&acctmode=0&pass_ticket=JNvcffq2Pqr568RDruHuK8v8nhxch5iB8trWJXdRqXJ%2Fje1TLwg3%2BxwrlFWpIGjt&wx_header=0","urlHash":4164132624},"e6667ddd-a3a1-4c9e-8b36-2986c65db3a3":{"favIconUrl":"fallback","id":"e6667ddd-a3a1-4c9e-8b36-2986c65db3a3","title":"Honey, I Shrunk the Language: Language Model Behavior at Reduced Scale","url":"https://arxiv.org/pdf/2305.17266.pdf","urlHash":3984338815},"e69482c7-81d5-4930-939b-7e600a8e7b2c":{"favIconUrl":"fallback","id":"e69482c7-81d5-4930-939b-7e600a8e7b2c","title":"Reading Walter Benjamin’s Theses on the Concept of History (Contents) – The Wasted World","url":"https://thewastedworld.com/2023/02/10/reading-benjamins-theses-p0/","urlHash":2216598841},"e6a53655-aada-453d-a17c-0224b83b6f5b":{"favIconUrl":"fallback","id":"e6a53655-aada-453d-a17c-0224b83b6f5b","title":"地久天长 王小波 - Google Search","url":"https://www.google.com/search?q=%E5%9C%B0%E4%B9%85%E5%A4%A9%E9%95%BF+%E7%8E%8B%E5%B0%8F%E6%B3%A2&newwindow=1&sxsrf=AOaemvLKO6u5iqifyQu5bh3oX-R_CRls-g%3A1635914834852&ei=UhSCYZa8M9zI0PEPz4mpsAk&oq=%E5%9C%B0%E4%B9%85%E5%A4%A9%E9%95%BF+%E7%8E%8B%E5%B0%8F%E6%B3%A2&gs_lcp=Cgdnd3Mtd2l6EAM6BwgAEEcQsAM6BQgAEIAEOgUILhCABDoHCAAQgAQQDDoFCAAQzQJKBAhBGABQoAlY-BlgtxpoAXACeACAAcUDiAGmFpIBCTAuMi41LjMuMZgBAKABAcgBCMABAQ&sclient=gws-wiz&ved=0ahUKEwiWrfTUsfvzAhVcJDQIHc9ECpYQ4dUDCA4&uact=5","urlHash":991987509},"e6b44118-05f1-4ff7-bdcd-02784dda0961":{"favIconUrl":"fallback","id":"e6b44118-05f1-4ff7-bdcd-02784dda0961","title":"interpreting GPT: the logit lens - Google Search","url":"https://www.google.com/search?q=interpreting%20GPT:%20the%20logit%20lens","urlHash":646465465},"e6bb4aad-6317-4ccb-8a30-1604d499ba41":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"e6bb4aad-6317-4ccb-8a30-1604d499ba41","title":"Quark: Controllable Text Generation with Reinforced Unlearning | Abstract","url":"https://arxiv.org/abs/2205.13636","urlHash":2748236629},"e6c4969d-521a-4589-85cb-1b493ad3a9f2":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e6c4969d-521a-4589-85cb-1b493ad3a9f2","title":"AK on X: \"Measuring Faithfulness in Chain-of-Thought Reasoning paper page: https://t.co/TUvsqzWLam Large language models (LLMs) perform better when they produce step-by-step, \"Chain-of-Thought\" (CoT) reasoning before answering a question, but it is unclear if the stated reasoning is a… https://t.co/9qEIlDKt9P\" / X","url":"https://twitter.com/_akhaliq/status/1684371256521662465","urlHash":437953311},"e6e8f815-a9d8-465b-b5a8-9dd1130e02eb":{"favIconUrl":"fallback","id":"e6e8f815-a9d8-465b-b5a8-9dd1130e02eb","title":"Finding Neurons in a Haystack Case Studies with Sparse Probing - Arxiv-2305.01610","url":"https://arxiv.org/abs/2305.01610","urlHash":313391009},"e702419a-5458-499a-af32-f9570b5966bf":{"favIconUrl":"https://osu-nlp-group.github.io/TravelPlanner/static/images/icon.png","id":"e702419a-5458-499a-af32-f9570b5966bf","title":"TravelPlanner: A Benchmark for Real-World Planning with Language Agents","url":"https://osu-nlp-group.github.io/TravelPlanner/","urlHash":778996245},"e7334f89-2a42-4809-b793-d663ac7bf5dc":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e7334f89-2a42-4809-b793-d663ac7bf5dc","title":"Sumit on X: \"INSTRUCTIR: A Benchmark for Instruction Following of Information Retrieval Models Presents a benchmark to evaluate IR systems on their ability to adapt search results to diverse user instructions and preferences. 📝https://t.co/JZKpqswJll 👨🏽‍💻https://t.co/yKlXw4koJz https://t.co/QplbXZGfCu\" / X","url":"https://twitter.com/_reachsumit/status/1760898348255727704","urlHash":3643270831},"e7485b1b-4137-4b93-9639-57db49b384a3":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"e7485b1b-4137-4b93-9639-57db49b384a3","title":"颠覆Transformer霸权！CMU普林斯顿推Mamba新架构，解决致命bug推理速度暴增5倍","url":"https://mp.weixin.qq.com/s?__biz=MzkwMjI3ODA5Mw==&mid=2247490207&idx=2&sn=164b69ae2c12c6a85e38a4f32cd816cc&chksm=c0a6a43df7d12d2b5e8d544da958d3d2cb7cd092d5fbcfcc28cd6a1190ee1758b466b7d88085&mpshare=1&scene=1&srcid=1206YvXbfsli1P0WiZQw6EGH&sharer_shareinfo=53b1a8ec5749fddf1bdcdfd2c1ddb076&sharer_shareinfo_first=425592135dbdd0e926de768f9225e063&exportkey=n_ChQIAhIQC5V%2FZDwVNTzpOy7MAJxrpBKWAgIE97dBBAEAAAAAABSIMlc8prQAAAAOpnltbLcz9gKNyK89dVj0tb4dfcpBoU9fK2YMR2mmsJjYg6KFeHNreoL7%2FR4Dt08Uh0OYlo7wQXjuDAM%2F7sQYxdTUgxyC6utqFnlSuSrfwagy2mFwOSBW%2B9vIRNyzHC31uTUrvmZIzIAF1G%2BzbDMJTmnYz0L1IRp%2BBTd3IDSqd%2Bpe2OR8SXpPQ89TjkFt8Nh2R0vTgSk5m5UEnUT%2BuMgcRMrO9C5iw0pxI8BnIsCfSniRB%2FlT6ZHJ0RyTw9gmr3vbSpqotNk0uJs0dPbeci4UIUYpyCNG5HJ4rB%2FlqCYv3QGK%2F6OFTCW%2FRynbxR85G1%2FbrnJ7278ZDevmSdLDT3bu&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsbZHuG0IkdAyqmhtOwNuXgkZYkpUvJ7c8GO4j1D9zJMbA%3D%3D&wx_header=0#rd","urlHash":1855736899},"e75cfab3-8ee2-444d-b436-03c2e3fb8dba":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"e75cfab3-8ee2-444d-b436-03c2e3fb8dba","title":"【自翻】在切斯特的一天——柄刀一","url":"https://www.douban.com/note/624863451/?_i=4053720oZQdRGV,1224207oZQdRGV","urlHash":1653412117},"e789d36f-c0cc-47b3-9336-6c3fed56e518":{"favIconUrl":"https://ssl.gstatic.com/images/branding/product/1x/drive_2020q4_32dp.png","id":"e789d36f-c0cc-47b3-9336-6c3fed56e518","title":"UCLA CS263 NLP_Guest Lecture_Pan Lu_2023.05.31.pdf - Google 云端硬盘","url":"https://drive.google.com/file/d/1tEXtFkR9vtLsLnMElu7O2uPdTJL-v4Ei/view","urlHash":624658536},"e7b9267d-573d-48c4-b12d-2f319e3451bc":{"favIconUrl":"fallback","id":"e7b9267d-573d-48c4-b12d-2f319e3451bc","title":"读了14篇论文，终于会拿捏Diffusion了","url":"https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&mid=2247492157&idx=1&sn=e429832288f50701056dfbaddc84cb52&chksm=9bba6b59accde24f2333e4c5004d45803a5aca256c13ee9f36d40c9b2ea592b91522ca142bbd&mpshare=1&scene=1&srcid=1218DyBY4tX32tEMyCu5J2q2&sharer_sharetime=1671346219166&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQnoWWuaFpvsZSZXPZG7L3rBKWAgIE97dBBAEAAAAAAG95MhSFeYkAAAAOpnltbLcz9gKNyK89dVj0JaRzsFvQODKXQx1RT0ZnNnU6ZRDfUClVynHx3qx0a28%2B7VnxRFmDRZ%2FJPJAe83Hla0gcNb2acQBdqp4f439O4h5d5tyP4jet2KzZPeWWAXFvXUa%2B10g5suDMyZQGLNoBonMuYkayLr9n1VuEw0q36H6r9Evww2tZu1idCBv%2FVbYnUqsVVcDjO3ITMvjrog1NC%2BJ3xOAmXELWCuc9rzbQg2nBX1HgUmFvXRlirKy3gq2KEw9NseH0aoqGzVIOje6ovlWUpa6iRHtfpTlMU1ol7wZ%2F4FK0kusrrM2OPMmhrCM%2Bt7eCol2E2gISKsKUMBd3&acctmode=0&pass_ticket=B%2Fr2wa0S%2FM5lL%2FB24fD%2FIrSWC3GeT01IvggTYRYcwuoqrEEB65byq958NpPvNdBJa12vc2jRboP3Uoa8Dgn0NQ%3D%3D&wx_header=0#rd","urlHash":695032825},"e7bd6b09-03d6-4259-a8b7-02f059426021":{"favIconUrl":"fallback","id":"e7bd6b09-03d6-4259-a8b7-02f059426021","title":"Tractatus Logico-Philosophicus","url":"http://people.umass.edu/klement/tlp/tlp.html","urlHash":3069335006},"e7ec0337-2569-4965-b894-199760565e3d":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e7ec0337-2569-4965-b894-199760565e3d","title":"Hanseok Oh on X: \"Can retrievers follow 📝instructions📝, including your intentions and preferences? 🧐 Introducing INSTRUCTIR, a benchmark for evaluating instruction following in information retrieval. [1/N] https://t.co/0J3TtqPcdw\" / X","url":"https://twitter.com/hanseok_oh/status/1763063167905829179","urlHash":2044459712},"e80c04a6-9015-4e7d-91c4-3e6d979f8d09":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"e80c04a6-9015-4e7d-91c4-3e6d979f8d09","title":"听说Attention与Softmax更配哦～ - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/9019","urlHash":4054821278},"e816fb20-ed33-4117-a868-7b7264cf0ab3":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e816fb20-ed33-4117-a868-7b7264cf0ab3","title":"twitter.com/awinyimgprocess/status/1646225454599372800","url":"https://twitter.com/awinyimgprocess/status/1646225454599372800","urlHash":1317948735},"e81b8908-3b4b-4ca7-b3a6-a5c6d159dc41":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e81b8908-3b4b-4ca7-b3a6-a5c6d159dc41","title":"Yang Chen on X: \"If you are interested in multimodal RAG, check out our new paper! - We propose a unified multimodal retriever trained with instruction-tuning on 8 tasks (🖼️image/📝text query -&gt; target) https://t.co/TtwifPl3Bg #RAG #multimodal\" / X","url":"https://twitter.com/ychenNLP/status/1730315951063625745","urlHash":3919125675},"e839b1b2-9b7f-4f75-806f-e0ce96a861a6":{"favIconUrl":"fallback","id":"e839b1b2-9b7f-4f75-806f-e0ce96a861a6","title":"Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To! - Arxiv-2310.03693","url":"https://arxiv.org/pdf/2310.03693.pdf","urlHash":128145339},"e84b961f-7031-433d-9de4-03dbe5d2da5b":{"favIconUrl":"https://assets.squarespace.com/universal/default-favicon.ico","id":"e84b961f-7031-433d-9de4-03dbe5d2da5b","title":"Mechanistic Interpretability — Neel Nanda","url":"https://www.neelnanda.io/mechanistic-interpretability","urlHash":3188330212},"e8625aa4-9029-4839-b8d2-976e5f6cee60":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e8625aa4-9029-4839-b8d2-976e5f6cee60","title":"Roberta Raileanu on X: \"🚨 Wondering when, where and how to improve your LLM’s reasoning? 🤖 Look no further! Our new method GLoRe shows how you can do just that. ⏲️ When? Use an outcome-based reward model (ORM) to decide which solutions need refinement. 🎯 Where? Use a step-wise ORM (SORM) to decide…\" / X","url":"https://twitter.com/robertarail/status/1760050866282004603","urlHash":1057670076},"e889f749-f79c-4d86-8acc-226fc49d04d3":{"favIconUrl":"fallback","id":"e889f749-f79c-4d86-8acc-226fc49d04d3","title":"Transformer Language Models without Positional Encodings Still Learn Positional Information","url":"https://arxiv.org/pdf/2203.16634.pdf","urlHash":1786052405},"e8919439-aba7-4180-9822-e9b9f1229388":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"e8919439-aba7-4180-9822-e9b9f1229388","title":"大语言模型潜在地执行了多跳推理吗？","url":"https://mp.weixin.qq.com/s?__biz=MzkwMjUwNTg3OA==&mid=2247485379&idx=1&sn=67dc371458bc4296dd53817dccf2131c&chksm=c0a5333af7d2ba2c16ac293794d6099f18dbd76e9f3d9f281dba9b6a56128f89704f9b75edd3&mpshare=1&scene=1&srcid=0228LxQP5Gw9WPJ07BnMGcqS&sharer_shareinfo=a375819e113e1befa3dcbe7e87c9c2ef&sharer_shareinfo_first=a375819e113e1befa3dcbe7e87c9c2ef&exportkey=n_ChQIAhIQIdgEiCA%2FXAud5yyEKOz6wBKWAgIE97dBBAEAAAAAAJ3SNQljz3EAAAAOpnltbLcz9gKNyK89dVj00FcHTplvTrzHolCAqufGFQuOuzM9zWXPNbiUbk1ErZ88EsIONc8Trg99kei7OAZXHyAHA0BmWGCZ3bjTRzQKalrWZf9jl0IANlpJP8vQmr1lTq4yD%2Bi7NCDfLlejdOXe23CY73yw5b2NOQa4roiDqJxzeM64hZMaKTmZ2DkxZ48v1GtpcYy%2F%2B2WImh04u2y%2Fvum7RXNFeVvPvTkTz0Y8thgCMGKcjBtbebObgon%2Ba%2F2ByfFD%2BzikcZIf7wat6YQcBRuvBki8wg7qZo1ad4MIj6MElDuhivZ23pWVPjyhOmxRyTKbcI88lo1JglHSp4Ok&acctmode=0&pass_ticket=2PIOTp07NumM73b6%2BDXCh%2BnkNx8%2F1ykJABKPHCCPJcNjUjsrGv4VPNab%2BPGNHN1JKZXPPs4Q5Yd0sia7l%2BY72Q%3D%3D&wx_header=0#rd","urlHash":3522856195},"e8bf78d1-66ff-43c1-90d7-ccc36d808cb4":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"e8bf78d1-66ff-43c1-90d7-ccc36d808cb4","title":"Fine-tune Language Models to Approximate Unbiased In-context Learning | PDF","url":"https://arxiv.org/pdf/2310.03331.pdf","urlHash":847602815},"e8c4df53-e1ec-4a03-a18f-82a9149f47b5":{"favIconUrl":"https://static.zhihu.com/heifetz/favicon.ico","id":"e8c4df53-e1ec-4a03-a18f-82a9149f47b5","title":"济时彦 - 知乎","url":"https://www.zhihu.com/people/Fred_Pagliari/answers","urlHash":4052209842},"e8eb15cd-720f-45db-b354-41ef32d00fcb":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e8eb15cd-720f-45db-b354-41ef32d00fcb","title":"Ansong Ni on X: \"Execution results are strong indicators of program correctness. But how can we improve LLMs for code generation with execution? In our new paper, we propose LEVER, a simple method that learns to verify and rerank LLM-generated programs with their execution results. 🧵👇 (1/n) https://t.co/P1LDplxOZx\" / X","url":"https://twitter.com/AnsongNi/status/1627818097791930368","urlHash":657619739},"e8fc1f3c-bca4-40a6-98b5-bbbecafbd2be":{"favIconUrl":"fallback","id":"e8fc1f3c-bca4-40a6-98b5-bbbecafbd2be","title":"What Does it Mean for a Language Model to Preserve Privacy? - Arxiv-2202.05520","url":"https://arxiv.org/abs/2202.05520","urlHash":2271605547},"e90a9489-09b7-43e3-9b35-5793ce93731a":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"e90a9489-09b7-43e3-9b35-5793ce93731a","title":"试过GPT-4V后，微软写了个166页的测评报告，业内人士：高级用户必读","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650892261&idx=1&sn=f869dee4d298977b230ae27475b0078b&chksm=84e4a39bb3932a8dd4c6070227f3844dbe306cdb775034a1204f08ab5a96c9efc5bb4a43e80b&mpshare=1&scene=1&srcid=0115SfU27EcWAoY2BBAXbBP7&sharer_shareinfo=3a8dea5a70c5dbb0c20e2b8abfde78c0&sharer_shareinfo_first=3a8dea5a70c5dbb0c20e2b8abfde78c0&exportkey=n_ChQIAhIQEEVrwzUOGp%2FvuHJQUhZUwRKWAgIE97dBBAEAAAAAACRvBUUZPB0AAAAOpnltbLcz9gKNyK89dVj0x45qCOjpCkMGkkd4z0VXXQy9GZRCp8AQSo8TYxCKh23HcL2b7Q5ZpGkYlLDoNTJjF%2FOD4cFXgZd8n2I%2Fc%2B2b4VnccjZuWL7aqr3%2BwKnO0x3AjNkX%2BwvGH3Y8TygE3ub5K53Y3TvJoKtGstr6giC%2FUCvQ1Htd%2FlrZxMl%2FUlebL2Pu0vrWtPILBJv28Gl2LOAAmNXoQ1Vvxo%2FsK0vZK5qxa17zhU6mzP9scRAadOM123v6bkmTBXtoHyXdrU7%2FP7mf9kyeDqiEoBSfOTD0wpId%2BPO7ZV6BG94E5vAyetCR6gjZhHy7sO%2B%2FO0rEWDvKZPig&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsaFmopsQrkUHP8TJCo2qUyhpOk5wYo00ajM9y4TK5SShA%3D%3D&wx_header=0#rd","urlHash":1517133134},"e96c92e8-5c30-431b-b545-3604f6235a01":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e96c92e8-5c30-431b-b545-3604f6235a01","title":"Xiaochuang Han on X: \"Have you chatted with Llama-2-chat? Do you know that you can also chat with the vanilla pretrained Llama-2 model (non-chat version) reasonably well? Here's a short note on how to do it by using ~9 in-context demonstrations for alignment! arXiv: https://t.co/fcou79PvdC https://t.co/N2XLpUZuZ8\" / X","url":"https://twitter.com/XiaochuangHan/status/1690072551803023360","urlHash":3868699834},"e96e3ab1-378b-4cd2-8775-938a5942fdbd":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"e96e3ab1-378b-4cd2-8775-938a5942fdbd","title":"Retrieval-Augmented Generation for Large Language Models: A Survey | Abstract","url":"https://arxiv.org/abs/2312.10997v1?utm_source=substack&utm_medium=email","urlHash":3631517853},"e9761205-4ea7-4b0b-aa53-494b902cfb99":{"favIconUrl":"fallback","id":"e9761205-4ea7-4b0b-aa53-494b902cfb99","title":"焦虑是自由引起的眩晕（呼吸）书评","url":"https://book.douban.com/review/12245641/","urlHash":3233773757},"e99397ed-a168-4b7c-a439-5284169d8121":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"e99397ed-a168-4b7c-a439-5284169d8121","title":"Yizhong Wang on X: \"When you use ChatGPT, do you notice that it has a data cutoff date? 🗓️ But as models are pretrained on web text originating from many historical periods, do they have a sense that they should use their latest knowledge to answer questions rather than historical info? Excited to… https://t.co/C0wzDoGgC0\" / X","url":"https://twitter.com/yizhongwyz/status/1763612583222018404","urlHash":4098672815},"e9a3c231-bef4-42a2-b8cb-93992837c989":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"e9a3c231-bef4-42a2-b8cb-93992837c989","title":"Transformers learn in-context by gradient descent | PDF","url":"https://arxiv.org/pdf/2212.07677.pdf","urlHash":1583333636},"ea07f017-2ad9-457a-ac2e-29ffa83c2e7a":{"favIconUrl":"fallback","id":"ea07f017-2ad9-457a-ac2e-29ffa83c2e7a","title":"Diffusion models as plug-and-play priors - Arxiv-2206.09012","url":"https://arxiv.org/pdf/2206.09012.pdf","urlHash":4037093276},"ea3defb6-2c5a-4be0-acf6-fac58b189630":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"ea3defb6-2c5a-4be0-acf6-fac58b189630","title":"Aran Komatsuzaki on X: \"Feedback Loops With Language Models Drive In-Context Reward Hacking Shows that feedback loops can cause in-context reward hacking, where the LLM at test-time optimizes an objective but creates negative side effects in the process https://t.co/OPSPVUUEiM https://t.co/UHDYErTLom\" / X","url":"https://twitter.com/arankomatsuzaki/status/1756857285773500879","urlHash":1614695704},"ea454c57-1428-4008-bac6-88247af196e1":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"ea454c57-1428-4008-bac6-88247af196e1","title":"Prompt-to-Prompt Image Editing with Cross Attention Control | PDF","url":"https://arxiv.org/pdf/2208.01626.pdf","urlHash":811646469},"ea86ebfe-29d5-4a76-9d8d-4692ffd3c6ff":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"ea86ebfe-29d5-4a76-9d8d-4692ffd3c6ff","title":"Boosted Prompt Ensembles for Large Language Models | Abstract","url":"https://arxiv.org/abs/2304.05970","urlHash":2647913628},"ea870603-e510-46df-a4b3-95c4e8c4f12a":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"ea870603-e510-46df-a4b3-95c4e8c4f12a","title":"Tatsunori Hashimoto on X: \"Language model hallucinations are a big problem. Can we build LMs w/ factuality &amp; correctness guarantees? Conformal factuality is a simple, practical modification to any LM that uses conformal prediction to give exact high-prob. correctness guarantees https://t.co/mdzgdwNbp6 https://t.co/FNAZvMPOXO\" / X","url":"https://twitter.com/tatsu_hashimoto/status/1759987601891533220","urlHash":3106089709},"ea890dbf-6c99-42ce-b24f-9e7fea4834e2":{"favIconUrl":"fallback","id":"ea890dbf-6c99-42ce-b24f-9e7fea4834e2","title":"Mitigating Data Poisoning in Text Classification with Differential Privacy","url":"https://aclanthology.org/2021.findings-emnlp.369.pdf","urlHash":1651988077},"ea8a02ae-3884-46b6-a255-c6bb2b9f040f":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"ea8a02ae-3884-46b6-a255-c6bb2b9f040f","title":"Yushi Hu on X: \"Multimodal reasoning is hard. Even the best LMMs struggle with counting😥 Any fix for it? Introduce VPD from @GoogleAI: we teach LMMs multimodal CoT reasoning with data synthesized from LLM + vision tools, and achieve new SOTAs on many multimodal tasks!🥳 https://t.co/bACXEhuzOC https://t.co/DOA1vOrQp8\" / X","url":"https://twitter.com/huyushi98/status/1733234299686780995","urlHash":928160543},"ea94d4bd-41bc-4f95-a636-7ff63085677d":{"favIconUrl":"fallback","id":"ea94d4bd-41bc-4f95-a636-7ff63085677d","title":"A Mathematical Exploration of Why Language Models Help Solve Downstream Tasks - Arxiv-2010.03648","url":"https://arxiv.org/abs/2010.03648","urlHash":3735129330},"ea9b0f3c-aeb2-4601-a2df-1be0381b17de":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"ea9b0f3c-aeb2-4601-a2df-1be0381b17de","title":"IDEA-Research/Grounded-Segment-Anything: Grounded-SAM: Marrying Grounding-DINO with Segment Anything & Stable Diffusion & Recognize Anything - Automatically Detect , Segment and Generate Anything","url":"https://github.com/IDEA-Research/Grounded-Segment-Anything","urlHash":1598520747},"eaa885f3-e248-48c7-b4eb-7e368c535b43":{"favIconUrl":"fallback","id":"eaa885f3-e248-48c7-b4eb-7e368c535b43","title":"https://arxiv.org/pdf/2110.07831.pdf","url":"https://arxiv.org/pdf/2110.07831.pdf","urlHash":1275722189},"eaf48806-3909-4ff7-87e2-15fa7d4eface":{"favIconUrl":"fallback","id":"eaf48806-3909-4ff7-87e2-15fa7d4eface","title":"卡尔维诺经典","url":"https://book.douban.com/series/11463","urlHash":2283787469},"eb3d2c81-9187-4572-bc81-feac47eee2c4":{"favIconUrl":"fallback","id":"eb3d2c81-9187-4572-bc81-feac47eee2c4","title":"Shortcut Learning of Large Language Models in Natural Language Understanding A Survey - Arxiv-2208.11857","url":"https://arxiv.org/pdf/2208.11857.pdf","urlHash":233064466},"eb656022-428a-474c-9c16-a62f53e4fb3e":{"favIconUrl":"fallback","id":"eb656022-428a-474c-9c16-a62f53e4fb3e","title":"One-2-3-45 Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization - Arxiv-2306.16928","url":"https://arxiv.org/abs/2306.16928","urlHash":2507509942},"eb84a4a4-55c2-456c-962e-2e3b0803994d":{"favIconUrl":"fallback","id":"eb84a4a4-55c2-456c-962e-2e3b0803994d","title":"Deep Learning meets Nonparametric Regression Are Weight-Decayed DNNs Locally Adaptive? - Arxiv-2204.09664","url":"https://arxiv.org/abs/2204.09664","urlHash":96795967},"eba900e5-15af-4985-9495-fdd4d5d4c60c":{"favIconUrl":"fallback","id":"eba900e5-15af-4985-9495-fdd4d5d4c60c","title":"AutoMix: Automatically Mixing Language Models","url":"https://arxiv.org/abs/2310.12963?utm_source=substack&utm_medium=email","urlHash":3695393589},"ebbdd5a1-74cc-45b8-b15d-2ab8c8593978":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"ebbdd5a1-74cc-45b8-b15d-2ab8c8593978","title":"HongjinSU on X: \"How to adapt LLMs for code 🖥️ to updated libraries and long-tail programming languages w/o training? 🤔 We introduce Arks ⛵️, Active Retrieval in Knowledge Soup, a general pipeline of retrieval-augmented generation for code (RACG). It features: 1️⃣A diverse knowledge soup… https://t.co/F3dxAIcxji\" / X","url":"https://twitter.com/hongjin_su/status/1759978005525643466","urlHash":2480338866},"ebd71c1b-5c02-4120-b356-0c9634b7d4a2":{"favIconUrl":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA99JREFUeNrsG4t1ozDMzQSM4A2ODUonKBucN2hugtIJ6E1AboLcBiQTkJsANiAb9OCd/OpzMWBJBl5TvaeXPiiyJetry0J8wW3D3QpjRh3GjneXDq+fSQA9s2mH9x3KDhN4foJfCb8N/Jrv+2fnDn8vLRQOplWHVYdvHZYdZsBcZP1vBmh/n8DzEmhUQDPaOuP9pFuY+JwJHwHnCLQE2tnWBGEyXozY9xCUgHMhhjE2I4heVWtgIkZ83wL6Qgxj1obfWBxymPwe+b00BCCRNPbwfb60yleAkkBHGT5AEehIYz7eJrFDMF9CvH4wwhcGHiHMneFvLDQwlwvMLQq58trRcYBWfYn0A0OgHWQUSu25mE+BnoYKnnEJoeIWAifzOv7vLWd2ZKRfWAIme3tOiUaQ3UnLkb0xj1FxRIeEGKaGIHOs9nEgLaaA9i0JRYo1Ic67wJW86KSKE/ZAM8KuVMk8ITVhmxUxJ3Cl2xlm9Vtkeju1+mpCQNxaEGNCY8bs9X2YqwNoQeGjBWut/ma0QAWy/TqAsHx9wSya3I5IRxOfTC+leG+kA/4vSeEcGBtNUN6byhu3+keEZCQJUNh8MAO7HL6H8pQLnsW/Hd4T4lv93TPjfM7A46iEEqbB5EDOvwYNW6tGNZzT/o+CZ6sqZ6wUtR/wf7mi/VL8iNciT6rHih48Y55b4nKCHJCCzb4y0nwFmin3ZEMIoLfZF8F7nncFmvnWBaBj7CGAYA/WGJsUwHdYqVDwAmNsUgAx4CGgAA7GOOxADYOFWOaIKifuVYzmOpREqA21Mo7aPsgiY1PhOMAmxtR+AUbYH3Id2wc0SAFIQTsn9IUGWR8k9jx3vtXSiAacFxTAGakBk9UudkNECd6jLe+6HrshshvIuC6IlLMRy7er+JpcKma24SlE4cFZSZJDGVVrsNvitQhQrDhW0jfiOLfFd47C42eHT56D/BK0To+58Ahj+cAT8HT1UWlfLZCCd/uKawzU0Rh2EyIX/Icqth3niG8ybNroezwe6khdCNxRN+l4XGdOLVLlOOt2hTRJlr1ETIuMAltVTMz70mJrkdGAaZLSmnBEqmAE32JCMmuTlCnRgsBENtOUpHhvvsYIL0ibnBkaC6QvKcR7738GKp0AKnim7xgUSNv1bpS8QwhBt8r+EP47v/oyRK/S34yJ9nT+AN0Tkm4OdB9E4BsmXM3SnMlRFUrtp6IDpV2eKzdYvF3etm3KhQksbOLChGkSmcBdmcEwvqkrMy5BzL00NZeu3qPYJOOuCc+5NjcWKXQxFvTa3NoXJ4d8in7fiAUuTt781dkvuHX4K8AA2Usy7yNKLy0AAAAASUVORK5CYII=","id":"ebd71c1b-5c02-4120-b356-0c9634b7d4a2","title":"Multimodal Neurons in Artificial Neural Networks","url":"https://distill.pub/2021/multimodal-neurons/","urlHash":8934602},"ec466f43-d856-4e67-a409-74dc145fc17b":{"favIconUrl":"https://ssl.gstatic.com/docs/documents/images/kix-favicon8.ico","id":"ec466f43-d856-4e67-a409-74dc145fc17b","title":"Neel Nanda MATS Admissions Procedure - Google 文档","url":"https://docs.google.com/document/d/1p-ggQV3vVWIQuCccXEl1fD0thJOgXimlbBpGk6FI32I/edit","urlHash":3898987484},"ec4a37aa-9d11-4b11-8003-e84b3b738357":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"ec4a37aa-9d11-4b11-8003-e84b3b738357","title":"AutoGPTQ/examples/quantization/basic_usage.py at main · PanQiWei/AutoGPTQ","url":"https://github.com/PanQiWei/AutoGPTQ/blob/main/examples/quantization/basic_usage.py","urlHash":846376162},"ec58ad06-5be7-47e7-9023-d0a053f03b3e":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"ec58ad06-5be7-47e7-9023-d0a053f03b3e","title":"A Survey of Hallucination in Large Foundation Models | Abstract","url":"https://arxiv.org/abs/2309.05922?utm_source=substack&utm_medium=email","urlHash":147707385},"ec5ccaae-839a-4c76-b64e-86487d840181":{"favIconUrl":"fallback","id":"ec5ccaae-839a-4c76-b64e-86487d840181","title":"Precision Loss in Transformers","url":"https://aslvrstn.com/posts/transformer_precision_loss/","urlHash":3375310298},"ec5fc6a9-7cc7-4c62-ada6-bb21ff9323ef":{"favIconUrl":"fallback","id":"ec5fc6a9-7cc7-4c62-ada6-bb21ff9323ef","title":"Stableboost","url":"https://stableboost.ai/home?tab=2&createModel=1","urlHash":1777537625},"ec6be2ec-7cc8-40cb-b88a-85b348d4a7ed":{"favIconUrl":"fallback","id":"ec6be2ec-7cc8-40cb-b88a-85b348d4a7ed","title":"APPLS: A Meta-evaluation Testbed for Plain Language Summarization","url":"https://arxiv.org/abs/2305.14341","urlHash":3615696018},"ec894930-e54e-434c-a676-cf7766c1a3a8":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"ec894930-e54e-434c-a676-cf7766c1a3a8","title":"thunlp/UltraChat: Large-scale, Informative, and Diverse Multi-round Chat Data (and Models)","url":"https://github.com/thunlp/UltraChat?tab=readme-ov-file","urlHash":3332179812},"ec9e1084-6b9b-49ef-923e-a8afb09f60d7":{"favIconUrl":"https://www.google.com/favicon.ico","id":"ec9e1084-6b9b-49ef-923e-a8afb09f60d7","title":"浮世绘流派史 - Google Search","url":"https://www.google.com/search?q=%E6%B5%AE%E4%B8%96%E7%BB%98%E6%B5%81%E6%B4%BE%E5%8F%B2&oq=%E6%B5%AE%E4%B8%96%E7%BB%98%E6%B5%81%E6%B4%BE%E5%8F%B2&aqs=chrome..69i57j0i546l4j69i60.150j0j1&sourceid=chrome&ie=UTF-8","urlHash":3316014275},"ecba58cd-6772-432b-bf48-4d26353ee786":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"ecba58cd-6772-432b-bf48-4d26353ee786","title":"LLMs cannot find reasoning errors, but can correct them! | Abstract","url":"https://arxiv.org/abs/2311.08516","urlHash":3899425805},"ecc23277-aebf-428e-8cdb-4399deae9e6c":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"ecc23277-aebf-428e-8cdb-4399deae9e6c","title":"OpenAI假设被推翻！给定计算量，较小模型打败大模型，Llama 2训练与GPU计算关联度","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652360053&idx=4&sn=63b82bafc236c7186e68af75b1fc2748&chksm=f124b984c65330927a453c8b26d6d76ccbdc731ddf0bdd24dd4952f4b47580d455ac2deafd8e&mpshare=1&scene=1&srcid=0813NrauHmck37SYEvdphNFp&sharer_sharetime=1691905131932&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQuB3HqW00VwDuO%2FICcFNnWhKWAgIE97dBBAEAAAAAANBTMLquZNwAAAAOpnltbLcz9gKNyK89dVj0Yh5OByz3iZZ10RU4CCvuiboQiPGHgX9GinFBNMzzXtW6fLuWyYmw0WcTShKeMaeUSAU0FrN2yBW%2B9AfJO6uriQr0ah%2FFlfssSEL9fkO6USzETg01JDK9NVEbN2rgTgeo86%2BMI%2BMaIgEuAfrQdf0Pldi62aWgWt1FF5GMAeAJHJo5focE%2FwMkkEfWm2LXa74gPB1kccAJQbi%2FBNu0%2FOZngQ4RGwVao%2FQkWhQox%2BidwIa8EyZ2yFDLXod27M2HOdtrmrw5kYLSnxBdG5AJ%2B1S0v%2BqzLq8l0Yn%2FcEbaZ53d7cg64fa7%2BX5M6JrdJF7pxjFh&acctmode=0&pass_ticket=9qVAJdNxyKlNyoIWvqjwwVNg3Fti14cFzUcp%2BPvDk3GP3WVmS4LjGYN%2F9%2Bfz7Nat&wx_header=0#rd","urlHash":4210863353},"ecc5e1e9-e4ba-4299-9e79-4ed998e3430c":{"favIconUrl":"fallback","id":"ecc5e1e9-e4ba-4299-9e79-4ed998e3430c","title":"芥川龙之介的《矿车》想表达什么？ - 知乎","url":"https://www.zhihu.com/question/316599382/answer/653444290","urlHash":2426256412},"ecd925dc-433e-4c9b-9d28-c96b6d880b0e":{"favIconUrl":"fallback","id":"ecd925dc-433e-4c9b-9d28-c96b6d880b0e","title":"(142) OPTML++ 10/12/2022 Tengyu Ma - YouTube","url":"https://www.youtube.com/watch?v=gmoX2SSk9q4&t=3s","urlHash":1862081224},"ecf88057-1dd4-4de9-9af4-d043e0a19f53":{"favIconUrl":"https://static.zhihu.com/heifetz/favicon.ico","id":"ecf88057-1dd4-4de9-9af4-d043e0a19f53","title":"三岛由纪夫的《金阁寺》和《丰饶之海》哪部作品更出彩？ - 知乎","url":"https://www.zhihu.com/question/291613005","urlHash":350803415},"ed156bb9-8409-4010-867a-8f19b5380fb9":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"ed156bb9-8409-4010-867a-8f19b5380fb9","title":"twitter.com/jeremy_scheurer/status/1668292694563758080","url":"https://twitter.com/jeremy_scheurer/status/1668292694563758080","urlHash":1476273991},"ed504e3f-25c0-4259-9185-7e05b7eeba54":{"favIconUrl":"fallback","id":"ed504e3f-25c0-4259-9185-7e05b7eeba54","title":"CS229br Foundations of Deep Learning (aka Topics in the Foundations of Machine Learning)","url":"https://boazbk.github.io/mltheoryseminar/","urlHash":3855518453},"ed746543-82bd-4d2a-9908-22c5847db491":{"favIconUrl":"fallback","id":"ed746543-82bd-4d2a-9908-22c5847db491","title":"Reformer: 一个在训练阶段存储极致压缩的Transformer模型 - 知乎","url":"https://zhuanlan.zhihu.com/p/357628257","urlHash":3703144731},"ed7c1fa3-c516-48b6-8b8f-2df50b8d26cd":{"favIconUrl":"fallback","id":"ed7c1fa3-c516-48b6-8b8f-2df50b8d26cd","title":"Stability AI连扔两个王炸！首个开源RLHF模型登基，DeepFloyd IF像素级出图","url":"https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652325930&idx=1&sn=6bf045e96327076a5d1678fba9849433&chksm=f1243cdbc653b5cdf9972b2e79c58ddd1280909b6648fd3e2fd7d9a730789fd7ca12eedabf4f&mpshare=1&scene=1&srcid=0511sobWlVzcY6z352EFGnRo&sharer_sharetime=1683767998610&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQVmSGEJHZzCujvGY5%2B%2FkekBKWAgIE97dBBAEAAAAAAG9XLfy3E9EAAAAOpnltbLcz9gKNyK89dVj0MYOSRDj0SvJdta%2FtJwIeq3tD5dclh6o1MDAxXViXf6Tv9OGiLNRD%2BvZyAxR6P9eHzjQ9TmiiDdwfE5JftKjqNwIgPUOZsY0UXLuRb2OjQITtxdDtXfTUEMdi%2BdmptEAqYq8EQzsHbqyzEG%2B%2FDTCvttK3yfC0xq7%2BoQ%2F99AH9yKi1WjmC9VlwwdQMrEGx20CDFL5TQvHT9XkWT7zn%2BNPwa%2BYAoTFqVSRONHY%2F93dWcLL7qfA452zio97kxzJMq0FETKuAryf05SuVUBhyh5J3CbVp3xC5e5P%2BfKq89jt7zUUxZ89NBo%2FcbOQFmviT%2BW36&acctmode=0&pass_ticket=CVx8wIecFZpLiqLziB53fbV73WifzfjFL8ONivSufgjWuGh7C4%2FOQ%2F8mJB%2FKnmOIMRO45KycHcczCYA%2FplnIug%3D%3D&wx_header=0#rd","urlHash":968430120},"edc057de-3e79-4649-b4d2-707942ff2b19":{"favIconUrl":"fallback","id":"edc057de-3e79-4649-b4d2-707942ff2b19","title":"Exploring The Landscape of Distributional Robustness for Question Answering Models - Arxiv-2210.12517","url":"https://arxiv.org/pdf/2210.12517.pdf","urlHash":3782543774},"ee18cfdf-4a4e-44e1-9186-871ddf4c7ae0":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"ee18cfdf-4a4e-44e1-9186-871ddf4c7ae0","title":"Exploring Format Consistency for Instruction Tuning | PDF","url":"https://arxiv.org/pdf/2307.15504.pdf","urlHash":4201478850},"ee32592c-36a4-413b-9402-279e9dfbd7ee":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"ee32592c-36a4-413b-9402-279e9dfbd7ee","title":"srush/Transformer-Puzzles: Puzzles for exploring transformers","url":"https://github.com/srush/Transformer-Puzzles?tab=readme-ov-file","urlHash":4128577408},"ee44bd45-d2da-4c3d-9cc2-e98cf23ba28f":{"favIconUrl":"fallback","id":"ee44bd45-d2da-4c3d-9cc2-e98cf23ba28f","title":"从几何视角来理解模型参数的初始化策略 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/7180/comment-page-1","urlHash":255620339},"ee618ce0-fb26-4efd-820f-6688e50007af":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"ee618ce0-fb26-4efd-820f-6688e50007af","title":"Does Video Summarization Require Videos? Quantifying the Effectiveness of Language in Video Summarization | Abstract","url":"https://arxiv.org/abs/2309.09405","urlHash":776034338},"ee618d2d-db05-429a-a19c-370faa1ecdc5":{"favIconUrl":"fallback","id":"ee618d2d-db05-429a-a19c-370faa1ecdc5","title":"GDL Blogs","url":"https://geometricdeeplearning.com/blogs/","urlHash":1198340208},"ee7f362d-4909-41e5-b35c-23cc147462b1":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"ee7f362d-4909-41e5-b35c-23cc147462b1","title":"ORPO: Monolithic Preference Optimization without Reference Model | Abstract","url":"https://arxiv.org/abs/2403.07691","urlHash":3637233232},"eea13735-4e7f-4b4a-9a94-172af96b145a":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"eea13735-4e7f-4b4a-9a94-172af96b145a","title":"微调都不要了？3个样本、1个提示搞定LLM对齐，提示工程师：全都回来了","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650899552&idx=1&sn=2a3b09010e988014ee7b81ec4a6e06da&exportkey=n_ChQIAhIQ3rXbg71Cz8AGTE%2FFeIoATRKWAgIE97dBBAEAAAAAACHGIQJ34zQAAAAOpnltbLcz9gKNyK89dVj0P%2B4dU0SYmQfbCID3MijGI3I9uuARSYzoGm99KoLHWuV64qJPahgJUYngVM82f6D7Fr07OUOXFpz%2FKj0tuX216aAv0xWdOAcqoCC3WGm%2BSfr8sYjZepKmPbJa2qPaNcN0ROZReW4wMTqURwgxJ9nOd5FtkHmCztiZxTFDixGkjbB%2FC7lwWYdbfdcuKL6UNcNKUMzAma%2FAMw7De1Z9HmkSIwk7TEjlbB5OmwiKEFU3BiXWRV0d2Pdz84i3Ign9xcIiv8yciQYNO6AU%2FqAnLtJOTdLWacUS70P4JVoQeAfsN8t3wgmaBzDjxm9fDsDTXJXC&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsbo3D7kvqSJnKX2AapwCRqM59UrdYZaBCoZBX8kndDozw%3D%3D&wx_header=0&poc_token=HFDw8GWjpLNFMUepYgzJmJ6tkeb5B6Bx2PlPKQ6c","urlHash":2145004806},"eebf3462-f365-48a5-add3-5af7269dcb81":{"favIconUrl":"fallback","id":"eebf3462-f365-48a5-add3-5af7269dcb81","title":"Differentially Private Model Compression - OR-NeurIPS-2022_68EuccCtO5i","url":"https://openreview.net/pdf?id=68EuccCtO5i","urlHash":2970838988},"eec5f64e-8c6c-4f33-8a22-6885b65de97a":{"favIconUrl":"https://cdn.semanticscholar.org/b5fbde4a4847434e/img/darkmode/favicon-32x32.png","id":"eec5f64e-8c6c-4f33-8a22-6885b65de97a","title":"[PDF] Localizing Model Behavior with Path Patching | Semantic Scholar","url":"https://www.semanticscholar.org/paper/Localizing-Model-Behavior-with-Path-Patching-Goldowsky-Dill-MacLeod/8d8fc878bf4c7005546c866824a72d0c46ca91a3","urlHash":397020341},"eeda4a4a-a0be-4259-8372-edf00f2646e6":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"eeda4a4a-a0be-4259-8372-edf00f2646e6","title":"twitter.com/ShunyuYao12/status/1659357547474681857","url":"https://twitter.com/ShunyuYao12/status/1659357547474681857","urlHash":1497185032},"eeddef85-9343-41e5-8bf8-29ecbb0a1be7":{"favIconUrl":"fallback","id":"eeddef85-9343-41e5-8bf8-29ecbb0a1be7","title":"NLP的“第四范式”之prompt learning总结 - 知乎","url":"https://zhuanlan.zhihu.com/p/419215591","urlHash":2048554020},"eefb602d-6ac5-4219-899c-4fc4e842ab9c":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"eefb602d-6ac5-4219-899c-4fc4e842ab9c","title":"Hailey Schoelkopf on X: \"This is really cool work! Turns out you don't just have to shove all your data at once into LM pretraining and hope for the best...\" / X","url":"https://twitter.com/haileysch__/status/1628145660464709633","urlHash":1361089496},"ef126cd1-e414-42f6-be4a-907a0dc7cb14":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"ef126cd1-e414-42f6-be4a-907a0dc7cb14","title":"RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback | PDF","url":"https://arxiv.org/pdf/2309.00267.pdf","urlHash":715822458},"ef1490ed-ae56-46d6-8469-eca7a185cdce":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"ef1490ed-ae56-46d6-8469-eca7a185cdce","title":"Multicalibration as Boosting for Regression | PDF","url":"https://arxiv.org/pdf/2301.13767.pdf","urlHash":2674346645},"ef370858-5e6c-4f19-aa04-6a94f8f99f64":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"ef370858-5e6c-4f19-aa04-6a94f8f99f64","title":"从梯度最大化看Attention的Scale操作 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/9812","urlHash":4924945},"ef6d92b9-a4bc-46f7-8338-52418873131e":{"favIconUrl":"fallback","id":"ef6d92b9-a4bc-46f7-8338-52418873131e","title":"Reformer: 搞笑（高效）的transformer结构(2020年2月Google) - 知乎","url":"https://zhuanlan.zhihu.com/p/208134502","urlHash":3981470230},"ef9596a3-8e88-46b9-916f-fb8c073d72db":{"favIconUrl":"fallback","id":"ef9596a3-8e88-46b9-916f-fb8c073d72db","title":"Certified Robustness Against Natural Language Attacks by Causal Intervention - Arxiv-2205.12331","url":"https://arxiv.org/abs/2205.12331","urlHash":1278749646},"ef9bdb3c-25c5-48e4-b5bc-91d0f4614167":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"ef9bdb3c-25c5-48e4-b5bc-91d0f4614167","title":"Principled Reinforcement Learning with Human Feedback from Pairwise or $K$-wise Comparisons | Abstract","url":"https://arxiv.org/abs/2301.11270","urlHash":1869075437},"efa242c8-3265-4a45-afc5-35542cc655f1":{"favIconUrl":"https://baikebcs.bdimg.com/cms/static/baike-icon.svg","id":"efa242c8-3265-4a45-afc5-35542cc655f1","title":"白光（鲁迅1922年创作短篇小说）_百度百科","url":"https://baike.baidu.com/item/%E7%99%BD%E5%85%89/10738851","urlHash":1958911901},"efb5a566-9927-422d-9f8f-137ba75da03a":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"efb5a566-9927-422d-9f8f-137ba75da03a","title":"Are Emergent Abilities of Large Language Models a Mirage? | Abstract","url":"https://arxiv.org/abs/2304.15004","urlHash":4222462948},"efe4f2a4-f218-4353-9a34-c31c39dd3be8":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"efe4f2a4-f218-4353-9a34-c31c39dd3be8","title":"Nikhil Prakash on X: \"Ever wondered how finetuning boosts a language model's performance? Our ICLR24 paper (w @TamarRottShaham @Tal_Ha535 @boknilev @davidbau) unveils the secret: fine-tuning enhances, rather than fundamentally alters, the existing mechanisms of original model. https://t.co/B8tJ8KGmpt https://t.co/4V3fPRdPdz\" / X","url":"https://twitter.com/nikhil07prakash/status/1761077688431980739","urlHash":2722992986},"f0a40b40-42da-4744-9302-f10045614f7d":{"favIconUrl":"fallback","id":"f0a40b40-42da-4744-9302-f10045614f7d","title":"DivDis","url":"https://sites.google.com/view/diversify-and-disambiguate","urlHash":3703725788},"f0acec57-d7a0-4478-81ca-257fad1a9790":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f0acec57-d7a0-4478-81ca-257fad1a9790","title":"Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models | PDF","url":"https://arxiv.org/pdf/2310.06692.pdf","urlHash":350167764},"f1367f2c-cd80-41d3-b310-a43c1a73baf8":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"f1367f2c-cd80-41d3-b310-a43c1a73baf8","title":"LLM Augmented LLMs: Expanding Capabilities through Composition | Abstract","url":"https://arxiv.org/abs/2401.02412?utm_source=substack&utm_medium=email","urlHash":643811276},"f1395f56-75f4-4639-a41c-63f6159f7302":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"f1395f56-75f4-4639-a41c-63f6159f7302","title":"指切りパズル (豆瓣)","url":"https://book.douban.com/subject/35581093/","urlHash":1820861845},"f1550665-5550-4298-af96-4c6330c0fec2":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"f1550665-5550-4298-af96-4c6330c0fec2","title":"Aran Komatsuzaki on X: \"More Agents Is All You Need Finds that, simply via a sampling-and-voting method, the performance of LLMs scales with the number of agents instantiated https://t.co/bErW3zs9ai https://t.co/XlprnwnJHq\" / X","url":"https://twitter.com/arankomatsuzaki/status/1755784989042520184","urlHash":3724932655},"f1d63886-1904-4db9-86d4-853336bbb8a3":{"favIconUrl":"fallback","id":"f1d63886-1904-4db9-86d4-853336bbb8a3","title":"torchbnn - Google Search","url":"https://www.google.com/search?q=torchbnn&oq=torchbnn&aqs=chrome..69i57j0i546l3.1895j0j1&sourceid=chrome&ie=UTF-8","urlHash":4201860341},"f1f6a750-f0bb-4ab5-9400-bc08c239ff6b":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"f1f6a750-f0bb-4ab5-9400-bc08c239ff6b","title":"srush/Autodiff-Puzzles","url":"https://github.com/srush/Autodiff-Puzzles","urlHash":1452535734},"f22e1f70-5551-499c-9dfa-b1428e10180a":{"favIconUrl":"fallback","id":"f22e1f70-5551-499c-9dfa-b1428e10180a","title":"A Survey of Knowledge-Enhanced Pre-trained Language Models - Arxiv-2211.05994","url":"https://arxiv.org/pdf/2211.05994.pdf","urlHash":1666554622},"f2959109-f530-45c8-82fe-2c0c0f432401":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"f2959109-f530-45c8-82fe-2c0c0f432401","title":"Niklas Muennighoff on X: \"Introducing GRIT🦾to unify text embedding 🔢&amp; generation 📝. GritLM is open SoTA on embedding (MTEB) &amp; generative tasks (BBH etc.) – Both in 1 model. See 🧵for how GRIT🦾 makes RAG &gt;60% faster &amp; more 📜https://t.co/eDX01YG5yJ 💻https://t.co/zloQjEhXIO 1/12 https://t.co/f2YOOi1CBs\" / X","url":"https://twitter.com/Muennighoff/status/1758307967802224770","urlHash":1741404361},"f2a30d31-5839-4368-9c8e-c08e95b8cd0b":{"favIconUrl":"fallback","id":"f2a30d31-5839-4368-9c8e-c08e95b8cd0b","title":"BERT 瘦身之路：Distillation，Quantization，Pruning - 知乎","url":"https://zhuanlan.zhihu.com/p/86900556","urlHash":3152428246},"f2b564da-e090-441b-9aac-cbd9b232af11":{"favIconUrl":"fallback","id":"f2b564da-e090-441b-9aac-cbd9b232af11","title":"互怼的艺术：从零直达WGAN-GP - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/4439","urlHash":2582063303},"f2c81bf7-11c1-4605-b1fe-89119cc21021":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"f2c81bf7-11c1-4605-b1fe-89119cc21021","title":"AK on X: \"AK trending papers today https://t.co/Q3CV4QTgAW\" / X","url":"https://twitter.com/_akhaliq/status/1649559709861531650","urlHash":2318288025},"f2d0f442-e643-437c-b43c-d43a00bf7f8b":{"favIconUrl":"fallback","id":"f2d0f442-e643-437c-b43c-d43a00bf7f8b","title":"Chelsea Finn · Invited Talk: The Big Problem with Meta-Learning and How Bayesians Can Fix It · SlidesLive","url":"https://slideslive.com/38922670/invited-talk-the-big-problem-with-metalearning-and-how-bayesians-can-fix-it","urlHash":2575744743},"f2da88f9-02f7-4bf4-9c02-3b98d9e34618":{"favIconUrl":"fallback","id":"f2da88f9-02f7-4bf4-9c02-3b98d9e34618","title":"A Discussion of 'Adversarial Examples Are Not Bugs, They Are Features'","url":"https://distill.pub/2019/advex-bugs-discussion/","urlHash":2698506236},"f2dcb80c-4dd0-41d8-8e38-a70b6fb9fbd5":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"f2dcb80c-4dd0-41d8-8e38-a70b6fb9fbd5","title":"John Nay on X: \"LLM Self-Play Fine-Tuning -LLM generates its own training data from its previous iterations, refining its policy by discerning its self-generated responses vs human ones -Unlocks full potential of human data -Significantly improves perf across benchmarks https://t.co/PTx0LMaaa7 https://t.co/FZsIUSeGwc\" / X","url":"https://twitter.com/johnjnay/status/1742391053552930993","urlHash":1194335187},"f2f05047-934d-4e50-bf54-2aa17ca00dda":{"favIconUrl":"fallback","id":"f2f05047-934d-4e50-bf54-2aa17ca00dda","title":"Shikra：新一代多模态大语言模型，理解指向，说出坐标","url":"https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&mid=2247494170&idx=1&sn=7517a7a0e81293cbc1737fe5888e06d0&chksm=9bba637eaccdea68433d0f4746ec7f4034846419c15d8d15f9e68224c04ebfa3c2a58c5ab51d&mpshare=1&scene=1&srcid=0813qIR9FpZ6OezvsXntQ9Ya&sharer_sharetime=1691904652963&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQNNC72cfdTM0Lz0SsRamtaxKWAgIE97dBBAEAAAAAACy5A%2BzAlKgAAAAOpnltbLcz9gKNyK89dVj0uRga%2Bl0PeB%2BKkafr6UAg3nYwa9KvczuC67PLw6MN%2BIqx1R7kKWvWoYP6y2WAgMUBj7VjubihAC6DdnGmOLLgVnJojA3jo2m%2BDn%2FVi7wR4uVk3hlLWD3hcWIQSrvdXlARx27GeQ48L%2BiKAD2EwCkbCX0z75gwyltdWAiSsTZ2jR5lAP8gl%2B7WQrrBPAOEDXgTIDesfsmB4dvePyktYDvBbCIJNH8sXD37QqlOAKN34dMG1xv97qChCUy3vU1Qg6chtQ00TWqn33lki370qvNl0xrZoiZmB2w8fvAQnEVK%2BUBDJxnmpNoBrcWmec2H31CG&acctmode=0&pass_ticket=GBYFapoIVN0COZKwn8GOc0Os%2FOIOMzQhsVt0u3KVaG9AJadz8fktmRExjMh3BpzP&wx_header=0#rd","urlHash":1096968359},"f2f7cee8-f186-4890-b850-70d7431b7371":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"f2f7cee8-f186-4890-b850-70d7431b7371","title":"Aran Komatsuzaki on X: \"Microsoft presents Language Feedback Models (LFM) - LFMs identify desirable behaviour for imitation learning in instruction following - LFMs outperform using LLMs as experts to directly predict actions and generalize to unseen environments https://t.co/pD5kScVUhq https://t.co/tLYWSlHSS2\" / X","url":"https://twitter.com/arankomatsuzaki/status/1757230767631913202","urlHash":1457257277},"f2f9b5fb-7784-473d-82cf-42178f020d59":{"favIconUrl":"fallback","id":"f2f9b5fb-7784-473d-82cf-42178f020d59","title":"REPLUG: Retrieval-Augmented Black-Box Language Models | PDF","url":"https://arxiv.org/pdf/2301.12652.pdf","urlHash":1911895143},"f2fee442-ae48-4512-8ebc-1b3a6877ed74":{"favIconUrl":"fallback","id":"f2fee442-ae48-4512-8ebc-1b3a6877ed74","title":"adambielski/pytorch-gconv-experiments: Experiments with Group Equivariant Convolutions in PyTorch","url":"https://github.com/adambielski/pytorch-gconv-experiments","urlHash":4251419567},"f309759e-402e-4a78-b02a-28cf725bf8ef":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"f309759e-402e-4a78-b02a-28cf725bf8ef","title":"Zhengxiang Shi on X: \"Thrilled to share our paper with @AldoLipani, \"Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner\" is accepted at #NeurIPS2023. Our work melds the idea of instruction tuning with continued pre-training to improve the performance of prompt-based fine-tuning.\" / X","url":"https://twitter.com/ZhengxiangShi/status/1705051878554526139","urlHash":1937958434},"f3744e8f-8434-4a5e-af93-f9f2fbc784b1":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f3744e8f-8434-4a5e-af93-f9f2fbc784b1","title":"data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language | PDF","url":"https://arxiv.org/pdf/2202.03555.pdf","urlHash":3262350034},"f394b376-0874-4c10-85ba-1c855ca689f8":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"f394b376-0874-4c10-85ba-1c855ca689f8","title":"InstructEdit: Instruction-based Knowledge Editing for Large Language Models | Abstract","url":"https://arxiv.org/abs/2402.16123#:~:text=InstructEdit%3A%20Instruction%2Dbased%20Knowledge%20Editing%20for%20Large%20Language%20Models,-Bozhong%20Tian%2C%20Siyuan&text=Knowledge%20editing%20for%20large%20language%20models%20can%20offer%20an%20efficient,negatively%20impacting%20the%20overall%20performance.","urlHash":2368401698},"f3e0ddcc-0027-40bc-82aa-5557aa37569c":{"favIconUrl":"fallback","id":"f3e0ddcc-0027-40bc-82aa-5557aa37569c","title":"泛化性乱弹：从随机噪声、梯度惩罚到虚拟对抗训练 - 科学空间|Scientific Spaces","url":"https://kexue.fm/archives/7466","urlHash":3551947665},"f3f1af24-b065-4858-98ae-26584bc95f09":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"f3f1af24-b065-4858-98ae-26584bc95f09","title":"3000多条数据里选出200条效果反而更好，MiniGPT-4被配置相同的模型超越了","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650888747&idx=1&sn=ea153de78e3b6cb57db94cdd69a814be&exportkey=n_ChQIAhIQCCeH3sPhRePts5cOBdwgehKWAgIE97dBBAEAAAAAAOfQAoh0l2MAAAAOpnltbLcz9gKNyK89dVj0WnWhgem8DjW8u9nCtX4fMwyKRMCi%2BOm9DFTgC8M87gdtBWtGL3DqIXypCP2PQLqU2YpMR85ALlIoEvw5RFNKJOh08W%2BkjgVceGtPrTMR2qgdeL9rz8Xnc2kMzHDQShNghFKryM%2BSaKFNK3%2BpEbdoFlanpAslm2Xhhal9je1knFxn6RlmEhR1lk%2Bub%2BJX%2FINI4HeOyYKhNg9SsIpKxW%2Bc5B29CF8ldGjrsl%2FSeQN3oQgGTx%2FzCMEyc3N9DA8HPMAwmyKmD97MEmbWPuf8V7iIX7PG95LosYPZMGNiksXocu6P1vhtnXNVUYsKkaLCHjux&acctmode=0&pass_ticket=eLKAS9uI1pzzyVBAyMGMh%2B%2BE7z5w1%2Blb2tqczp6ccuxG8cF15MsUBty4sir7Dvk0&wx_header=0","urlHash":3945930942},"f40f6fd1-a6dc-4541-bfda-2e754c17a97b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"f40f6fd1-a6dc-4541-bfda-2e754c17a97b","title":"Bill Yuchen Lin 🤖 on X: \"How should we maximize the planning ability of #LLM while reducing the computation cost? 🚀 Introducing SwiftSage, an agent inspired by “fast &amp; slow thinking”, which solves complex interactive tasks much better than prior agents (e.g., DRRN, SayCan, ReAct, and Reflexion). [1/n] https://t.co/lXnJoa6rJL\" / X","url":"https://twitter.com/billyuchenlin/status/1663603372220616704","urlHash":988092097},"f422b44f-9a3a-4ed3-afb0-8a75406f6079":{"favIconUrl":"https://res.cloudinary.com/dq3pms5lt/image/upload/v1531267596/alignmentForum_favicon_o9bjnl.png","id":"f422b44f-9a3a-4ed3-afb0-8a75406f6079","title":"AXRP Episode 19 - Mechanistic Interpretability with Neel Nanda — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/r2yTwkGt3kbQG2mXi/axrp-episode-19-mechanistic-interpretability-with-neel-nanda","urlHash":806584215},"f4297e3d-ed44-4b1f-9254-018fb6bae757":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"f4297e3d-ed44-4b1f-9254-018fb6bae757","title":"Continual Pre-Training of Large Language Models: How to (re)warm your model? | Abstract","url":"https://arxiv.org/abs/2308.04014","urlHash":3308847257},"f438d6e5-6e7d-4191-a360-e007188e7447":{"favIconUrl":"fallback","id":"f438d6e5-6e7d-4191-a360-e007188e7447","title":"必须要GPT3吗？不，BERT的MLM模型也能小样本学习 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/7764","urlHash":491792033},"f453b916-987a-4536-acc8-0ebf44d2d75c":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f453b916-987a-4536-acc8-0ebf44d2d75c","title":"Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research | PDF","url":"https://arxiv.org/pdf/1802.09464.pdf","urlHash":1337191064},"f45af863-78f8-4e9d-9a1f-5c1862030ff6":{"favIconUrl":"fallback","id":"f45af863-78f8-4e9d-9a1f-5c1862030ff6","title":"Rethinking the Role of PPO in RLHF – The Berkeley Artificial Intelligence Research Blog","url":"https://bair.berkeley.edu/blog/2023/10/16/p3o/","urlHash":1890289408},"f47e4dc7-dc7c-4f13-a4d9-810bd91c9ea6":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"f47e4dc7-dc7c-4f13-a4d9-810bd91c9ea6","title":"FP8-LM: Training FP8 Large Language Models | Abstract","url":"https://arxiv.org/abs/2310.18313?utm_source=substack&utm_medium=email","urlHash":2429650517},"f49fe8e9-aaf7-4c21-87a3-dce872c4b241":{"favIconUrl":"fallback","id":"f49fe8e9-aaf7-4c21-87a3-dce872c4b241","title":"Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts - Arxiv-2209.12711","url":"https://arxiv.org/pdf/2209.12711.pdf","urlHash":4074537506},"f4bd15a9-5bf0-43a5-ab6d-04a5600a811b":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f4bd15a9-5bf0-43a5-ab6d-04a5600a811b","title":"A Preliminary Evaluation of ChatGPT for Zero-shot Dialogue Understanding | PDF","url":"https://arxiv.org/pdf/2304.04256.pdf","urlHash":2667089977},"f501d3e2-7f4b-4fca-8a56-3d8280b5e5f9":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"f501d3e2-7f4b-4fca-8a56-3d8280b5e5f9","title":"GPT-4V被曝离谱bug：突然执行神秘代码，空白图片读出打折信息，网友们都看呆了","url":"https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247699263&idx=1&sn=d3e240f41b3137c0ee06977b768a17db&exportkey=n_ChQIAhIQMK1y%2BYc%2F6ScGbow3p50QLhKWAgIE97dBBAEAAAAAABl5Aatyy6UAAAAOpnltbLcz9gKNyK89dVj0qRQmPUlERMnvpqszBFqiqGcrRtCOmEzokpaqWQZsmqgd%2FeEWaIZErk8s0PSgjKy3fKNwgDaE3LuQL4vdesVnlThBHmutnbkxjIwgbNk9ZEruof9kHY3CHrFWV9idqjZyd9W8oyFPUq6m1Uo94M6IS3oqU0Sx81pqAmsVzPTH6zb7RQYpQCO18gKVs%2BfjdRE9mU1ZHkCJsfmgqnGtHSBDA2OoDII5OEBK5MPXCnmRmhXiYsU%2F4cS5qwkojz%2FMzi6nC8zW2LW%2FaFLKC%2BW9rqClP765Bj54nwnrhdl2v7Ee7yuxHfNYLQKtWD90V7aJ%2BMVY&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsaFj1DFDMLDvgEj6LJU19%2BGn3sLY9u4hSEUwbzIYR4Nxg%3D%3D&wx_header=0","urlHash":650153016},"f511bb73-f7ac-41a1-8bf3-b25b01886716":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"f511bb73-f7ac-41a1-8bf3-b25b01886716","title":"Saurabh Srivastava on X: \"More than 50% of the reported reasoning abilities of LLMs might not be true reasoning. How do we evaluate models trained on the entire internet? I.e., what novel questions can we ask of something that has seen all written knowledge? Below: new eval, results, code, and paper.… https://t.co/wy1mJQmun4\" / X","url":"https://twitter.com/_saurabh/status/1763626711407816930?utm_source=substack&utm_medium=email","urlHash":3368102152},"f51357af-c8b1-4466-95d1-901163454f10":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"f51357af-c8b1-4466-95d1-901163454f10","title":"IDEA-Research/OpenSeeD: [ICCV 2023] Official implementation of the paper \"A Simple Framework for Open-Vocabulary Segmentation and Detection\"","url":"https://github.com/IDEA-Research/OpenSeeD","urlHash":4225912676},"f51dfa50-e0fe-4ae8-9acf-86d61bc53f92":{"favIconUrl":"https://underline.io/favicon/favicon.ico","id":"f51dfa50-e0fe-4ae8-9acf-86d61bc53f92","title":"Underline | Does GPT-3 Grasp Metaphors? Identifying Metaphor Mappings with Generative Language Models","url":"https://underline.io/events/395/sessions/15253/lecture/76239-does-gpt-3-grasp-metaphorsquestion-identifying-metaphor-mappings-with-generative-language-models","urlHash":1921631332},"f52cd846-f4f7-450c-aa6b-1e452cc7b08d":{"favIconUrl":"fallback","id":"f52cd846-f4f7-450c-aa6b-1e452cc7b08d","title":"IDEA-Research/OSX: [CVPR 2023] Official implementation of the paper \"One-Stage 3D Whole-Body Mesh Recovery with Component Aware Transformer\"","url":"https://github.com/IDEA-Research/OSX","urlHash":2423506804},"f54ae8c9-0703-4953-86b2-fdd6ab2a87d0":{"favIconUrl":"https://abs.twimg.com/favicons/twitter-pip.3.ico","id":"f54ae8c9-0703-4953-86b2-fdd6ab2a87d0","title":"(2) Alon Albalak on X: \"Thanks for sharing our work @arankomatsuzaki! We also have a paper list 📜 https://t.co/O4d3N9C2CH\" / X","url":"https://twitter.com/AlbalakAlon/status/1762519188969783526","urlHash":485449021},"f56534d4-58a1-4df2-b505-2634d9262853":{"favIconUrl":"fallback","id":"f56534d4-58a1-4df2-b505-2634d9262853","title":"Dirichlet distribution - Wikiwand","url":"https://www.wikiwand.com/en/Dirichlet_distribution","urlHash":286131681},"f57ecca7-8d35-4c76-b9fd-3998d7cba37c":{"favIconUrl":"fallback","id":"f57ecca7-8d35-4c76-b9fd-3998d7cba37c","title":"Bag of Tricks for Training Data Extraction from Language Models - Arxiv-2302.04460","url":"https://arxiv.org/abs/2302.04460","urlHash":989004487},"f6275902-9d08-4077-bd64-25fc019ff273":{"favIconUrl":"fallback","id":"f6275902-9d08-4077-bd64-25fc019ff273","title":"Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture","url":"https://arxiv.org/abs/2301.08243","urlHash":3009514575},"f6406f75-fe1d-4720-8388-1b5feaf4c7e6":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f6406f75-fe1d-4720-8388-1b5feaf4c7e6","title":"Secrets of RLHF in Large Language Models Part I: PPO | PDF","url":"https://arxiv.org/pdf/2307.04964.pdf","urlHash":3069931823},"f64ff1cf-b4f8-428a-8a20-4325a7ddae83":{"favIconUrl":"fallback","id":"f64ff1cf-b4f8-428a-8a20-4325a7ddae83","title":"Inner Monologue Embodied Reasoning through Planning with Language Models - OR-CoRL-2022_3R3Pz5i0tye","url":"https://arxiv.org/pdf/2207.05608.pdf","urlHash":275737571},"f658f451-657b-4bfc-8ce8-d1040e0d360d":{"favIconUrl":"fallback","id":"f658f451-657b-4bfc-8ce8-d1040e0d360d","title":"(126) Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI","url":"https://www.youtube.com/watch?v=L_Guz73e6fw","urlHash":862641963},"f6adbea3-8f5d-4209-927e-90f92a4bb9a9":{"favIconUrl":"fallback","id":"f6adbea3-8f5d-4209-927e-90f92a4bb9a9","title":"Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning | PDF","url":"https://arxiv.org/pdf/2402.07818.pdf","urlHash":2248506230},"f6c2fbfb-98aa-4109-b8ad-6861e4929ff4":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f6c2fbfb-98aa-4109-b8ad-6861e4929ff4","title":"Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training | PDF","url":"https://arxiv.org/pdf/2401.05566.pdf","urlHash":2960897309},"f6f4efc7-b501-47ed-bc8c-a41899ad9084":{"favIconUrl":"fallback","id":"f6f4efc7-b501-47ed-bc8c-a41899ad9084","title":"Measuring and Narrowing the Compositionality Gap in Language Models - Arxiv-2210.03350","url":"https://arxiv.org/pdf/2210.03350.pdf","urlHash":4190558825},"f72b7065-9e71-4737-8a82-437449d669ba":{"favIconUrl":"https://spaces.ac.cn/usr/themes/geekg/favicon.ico","id":"f72b7065-9e71-4737-8a82-437449d669ba","title":"概率分布的熵归一化（Entropy Normalization） - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/8829","urlHash":1177014712},"f73f5a44-81e2-47ed-a5b3-7a5bbbf1a681":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f73f5a44-81e2-47ed-a5b3-7a5bbbf1a681","title":"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small | PDF","url":"https://arxiv.org/pdf/2211.00593.pdf","urlHash":1619438396},"f743f225-a18e-4b1c-b957-7cfa09b6bd20":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"f743f225-a18e-4b1c-b957-7cfa09b6bd20","title":"Yu Su on X: \"Q* from OpenAI and tree-of-thought reasoning triggered a lot of enthusiasm on augmenting LLMs' reasoning/planning capabilities with search. But is search really the panacea for LLMs? Answer from our new study @osunlp: Not quite yet. TLDR: For advanced planning methods like tree… https://t.co/UeYaxONuOw\" / X","url":"https://twitter.com/ysu_nlp/status/1759757711061704913?utm_source=substack&utm_medium=email","urlHash":135144060},"f745c269-0932-4aa4-a5e4-807f4b37fd64":{"favIconUrl":"fallback","id":"f745c269-0932-4aa4-a5e4-807f4b37fd64","title":"facebookresearch/CutLER: Code release for \"Cut and Learn for Unsupervised Object Detection and Instance Segmentation\"","url":"https://github.com/facebookresearch/CutLER","urlHash":2086003364},"f7692d26-b829-4efe-848b-ae7a67a12c11":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"f7692d26-b829-4efe-848b-ae7a67a12c11","title":"stanford-futuredata/megablocks","url":"https://github.com/stanford-futuredata/megablocks","urlHash":4262898414},"f78e123a-2945-4d31-a1c9-5e5b2300543d":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f78e123a-2945-4d31-a1c9-5e5b2300543d","title":"The Impact of Positional Encoding on Length Generalization in Transformers | PDF","url":"https://arxiv.org/pdf/2305.19466.pdf","urlHash":216648084},"f7923bbd-aa27-41e9-ad7e-4d5ca803e375":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"f7923bbd-aa27-41e9-ad7e-4d5ca803e375","title":"Direct Fact Retrieval from Knowledge Graphs without Entity Linking | Abstract","url":"https://arxiv.org/abs/2305.12416","urlHash":2170043944},"f7b149dd-36cb-4bb4-abe6-1db51131af4c":{"favIconUrl":"fallback","id":"f7b149dd-36cb-4bb4-abe6-1db51131af4c","title":"Stable Diffusion最强版本SDXL 1.0，来了！「最强文生图开放模型」免费在线玩","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247557633&idx=2&sn=fd25afe271060324a6f5ee4934bca489&exportkey=n_ChQIAhIQjnP8wVhoy212l7J%2FZBltdxKWAgIE97dBBAEAAAAAAMl8IQiYnooAAAAOpnltbLcz9gKNyK89dVj0gb2Y%2FT%2B%2BjpKia6s03tVTxjzMebI%2BxEYCF6Eyau7feStvooCQCTc5d%2FM0pT%2FPGdCnHg%2BGvLCmWw9Vn6TUAjfnaejTahX09hIG5kGHXvSIf286dpjG%2BefMwaYKHH7r2qLZnj0BXnbhw9h5KAScwVy4lCWf%2BHJJ0oA6Yy2FadJvV9wfSpm%2FPtiZALEg4kVjkD0YsJOMftgKYWudCzc4Mn2z9I%2BI4yroBTI9RZB0%2BLYLVcxJGY2QaRamGS8ImAOA%2FjDkfj4xFDLc77KbOA2u16dcGR%2FQEZA0TXxjlKVmchhJkfxZr%2BCMNlC0QCzJzMmdDwMM&acctmode=0&pass_ticket=BuUkkONr2gaPXGD0SSYEJRgrxAYThWkhW43%2FQ16PavOznxxoKiwQO0hfEIa9pbs0&wx_header=0","urlHash":808867681},"f7b48769-dc08-4201-b579-87cb49c78b72":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"f7b48769-dc08-4201-b579-87cb49c78b72","title":"ACL‘22杰出论文：Prompt范式有bug！","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247529906&idx=1&sn=f30387b45d8e882adb4044dbd58d5859&exportkey=n_ChQIAhIQCudZbohJE3oYB8H5QNBjwxKWAgIE97dBBAEAAAAAAO72DJxUd6UAAAAOpnltbLcz9gKNyK89dVj0NTjKh7iKftDMbuAfhghIvd2g6L1sR2AOMvgzGKNp25KnhhCgvny6rdPaHRSVwJaL0e5oOaYSRN2e6zOlbbhen4cb2ktdJJ2%2F0FcDNTWFj4ii3swRBcHFOa%2BZ0Fnv2jr%2F5nKsl2axU1P6bwlFmKOx%2BCj7H4sOnM884Fz2%2BU9eFqWTZulbBaEHj2DR1vHfYDYiog%2BDS6JlczxLQk48pmuuM3tpmvEFYHKKtlXNBQkyFHaw1ImRKFOFI%2FrSiyFV31xNpjMFqAcIhbt8JA5iXfObUTe9FPc88eYiEB9zL7FSYi49YMeI%2Fkyf49wSMDz5MMmE&acctmode=0&pass_ticket=dk1%2BYeI9KcxVieaewIrrrbKjqtemDbE%2BLsWThaEB6q3t4hBtrl2cOqzk9ACigs94&wx_header=0","urlHash":594417112},"f7b747e6-1c18-45d5-8fa1-70f4cc8d7772":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f7b747e6-1c18-45d5-8fa1-70f4cc8d7772","title":"Faithful Chain-of-Thought Reasoning | PDF","url":"https://arxiv.org/pdf/2301.13379.pdf","urlHash":4034039357},"f824e2d0-9a33-4a83-86a3-e28ed3b2ce79":{"favIconUrl":"fallback","id":"f824e2d0-9a33-4a83-86a3-e28ed3b2ce79","title":"Structured Pruning Learns Compact and Accurate Models - Arxiv-2204.00408","url":"https://arxiv.org/pdf/2204.00408.pdf","urlHash":3929867355},"f8502f8f-761d-485a-aa4d-212c5bc723da":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f8502f8f-761d-485a-aa4d-212c5bc723da","title":"Red Teaming Language Models with Language Models | PDF","url":"https://arxiv.org/pdf/2202.03286.pdf","urlHash":2807156642},"f87b87e5-f518-4c00-9770-9f142a5d0e4c":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"f87b87e5-f518-4c00-9770-9f142a5d0e4c","title":"Lightweight reranking for language model generations | Abstract","url":"https://arxiv.org/abs/2307.06857","urlHash":2389397285},"f8822de3-b4d3-4289-9b8b-44285dde8f66":{"favIconUrl":"fallback","id":"f8822de3-b4d3-4289-9b8b-44285dde8f66","title":"(41 封私信 / 80 条消息) 张俊林 - 知乎","url":"https://www.zhihu.com/people/zhang-jun-lin-76/posts","urlHash":2474737214},"f89555e2-61fb-4051-be0e-944d2c355066":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f89555e2-61fb-4051-be0e-944d2c355066","title":"Diversity is All You Need: Learning Skills without a Reward Function | PDF","url":"https://arxiv.org/pdf/1802.06070.pdf","urlHash":815883537},"f8a6aabf-4c99-44fb-82ee-4c5c4e7d549d":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"f8a6aabf-4c99-44fb-82ee-4c5c4e7d549d","title":"Landmark Attention: Random-Access Infinite Context Length for Transformers | Abstract","url":"https://arxiv.org/abs/2305.16300","urlHash":1678881225},"f8a95621-b926-40b3-b616-bb1a521ecb30":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"f8a95621-b926-40b3-b616-bb1a521ecb30","title":"小模型生成结构数据能比大模型更好吗？","url":"https://mp.weixin.qq.com/s?__biz=MzkwMjUwNTg3OA==&mid=2247484849&idx=1&sn=d6282549ad4bf89fd4610246500b8d1e&exportkey=n_ChQIAhIQG5yD6MnNnA%2B7FWvXa1oZ1hKWAgIE97dBBAEAAAAAAAx0LCwod0MAAAAOpnltbLcz9gKNyK89dVj0MQtZF8W%2FXisuVxsJxu%2FP9WzLrO5LAq8mvzsjn8YTETN%2FWi4u97fVE5qjK%2BzYvJ1sC1qbvh%2BMTE1%2BjciqJNUZmD5%2BEfqcPIT1Er0du2XYkPhg2ky6cS5wMyLp6SepDurZoW17qms3itbaSxxaJtLBQ%2FSWRQbfKlviCQ%2BIBqh%2FQ2jq9sYmZndCeYzgrAyWy04V%2FVrbr4RB5va9yZAzeIdn52S4GGEbMhKwZjZhZSJ4wlLvloS2eaKtHeJ2Ai4QHhep05JfAmPjNNHsRlFqthzuSWcwbB633miCahZ%2BXJR0FaKVqbB1dOfdYvvcsSP3IHT6&acctmode=0&pass_ticket=MibgIcpdsOz0mTP2Y8H9n3wKMNnX5AMlbyAWQDifu4RWPNkYTc7xONlco62gf79p&wx_header=0","urlHash":1328633324},"f8ac1493-3e17-457c-8751-17b34332c8e1":{"favIconUrl":"fallback","id":"f8ac1493-3e17-457c-8751-17b34332c8e1","title":"THUDM/P-tuning-v2: An optimized deep prompt tuning strategy comparable to fine-tuning across scales and tasks","url":"https://github.com/THUDM/P-tuning-v2","urlHash":352963873},"f8bf7272-e94a-472e-b5f0-58269d2f8b15":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f8bf7272-e94a-472e-b5f0-58269d2f8b15","title":"Linguistic Knowledge and Transferability of Contextual Representations | PDF","url":"https://arxiv.org/pdf/1903.08855.pdf","urlHash":4151064722},"f8e269b0-9707-48b4-8c12-c239877bcd58":{"favIconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","id":"f8e269b0-9707-48b4-8c12-c239877bcd58","title":"Explaining the Transformer Circuits Framework by Example — LessWrong","url":"https://www.lesswrong.com/posts/CJsxd8ofLjGFxkmAP/explaining-the-transformer-circuits-framework-by-example","urlHash":1040300222},"f8ec3257-6092-48f2-87e7-46289cccacd1":{"favIconUrl":"fallback","id":"f8ec3257-6092-48f2-87e7-46289cccacd1","title":"Learning-from-data/Chapter 2 Training versus Testing.pdf at master · Doraemonzzz/Learning-from-data","url":"https://github.com/Doraemonzzz/Learning-from-data/blob/master/Chapter2/Chapter%202%20Training%20versus%20Testing.pdf","urlHash":2751703097},"f906d180-ddef-4dbb-8353-17ad5b0c96ab":{"favIconUrl":"fallback","id":"f906d180-ddef-4dbb-8353-17ad5b0c96ab","title":"index","url":"http://www.cs.toronto.edu/~duvenaud/courses/csc2541/index.html","urlHash":2764432700},"f91a2350-1a0e-400f-a917-0d6138297e53":{"favIconUrl":"fallback","id":"f91a2350-1a0e-400f-a917-0d6138297e53","title":"Zero-shot Image-to-Image Translation - Arxiv-2302.03027","url":"https://arxiv.org/pdf/2302.03027.pdf","urlHash":3842764214},"f930d7b6-5558-48b2-a29d-efe98884d2a0":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"f930d7b6-5558-48b2-a29d-efe98884d2a0","title":"An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion | PDF","url":"https://arxiv.org/pdf/2208.01618.pdf","urlHash":1649082029},"f953d662-6c3b-4172-a985-00c1918bd5fd":{"favIconUrl":"https://cdn.sstatic.net/Sites/dsp/Img/favicon.ico?v=a0f03f004bf6","id":"f953d662-6c3b-4172-a985-00c1918bd5fd","title":"matlab - How does resizing an image affect the intrinsic camera matrix? - Signal Processing Stack Exchange","url":"https://dsp.stackexchange.com/questions/6055/how-does-resizing-an-image-affect-the-intrinsic-camera-matrix","urlHash":1646338985},"f959954e-09c0-4456-990c-7cea21a75fbf":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"f959954e-09c0-4456-990c-7cea21a75fbf","title":"GPT-4V(ision) is a Generalist Web Agent, if Grounded | Abstract","url":"https://arxiv.org/abs/2401.01614?utm_source=substack&utm_medium=email","urlHash":1467502838},"f99ff99c-71d2-4abd-a947-d136c12dc213":{"favIconUrl":"fallback","id":"f99ff99c-71d2-4abd-a947-d136c12dc213","title":"Survey Text Based Image Synthesis - HackMD","url":"https://hackmd.io/@prajwalsingh/imagesynthesis#","urlHash":1359975083},"f9b51c9c-3976-4b82-85cb-157d918f19d5":{"favIconUrl":"fallback","id":"f9b51c9c-3976-4b82-85cb-157d918f19d5","title":"The CoT Collection Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning - Arxiv-2305.14045","url":"https://arxiv.org/abs/2305.14045","urlHash":1479850230},"f9c1a834-4ced-41f2-ab03-1730cef268ad":{"favIconUrl":"fallback","id":"f9c1a834-4ced-41f2-ab03-1730cef268ad","title":"Label-Smoothed Backdoor Attack","url":"https://arxiv.org/pdf/2202.11203.pdf","urlHash":4186122129},"f9c40d02-4f41-4998-8d75-e772466019ce":{"favIconUrl":"fallback","id":"f9c40d02-4f41-4998-8d75-e772466019ce","title":"MIT指出公开预训练模型不能乱用","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247531708&idx=1&sn=0dd6bd51624cf3aa21d6679e19ed1796&exportkey=n_ChQIAhIQ7XraOwDDZUo9JAdAQEhp%2FRKWAgIE97dBBAEAAAAAAF0WLQWcV2cAAAAOpnltbLcz9gKNyK89dVj092%2F1BY5VluWiHtdbuuQR1zyTqn9bjzPlu9XYuZGQYSuMlNBySPzus0G3vWcuhC6iRl%2Bz4zBUsmUifs5V4ZJAft6945Mj3APCAeBiOGdRn9aSBhocNIG6uoHaVyLN3zlG4e%2BeKMIYoZRPiAoCdd%2FPu6kiGKmz%2BLbVAihSWzGfyvIzlCjYfXkrzNHZqaA%2BEkkU%2Bp%2BFNggF4h%2B1L25znq0IJpXGVHtgtWEdFypgPdfoD8AxMmkz705jCa%2BIhzH9OEIv%2Bp4ZehS2NhP9bdxViLXonv2ig9sW6wnpI1sk79T5xroqRk7AyFWKsS6dEp%2FgXPKs&acctmode=0&pass_ticket=zUvJ6Bt8HsTNAPBA6U4qajGZ5sn0Pt6WEGVtKUG1A6McGlT1Awcq8l9VBLNEv8Kt&wx_header=0","urlHash":2522195777},"f9f7ede2-8b1c-4f39-94a9-a6ef2f447271":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"f9f7ede2-8b1c-4f39-94a9-a6ef2f447271","title":"Link-AGI/AutoAgents: Generate different roles for GPTs to form a collaborative entity for complex tasks.","url":"https://github.com/Link-AGI/AutoAgents","urlHash":1362852906},"fa0ab406-b3d9-484f-b803-04edcb4ce944":{"favIconUrl":"fallback","id":"fa0ab406-b3d9-484f-b803-04edcb4ce944","title":"2020年9月谷歌研究给出的综述“Efficient Transformers: A Survey” - 知乎","url":"https://zhuanlan.zhihu.com/p/316865623","urlHash":3948665111},"fa0f2473-7e8d-484b-8398-8f9a8116496d":{"favIconUrl":"fallback","id":"fa0f2473-7e8d-484b-8398-8f9a8116496d","title":"RLPrompt Optimizing Discrete Text Prompts with Reinforcement Learning - Arxiv-2205.12548","url":"https://arxiv.org/abs/2205.12548","urlHash":2779248007},"fa2cbf6d-000f-4e6d-be29-87e07cf66997":{"favIconUrl":"https://underline.io/favicon/favicon.ico","id":"fa2cbf6d-000f-4e6d-be29-87e07cf66997","title":"Underline | Generalizing Backpropagation for Gradient-Based Interpretability","url":"https://underline.io/events/395/sessions/15222/lecture/76222-generalizing-backpropagation-for-gradient-based-interpretability","urlHash":1494426619},"fa5b425b-1658-4511-bb0d-7facf0d68c20":{"favIconUrl":"fallback","id":"fa5b425b-1658-4511-bb0d-7facf0d68c20","title":"Scalable Differential Privacy with Certified Robustness in Adversarial Learning","url":"http://proceedings.mlr.press/v119/phan20a/phan20a.pdf","urlHash":4063795556},"fa73cdb1-8836-4740-98b9-3f85b83df258":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"fa73cdb1-8836-4740-98b9-3f85b83df258","title":"In-Context Unlearning: Language Models as Few Shot Unlearners | PDF","url":"https://arxiv.org/pdf/2310.07579.pdf","urlHash":565164423},"fab02f30-74aa-43d8-ab88-70bf2f9d51d5":{"favIconUrl":"fallback","id":"fab02f30-74aa-43d8-ab88-70bf2f9d51d5","title":"The CRINGE Loss: Learning what language not to model","url":"https://arxiv.org/abs/2211.05826","urlHash":1000026236},"fab5d6df-edcf-4136-8e26-7bad66b3095a":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"fab5d6df-edcf-4136-8e26-7bad66b3095a","title":"AGI-Edgerunners/LLM-Agents-Papers: A repo lists papers related to LLM based agent","url":"https://github.com/AGI-Edgerunners/LLM-Agents-Papers","urlHash":714897600},"facfe755-ba3f-41ae-a73b-397f17bef499":{"favIconUrl":"fallback","id":"facfe755-ba3f-41ae-a73b-397f17bef499","title":"Attention is not only a weight: Analyzing transformers with vector norms - Google Search","url":"https://www.google.com/search?q=Attention%20is%20not%20only%20a%20weight:%20Analyzing%20transformers%20with%20vector%20norms%0A","urlHash":2517045343},"fadff827-3449-46f2-b83c-75b85ad955fb":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"fadff827-3449-46f2-b83c-75b85ad955fb","title":"When can transformers reason with abstract symbols? | PDF","url":"https://arxiv.org/pdf/2310.09753.pdf","urlHash":1499111405},"fb0307ee-079d-454c-9dfc-165669678a0e":{"favIconUrl":"fallback","id":"fb0307ee-079d-454c-9dfc-165669678a0e","title":"What learning algorithm is in-context learning? Investigations with linear models","url":"https://arxiv.org/abs/2211.15661","urlHash":2288567854},"fb07fcff-4322-4b4c-90f4-c653e7990efc":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"fb07fcff-4322-4b4c-90f4-c653e7990efc","title":"Detecting Pretraining Data from Large Language Models | PDF","url":"https://arxiv.org/pdf/2310.16789.pdf","urlHash":164010873},"fb0af0e6-745b-43fd-9096-75e96afad332":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"fb0af0e6-745b-43fd-9096-75e96afad332","title":"Jason Wei on X: \"Nice paper by Tu Vu on factuality in LLMs: https://t.co/JNe4eU4pHy, enjoyed contributing in a minor role to it while I was at Google. The main takeaway for me is that most factuality benchmarks for LLMs don't really take into account the fact that many types of knowledge…\" / X","url":"https://twitter.com/_jasonwei/status/1710465395105411120","urlHash":3331835232},"fb1107e6-ef0a-4398-90f3-1448263549ac":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"fb1107e6-ef0a-4398-90f3-1448263549ac","title":"Aran Komatsuzaki on X: \"SelfEval: Leveraging the discriminative nature of generative models for evaluation Shows that text-to-image generative models can be ‘inverted’ to assess their own text-image understanding capabilities in a completely automated manner https://t.co/wA4GeUPCoN https://t.co/qrdyASSSHz\" / X","url":"https://twitter.com/arankomatsuzaki/status/1726417051370098997","urlHash":300067958},"fb372b96-5622-45e1-bbee-8c8020dd6fc3":{"favIconUrl":"fallback","id":"fb372b96-5622-45e1-bbee-8c8020dd6fc3","title":"Paper Notes by Vitaly Kurin","url":"https://mighty-melody-f4b.notion.site/Paper-Notes-by-Vitaly-Kurin-97827e14e5cd4183815cfe3a5ecf2f4c","urlHash":1915937915},"fb9854b8-0a26-4173-ade4-02fe7fb7c3fd":{"favIconUrl":"fallback","id":"fb9854b8-0a26-4173-ade4-02fe7fb7c3fd","title":"地久天长_王小波_在线阅读_九九藏书网","url":"https://www.99csw.com/book/1970/index.htm","urlHash":1715118557},"fba88ecd-f0ad-4e44-89af-751bba64b2c5":{"favIconUrl":"fallback","id":"fba88ecd-f0ad-4e44-89af-751bba64b2c5","title":"Can tracking anything track all objects in a class in a long video? · Issue #98 · gaomingqi/Track-Anything","url":"https://github.com/gaomingqi/Track-Anything/issues/98","urlHash":82893579},"fbb2b2d3-5933-4eb7-9519-3ff651fb8faf":{"favIconUrl":"https://jayfeather1024.github.io/Finetuning-Jailbreak-Defense/static/images/icon.png","id":"fbb2b2d3-5933-4eb7-9519-3ff651fb8faf","title":"BackdoorAlign: Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment","url":"https://jayfeather1024.github.io/Finetuning-Jailbreak-Defense/","urlHash":483372034},"fbbfdd7c-9d97-4937-bdcc-6b82f84dba6c":{"favIconUrl":"https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"fbbfdd7c-9d97-4937-bdcc-6b82f84dba6c","title":"Boolformer: Symbolic Regression of Logic Functions with Transformers | Abstract","url":"https://arxiv.org/abs/2309.12207?utm_source=substack&utm_medium=email","urlHash":1144485327},"fbcee4a8-6a0b-45c8-b412-f8a73f38aafc":{"favIconUrl":"fallback","id":"fbcee4a8-6a0b-45c8-b412-f8a73f38aafc","title":"r-barnes/MatrixForensics: Collection of Matrix/Linear Algebra Information","url":"https://github.com/r-barnes/MatrixForensics","urlHash":1215253519},"fbe0dcbe-656b-4a8f-ac22-50358dd1ef82":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"fbe0dcbe-656b-4a8f-ac22-50358dd1ef82","title":"langchain/cookbook/tree_of_thought.ipynb at master · langchain-ai/langchain","url":"https://github.com/langchain-ai/langchain/blob/master/cookbook/tree_of_thought.ipynb","urlHash":2655972516},"fc071d7e-60ad-40ae-af2a-f912ce77708c":{"favIconUrl":"fallback","id":"fc071d7e-60ad-40ae-af2a-f912ce77708c","title":"熵不变性Softmax的一个快速推导 - 科学空间|Scientific Spaces","url":"https://spaces.ac.cn/archives/9034","urlHash":580155861},"fc38f5e6-a4e8-484a-8991-a47c9052c3ab":{"favIconUrl":"fallback","id":"fc38f5e6-a4e8-484a-8991-a47c9052c3ab","title":"An Explanation of In-context Learning as Implicit Bayesian Inference - Arxiv-2111.02080","url":"https://arxiv.org/pdf/2111.02080.pdf","urlHash":2730900216},"fc59d3a2-0286-47d4-b0d4-1f81f674e3d7":{"favIconUrl":"fallback","id":"fc59d3a2-0286-47d4-b0d4-1f81f674e3d7","title":"Yann LeCun 新作！大幅超越 MAE，图像语义表示卷出新高度","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247542040&idx=1&sn=e44561c9ebfdd0e7d2a4610b934502f5&chksm=970f0dcea07884d8b71ede7e627926411c8c7485b537694aa5c4b215db700a4a3958bf935251&mpshare=1&scene=1&srcid=0412Y1dpyLK0CGjd1XGlTt4I&sharer_sharetime=1681301484252&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQ1wx0r7bFcgl20lQSO756shKWAgIE97dBBAEAAAAAACtJI%2FJ%2BK%2F0AAAAOpnltbLcz9gKNyK89dVj0v9YgZ1GqI0bBMvu%2FFFSUquoW0dxJCKWfEoLH2f2Hu9scI3dJWI8r4Q7iGFDnQ2j%2BUZog%2BcSeDvWFw6kmxcTrxLyfUDFNnnLeBu674J4OGfe%2BTE6CglFoLHja%2FbpTJpF%2B%2BK97Be%2BIWovMgcGYUhEZMxUGnPKCU1H15drKjYz5A9EWS9MLGWP%2F%2FLI5BdSyK43yc6jQgSSm84KX3krntxMr0zMcffN0InzrWLBStVNse1b2VoqGt78m4ZUsFgpiibCuBx07Su%2F99R92xwClN%2BjQx6zSrCIoP3Fzh3KecI4S9MkaWKn3bmiYGmsGW1nwz6Ll&acctmode=0&pass_ticket=DUWJdFUi1JDJOm6OXRe2ZUPZKRPw403wXxhVQ6QEDdvQjp2YotQQGaljjYLenRmeyNcbKwQUK1Xo3E6YxAxWYA%3D%3D&wx_header=0#rd","urlHash":1057859834},"fc662e90-ba09-4f40-9936-f677a7a448a8":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"fc662e90-ba09-4f40-9936-f677a7a448a8","title":"简化版Transformer来了，网友：年度论文","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650898500&idx=1&sn=0cca2c82b6fc8d81b4b62c2d92c7c9b3&exportkey=n_ChQIAhIQ5zXwW5HUcYwQS4UnndAmDRKWAgIE97dBBAEAAAAAAB9EBbFDTzUAAAAOpnltbLcz9gKNyK89dVj0Re7Ig3NlXMRXtIFSRveylJ%2B%2FsrQas%2FAHtIvg8%2FLPxBMs41GNKtLI1Irrfd62HRU0InSsJ4HOQgKBOMp2i%2FUOP3%2BGkIEy5j6cyV35%2FXbQoGe01yMZX1rKJVjn3dLszcK0CB2uAJeNSdQ%2BC8F8iTUkBMntVUGueWzTy6M8KSy5ayoC%2BEtCQboY%2BSSwgmNc9B5JNURawaEFAEE6Dj4L2qxIOtSvx07l8Gh8iL5euuAO7pu3431XSev%2B4v7OsnI%2BJXPDrbDZpgBydk2xD4YYZpl3jOQXNuAsy0HuD2G3dSkBwzopt3n30Sa37rBDtTLL%2F%2B7l&acctmode=0&pass_ticket=uIIc5zHl5NqUS%2FABTo0tvsFHdZG2jwQS7SSNNrFSlsal2mrM1CAPP3%2B8Dw6XHJmD2mAJ4jVSESmD%2FSVpS0b1uw%3D%3D&wx_header=0","urlHash":1388319075},"fc807498-7e25-4d80-a990-01f937b28283":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"fc807498-7e25-4d80-a990-01f937b28283","title":"twitter.com/Francis_YAO_/status/1668856941005914114","url":"https://twitter.com/Francis_YAO_/status/1668856941005914114","urlHash":1299324213},"fcd7ed61-0181-450a-8f63-be058e7ce8d8":{"favIconUrl":"fallback","id":"fcd7ed61-0181-450a-8f63-be058e7ce8d8","title":"Interpreting Neural Networks through the Polytope Lens — AI Alignment Forum","url":"https://www.alignmentforum.org/posts/eDicGjD9yte6FLSie/interpreting-neural-networks-through-the-polytope-lens","urlHash":1231903953},"fce97f28-1cff-4bb2-8c4b-7d8af0f6870c":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"fce97f28-1cff-4bb2-8c4b-7d8af0f6870c","title":"刷爆多模态任务榜单！贾佳亚团队Mini-Gemini登热榜，代码、模型、数据全部开源","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650914473&idx=1&sn=8dad00b827b995d6b20690c2c7adb1c1&chksm=84e47ad7b393f3c15f67efd3d267e41f9dc85a21f5a726b99b2d951910fe0637ddc896c96a25&mpshare=1&scene=1&srcid=04155Yjpd1qQIqDLFa8ilqxQ&sharer_shareinfo=8f7709fd9e8f7ed51d29abb409580909&sharer_shareinfo_first=8f7709fd9e8f7ed51d29abb409580909&exportkey=n_ChQIAhIQ1V7lZUL9tI1xz9WIJzloABKWAgIE97dBBAEAAAAAADTIGsMUcOIAAAAOpnltbLcz9gKNyK89dVj0Yj6VoMRKW5JNxF08A5%2FB%2BlW0KvSIP6rgSKyUoc7iNO7uQzcJ1wyTQPj478QykyUFH5sFIfcTzMakzPbJqRtdIQBsxGEFr4ZckrhkaaxSyPfcSI6lpA%2FsCx2D7MU%2B9zSMggvtIyFJwp7P4DofoKiTzZlcmbx9LfIZaTqCSOxISRCqfjvm5S%2BM%2BE9CianjotP4t%2FdSKdM0VCQ98Eud%2FkfhpcOEnTDS5Vi%2Fzpck64PP2AFPhezqDZRfQtL2iByityG11t79Enxjbh9DLsR%2Fslk2N1c%2BIJYPEfkHy8xLAYu%2F2HDTzLcT5g1pXj00USgnOinT&acctmode=0&pass_ticket=zqEgmthDdfrNOu4vs0csRSeG%2BRxHO0e7wN9QX6x3vCP4Va4gYvxsnWjoSWHaV2tVmYbxbiOZAswbAxQ%2FEZ0%2BFQ%3D%3D&wx_header=0#rd","urlHash":440211012},"fcefa065-9df1-49eb-b292-fa33ac65495d":{"favIconUrl":"fallback","id":"fcefa065-9df1-49eb-b292-fa33ac65495d","title":"A Theory on Adam Instability in Large-Scale Machine Learning | PDF","url":"https://arxiv.org/pdf/2304.09871.pdf","urlHash":4045303773},"fcf457f4-bf67-4a74-8e72-0a534642a86b":{"favIconUrl":"https://ssl.gstatic.com/colaboratory-static/common/27ed55654157d4fccaba00d81cbe557a/img/favicon.ico","id":"fcf457f4-bf67-4a74-8e72-0a534642a86b","title":"recognize_anything_demo.ipynb - Colaboratory","url":"https://colab.research.google.com/github/mhd-medfa/recognize-anything/blob/main/recognize_anything_demo.ipynb#scrollTo=plSIPdmK7-Pn","urlHash":3914274105},"fd029c22-382f-48ef-9798-57614a703a0b":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"fd029c22-382f-48ef-9798-57614a703a0b","title":"LLM是世界模型的新证据？ChatGPT能理解WiFi等物理信号，并猜出你的位置","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650907486&idx=4&sn=99332aa9d27ba36b0d4323c706aeb0d6&chksm=84e46720b393ee36e8c2f82a7972d2b15ad71111fe9e609864b053e877ae45393656f7683c77&mpshare=1&scene=1&srcid=0214HW36rZBYyOCXmhJMGS3k&sharer_shareinfo=3fcb7be4d531537b39e29a5c984dd961&sharer_shareinfo_first=3fcb7be4d531537b39e29a5c984dd961&exportkey=n_ChQIAhIQJA%2FV7QnL7C1IkYrLDait4BKWAgIE97dBBAEAAAAAAK3pOizepaEAAAAOpnltbLcz9gKNyK89dVj0BIVDQAYv1pZ%2BFfxfMqwDF7%2F9MBhAZ5phkl4sZovGGlcXdTNtYFWyJdKCy0mQ02B28LllBHx0kjydtKfR0ZoLYfhwA6NUzhlGDUJOybQYuXf4YpyVbRlJdKKR5iAHeDQ85DEaCbUMHlxqjcgxHCdQDfsGcN%2BBj4KlXS7Xh%2FJkkh9DxIqNOppASH6M1AvAukkEqzUl1%2F64o0RacyeWNTdoMzwyxgynjnpQV%2F8DGg9mDZ%2Fuzd37nC9frmSgwQ5RlTS9NHacG9UgwbpjiSUh5jo7K2U%2BONQ8W1kytzE8DoM%2Bh1t8MSmePCjyIXcJZMbk2mZl&acctmode=0&pass_ticket=UVp5c6eXbQE31r6cgbLQRqmyjWJV2y4XrwA0QRFP0HOvW10XSVmZeaUzTMipnA51OorgXuL9iQSYV9TmHfR46A%3D%3D&wx_header=0#rd","urlHash":3157413405},"fd1545e0-9209-416f-bdf8-283821e4b2c2":{"favIconUrl":"fallback","id":"fd1545e0-9209-416f-bdf8-283821e4b2c2","title":"大模型的最大bug，回答正确率几乎为零，GPT到Llama无一幸免","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650891067&idx=1&sn=cf3ad74ff6356e2dda519d32d3b9a940&exportkey=n_ChQIAhIQnFanqkgWoU%2Fu4%2BSRiUEZFBKWAgIE97dBBAEAAAAAAHKEOjzNAxcAAAAOpnltbLcz9gKNyK89dVj0FJUHCTWntam%2Fp4gJeuCSAkM6f%2BBvQWcJ5s21577KD6AC%2BmAI02C9VmUyGgkegWLQr0b1Up7ZBsDGCe%2FdEV4QUkxeTXJdI7yWSabGF%2BLZNv%2FM8dT53q6KrvS4FQsgWPDg%2F6N2C93TyEwuDYvsih5kM3VKH8lRSKWkiHUM3bQYRWZUTRWaP4yYegiGX56z3pfLedciW4gYl4rywHgch2yXLeoIaXjdWCpZz04WHqvrtyKv9qPMUvMZjq854L2gVMdfZ%2FIMhr1Jukh1pLskPB7aVguRoQ6343oYOuoSpd8luxViOYEY%2F0TX9iXh0g1XU2i%2B&acctmode=0&pass_ticket=S0w7HF8LaY0GuPM%2Fy%2FNi7Yn61KjA25VWp%2FbNhXYxVSoqttdSH9wQWf3jK5wmkI%2Bw&wx_header=0","urlHash":2148934932},"fd95cfae-3969-4cd0-b858-c61abc923a1d":{"favIconUrl":"https://img1.doubanio.com/favicon.ico","id":"fd95cfae-3969-4cd0-b858-c61abc923a1d","title":"人中吕布 (豆瓣)","url":"https://book.douban.com/subject/36170458/","urlHash":4048781848},"fdd22754-9a43-4e54-9578-0974be8bfd44":{"favIconUrl":"fallback","id":"fdd22754-9a43-4e54-9578-0974be8bfd44","title":"怎么评价保罗·奥斯特的作品？ - 知乎","url":"https://www.zhihu.com/question/19840838","urlHash":3049109720},"fe1d24dc-d0e3-456e-b0a3-481708543a63":{"favIconUrl":"https://arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png","id":"fe1d24dc-d0e3-456e-b0a3-481708543a63","title":"Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations | Abstract","url":"https://arxiv.org/abs/2310.06387","urlHash":3937801611},"fe3cc76e-9a6e-441c-9fbe-3acb0b106cd2":{"favIconUrl":"fallback","id":"fe3cc76e-9a6e-441c-9fbe-3acb0b106cd2","title":"CiT Curation in Training for Effective Vision-Language Data - Arxiv-2301.02241","url":"https://arxiv.org/abs/2301.02241","urlHash":1243881876},"fe4a391e-43f1-4289-b7d9-c827cf7dde8a":{"favIconUrl":"fallback","id":"fe4a391e-43f1-4289-b7d9-c827cf7dde8a","title":"A Kernel-Based View of Language Model Fine-Tuning - Arxiv-2210.05643","url":"https://arxiv.org/pdf/2210.05643.pdf","urlHash":1844344875},"fe53e37c-2581-478d-a81d-27c4766e0826":{"favIconUrl":"https://g.csdnimg.cn/static/logo/favicon32.ico","id":"fe53e37c-2581-478d-a81d-27c4766e0826","title":"详解带RLHF的类ChatGPT：从TRL、ChatLLaMA到ColossalChat、DSC_类chatgpt逐行代码解读(1/2):从零实现transformer、chatglm-6b-CSDN博客","url":"https://blog.csdn.net/v_JULY_v/article/details/129996493","urlHash":1530424574},"fe64ced5-e590-4c93-a9e1-6c36619ea871":{"favIconUrl":"https://arxiv.org/favicon.ico","id":"fe64ced5-e590-4c93-a9e1-6c36619ea871","title":"Ring Attention with Blockwise Transformers for Near-Infinite Context | PDF","url":"https://arxiv.org/pdf/2310.01889.pdf","urlHash":1086947719},"fe91a0ee-1168-4d04-b79f-c8d02915359b":{"favIconUrl":"https://abs.twimg.com/favicons/twitter.3.ico","id":"fe91a0ee-1168-4d04-b79f-c8d02915359b","title":"Zhengxuan Wu on X: \"📣How does 🔥Alpaca🦙 follow your instructions? Mechanistic interpretability at scale – our new paper identifies the causal mechanisms the Alpaca 7B model uses to solve simple reasoning tasks (with Atticus Geiger, @ChrisGPotts, and @noahdgoodman!) Paper: https://t.co/OrJCNQgNv1 https://t.co/f7QFSnF9pV\" / X","url":"https://twitter.com/ZhengxuanZenWu/status/1658526241040003072","urlHash":4090285812},"fe95b612-5735-448f-92e1-3cf747616cac":{"favIconUrl":"https://llava-vl.github.io/llava-interactive/images/llava_interactive_logo.png","id":"fe95b612-5735-448f-92e1-3cf747616cac","title":"LLaVA-Interactive","url":"https://llava-vl.github.io/llava-interactive/","urlHash":3626767106},"feba601a-dbac-4a31-a701-9ede211b01fa":{"favIconUrl":"fallback","id":"feba601a-dbac-4a31-a701-9ede211b01fa","title":"Giraffe Adventures in Expanding Context Lengths in LLMs - Arxiv-2308.10882","url":"https://arxiv.org/abs/2308.10882?utm_source=substack&utm_medium=email","urlHash":358004052},"ff08605e-4ccc-409d-9277-4b7d10e232be":{"favIconUrl":"fallback","id":"ff08605e-4ccc-409d-9277-4b7d10e232be","title":"kohpangwei/influence-release","url":"https://github.com/kohpangwei/influence-release","urlHash":1834992349},"ff1007fa-7ad9-49bf-aaa5-c584c08bfcaf":{"favIconUrl":"fallback","id":"ff1007fa-7ad9-49bf-aaa5-c584c08bfcaf","title":"Impact of Pretraining Term Frequencies on Few-Shot Reasoning - Arxiv-2202.07206","url":"https://arxiv.org/pdf/2202.07206.pdf","urlHash":54122432},"ff7cf611-c232-4667-8957-9e44cc0982ef":{"favIconUrl":"fallback","id":"ff7cf611-c232-4667-8957-9e44cc0982ef","title":"Lexicon Learning for Few-Shot Neural Sequence Modeling - Arxiv-2106.03993","url":"https://arxiv.org/abs/2106.03993","urlHash":871124526},"ff7ebdc3-da5f-4685-b6bd-a5108b6269ac":{"favIconUrl":"fallback","id":"ff7ebdc3-da5f-4685-b6bd-a5108b6269ac","title":"tscohen/GrouPy: Group Equivariant Convolutional Neural Networks","url":"https://github.com/tscohen/GrouPy","urlHash":2224677789},"ff88914e-12c1-4b4f-8af4-bc408e2463e9":{"favIconUrl":"fallback","id":"ff88914e-12c1-4b4f-8af4-bc408e2463e9","title":"[Re] Exacerbating Algorithmic Bias through Fairness Attacks - OR-ML_Reproducibility_Challenge-2022_rYLMJ6zX3RF","url":"https://openreview.net/forum?id=rYLMJ6zX3RF","urlHash":1511620759},"ffb90a50-770e-45b8-ba02-14ca10b89678":{"favIconUrl":"https://github.githubassets.com/favicons/favicon-dark.svg","id":"ffb90a50-770e-45b8-ba02-14ca10b89678","title":"deepset-ai/haystack: :mag: LLM orchestration framework to build customizable, production-ready LLM applications. Connect components (models, vector DBs, file converters) to pipelines or agents that can interact with your data. With advanced retrieval methods, it's best suited for building RAG, question answering, semantic search or conversational agent chatbots.","url":"https://github.com/deepset-ai/haystack","urlHash":3240378486},"ffd3fb69-8009-4af4-b959-a6bb4cf07d7e":{"favIconUrl":"https://res.wx.qq.com/a/wx_fed/assets/res/NTI4MWU5.ico","id":"ffd3fb69-8009-4af4-b959-a6bb4cf07d7e","title":"清北微软深挖GPT，把上下文学习整明白了！和微调基本一致，只是参数没变而已","url":"https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247542265&idx=3&sn=67a766b8c21501bb362e48ddbc82bb4e&exportkey=n_ChQIAhIQsEJDiJ2TEwgMneSnCsi%2B6BKWAgIE97dBBAEAAAAAAFiwNTpEWqUAAAAOpnltbLcz9gKNyK89dVj0CV3FLP0s6XYSwfn2WK43YknhMZipolyxh%2FwvnMjvq05MwrM1xQu7oA5ez7h8hIZ6lukRCOMwoHxDxE1T0OKEYkvLi60k3nlHWBTKuCTnbdytukW1XGFh%2BxDuZYUCPVB2oeyXZyQWarfoEinI8TrGs2tSn%2Fk%2F5W8ewNSkIAWJxslUTSVkawrBg9FB8q2dBweR5wrbKT867dNTplo4hQFx8fysBijiOB4XYT61KgWz8QIK2yYjH6zndgp%2Fs98HLVHm1KthZki%2FciVrxHnfbe%2B%2FKYwMyd37wBeM%2FhynJBRpO2PMoi1CenpHJy6mMNNeU00A&acctmode=0&pass_ticket=DUWJdFUi1JDJOm6OXRe2ZUPZKRPw403wXxhVQ6QEDdu3S6U4z2DiIx9VyD4xhwWwxnqpOHciKbvEuCN65nO6jQ%3D%3D&wx_header=0","urlHash":3116927034},"ffd85426-8bda-4c81-a6fa-d98dbf463966":{"favIconUrl":"fallback","id":"ffd85426-8bda-4c81-a6fa-d98dbf463966","title":"给张图就能反推Prompt，AI绘画神器Midjourney能够「看图说话」了","url":"https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650872869&idx=2&sn=1d508d6ca5745518b83866676e5d3edf&chksm=84e4d85bb393514d67b7be110b7daf5bbc3b37ec23d38e80377ff5205b6c422a01715c887200&mpshare=1&scene=1&srcid=04124NCLOp7DQplMLZOC2LGi&sharer_sharetime=1681301454573&sharer_shareid=5d63aa4dfc13f490ea99a15b75d4f593&exportkey=n_ChQIAhIQWEfvtSgS5FKObLAP9oiTYRKWAgIE97dBBAEAAAAAAJcnOp%2BxgAYAAAAOpnltbLcz9gKNyK89dVj0w17gkQ4ywJ1CGpsDRrqFj8hQ9GBxOj6uXXRz6EeUAF12cn2dGj681p7BZZvrd20stPEAhGDXYr00GGtzb%2FOB%2FWyHq9BuDVHxp0UH4ilOU7a8SsGDvTbqRjXZoZnkkkP9eCM0ldn8RPaDNeOki8DZ1Bx32In5G63ot3SzWOpLWgjo%2BQ%2BC9yVf%2Buk4x5QK%2FFK9uYJVZo09OJ3bAeOWXCWAMoQ4TVj1q7KmloNHy5ggDtAnee5UndviTtzfFrIQku1agqRbPMEIo1v0fVhEzeoF53utk0nDrLcNNxEo%2BVHEJlg%2B6tc9bYV48wu3e6fiYchK&acctmode=0&pass_ticket=DUWJdFUi1JDJOm6OXRe2ZUPZKRPw403wXxhVQ6QEDduZNA1sLdfcEsMzlMnu3OdgzmTR6Sl%2Ff1%2B0oozC%2F4%2B%2BAw%3D%3D&wx_header=0#rd","urlHash":426577793},"fffc1f95-0a4b-4759-bd2b-a433cd0e0e9a":{"favIconUrl":"fallback","id":"fffc1f95-0a4b-4759-bd2b-a433cd0e0e9a","title":"機器學習基石(Machine Learning Foundations) 机器学习基石 作业二 课后习题解答_Mac Jiang的博客-CSDN博客","url":"https://blog.csdn.net/a1015553840/article/details/51043019","urlHash":2547902428}}}